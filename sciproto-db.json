{
  "analyses": {
    "arxiv-2602.04883": {
      "hash": "arxiv-2602.04883",
      "filename": "2602.04883.pdf",
      "raw_text": "Protein Autoregressive Modeling via Multiscale Structure\nGeneration\nYanru Qu1,2,∗, Cheng-Yen Hsieh1,∗,†, Zaixiang Zheng1, Ge Liu2, Quanquan Gu1,‡\n1ByteDance Seed, 2University of Illinois Urbana-Champaign\n∗Equal Contributions, †Project Lead, ‡Corresponding Author\nAbstract\nWe present protein autoregressive modeling (PAR), the first multi-scale autoregressive framework for\nprotein backbone generation via coarse-to-fine next-scale prediction. Using the hierarchical nature\nof proteins, PAR generates structures that mimic sculpting a statue, forming a coarse topology and\nrefining structural details over scales. To achieve this, PAR consists of three key components: (i)\nmulti-scale downsampling operations that represent protein structures across multiple scales during\ntraining; (ii) an autoregressive transformer that encodes multi-scale information and produces\nconditional embeddings to guide structure generation; (iii) a flow-based backbone decoder that\ngenerates backbone atoms conditioned on these embeddings. Moreover, autoregressive models\nsuffer from exposure bias, caused by the training and the generation procedure mismatch, and\nsubstantially degrades structure generation quality. We effectively alleviate this issue by adopting\nnoisy context learning and scheduled sampling, enabling robust backbone generation. Notably,\nPAR exhibits strong zero-shot generalization, supporting flexible human-prompted conditional\ngeneration and motif scaffolding without requiring fine-tuning. On the unconditional generation\nbenchmark, PAR effectively learns protein distributions and produces backbones of high design\nquality, and exhibits favorable scaling behavior. Together, these properties establish PAR as a\npromising framework for protein structure generation.\nDate: February 5, 2026\nCorrespondence: Quanquan Gu quanquan.gu@bytedance.com\nProject Page: https://par-protein.github.io\nNote: Work was done during Yanru Qu’s internship at ByteDance Seed\n1 Introduction\nDeep generative modeling of proteins has emerged as a way to design and model novel structures with desired\nfunctions and properties, with broad applications in biomedicine and nanotechnology [ 21, 25 ]. A widely\nadopted approach is to directly model the distribution of three-dimensional protein structures, which govern\nprotein function. Typically, structure generative models produce protein backbones without sequences or side\nchains. Prior work in this area could be broadly categorized into methods that predict the SE(3) backbone\nframe representations [ 45 , 47] and those that directly model atoms, e.g., Cα coordinates for simplicity and\nscalability [ 14, 31]. However, all these works are based on diffusion models and their variations (e.g., flow\nmatching).\n1\narXiv:2602.04883v1 [cs.LG] 4 Feb 2026\n\n-- 1 of 23 --\n\nFigure 1 Overview of PAR. PAR comprises the autoregressive (AR) transformer Tθ and the flow-based backbone\ndecoder vθ . During training, we downsample a backbone x ∈ RL×3 into multi-scale representations {x1, . . . , x}.\nAR transformer performs next-scale prediction, producing conditional embeddings (z1, . . . , zn) from (bos, . . . , xn−1).\nThe shared flow-based decoder learns to denoise backbones xi at each scale conditioned on zi. At inference, PAR\nautoregressively generates xi until the final structure x is constructed.\nOn the other hand, autoregressive (AR) modeling has emerged as a powerful paradigm for large language\nmodels [ 1, 41]. AR models employ next-token prediction to model the probability of each token based on prior\nones, showing striking empirical behaviors such as scalability [ 24] and zero-shot generalization to unseen tasks\n[6].\nDespite its success in other domains, AR modeling has received little attention in backbone modeling. We\nidentify two main reasons. (i) Extending AR models to continuous data, e.g. atomic positions in 3D, often\nrelies on data discretization [12], which can reduce structural fidelity and fine-grained details for proteins,\nlimiting generative performance [ 19]. (ii) Protein residues exhibit strong bidirectional dependencies: residues\ndistant in sequence may be spatially close and form hydrogen bonds or hydrophobic contacts. This mutual\ndependency conflicts with the unidirectional assumption of standard AR models, and thus limits the quality\nof previous attempts on autoregressive structure generation [ 13]. A natural question therefore arises: can we\napply AR modeling to protein backbone design?\nIn this paper, we answer the above question affirmatively, and propose PAR, a Protein AutoRegressive\nframework, to unlock the power of AR models for protein backbone generation. We take initiative from the\nhierarchical nature of proteins: their structures span multiple scales of granularity, from coarse 3D topology\nand tertiary fold arrangements, local secondary structures, to the finest atomic coordinates. PAR thus adopts\na multi-scale autoregressive framework via next-scale prediction, predicting each scale conditioned on prior\ncoarser scales. This strategy, inspired by advances in image generation, enabled AR models to surpass strong\ndiffusion models in image synthesis for the first time [ 40 ], and further allows multimodal LLMs to achieve\nunified text and image generation framework [28].\nBuilding on this multi-scale framework, PAR includes three key components (Fig. 1). The multi-scale\ndownsampling creates coarse-to-fine structural representations to serve as structural context and targets\nduring training. AR transformer, a stack of non-equivariant attention layers [42 ], encodes all preceding\nscales to produce a scale-wise conditional embedding following Li et al. [30] . The flow-based backbone decoder\nis conditioned on this embedding to model Cα backbone atoms directly. As a result, PAR avoids both\ndiscretization of protein structures and residue-wise unidirectional autoregressive ordering, thereby overcoming\nthe two aforementioned limitations that compromise structural fidelity and generative quality. Moreover,\ntraining on ground-truth structural context, AR models suffer from exposure bias [ 3], which is a key challenge\nsubstantially reducing structure generation quality in our preliminary study. We effectively mitigate such\nissue via noisy context learning and scheduled sampling, allowing the model to learn from corrupted context.\nThis multi-scale approach introduces several notable model behaviors. PAR generates backbones by establishing\na global topology and performing refinements, analogous to progressively sculpting a statue into a masterpiece\n(Fig. 2). For unconditional generation, PAR exhibits favorable scaling behavior, yielding competitive results on\n2\n\n-- 2 of 23 --\n\nFigure 2 Samples generated by PAR over scales. We illustrate PAR’s generation process across five scales. Much\nlike sculpting a statue, the model first formulates the global structural layout at coarse scales and progressively refines\nthe details at later scales.\ndistributional metrics like Fréchet Protein Structure Distance (FPSD). Unlike diffusion models, which operate\nat a single scale, PAR flexibly handles inputs at various granularities, and hence shows zero-shot generalization\nin tasks like prompt-based generation and motif scaffolding. The multi-scale formulation enables PAR to\norchestrate sampling strategies, achieving a 2.5x sampling speedup compared to single-scale baselines. Finally,\nPAR provides a more general framework, incorporating flow-based models as a special case when restricted to\na single scale, and thus remains compatible with techniques from flow-based models like self-conditioning [9].\nMain contributions: (i) We present PAR, the first multi-scale AR model for protein backbone generation\nthat addresses key limitations of existing AR methods. (ii) PAR comprises multi-scale downsampling, AR\ntransformer, and a flow-based decoder, to directly model Cα atom, avoiding discretization loss. (iii) We\nalleviate exposure bias through noisy context learning and scheduled sampling, effectively improving structure\ngeneration. (iv) Our model shows an interpretable generation process that forms coarse backbone topology\nand refines it progressively. (v) Benchmarking results show that PAR effectively captures protein data\ndistributions, achieving FPSD score of 161.0 against PDB dataset that further scale with training compute.\n(vi) PAR exhibits efficient sampling and zero-shot generalization potential, reflecting the versatility of AR\nlarge language models.\n2 Background and Related Work\nFlow and diffusion-based structure generative models. Flow-based and diffusion methods [18, 34] operate by\ntransforming samples from a prior distribution to the target data distribution, and have been widely applied\nto protein backbone generation. These methods either predict per-residue rotations and translations using\na frame-based Riemannian manifold representation [ 5, 22, 45, 47, 48 ] or directly model atom coordinates,\nsuch as Cα positions [14, 31 , 32], with some approaches generating fully atomistic proteins including side\nchains [ 10, 37]. Discrete diffusion methods [15, 43], trained on structure tokens, often reduce structural fidelity\nand limit generation quality [ 19]. Unlike most diffusion approaches, which are single-scale, PAR models\nprotein structures across multiple scales using a parameterized upsampling autoregressive process from short\nto long, allowing flexible handling of different structural granularities and zero-shot generalization to tasks\nlike prompt-based generation. In addition, PAR provides a more general framework, as it naturally reduces to\na flow-based model when restricted to a single scale.\n3\n\n-- 3 of 23 --\n\nAutoregressive modeling. Autoregressive (AR) modeling has been driving natural language processing and\ncomputer vision due to its strong scalability and zero-shot generalization [1, 40, 41]. The approach relies on\nnext-token prediction that predicts the distribution of the next token based on prior ones in a unidirectional\nsequence. However, adapting autoregressive models to continuous domains, like image generation, often\ninvolves tokenizers such as VQVAE [12 ], which discretizes the data for transformer training and may discard\nfine-grained details. Recently, Li et al. [30] used the AR model that produces conditioning for a diffusion\nnetwork (e.g., a small MLP) to model image latents, unlocking the operations of AR models in a continuous-\nvalued space. In addition, defining appropriate autoregressive orders that preserve data properties is crucial.\nSince next-token prediction inherently discards spatial locality by flattening the 2D image feature map into a\n1D sequence, VAR [40] introduced next-scale prediction. Leveraging a multi-scale VQVAE, the image feature\nmap is quantized into n multi-scale token maps that preserve the spatial and bidirectional correlations. To\nour knowledge, autoregressive modeling has not been widely applied to protein structure generation despite\ntheir success in other domains. The only exception is Gaujac et al. [13], which models structure tokens with\na causal transformer. In contrast, we design a multi-scale autoregressive framework that operates directly\nin continuous backbone space using a flow-based backbone decoder, thereby addressing the limitations of\ndiscrete token maps while respecting the bidirectional biophysical relations of protein structures.\n3 Protein Autoregressive Modeling\nIn this section, we introduce PAR, a multi-scale autoregressive (AR) framework for protein backbone generation.\nFormally, we want to model a protein backbone Cα structure with L residues x ∈ RL×3 in an autoregressive\nmanner as follows: pθ (x) = EX∼qdecompose(·|x)\n\u0002pθ (X = {x1, . . . , xn})\u0003\n= EX∼qdecompose(·|x)\nn\tY\ni=1\npθ (xi | X<i). (1)\nwhere qdecompose(·|x) defines a decomposition of autoregressive order for protein structure x into n scales\nX = {x1, . . . , xn} with xn = x, while pθ (xi | X<i) is the desired PAR model learning to generate x via a\nscale-wise autoregression.\nThe design space of qdecompose and pθ under this formulation (Eqn. 1) can be flexible. Recall that our goal is\nto enable AR modeling to preserve spatial dependencies and avoid discretization, as discussed in §1. To this\nend, in §3.1, we devise a non-parametric and deterministic qdecompose by multi-scale protein downsampling\n(Fig. 1) that represents protein backbones at multiple scales via hierarchical down-sampling (Eqn. 2), providing\nstructural context and training targets. In §3.2, we parameterize PAR pθ as a backbone autoregressive\nupsampling process via next-scale prediction and achieve direct Cα modeling in the continuous space (Eqn. 3).\nThis comprises two key components: (i) an autoregressive transformer (Fig. 1) that produces scale-wise\nconditional embeddings informed by preceding scales to guide generation (Eqn. 4); and (ii) a flow-based\nbackbone decoder (Fig. 1) which samples Cα backbone coordinates conditioned on the learned embeddings\n(Eqn. 5).\nFinally, in §3.3, we dedicated strategies to mitigate exposure bias [ 3], a mismatch between training on ground-\ntruth data and inference on model predictions that leads to error accumulations and degrading generation\nquality in AR models. Together, these components enable PAR to robustly generate protein backbones in a\ncoarse-to-fine manner.\n3.1 Multi-scale Protein Downsampling\nWe construct the multi-scale representations of protein structures via hierarchical downsampling to serve as\ntraining context and targets for PAR (Fig. 1). Given a protein structure x ∈ RL×3, it produces a hierarchy of\ncoarse-to-fine scales by progressively downsampling x into n scales:\nqdecompose : x 7 → X = {x1, x2, . . . , xn}\n= {Down(x, size(1)), Down(x, size(2)), . . . , x}. (2)\n4\n\n-- 4 of 23 --\n\nwhere Down(x, size(i)) ∈ Rsize(i)×3 denotes a downsampling operation that interpolates x along the sequence\ndimension, leading to size(i) 3D centroids that provide a coarse structural layout. Since qdecompose is designed\nas a deterministic mapping for every x, the likelihood of Eqn. 1 can be simplified without marginalization:\npθ (x) = Qn\ni=1 pθ (xi | X<i). We show that this downsampling strategy properly preserves pairwise spatial\nrelationships in §C.8.\nScale configurations. S = {size(1), . . . , size(n)} could be defined in two ways. When defined by length,\nscales are chosen as hyperparameters, e.g., S = {64, 128, 256}. In this case, if L lies in (size(i), size(i + 1)],\nthe protein could be generated with only i+1 autoregressive steps. When defined by ratio, scales are adaptively\ndetermined based on protein length, e.g., S = {L/4, L/2, L}. Empirically, defining scales by length yields\nslightly better results in modeling data distributions. We adopt this as the default configuration. This\ndesign enables training PAR with flexible scale configurations. In the following sections, we describe how this\nhierarchy of representations are modeled using the autoregressive transformer and backbone decoder.\n3.2 Coarse-to-Fine Backbone Autoregressive Modeling\nPreserving the inherent dependencies in data when defining the autoregressive order is crucial and affects\ngeneration performance [ 40]. Standard AR models assume unidirectional dependency, which conflicts with\nthe strong bidirectional interactions in protein sequences, e.g., spatially close residues can form hydrophobic\ncontacts or hydrogen bonds even if distant in sequence. PAR addresses this with a multi-scale AR framework\nvia next-scale prediction, capturing mutual structural dependency over each scale. Motivated by Li et al. [30] ,\nwe propose to use an AR Transformer with diffusion/flow-based regression loss to enable modeling of Cα\natoms directly in continuous space. That is, we could rewrite the likelihood as:\npθ (X = {x1, . . . , xn}) =\nn\tY\ni=1\npθ (xi|X<i)\n=\nn\tY\ni=1\npθ (xi | zi = Tθ (X<i)),\n(3)\nwhere Tθ is an AR Transformer that produces scale-wise conditioning zi while pθ (xi|zi) is optimized with a\nflow-based atomic decoder vθ with flow matching. This avoids discretizing protein structures into tokens,\npreserving structural details and generation fidelity. We describe each component below.\nAutoregressive transformer for scale-wise conditioning. To formulate the autoregressive order, we leverage\nthe hierarchical nature of proteins, where a protein structure could span various levels of representations from\ncoarse tertiary topology to the finest atomic coordinates. We adopt the next-scale prediction to model per-scale\ndistribution based on prior coarser scales, which further ensures that the bidirectional dependencies of residues\nare modeled over each scale. We train our autoregressive model (Fig. 1), a non-equivariant transformer Tθ , to\nproduce scale-wise conditioning embedding zi for scale i depending on prior scales X<i = {x1, . . . , xi−1}:\nzi = Tθ (X<i) = Tθ\n\u0010\u0002bos, Up(x1, size(2)), . . . , Up(xi−1, size(i))\u0003\u0011\n. (4)\nwhere bos ∈ Rsize(1)×3 is a learnable embedding, and Up(xi−1, size(i)) interpolates xi−1 to size(i) 3D\npoints. All inputs are concatenated along the sequence dimension before being fed into Tθ . The embedding zi\nis then used to condition the flow matching decoder to predict the backbone coordinates xi, detailed below.\nFlow-based atomic decoder. We enable PAR to directly model Cα positions x, wherein pθ (x|zi) is param-\neterized by an atomic decoder vθ with flow matching [FM, 34], which maps standard normal distribution\nto the target data distribution. We condition the vθ with scale-wise conditioning zi predicted by the AR\nTransformer Tθ at each scale i (Fig. 1). During training, we sample the noise ϵi ∼ N (0, I) and a time variable\nti ∈ [0, 1], and compute the interpolated sample as xi\nti = ti · xi + (1 − ti) · ϵi. As such, we can jointly train vθ\nand Tθ with an FM objective:\nL(θ) = Ex∼pD\n\u0014 1\nn\nn\tX\ni=1\n1\nsize(i) Eti∼p(ti),ϵi∼N (0,I) vθ (xi\nti , ti, zi) − (xi − ϵi) 2\n\u0015\n. (5)\n5\n\n-- 5 of 23 --\n\nwhere pD (x) denotes the training data distribution and p(t) denotes the t-sampling distribution in Geffner\net al. [14] . The conditioning embedding zi is injected into the atomic decoder network vθ through adaptive\nlayer norms [36]. We further concatenate a learnable scale embedding alongside zi to help the model identify\ndifferent scales and incorporate self-conditioning input as an additional condition [ 9], though we omit them in\nthe equation for simplicity. To formulate the indices for positional encoding pi at scale i, we uniformly sample\nsize(i) numbers from the interval [1, L], i.e., pi = linspace(1, L, size(i)). At coarse scales, the wide spacing\nbetween adjacent indices encourages the model to capture global structural layout, while at finer scales the\ndense indices allow the model to focus on local details. For more details, please refer to §A.1.\nLeveraging the learned flow network vθ , sampling could be performed at each scale through ordinary differential\nequation (ODE) dxt = vθ (xt, t) dt, with the scale superscript i and condition z omitted for simplicity. Moreover,\nwe could define the stochastic differential equation (SDE) for sampling:\ndxt = vθ (xt, t) dt + g(t) sθ (xt, t) dt + p2g(t)γ dWt, (6)\nwhere g(t) is a time-dependent scaling function for the score function sθ (xt, t) [2, 35] and the noise term, γ is\na noise scaling parameter, and Wt is a standard Wiener process. The score function, defined as the gradient\nof the log-probability of the noisy data distribution at time t, could be computed as sθ (xt, t) = t vθ (xt,t)−xt\n1−t .\nMulti-scale structure generation. At inference, the autoregressive transformer first produces z1 at the coarsest\nscale, which conditions the flow matching decoder to generate x1 either via ODE or SDE sampling in Eqn. 6.\nWe upsample x1 using Up(x1, size(2)) and send it back into the autoregressive transformer to predict the\nnext scale embedding z2. This coarse-to-fine process iterates n times until the flow-matching model generates\nthe full-resolution backbone x. KV cache is applied throughout the autoregressive process for efficiency.\n3.3 Mitigating Exposure Bias\nTraining AR models typically uses teacher forcing [46], where ground-truth data are fed as context to stabilize\nlearning. However, during inference the model is conditioned on its own predictions, creating a training-\ninference mismatch known as exposure bias [ 3, 16]. Errors can then accumulate across autoregressive steps,\ndegrading output quality. Our preliminary study shows that teacher forcing greatly reduces the designability\nof generated structures. To mitigate this, we adapt Noisy Context Learning (NCL) and Scheduled Sampling\n(SS), techniques from language and image AR modeling [4, 38], for PAR.\nNoisy context learning. We train PAR with noisy context, adding noise to the ground-truth prior-scale input\nduring training. This encourages the model to learn the per-scale distribution without relying on perfectly\naccurate context, improving robustness. We randomly sample n noise weights {w1\nncl, · · · , wn\nncl} ∈ [0, 1], and\ndraw n noise samples {ϵ1\nncl, · · · , ϵn\nncl} ∈ N (0, I). Each input context xi is corrupted as xi\nncl = wi\nncl · xi +\n(1 − wi\nncl) · ϵi\nncl. This perturbation is applied to the input context only during training, which updates the\nautoregressive step in Eqn. 4 as zi = Tθ\n\u0010\u0002bos, Up(x1\nncl, size(2)), . . . , Up(xi−1\nncl , size(i))\u0003\u0011\n.\nScheduled sampling. During training, we use scheduled sampling [ 4] by running the forward process\niteratively across scales. At the i-th scale, the flow-based backbone decoder predicts the clean data xi\npred =\nxi\nt + (1 − ti)vθ (xi\nt, ti, zi). With a probability of 0.5, we replace the ground truth context xi with this prediction\nxi\npred at later scales. This exposes the model to its own output and reduces the train-test gap. Notably, we\ncould combine noisy context learning with this technique by adding noises to the model predicted context\nxi\npred.\n4 Experiments\nWe begin by evaluating PAR on unconditional backbone generation and compare it with existing structure\ngenerative methods in §4.1. Next, we examine its zero-shot generalization ability in §4.2. We then study the\nscaling behavior, efficient sampling, and propose strategies to mitigate exposure bias, along with additional\nablations in §4.3. We include additional empirical analysis in §C.\n6\n\n-- 6 of 23 --\n\nTable 1 Unconditional backbone generation performance. We follow Geffner et al. [14] in adopting FPSD and fS\nto evaluate the model’s ability to capture the data distribution. PARpdb denotes the 400M model finetuned on the\nPDB subset.\nMethod \tDesignability FPSD vs. fS Diversity Sec. Struct. %\n(%)↑ sc-RMSD↓ PDB↓ AFDB↓ (C / A / T)↑ TM-Sc.↓ (α/β)\nFrameDiff (17M) 65.4 - 194.2 258.1 2.46/5.78/23.35 0.40 64.9/11.2\nRFDiffusion (60M) 94.4 - 253.7 252.4 2.25/5.06/19.83 0.42 64.3/17.2\nESM3 (1.4B) 22.0 - 933.9 855.4 3.19/6.71/17.73 0.42 64.5/8.5\nGenie2 (16M) 95.2 - 350.0 313.8 1.55/3.66/11.65 0.38 72.7/4.8\nProteina (200M) 92.8 1.14 282.3 285.6 2.17/6.22/21.48 0.37 66.3/9.2\nProteina (400M) 92.6 1.09 271.3 272.6 2.13/6.14/21.18 0.37 65.1/9.5\nPAR (200M) 87.0 1.33 252.0 237.9 2.11/6.41/19.22 0.37 64.3/8.8\nPAR (400M) 96.0 1.01 313.9 296.4 2.24/6.60/16.71 0.39 66.3/8.9\nγ=0.45 88.0 1.28 231.5 211.8 2.20/6.59/20.96 0.36 63.2/9.7\nPARpdb \t96.6 1.04 161.0 228.4 2.57/7.42/23.61 0.43 50.2/16.7\nγ=0.45 88.8 1.34 176.6 256.4 2.62/7.52/30.99 0.40 50.2/16.2\n4.1 Protein Backbone Generation\nGeneration over scales. We illustrate PAR’s backbone generation using a 5-scale model in Fig. 2 (i.e.,\nS = {L/16, L/8, L/4, L/2, L}), showing generated structures with target lengths of {50, 100, 200, 250} residues.\nGeneration proceeds in a coarse-to-fine manner, which resonates with statue sculpting: the coarser scales\nestablish a rough global layout, and finer scales progressively add local details. This multi-scale formulation\nyields a clear and interpretable generation process. We present the quantitative analysis on PAR’s backbone\ngeneration in the next paragraph.\nUnconditional generation benchmark. We compare 3-scale PAR’s (S = {64, 128, 256}) backbone generation\nperformance with other baselines in Tab. 1, following the evaluation protocol in Geffner et al. [14]. The\nbaselines span three categories: frame-based diffusion methods [ 45 , 48], multimodal protein language models\n[ 15], and diffusion/flow-based Cα generators [ 14, 32 ]. We disable the optional pair representations and triangle-\nbased modules [23] in both PAR and Proteina to align architectural capacity and improve computational\nefficiency. We train PAR using a two-stage procedure following Geffner et al. [14]: the model is first trained\nfor 200K steps on the AFDB representative dataset and subsequently fine-tuned for 5K steps on a PDB subset\nof 21K designable samples. Results for the remaining baselines are taken directly from Geffner et al. [14] .\nEvaluation metrics and baseline categories are detailed in §A.2§A.3. To better reflect the goal of unconditional\nprotein generation as modeling the full data distribution, we adopt FPSD, which jointly measures quality\nand diversity by comparing generated and reference distributions, analogous to FID in image generation\n[ 17]. As shown in Tab. 1, PAR generates samples that closely match the reference data distribution and\nmaintains competitive designability. On FPSD, PAR achieves scores of 211.8 against AFDB and 231.5 against\nPDB. By reducing the noise scaling parameter γ (Equation 6) from 0.45 to 0.3 in SDE sampling, we can\nreduce sampling stochasticity and further improve sample quality, improving the designability from 88.0% to\n96.00%. After fine-tuning, PAR achieved 96.6% designability and 161.0 FPSD against the PDB, highlighting\nits superior distributional fidelity compared to pure diffusion-based baselines. We provide additional analysis\non longer proteins in §C.3.\n4.2 Zero-Shot Task Generalization\nGuiding backbone generation with human-specified prompt. Proteins possess hierarchical and complex\nstructures, which makes it challenging to directly specify a target shape and design proteins accordingly. By\nleveraging PAR’s coarse-to-fine generation, a simple prompt (e.g., 16 points) can specify a protein’s coarse\nlayout, from which the model generates the complete structure as shown in Fig. 3. In particular, we first\nobtain a 16-point input prompt either by downsampling a real protein structure from the test set, or by\nspecifying the points manually (the top row in Fig. 3). Using a 5-scale PAR (S = {16, 32, 64, 128, 256}), we\ninitialize the first-scale prediction with the 16-point prompt and autoregressively upsample until the full\n7\n\n-- 7 of 23 --\n\nPrompt\n(16 points)\nGenerated\nstructure\nmainly alpha mainly beta mainly alpha \tbeta barrel \tmixed \tshape A\tshape P \tshape R\nFigure 3 Backbone generation with human prompt. Given a small number of points (e.g., 16) as prompt, PAR can\ngenerate protein backbones that adhere to the global arrangements specified by these points, without any finetuning.\nFor visualization, input points are interpolated to match the length of the generated structure.\nFigure 4 Zero-shot motif scaffolding. Given a motif structure, PAR can generate diverse, plausible scaffold\nstructures that accurately preserve the motif via teacher-forcing the motif coordinates at each scale, without additional\nconditioning or fine-tuning.\nprotein structure is generated, as illustrated in the bottom row of Fig. 3. Following this process, PAR can\ngenerate a new structure that preserves the coarse structural layout (first five examples), and explore entirely\nnovel structures (last three examples). If desired, longer prompts (e.g., 32 points) could be specified to achieve\nmore finer-grained control over backbone generation. As later shown in Tab. 5, we quantitatively evaluate the\nstructural consistency (TM-score) between the prompted layout and the final generation.\nMotif scaffolding. Besides the point-based layout, PAR can preserve finer-grained prompts like atomic\ncoordinates. Fig. 4 highlights the zero-shot motif scaffolding capabilities of PAR. Using a 5-scale PAR, we\ndownsample a raw protein structure into five scales and teacher-force the ground-truth motif coordinates at\neach scale before propagating into the next scale. To avoid clashes or discontinuities, we superimpose the\nground-truth motif residues and the generated motif segments before replacement. With no fine-tuning and\nno conditioning, PAR generates plausible scaffolds that preserve motif structures with high fidelity. This\nstands in contrast to diffusion or flow-based frameworks, which typically require fine-tuning on additional\nconditions such as masks or motif coordinates, or rely on decomposition strategies [14, 44, 45]. Moreover, the\ngenerated scaffolds differ substantially from the input structure, showing that PAR generates structurally\ndiverse scaffolds rather than merely copying. For example, the leftmost example in Fig. 4 preserves the yellow\nmotif helix while introducing new secondary structure elements like β-sheet and loops, in contrast to the\noriginal helices. We further benchmark zero-shot motif scaffolding in Tab. 10 in the appendix, following\nevaluation protocols in [14, 32].\n8\n\n-- 8 of 23 --\n\nFigure 5 Scaling effects of PAR. Performance of four metrics over varying training steps and model sizes, (a) FPSD\nvs. PDB, (b) FPSD vs. AFDB, (c) fS(T), (d) sc-RMSD.\nTable 2 Sampling efficiency. Combining SDE and ODE sampling across scales yields a 2.5× inference speedup\ncompared to the single-scale 400-step baseline, shown in the first and the last row. We generate 100 samples at each\nlength.\nSampling Steps Length 150 Length 200\nTime (s) Design. (%) Time (s) Design. (%)\nProteina (SDE) 0/0/400 131 97% 170 92%\n0/0/200 67 89% 86 80%\nAll SDE 400/400/400 312 97% 351 94%\n400/400/2 184 0% - -\nAll ODE 400/400/400 312 28% - -\nS/S/O 400/400/400 312 98% - -\n400/400/2 184 99% 186 91%\nS/O/O 400/400/400 312 96% - -\n400/2/2 67 97% 68 94%\n4.3 Empirical Analysis of Multiscale PAR\nScaling effects of PAR. We examine the model’s behaviors by varying the backbone decoder’s size and\nnumber of training steps in Fig. 5. We train PAR with 3 scales over three different model sizes with 60,200,400\nmillion parameters and three training durations over 200, 400, 600K steps. PAR demonstrates favorable\nbehavior when scaling both model size and training duration, effectively improving its ability to capture the\nprotein data distribution with FPSD scores of 187 against PDB and 170 against AFDB (first two columns in\nFig. 5). Further, the fS scores, which reflect quality and diversity, increase with larger model sizes and greater\ncomputational budgets. While extending training duration alone offers negligible gains, increasing model size\nsubstantially enhances designability, leading to lower sc-RMSD values. Meanwhile, we empirically observe\nthat scaling the autoregressive transformer has minimal impacts on the evaluation results. This allows us to\nreduce computational costs and prioritize increasing the backbone decoder’s model capacity that effectively\nimproves generation quality. We provide more discussion on varying model sizes in §C.7.\nEfficient sampling with multi-scale orchestration of SDE/ODE. While Tab. 1 reports results using a uniform\nnumber of sampling steps across scales, the multi-scale formulation of PAR actually offers advantages in\nsampling efficiency, as shown in Tab. 2. More specifically, (1) sampling at the coarser scale (e.g., first scale) is\nmore efficient than sampling at finer scales (e.g., 2nd scale) due to shorter sequence length; (2) we can use less\nnumber of sampling steps at finer scales than coarser scales. As shown in Tab. 2, by using SDE sampling only\nat the first scale, and switching to ODE sampling for the remaining scales, PAR could dramatically reduce\nthe diffusion steps from 400 to 2 steps at the last two scales without harming designability (97%), yielding\na 4.7x inference speedup. This is possible because a high-quality coarse topology places the model near\nhigh-density regions, enabling efficient refinement with ODE sampling. Naively reducing the SDE sampling\n9\n\n-- 9 of 23 --\n\nsteps significantly harms designability, dropping to 22% when reducing steps to 50, as shown in Fig. 7. This is\nconsistent with the observation of single-scale models like Proteina, where designability degrades to 89% when\nreducing SDE sampling steps to 200 in Tab. 2. Crucially, SDE sampling at the first scale is necessary for\nestablishing a reliable global topology, given that ODE-only sampling exhibits poor designability. Compared\nto the single-scale 400-step baseline, PAR achieves 1.96x and 2.5x sampling speedup at length 150 and 200,\nrespectively. This improvement is driven by speeding up the final scales, where the longer sequence lengths\ncause computational costs to grow quadratically in transformer architectures. Moreover, the computational\ncosts remain constant at the first scale because it has a fixed size 64, even when generating longer sequences.\nTable 3 Mitigating exposure bias for PAR. We adopted various training strategies to mitigate the exposure bias for\nmulti-scale autoregressive modeling. These techniques are consistently effective effective in improving structure quality.\nNCL: Noisy Context Learning. SS: Schedule Sampling. Results are obtained with 60M PAR trained for 100K steps.\nMethod sc-RMSD ↓ FPSD vs. (PDB/AFDB) ↓ fS-(C/A/T) ↑\nTeacher Forcing 2.20 99.66 / 37.64 2.53 / 5.56 / 29.67\n+ NCL 1.58 89.70 / 23.69 2.54 / 5.85 / 28.37\n+ NCL & SS 1.48 90.66 / 24.59 2.54 / 5.84 / 28.77\nMitigating exposure bias. To mitigate exposure bias, we adopted noisy context learning (NCL) and scheduled\nsampling (SS) as defined in §3.3. Noisy context learning encourages the model to infer structural guidance\nfrom corrupted context and boosts the structure generation quality. Tab. 3 shows that noisy context learning\neffectively improves the sc-RMSD of the generated structure from 2.20 to 1.58, and reduces FPSD against\nAFDB to 23.69 when using ODE sampling. The designability further improved to 1.48 along with scheduled\nsampling, which makes the training process more aligned with the inference scenario. Results are obtained\nwith 60M PAR trained for 100K steps.\n1 \t2 \t3 \t4 \t5\n1\n2\n3\n4\n5\nLayer 0\n1 \t2 \t3 \t4 \t5\n1\n2\n3\n4\n5\nLayer 5\n1 \t2 \t3 \t4 \t5\n1\n2\n3\n4\n5\nLayer 11\n0.2\n0.4\n0.6\n0.8\n1.0\nFigure 6 Visualization of the average attention scores in PAR autoregressive transformer over 5 scales.\nObtained from samples with lengths in (128, 256]. We provide attention map visualization for shorter proteins in §C.9\nInterpreting multi-scale PAR. We visualize the attention maps of the autoregressive transformer at each scale\n(Fig. 6). We average the attention scores within each scale, normalize them such that the scores across\nscales sum to 1, and average them over 50 test samples to obtain the scale-level attention distribution during\ninference. We summarize three key observations: (i) Most scales barely attend to the first scale, since the\ninput to this scale, a bos token, carries little structural signal. (ii) Each scale primarily attends to the previous\nscale, which typically contains richer contextual and structural information. (iii) Despite focusing most heavily\non the current scale, the model still retains non-negligible attention to earlier scales. This indicates that PAR\neffectively integrates information across multiple scales and maintains structural consistency during generation.\nThis aligns with results in Tab. 5 where the autoregressive Transformer effectively improves consistency with\nthe given prompt. We also observe similar patterns on shorter proteins, as shown by the attention maps in\nFig. 10 in the appendix.\nMulti-scale formulation. We ablate the effect of defining scale by length versus ratio, as shown in §3.1. Tab. 4\nshows that under comparable levels of upsampling ratio ({64, 128, 256} and {L/4, L/2, L}), the by-length\nstrategy outperforms by-ratio. Meanwhile, PAR obtains better designability and FPSD when increasing from\n10\n\n-- 10 of 23 --\n\nTable 4 Multi-scale formulation. We ablate different strategies for scale configuration in downsampling. Results are\nobtained with 60M PAR.\nDesignability FPSD vs. fS\nDefine scale (%)↑ (sc-RMSD)↓ PDB↓ AFDB↓ (C / A / T)↑\n{64, 256} 83.0 1.38 282.85 274.32 2.14/6.58/20.66\n{64, 128, 256} 85.0 1.39 279.63 267.35 2.15/6.52/20.35\n{64, 128, 192, 256} 77.8 1.55 296.70 282.69 2.05/6.04/18.69\n{64, 96, 128, 192, 256} 81.0 1.51 276.00 263.58 2.17/6.31/20.65\n{L/4, L/2, L} 86.4 1.49 310.64 298.30 2.00/5.87/18.91\ntwo scales to three scales. Beyond this point, increasing the scale configurations to four and five scales results\nin degraded designability, potentially due to error accumulation and exposure bias. These results support our\nchoice of adopting the 3-scale PAR as the default. All results are obtained using the 60M model.\nTable 5 Structural consistency for prompted generation. Using a transformer to encode prior-scale structural\nconditions shows better prompt-following than direct input. Results are obtained with 60M PAR.\nRMSD vs. Reference ↓ TM-score vs. Prompt ↑\nLength (32.64] (64,128] (128,256] (32.64] (64,128] (128,256]\nReference - - - 0.60 0.61 0.59\nDirect Input 2.13 3.38 6.51 0.58 0.61 0.59\nTrans. Encode 1.45 2.72 5.75 0.60 0.64 0.61\nAR Transformer improves structural consistency. We conduct an ablation study to evaluate the effectiveness\nof the autoregressive transformer in Tab. 5. We compare two different strategies for encoding prior-scale\nstructural context, including (i) direct input, where the multi-scale structures are directly fed into the\nbackbone decoder without any intermediate encoding; and (ii) transformer encoder, where all scales are\nprocessed autoregressively by a Transformer encoder, and the resulting encoded representation is then passed\nto the backbone decoder. We train two 60M models and evaluate both models by downsampling 588 testing\nstructures as prompts and re-upsamples them with PAR. As shown in Tab. 5, the transformer encoder\ndemonstrates better structural consistency, indicating that autoregressive encoding across scales produces\ncoherent structural guidance over scales, consistent with attention maps in Fig. 6.\n5 Discussion\nPAR is the first multi-scale autoregressive model for protein backbone generation, offering a general framework\nthat includes flow-based methods as a special case. PAR addressed limitations of standard autoregressive\nmodels, such as unidirectional dependency, discretization, and exposure bias. Our method robustly models\nstructures over multiple granularities and in turn enables strong zero-shot generalization. This capability\nincludes coarse-prompted conditional generation using points (e.g., 16 points) as structural layout and finer-\ngrained controls such as atomic-coordinate-based motif scaffolding. For unconditional backbone generation,\nPAR exhibits powerful distributional fidelity and generation quality. The analysis of scale-level attention map\nprovides additional insights into how the multi-scale formulation operates.\nWe hope that PAR unlocks the potential of autoregressive modeling for protein design. Some promising\nopen directions include: (1) Conformational dynamics modeling. PAR can, in principle, perform zero-shot\nmodeling of conformational distributions: we downsample a structure and upsample it with PAR to mimic\nlocal molecular dynamics. We leave this exciting application for future research. (2) All-atom modeling. This\nwork focuses on backbone Cα atoms to prioritize autoregressive design, but it’s natural to extend to full-atom\nrepresentations [37]. The multi-scale framework offers an advantage for flexible zero-shot prompt-based\nall-atom designs.\n11\n\n-- 11 of 23 --\n\nAcknowledgments\nWe thank Dr. Hang Li, Liang Hong, Xinyou Wang, Jiasheng Ye, Yi Zhou, Jing Yuan, Yilai Li, Zhenghua\nWang, Yuning Shen, Huizhuo Yuan, as well as other colleagues at ByteDance Seed for their valuable comments\nand support.\n12\n\n-- 12 of 23 --\n\nReferences\n[1] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo\nAlmeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint\narXiv:2303.08774, 2023.\n[2] Michael S Albergo, Nicholas M Boffi, and Eric Vanden-Eijnden. Stochastic interpolants: A unifying framework\nfor flows and diffusions. arXiv preprint arXiv:2303.08797, 2023.\n[3] Kushal Arora, Layla El Asri, Hareesh Bahuleyan, and Jackie Chi Kit Cheung. Why exposure bias matters: An\nimitation learning perspective of error accumulation in language generation. arXiv preprint arXiv:2204.01171,\n2022.\n[4] Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence prediction with\nrecurrent neural networks. Advances in neural information processing systems, 28, 2015.\n[5] Avishek Joey Bose, Tara Akhound-Sadegh, Guillaume Huguet, Kilian Fatras, Jarrid Rector-Brooks, Cheng-Hao\nLiu, Andrei Cristian Nica, Maksym Korablyov, Michael Bronstein, and Alexander Tong. Se (3)-stochastic flow\nmatching for protein backbone generation. arXiv preprint arXiv:2310.02391, 2023.\n[6] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\nNeelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners.\nAdvances in neural information processing systems, 33:1877–1901, 2020.\n[7] Andrew Campbell, Jason Yim, Regina Barzilay, Tom Rainforth, and Tommi Jaakkola. Generative flows on discrete\nstate-spaces: Enabling multimodal flows with applications to protein co-design. arXiv preprint arXiv:2402.04997,\n2024.\n[8] Shoufa Chen, Chongjian Ge, Shilong Zhang, Peize Sun, and Ping Luo. Pixelflow: Pixel-space generative models\nwith flow. arXiv preprint arXiv:2504.07963, 2025.\n[9] Ting Chen, Ruixiang Zhang, and Geoffrey Hinton. Analog bits: Generating discrete data using diffusion models\nwith self-conditioning. arXiv preprint arXiv:2208.04202, 2022.\n[10] Alexander E Chu, Jinho Kim, Lucy Cheng, Gina El Nesr, Minkai Xu, Richard W Shuai, and Po-Ssu Huang. An\nall-atom protein generative model. Proceedings of the National Academy of Sciences, 121(27):e2311500121, 2024.\n[11] Justas Dauparas, Ivan Anishchenko, Nathaniel Bennett, Hua Bai, Robert J Ragotte, Lukas F Milles, Basile IM\nWicky, Alexis Courbet, Rob J de Haas, Neville Bethel, et al. Robust deep learning–based protein sequence design\nusing proteinmpnn. Science, 378(6615):49–56, 2022.\n[12] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages 12873–12883, 2021.\n[13] Benoit Gaujac, Jérémie Donà, Liviu Copoiu, Timothy Atkinson, Thomas Pierrot, and Thomas D Barrett. Learning\nthe language of protein structure. arXiv preprint arXiv:2405.15840, 2024.\n[14] Tomas Geffner, Kieran Didi, Zuobai Zhang, Danny Reidenbach, Zhonglin Cao, Jason Yim, Mario Geiger, Christian\nDallago, Emine Kucukbenli, Arash Vahdat, et al. Proteina: Scaling flow-based protein structure generative models.\narXiv preprint arXiv:2503.00710, 2025.\n[15] Thomas Hayes, Roshan Rao, Halil Akin, Nicholas J Sofroniew, Deniz Oktay, Zeming Lin, Robert Verkuil, Vincent Q\nTran, Jonathan Deaton, Marius Wiggert, et al. Simulating 500 million years of evolution with a language model.\nScience, 387(6736):850–858, 2025.\n[16] Tianxing He, Jingzhao Zhang, Zhiming Zhou, and James Glass. Exposure bias versus self-recovery: Are distortions\nreally incremental for autoregressive text generation? arXiv preprint arXiv:1905.10617, 2019.\n[17] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained\nby a two time-scale update rule converge to a local nash equilibrium. Advances in neural information processing\nsystems, 30, 2017.\n[18] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural\ninformation processing systems, 33:6840–6851, 2020.\n13\n\n-- 13 of 23 --\n\n[19] Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, and Quan-\nquan Gu. Elucidating the design space of multimodal protein language models. arXiv preprint arXiv:2504.11454,\n2025.\n[20] Chin-Wei Huang, Milad Aghajohari, Joey Bose, Prakash Panangaden, and Aaron C Courville. Riemannian\ndiffusion models. Advances in Neural Information Processing Systems, 35:2750–2761, 2022.\n[21] Po-Ssu Huang, Scott E Boyken, and David Baker. The coming of age of de novo protein design. Nature, 537\n(7620):320–327, 2016.\n[22] John B Ingraham, Max Baranov, Zak Costello, Karl W Barber, Wujie Wang, Ahmed Ismail, Vincent Frappier,\nDana M Lord, Christopher Ng-Thow-Hing, Erik R Van Vlack, et al. Illuminating protein space with a programmable\ngenerative model. Nature, 623(7989):1070–1078, 2023.\n[23] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn\nTunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure prediction\nwith alphafold. nature, 596(7873):583–589, 2021.\n[24] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec\nRadford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361,\n2020.\n[25] Brian Kuhlman and Philip Bradley. Advances in protein structure prediction and design. Nature reviews molecular\ncell biology, 20(11):681–697, 2019.\n[26] Patrick Kunzmann and Kay Hamacher. Biotite: a unifying open source computational biology framework in\npython. BMC bioinformatics, 19(1):346, 2018.\n[27] Gilles Labesse, N Colloc’h, Joël Pothier, and J-P Mornon. P-sea: a new efficient assignment of secondary structure\nfrom cα trace of proteins. Bioinformatics, 13(3):291–295, 1997.\n[28] Han Li, Xinyu Peng, Yaoming Wang, Zelin Peng, Xin Chen, Rongxiang Weng, Jingang Wang, Xunliang Cai,\nWenrui Dai, and Hongkai Xiong. Onecat: Decoder-only auto-regressive model for unified understanding and\ngeneration. arXiv preprint arXiv:2509.03498, 2025.\n[29] Tianhong Li and Kaiming He. Back to basics: Let denoising generative models denoise. arXiv preprint\narXiv:2511.13720, 2025.\n[30] Tianhong Li, Yonglong Tian, He Li, Mingyang Deng, and Kaiming He. Autoregressive image generation without\nvector quantization. Advances in Neural Information Processing Systems, 37:56424–56445, 2024.\n[31] Yeqing Lin and Mohammed AlQuraishi. Generating novel, designable, and diverse protein structures by equivari-\nantly diffusing oriented residue clouds. arXiv preprint arXiv:2301.12485, 2023.\n[32] Yeqing Lin, Minji Lee, Zhao Zhang, and Mohammed AlQuraishi. Out of many, one: Designing and scaffolding\nproteins at the scale of the structural universe with genie 2. arXiv preprint arXiv:2405.15489, 2024.\n[33] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil,\nOri Kabeli, Yaniv Shmueli, et al. Evolutionary-scale prediction of atomic-level protein structure with a language\nmodel. Science, 379(6637):1123–1130, 2023.\n[34] Yaron Lipman, Ricky TQ Chen, Heli Ben-Hamu, Maximilian Nickel, and Matt Le. Flow matching for generative\nmodeling. arXiv preprint arXiv:2210.02747, 2022.\n[35] Nanye Ma, Mark Goldstein, Michael S Albergo, Nicholas M Boffi, Eric Vanden-Eijnden, and Saining Xie. Sit:\nExploring flow and diffusion-based generative models with scalable interpolant transformers. In European\nConference on Computer Vision, pages 23–40. Springer, 2024.\n[36] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF\ninternational conference on computer vision, pages 4195–4205, 2023.\n[37] Wei Qu, Jiawei Guan, Rui Ma, Ke Zhai, Weikun Wu, and Haobo Wang. P (all-atom) is unlocking new path for\nprotein design. bioRxiv, pages 2024–08, 2024.\n[38] Sucheng Ren, Qihang Yu, Ju He, Xiaohui Shen, Alan Yuille, and Liang-Chieh Chen. Beyond next-token: Next-x\nprediction for autoregressive visual generation. arXiv preprint arXiv:2502.20388, 2025.\n14\n\n-- 14 of 23 --\n\n[39] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques\nfor training gans. Advances in neural information processing systems, 29, 2016.\n[40] Keyu Tian, Yi Jiang, Zehuan Yuan, Bingyue Peng, and Liwei Wang. Visual autoregressive modeling: Scalable\nimage generation via next-scale prediction. Advances in neural information processing systems, 37:84839–84865,\n2024.\n[41] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix,\nBaptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language\nmodels. arXiv preprint arXiv:2302.13971, 2023.\n[42] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and\nIllia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.\n[43] Xinyou Wang, Zaixiang Zheng, Fei Ye, Dongyu Xue, Shujian Huang, and Quanquan Gu. Dplm-2: A multimodal\ndiffusion protein language model. arXiv preprint arXiv:2410.13782, 2024.\n[44] Yinhuai Wang, Jiwen Yu, and Jian Zhang. Zero-shot image restoration using denoising diffusion null-space model.\narXiv preprint arXiv:2212.00490, 2022.\n[45] Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen E Eisenach, Woody\nAhern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novo design of protein structure and function\nwith rfdiffusion. Nature, 620(7976):1089–1100, 2023.\n[46] Ronald J Williams and David Zipser. A learning algorithm for continually running fully recurrent neural networks.\nNeural computation, 1(2):270–280, 1989.\n[47] Jason Yim, Andrew Campbell, Andrew YK Foong, Michael Gastegger, José Jiménez-Luna, Sarah Lewis, Vic-\ntor Garcia Satorras, Bastiaan S Veeling, Regina Barzilay, Tommi Jaakkola, et al. Fast protein backbone generation\nwith se (3) flow matching. arXiv preprint arXiv:2310.05297, 2023.\n[48] Jason Yim, Brian L Trippe, Valentin De Bortoli, Emile Mathieu, Arnaud Doucet, Regina Barzilay, and Tommi\nJaakkola. Se (3) diffusion model with application to protein backbone generation. In International Conference on\nMachine Learning, pages 40001–40039. PMLR, 2023.\n[49] Boyang Zheng, Nanye Ma, Shengbang Tong, and Saining Xie. Diffusion transformers with representation\nautoencoders. arXiv preprint arXiv:2510.11690, 2025.\n15\n\n-- 15 of 23 --\n\nAppendix\nA Implementation and Evaluation Details\nWe follow the implementation of Proteina [ 14 ] for training PAR, using the same architecture and hyperparameter\nsetup. Training is conducted on 8 H100 GPUs, with a batch size of 15 per GPU, for a total of 200k steps.\nWe train the flow-based backbone decoder with 60 M, 200 M, and 400 M parameters, using the same\nnon-equivariant transformer architecture as Proteina. For the autoregressive module, we adopt Proteina’s\nsmallest configuration (60 M parameters), as we find that a small AR module is enough to yield competitive\ngeneration quality, discussed in §4.3. For a fair comparison, we trained Proteina from scratch under the same\nsetting and achieved similar or even better performance than results reported in the original paper. For other\nbaselines, we directly obtain the results from [ 14 ]. Model and training configurations can be found in Tab. 6.\nNote that we remove pair representations, triangle update as well as auxiliary loss for memory and training\nefficiency, and the additional trainable parameters come from the 60M autoregressive transformer encoder.\nTable 6 Hyperparameters for PAR models. Tθ : autoregressive transformer; vθ : flow-based atomic decoder.\nTθ \tvθ\nPAR Architecture \t60M 60M 200M 400M\ninitialization \trandom random random random\nsequence repr dim \t512 512 768 1024\nsequence cond dim \t128 128 512 512\nt sinusoidal enc dim \t196 196 256 256\ninterpolated position enc dim 196 196 128 128\n# attention heads \t12 \t12 \t12 \t16\n# transformer layers \t12 \t12 \t15 \t18\n# trainable parameters \t60M 60M 200M 400M\nA.1 Implementation Details\nIn §3.2 we briefly introduce two novel techniques for our autoregressive modeling: scale embedding and\ninterpolated position embedding.\nScale Embedding. Since we use a shared decoder to train across all scales, we introduce a scale embedding to\ndistinguish data distributions at different scales. Each scale is assigned a unique scale id, which is incorporated\ninto the model to help disambiguate the varying statistical characteristics associated with different scales.\nInterpolated Position Embedding. Interpolated position embedding is a natural extension to the standard\nposition embedding for sequence representation. In the raw structure, each residue is associated with a\n3D coordinate and a position ID ranging from 1 to L, where L is the protein length. Our downsampled\nstructure and interpolated position embeddings are derived from the raw structure and position IDs via\ninterpolation, following the sequential order of residues. Each interpolated residue is computed by interpolating\nthe coordinates of neighboring real residues, while each interpolated position ID is obtained by interpolating\nover the corresponding relative positions. This approach has the advantage that, across inputs of different\nlengths (i.e., different scales), the interpolated positions still reflect the relative location of each interpolated\nresidue within the original structure, providing a coarse-grained view of the real protein.\nA.2 Evaluation Metrics\nWe evaluate the model from multiple perspectives, including quality and diversity, following evaluation\nprotocols established in prior literature by [5, 48]. Specifically, we sample 100 structures for each of the five\nsequence lengths: 50, 100, 150, 200, and 250, resulting in a total of 500 structures for evaluation.\nDesignability. Following the procedure from Yim et al. [48], we generate 8 candidate sequences for each\nstructure using ProteinMPNN [ 11 ] with a temperature of 0.1. Each sequence is folded into a predicted\nstructure using ESMFold [ 33]. We compute the root-mean-square deviation (RMSD) between each predicted\n16\n\n-- 16 of 23 --\n\nstructure and the original generated structure, and record the minimum RMSD across the 8 predictions.\nA structure is considered designable if its minimum RMSD is less than 2 Å. We report the proportion of\ndesignable structures and the average minimum RMSD across all samples.\nDiversity. Following Bose et al. [5] , we compute the average pairwise TM-score among all designable structures\nfor each sequence length. The final diversity score is obtained by averaging these values across all five lengths.\nSecondary Structure. To analyze secondary structure characteristics, we annotate all designable structures\nusing the P-SEA algorithm [ 27] as implemented in Biotite [26]. For each structure, we compute the proportion\nof alpha helices and beta sheets, and report the average proportions across all samples.\nTo better assess the model’s overall structural fidelity at the distributional level, we adopt two metrics\nintroduced in Geffner et al. [14]. We randomly sample 125 structures at each sequence length from 60 to 255\n(with a step size of 5), resulting in 5,000 structures in total. Importantly, no designability filtering is applied\nduring this stage, and all samples are used for evaluation.\nFrchet Protein Structure Distance (FPSD). Analogous to the Fréchet Inception Distance (FID) [17 ], FPSD\nmeasures the Wasserstein distance between the distributions of generated and reference structures. Structures\nare embedded into a feature space defined by a fold class predictor, and the distance is computed based on\nthe resulting Gaussian approximations.\nProtein Fold Score (fS). Inspired by the Inception Score (IS) [ 39 ], the fS metric encourages both diversity\nand sample-level quality. High-quality generations lead to confident fold class predictions, while diversity is\ncaptured by the entropy across the predicted fold distribution.\nA.3 Unconditional Backbone Generation\nWe train 200M and 400M models for Proteina and PAR for 200k steps, using Adam optimizer with learning\nrate 1e-4, no warmup applied. For evaluation, we sample from Proteina and PAR with the same techniques\nbelow. We follow the optimal configuration and sample 400 steps for Proteina. For PAR, we find 1k steps\nshow better results.\nSelf conditioning. Self-conditioning has been widely employed in protein design. During sampling, the model’s\nown previous predictions\nˆx(xt) = xt + (1 − t)vθ\nt (xt) (7)\nare fed back as conditions to guide subsequent generation. During training, the model is conditioned on its own\npredictions with a probability of 50%. Sampling can be performed either with or without self-conditioning.\nLow temperature sampling. In Eqn. 6, the parameter γ is injected to control the scale of noise. When γ = 1,\nthis SDE yields the same marginals as the ODE defined by flow model. In practice, it is common to use a\nlower γ < 1 which empirically improves designability at the cost of diversity. In this paper, we use γ = 0.30\nby default.\nCategory of unconditional backbone generation baselines. We categorize each baseline based on their\nmodeling types and frameworks in the table below.\nTable 7 Category of unconditional backbone generation baselines.\nMethod Type Framework\nFrameDiff Frame Diffusion\nRFDiffusion Frame Diffusion\nESM3 Token PLM\nGenie2 Ca Diffusion\nProteina Ca FM\nPAR Ca PAR\n17\n\n-- 17 of 23 --\n\nB Datasets\nThe training data is derived from the curated AFDB representative dataset (denoted as DFS, containing 0.6M\nstructures), as processed by Proteina. This dataset ensures both high quality (pLDDT > 80) and structural\ndiversity, with sequence lengths ranging from 32 to 256 residues. We follow [14 ] and split it by 98:19:1 for\ntraining, validation and testing. For PDB finetuning, as the dataset used in [14] is not publicly available, we\nreproduce their filtering protocol and curate a designable subset of 21K samples from PDB.\nC More Empirical Analysis\nC.1 Efficient Sampling with SDE/ODE Orchestration\nFigure 7 Designability analysis of multi-scale SDE/ODE sampling methods. Naively reducing the SDE\nsampling steps substantially degrades the designability (red). Using ODE alone exhibits limited designability (purple).\nOrchestrating SDE and ODE sampling enables reduced sampling steps while retaining designability (blue and green).\nWe report the designability over varying sampling steps in Fig. 7. Leveraging SDE sampling at the first scale\nand ODE for the remaining scales, PAR could effectively reduce diffusion steps without harming designability,\nhighlighting the unique advantage of multi-scale design to orchestrate SDE and ODE sampling at different\nscales. In addition, aggressively reducing SDE steps or replacing SDE with ODE across all scales yields much\nworse designability, highlighting the necessity of combining both sampling methods. These results suggest\nthat PAR decomposes backbone generation into coarse topology formation and efficient structure refinement\nat later scales.\nC.2 Ablation with Self-Conditioning\nMulti-scale autoregressive modeling and self-conditioning similarly guide the generation with a coarse estimate\nof the structure. To evaluate the role of self-conditioning in our multiscale framework, we conducted an\nablation study (Fig. 8), where the results are from the same 60M model in the previous ablation study. Across\nall length ranges, the model with self-conditioning consistently generates higher-quality protein structures,\nin terms of sc-RMSD. Although self-conditioning also supplies an intermediate structural estimate during\ngeneration, it is complementary to the multi-scale formulation and yields further improvements in structural\nquality.\nC.3 Long Protein Generation\nFinetuning on longer protein chains. We follow Proteina to finetune our models on datasets with longer\nproteins. Since Proteina has not released its long-protein dataset, we cannot fully reproduce their experiment\nsetups. Instead, we follow the filtering procedure described in their appendix on PDB structures to curate\n18\n\n-- 18 of 23 --\n\n50 \t100 \t150 \t200 \t250\nProtein Length\n0.50\n0.75\n1.00\n1.25\n1.50\n1.75\n2.00\nsc-RMSD (Å)\n0.79\n1.07\n1.43\n1.81\n1.97\n0.88\n1.08\n1.57\n1.86\n2.02\nPAR\nw/o self-condition\nFigure 8 Ablation with self-conditioning. Self-conditioning consistently improves backbone generation performance\nof PAR across varying protein lengths, showing that both methods are compatible. Results are obtained with 60M\nPAR.\n300 \t400 \t500 \t600 \t700\nResidue Length\n0.000\n0.002\n0.004\n0.006\n0.008\n0.010\n0.012\nDensity\nDistribution of Residue Lengths\nFigure 9 Protein length distribution for long protein finetuning.\na long-protein dataset. We filter PDB structures to lengths between 256 and 768 residues and keep only\ndesignable samples, resulting in 26k high-quality proteins. The length-distribution of this dataset (Fig. 9)\nexhibits a long-tail shape with peaks around 300-400 residues. We then finetune the 400M PAR and Proteina\nmodels in Tab. 1 on this dataset for 10k steps.\nLong-protein generation. We generate 100 proteins for each length in {300, 400, 500, 600, 700}. PAR exhibits\nhigher designability at lengths {300, 400}, consistent with the higher density of training samples in this range.\nAt lengths between 500 to 700, both Proteina and PAR show degraded designability, while PAR demonstrating\nslightly better results. We attribute this to the long-tail nature of the training set, which includes far fewer\nsamples in the length range between 500 and 700. The limited size of the training set (26K) also potentially\nhinders the model from reaching its full potential. We leave scaling up long-protein data as a promising\ndirection for future work.\nTable 8 Long protein generation. scR: sc-RMSD (Å) ↑. DesA: Designability (%) ↓.\n300 400 500 600 700\nscR DesA scR DesA scR DesA scR DesA scR DesA\nProteina 1.91 85 2.70 61 4.09 49 7.90 21 13.32 4\nPAR 1.28 93 1.65 72 3.19 52 6.80 29 11.29 10\n19\n\n-- 19 of 23 --\n\nC.4 Foldseek Cluster Diversity\nTable 9 Foldseek cluster diversity.\nγ Designable Clusters\n0.35 119\n0.40 126\n0.45 142\n0.50 140\n0.60 164\n0.70 160\n0.80 146\nWe investigated the foldseek cluster diversity of PAR-generated samples. A larger γ increases sampling\nstochasticity and improves the diversity, reaching its peak value at γ=0.6. We generate 500 structures, with\n100 samples for each length in {50, 100, 150, 200, 250}. We use the same foldseek command following Geffner\net al. [14] with a tmscore threshold of 0.5. The command is\nfoldseek easy-cluster <path_samples> <path_tmp>/res <path_tmp>\n--alignment-type 1 --cov-mode 0 --min-seq-id 0\n--tmscore-threshold 0.5\nC.5 Zero-shot Motif Scaffold Benchmark\nTable 10 Zero-shot motif scaffold benchmark. PAR* indicates our zero-shot model, producing 100 samples, while\nother baselines require finetuning. Baseline results are taken directly from Geffner et al. [14], which reports results\nusing 1000 samples. SR: success rate. Results are obtained with 60M PAR.\nUnique Solutions (%)\nPAR* Proteina Genie2 RFDiffusion FrameFlow\n1PRW \t0 \t0.3 \t0.2 \t0.1 \t0.3\n1BCF \t0 \t0.1 \t0.1 \t0.1 \t0.1\n5TPN \t0 \t0.4 \t0.8 \t0.5 \t0.6\n5IUS \t0 \t0.1 \t0.1 \t0.1 \t0\n3IXT \t6.0 \t0.8 \t1.4 \t0.3 \t0.8\n5YUI \t0 \t0.5 \t0.3 \t0.1 \t0.1\n1QJG \t1.0 \t0.3 \t0.5 \t0.1 \t1.8\n1YCR \t4.0 \t24.9 13.4 \t0.7 \t14.9\n2KL8 \t4.0 \t0.1 \t0.1 \t0.1 \t0.1\n7MRX.60 \t0 \t0.2 \t0.5 \t0.1 \t0.1\n7MRX.85 \t1.0 \t3.1 \t2.3 \t1.3 \t2.2\n7MRX.128 \t1.0 \t5.1 \t2.7 \t6.6 \t3.5\n4JHW \t0 \t0 \t0 \t0 \t0\n4ZYP \t0 \t1.1 \t0.3 \t0.6 \t0.4\n5WN9 \t0 \t0.2 \t0.1 \t0 \t0.3\n5TRV_short \t0 \t0.1 \t0.3 \t0.1 \t0.1\n5TRV_med \t1.0 \t2.2 \t2.3 \t1.0 \t2.1\n5TRV_long \t0 \t17.9 \t9.7 \t2.3 \t7.7\n6E6R_short \t6.0 \t5.6 \t2.6 \t2.3 \t2.5\n6E6R_med \t3.0 \t41.7 27.2 \t15.1 \t9.9\n6E6R_long \t3.0 \t71.3 41.5 \t38.1 \t11.0\n6EXZ_short \t3.0 \t0.3 \t0.2 \t0.1 \t0.3\n6EXZ_med \t8.0 \t4.3 \t5.4 \t2.5 \t11.0\n6EXZ_long \t10.0 29.0 32.6 \t16.7 \t40.3\n# tasks (SR ≥ 1%) 13 \t11 \t11 \t9 \t11\nWe quantify the zero-shot motif scaffolding performance of PAR in Tab. 10. For other training-based methods,\nwe directly quote the results reported in Proteina [14].\nWe use PAR to generate 100 backbone structures for each benchmark problem in Watson et al. [45] . Following\nProteina’s evaluation protocol, we produce 8 ProteinMPNN sequences with the motif residues fixed, and feed\n20\n\n-- 20 of 23 --\n\neach sequence to ESMFold. Using the predicted structure, we calculate ca-RMSD and MotifRMSD. A design\nis considered a success if any sequence achieves scRMSD ≤ 2Å, a motifRMSD ≤ 1Å, pLDDT ≥ 70, and pAE\n≤ 5. Note that our method is the only one evaluated in a zero-shot setting, whereas all other baselines rely\non training or finetuning with additional motif conditioning.\nC.6 Scale-Agnostic Inference\nTable 11 Inference with flexible scale configuration.\nDesignability FPSD ↓ fS ↑\n(%) ↑ (sc-RMSD) ↓ vs. PDB vs. AFDB (C/A/T)\nPAR (3 scale) 96.6 1.04 160.99 228.44 2.57/7.42/23.61\nw/o scale emb 92.8 1.16 175.09 246.34 2.54/7.66/26.68\n5 scale inference 72.6 1.74 177.01 246.76 2.56/7.53/26.78\nIn our original setup, we included a learnable scale embedding vector as part of the AR module’s conditioning.\nThis embedding allows the model to identify the current scale and adjust its behavior (e.g., generating coarse\nvs. fine structures). However, since the dimensionality of this learnable embedding is fixed to the number of\nscales, the model cannot be applied to a different scale configuration at inference.\nTo explore flexible scale configurations, we finetune an alternative model that simply discards the learnable\nembedding on the PDB designable subset for 5k steps. This formulation cancels the embedding from a fixed\nnumber of scales and enables inference across arbitrary scale settings. As shown in the Tab. 11, when inferring\nwith five scales using this 3-scale model, FPSD remains stable, suggesting that the model still captures the\nunderlying data distribution under altered scale configurations. However, the designability substantially drops,\nindicating that sampling with an unseen scale configuration fails to preserve structural detail, ultimately\nleading to lower-quality results.\nC.7 Ablating AR and Decoder Size\nTable 12 Effect of AR module and decoder size. Both AR and decoder utilize transformer-based architectures.\nAR Decoder sc-RMSD Designability (%)\n400M 60M 1.26 87.80\n60M 400M 1.01 96.00\n60M 60M 1.19 92.60\nWe introduced an ablation study examining the AR encoder size, and discussed crucial design choices for\nboth the AR encoder and flow-based decoder. We summarize key findings below.\nPer-token vs per-scale decoder. In our preliminary study, we implemented the model with a 200M-parameter\nAR module and, following MAR [ 30], used a 3-layer MLP ( 20M) as the diffusion head. However, this setup\nfailed to generate reasonable structures, yielding an average sc-RMSD of 16. This likely occurs because a\nper-token decoder is not expressive enough to capture the global correlations between atoms that is required\nto produce a reliable coarse structure at the first scale, which is crucial for the subsequent coarse-to-fine\nrefinement. These observations motivated our shift to a per-scale transformer-based decoder.\nLarge vs. small decoder. As shown in Tab. 12 and our scaling experiments in §4.3, using a large decoder\nbrings effective improvements to generation quality.\nLarge AR vs small AR. With the decoder size fixed, increasing the AR transformer size from 60M to 400M\ndoes not offer improvements. One one hand, this is consistent with the module’s role to generate scale-wise\nconditioning to guide the backbone generation, which does not require large model capacity—a similar trend\nobserved in image generation [ 8]. In addition, we believe this is due to exposure bias: the AR module overfits\n21\n\n-- 21 of 23 --\n\nto ground truth context to stabilize training, resulting in a mismatch with inference, where the model relies\non its predictions as context. This issue becomes more severe under several conditions:\n(1) Larger AR models tend to overfit the context more strongly, making exposure bias more severe.\n(2) Limited data increases overfitting risks: our 588K training structures (32–256 residues each) provide far\nless coverage than datasets like ImageNet (1.28M 256x256 images).\n(3) High precision tasks like protein modeling are sensitive to small errors, making exposure bias more serious\nthan in image generation, where the compressed VAE latents lie in a smoother Gaussian space that is\nrobust to small errors at the cost of some visual details [29, 49].\nOur noisy context learning and scheduled sampling mitigate this issue for the 60M PAR, but scaling the AR\ntransformer appears to intensify this issue. Exploring more training data is a potential solution and we leave\nthis for future work.\nC.8 Sequence-Based Downsampling Preserves Pairwise Spatial Relationships\nTable 13 RMSE and LDDT across different downsample sizes.\nSize(i) 16 32 64 128\nRMSE 0.362 0.275 0.217 0.170\nLDDT 1 1 1 1\nWe discuss whether 1D downsampling properly preserves pairwise spatial relationships. To study this,\nwe attempt to investigate the difference between pairwise distances computed after downsampling the 1D\ncoordinate sequence and those obtained by downsampling the full-resolution 2D distance map. We discuss\ndetails below.\nSpatial relationships in downsampled 1D sequence. We follow the process below to quantify the spatial\nrelationships:\n1. Downsample the coordinate sequence from RL×3 to Rsize(i)×3 for each scale i.\n2. We compute pairwise distance maps using the downsampled sequence, leading to a size(i) × size(i)\nmap.\nSpatial relationships in 3D space after downsampling. We quantify this using the pairwise distance map\ncalculated from the full-resolution structure:\n1. Calculate the pairwise distance map of the structure, producing a L × L map.\n2. We downsample pairwise map this using the F.interpolate(mode=’bicubic’) operation, resulting in\na size(i) × size(i) map.\nDoes sequence-based downsampling preserve spatial relationships?\nWe select all samples from the testing set, and calculate the RMSE and LDDT between the aforementioned\ntwo size(i) × size(i) pairwise maps for each sample. As expected, rmse slightly increases as size(i) decreases,\nreflecting the loss of fine-grained details at coarser scales. However, lddt remains consistently at 1 and the\nrmse values remain low across all scales. Together, these results indicate that, despiste small information loss\nat the coarse scales, 1D sequence downsampling preserves the essential pairwise spatial correlations captured\nby the downsampled 2D distance map.\nC.9 Visualization of Attention Scores\nWe provide attention score visualization for shorter proteins in Fig. 10. The pattern generally aligns with\nFig. 6, where each scale primarily attends to its previous scale.\n22\n\n-- 22 of 23 --\n\n1 \t2 \t3\n1\n2\n3\nLayer 0\n1 \t2 \t3\n1\n2\n3\nLayer 5\n1 \t2 \t3\n1\n2\n3\nLayer 11\n0.2\n0.4\n0.6\n0.8\n1.0\n1 \t2 \t3 \t4\n1\n2\n3\n4\nLayer 0\n1 \t2 \t3 \t4\n1\n2\n3\n4\nLayer 5\n1 \t2 \t3 \t4\n1\n2\n3\n4\nLayer 11\n0.2\n0.4\n0.6\n0.8\n1.0\nFigure 10 Visualization of the average attention scores in PAR autoregressive transformer over 3/4 scales.\nLeft Length ∈ (32, 64]. Right Length ∈ (64, 128].\nD Other Related Work\nFlow and diffusion-based structure generative models. Flow-based and diffusion methods have been\nwidely applied to protein backbone generation, with examples including RFDiffusion [ 45] and Chroma [22].\nSubsequently, various protein representations have been proposed for protein structure generation. FrameDiff,\nFoldFlow and FrameFlow [ 5, 47, 48] model protein structures through per-residue rotation and translation\npredictions, employing a frame-based Riemannian manifold representation [20 , 23]. Building upon FrameFlow,\nMultiflow [ 7] jointly models sequence and structures. In contrast, Genie and Genie2 [31, 32] generate protein\nbackbones by diffusing the Cα coordinates. Pallatom and Protpardelle [ 10, 37] further generate fully atomistic\nproteins that include side-chains. Meanwhile, Proteina [14] leverages a non-equivariant transformer architecture\nto model the Cα backbone coordinates, exhibiting scalability and simplicity. In addition to continuous diffusion\nand flow-matching based approaches, discrete diffusion methods like ESM3 [15 ] and DPLM-2 [ 43] have been\ntrained on structure tokens, which often reduce structural fidelity and thus limit structure generation quality\n[19].\n23\n\n-- 23 of 23 --\n\n",
      "analysis_json": "{\"title\":\"Protein Autoregressive Modeling via Multiscale Structure Generation\",\"authors\":[\"Yanru Qu\",\"Cheng-Yen Hsieh\",\"Zaixiang Zheng\",\"Ge Liu\",\"Quanquan Gu\"],\"publication_year\":\"2026\",\"summary\":\"PAR is a hierarchical protein structure generation framework that treats the protein design process like sculpting a statue. Unlike previous autoregressive models that struggle with protein geometry, PAR uses a multi-scale approach to predict coarse topology first and then refine structural details. It integrates an autoregressive transformer with a flow-based decoder to generate continuous 3D coordinates, overcoming the limitations of discretization and exposure bias through novel training strategies like noisy context learning.\",\"breakthrough_score\":85,\"breakthrough_reasoning\":\"This work successfully adapts the autoregressive paradigm—highly successful in LLMs—to the continuous 3D domain of protein structures. By moving from sequence-order prediction to 'next-scale' prediction, it solves the bidirectional dependency problem that previously made AR models inferior to Diffusion in structural biology. The zero-shot prompt-following capability is a significant advancement for functional protein design.\",\"key_claims\":[\"Next-scale prediction preserves spatial and bidirectional dependencies better than sequence-based prediction.\",\"A continuous flow-based decoder avoids the fidelity loss associated with tokenizing protein structures.\",\"Noisy context learning and scheduled sampling effectively mitigate the exposure bias typical of AR models.\",\"PAR enables zero-shot motif scaffolding and human-prompted generation without specific fine-tuning.\",\"A multi-scale approach allows for SDE/ODE orchestration, achieving up to 2.5x faster sampling than single-scale models.\"],\"testable_hypotheses\":[{\"hypothesis\":\"Coarse-scale SDE sampling combined with fine-scale ODE refinement maintains structural designability while significantly reducing compute time.\",\"how_to_test\":\"Compare a baseline model using 400 SDE steps at all scales against a PAR model using 400 SDE steps at the 1/4 scale and 2 ODE steps at the full scale.\",\"expected_outcome\":\"The hybrid SDE/ODE approach should maintain over 90 percent designability while reducing inference time by 2-3x.\"},{\"hypothesis\":\"Noisy Context Learning (NCL) is the primary factor in preventing error accumulation across scales.\",\"how_to_test\":\"Train identical PAR architectures with and without NCL, then measure the self-consistency RMSD (sc-RMSD) of generated proteins at the final scale.\",\"expected_outcome\":\"Models without NCL will show significantly higher sc-RMSD (poor quality) due to sensitivity to small errors in the initial coarse topology.\"}],\"key_equations\":[{\"name\":\"Multiscale Autoregressive Likelihood\",\"latex\":\"p_theta(X) = Product_{i=1}^{n} p_theta(x_i | X_{<i})\",\"description\":\"The probability of a full protein structure is decomposed into the product of probabilities of each scale given all previous (coarser) scales.\",\"variables\":[{\"name\":\"x_i\",\"description\":\"The protein representation at the i-th scale of granularity\",\"typical_range\":\"i=1 to 5\"},{\"name\":\"X_{<i}\",\"description\":\"All structural context generated in previous coarser steps\",\"typical_range\":\"Set of 3D coordinates\"}]},{\"name\":\"Flow Matching Objective with Multi-scale Conditioning\",\"latex\":\"L(theta) = E || v_theta(x_t, t, z_i) - (x_i - epsilon_i) ||^2\",\"description\":\"The decoder learns to predict the vector field that transforms noise into the target structural scale, conditioned on latent embeddings from the AR transformer.\",\"variables\":[{\"name\":\"v_theta\",\"description\":\"The flow-based backbone decoder network\",\"typical_range\":\"Velocity field\"},{\"name\":\"z_i\",\"description\":\"Conditional embedding produced by the AR transformer for scale i\",\"typical_range\":\"High-dimensional vector\"}]}],\"simulation_possibilities\":[{\"title\":\"Interactive 'Protein Sculptor'\",\"description\":\"A visualization tool showing the 5-scale generation process. Users can see a 'cloud' of 16 points expand into a rough 3D fold and finally refine into an alpha-helix or beta-sheet structure.\",\"complexity\":\"Medium\",\"variables\":[\"Sampling steps per scale\",\"Scale granularity\",\"Noise scaling parameter (gamma)\"],\"expected_insights\":\"Users see how the global topology is locked in early (Scale 1-2) while the secondary structure details only emerge at the final scales.\",\"visualization_type\":\"3d\"},{\"title\":\"Zero-Shot Motif Scaffolder\",\"description\":\"Users upload a small functional motif (e.g., a binding loop). The simulation 'freezes' these points and asks the AR transformer to generate the rest of the protein around it scale-by-scale.\",\"complexity\":\"High\",\"variables\":[\"Motif location\",\"Target protein length\",\"Teacher-forcing strength\"],\"expected_insights\":\"Demonstrates how the model naturally fills in gaps to create a stable structure that supports a specific function without specific task training.\",\"visualization_type\":\"interactive\"},{\"title\":\"SDE vs ODE Efficiency Explorer\",\"description\":\"A side-by-side comparison of generation speed and quality using different sampling strategies (All SDE vs. PAR's Hybrid S/O/O strategy).\",\"complexity\":\"Low\",\"variables\":[\"Inference time\",\"Trajectory smoothness\",\"Final structure designability\"],\"expected_insights\":\"Shows that 'stochasticity' is vital for finding the global shape but 'determinism' is sufficient for refining details.\",\"visualization_type\":\"chart\"}],\"field\":\"Computational Biology\",\"related_fields\":[\"Machine Learning\",\"Structural Bioinformatics\",\"Generative AI\",\"Biophysics\"],\"limitations\":[\"Currently limited to C-alpha backbone atoms only, requiring separate models for all-atom reconstruction.\",\"Exposure bias is mitigated but not entirely eliminated, potentially limiting performance on extremely long proteins.\",\"Quadratic scaling of transformer attention still poses challenges for very large protein complexes.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Transformers and Attention Mechanisms\",\"Flow Matching and Diffusion Models\",\"Protein Hierarchical Structure (Primary/Secondary/Tertiary)\",\"Autoregressive Learning Principles\"]}",
      "created_at": 1770295429557
    },
    "arxiv-2602.04836": {
      "hash": "arxiv-2602.04836",
      "filename": "2602.04836.pdf",
      "raw_text": "Are AI Capabilities Increasing Exponentially? A Competing Hypothesis\nHaosen Ge 1 Hamsa Bastani 2 Osbert Bastani 3\nAbstract\nRapidly increasing AI capabilities have sub-\nstantial real-world consequences, ranging from\nAI safety concerns to labor market conse-\nquences. The Model Evaluation & Threat Re-\nsearch (METR) report argues that AI capabilities\nhave exhibited exponential growth since 2019. In\nthis note, we argue that the data does not support\nexponential growth, even in shorter-term horizons.\nWhereas the METR study claims that fitting sig-\nmoid/logistic curves results in inflection points\nfar in the future, we fit a sigmoid curve to their\ncurrent data and find that the inflection point has\nalready passed. In addition, we propose a more\ncomplex model that decomposes AI capabilities\ninto base and reasoning capabilities, exhibiting in-\ndividual rates of improvement. We prove that this\nmodel supports our hypothesis that AI capabilities\nwill exhibit an inflection point in the near future.\nOur goal is not to establish a rigorous forecast of\nour own, but to highlight the fragility of existing\nforecasts of exponential growth.1\n1. Introduction\nA recent report by Model Evaluation & Threat Research\n(METR) (Kwa et al., 2025) conducted a series of analyses\nto measure AI capabilities in realistic tasks that require\nsignificant effort from human experts. They propose a novel\nmetric: 50% model horizon, which measures the difficulty\nof tasks that a model can solve successfully 50% of the time.\nThen, they show that according to this metric, AI capabilities\nare increasing exponentially over time—specifically, model\n1Wharton AI & Analytics Initiative, The Wharton School,\nUniversity of Pennsylvania, USA 2Department of Operations,\nInformation and Decisions, The Wharton School, University\nof Pennsylvania, USA 3Department of Computer and Infor-\nmation Science, University of Pennsylvania, USA. Correspon-\ndence to: Haosen Ge <hge@wharton.upenn.edu>, Hamsa Bas-\ntani <hamsab@wharton.upenn.edu>, Osbert Bastani <obas-\ntani@seas.upenn.edu>.\nPreprint. February 5, 2026.\n1Our code is available at https://github.com/\nobastani/AI_Forecasting.\nhorizons have been doubling every seven months since 2019.\nBased on these results, they predict that “within 5 years, AI\nsystems will be capable of automating many software tasks\nthat currently take humans a month.”\nSince dissemination, this report has drawn significant atten-\ntion and started heated discussion on the potential impact\nof such rapid improvement of AI capabilities. Much of the\nacademic conversation has focused on safety (Barnett &\nScher, 2025). However, there are substantial consequences\nfor rapidly increasing AI capabilities beyond safety. Most\nnotably, these results have raised substantial concerns about\nlabor market consequences, raising the potential for large-\nscale displacement of skilled workers (Brynjolfsson et al.,\n2025). Importantly, many consequences of these forecasts\nare immediate, shaping both policy outcomes as well as\nindividual decisions such as choices about education and\ncareer paths. Given the substantial consequences of the po-\ntential for exponential increase in AI capabilities, there is\nan urgent need for rigorous methodologies for performing\nand validating these kinds forecasts.\nWe argue to the contrary—plateauing growth is similarly\nwell supported by the data. While the METR study com-\npares to a small number of alternative hypotheses, aside\nfrom linear and super-exponential, none of these alterna-\ntives are visualized or discussed in detail. Most notably,\nthey discuss the sigmoid curve as a potential alternative, but\nclaim that their estimate of this model yields an inflection\npoint far in the future (see Appendix D.1 in their paper (Kwa\net al., 2025)); they rule out plateauing growth in the near\nfuture based on this finding. However, we find that fitting\na sigmoid curve results in an inflection point that is actu-\nally in the past (specifically, 2025-06-06), as visualized in\nFigure 1.2 This finding suggests that at the very least, it is\nplausible that AI capabilities may plateau soon.\nIn general, it is impossible to rule out either alternative from\ndata alone. Thus, to support our hypothesis, we posit a\ntheoretical model under which the exponential appearance\nof recent gains in AI capabilities can be interpreted as a\nconsequence of the introduction of reasoning capabilities\ninto base LLMs. Specifically, we model reasoning as a\n2While this fit is in-sample (due to the small dataset size), our\nmain goal is to estimate the inflection point from the data rather\nthan to provide accurate forecasts into the future.\n1\narXiv:2602.04836v1 [cs.AI] 4 Feb 2026\n\n-- 1 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\n(a) Sigmoid Curve Fit (b) Sigmoid Curve Fit vs METR\nFigure 1. Sigmoid Curve. This sigmoid curve is fit by minimizing the mean-squared error (MSE) of the curve hmodel = γ ·σ(δ1 ·dmodel +δ2)\nto the METR dataset, where hmodel is METR’s “50% model horizon time” for the given model, dmodel is the model release date, and\nγ, δ1, δ2 are parameters. We use gradient descent in PyTorch for parameter estimation. While it is not clear that progress will plateau,\nrecent progress clearly fits in the linear part of the sigmoid and the inflection point (2025-06-06) is in the past.\nseparate technology that contributes multiplicatively to the\noverall capability of LLMs—i.e., LLM capabilities can be\ndecomposed into two sigmoids, one for the base LLM and\none for reasoning. Indeed, as can be seen from Figure 1, the\nperiod of progress from o1-preview (released 2024-09-12)\nto the present forms the linear part of the sigmoid curve.\nThus, our hypothesis is that following initial exponential\ngrowth due to scaling data and model size, base capabilities\nplateaued, but overall capabilities continued to grow for a\nperiod due to rapid improvements in reasoning.\nWhile we present a specific alternative analysis, our goal is\nnot to discount the METR study; in fact, we believe con-\ntinuing exponential improvement is a plausible viewpoint,\nand it is important to take this potential outcome into con-\nsideration. However, we believe that our approach provides\na plausible alternative that similarly merits consideration.\n2. Background on the METR Study\nWe focus on the recent METR study (Kwa et al., 2025),\nwhich forecasts that AI capabilities are exponentially in-\ncreasing. This study was itself critiquing prior work, point-\ning out that existing metrics such as accuracy are bounded\nand cannot assess whether growth is exponential. To rem-\nedy this issue, they introduce a novel metric, the 50% model\nhorizon time, which quantifies the difficulty of tasks that a\nmodel can solve reliably. Unlike prior metrics, this one can\nincrease unboundedly, making it suitable for assessing the\npossibility of exponential growth. Their analysis concludes\nthat AI capabilities are improving exponentially.\nTheir experiments include three task families: HCAST, RE-\nBench, and SWAA. Specifically, HCAST contains a diverse\nset of challenges in cybersecurity, machine learning, soft-\nware engineering, and general reasoning. RE-Bench con-\nsists of challenging open-ended machine learning research\nengineering environments, each of which are intended to\ntake a human expert approximately 8 hours to complete.\nSWAA comprises 66 small tasks commonly performed in\nsoftware engineering work. In total, their study includes\n170 unique tasks from the three task families. Then, they\nevaluate 28 popular models on the 170 tasks. Among the\nmodels, they label a subset of 15 models as state-of-the-art\n(SOTA), representing the frontier of AI capabilities. We\nreuse their experimental results and focus exclusively on the\n15 state-of-the-art models to better characterize the scaling\nbehavior of frontier AI capabilities. We include the list of\nSOTA models and their release dates in Table 1.\nTheir data analysis first estimates the horizon time of each\nmodel on each dataset using the following regression:\npmodel = σ((log hmodel − log ttask) · βmodel), (1)\nwhere pmodel denotes the probability that the model solves a\ntask correctly, ttask denotes the difficulty of the task (mea-\nsured by the amount of time human expert takes to com-\nplete the task), hmodel is the 50% horizon time, βmodel is\nthe parameter they estimate, and σ(x) = ex/(1 + ex) is\n2\n\n-- 2 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\nTable 1. Release Dates of the Selected SOTA Models.\nModel Release Date\nDavinci-002 2020-05-28\nGPT-4 2023-03-14\nGrok-4 2025-07-09\nClaude 3.5 Sonnet (Oct 2024) 2024-10-22\nGPT-5 2025-08-07\nClaude 3.7 Sonnet 2025-02-24\nGPT-2 2019-02-14\nGPT-3.5 Turbo Instruct 2022-03-15\nGPT-o1-preview 2024-09-12\nGPT-4 (1106) 2023-11-06\nGPT-5.1 Codex Max 2025-11-19\nGPT-4o 2024-05-13\nClaude 3.5 Sonnet 2024-06-20\nGPT-o3 2025-04-16\nGPT-o1-elicited 2024-12-05\nthe sigmoid function. By construction, pmodel = 1/2 when\nlog hmodel = log ttask; thus, a model with capability hmodel\nattains a success probability of 1/2 on tasks with difficulty\nttask = hmodel. Thus, hmodel characterizes the task difficulty\nthreshold at which the model achieves a success rate of 1/2.\nAfter estimating the 50% horizon time, they examine the\ntemporal trend in model capabilities by fitting the following\nlinear regression model:\nlog hmodel = β0 + β1 · dmodel,\nwhere dmodel denotes the model’s release date; they fit this\ndata by treating the estimate hmodel from the previous step\nas ground truth h∗\nmodel and applying linear regression. Note\nthat this model is equivalent to\nhmodel = exp (β0 + β1 · dmodel) , (2)\nimplying an exponential relationship between the model’s\n50% horizon time and its release date. METR reports an\nR2 value of 0.98 for this regression, which they interpret as\nstrong evidence that the capabilities of frontier models grow\nexponentially over time. In their main paper, they compare\nthis regression to two others—linear and hyperbolic—and\nfind that an exponential curve fits the data substantially\nbetter. They discuss additional comparisons informally in\nAppendix D.1 of their paper, but do not provide quantitative\nevidence to support ruling out these alternatives. However,\nthis limited comparison to alternatives makes it difficult to\nassess the confidence we should have in their findings.\n3. Multiplicative Model of AI Progress\nWe present a model of growing AI capabilities that decom-\nposes it into two component technologies: the base model\nand reasoning. We prove that this model produces a growth\ncurve that is qualitatively consistent with the METR data.\n3.1. Motivation\nThe main hypothesis behind our model of AI progress is that\nmuch of the recent growth in AI capabilities has been driven\nby the introduction of reasoning into base LLMs. Specif-\nically, while chain-of-thought reasoning has been popular\nfor some time now (Wei et al., 2022), explicitly training\nmodels to perform reasoning is a more recent phenomenon,\nstarting with OpenAI’s o1 model (Jaech et al., 2024; Shao\net al., 2024). Since the release of o1, there has been startling\nprogress on a number of benchmarks, with current LLMs\nappearing to approach the performance of human experts.\nWe propose a model that explicitly separates progress on\nbase model capabilities from progress on reasoning capabil-\nities. Intuitively, the reason this model might show support\nfor slowing improvements is that technologies tend to ex-\nhibit very rapid growth during their introduction. Since\nLLMs have only been finetuned for chain-of-thought rea-\nsoning for a little over a year (starting with the introduction\nof OpenAI’s o1 model (Jaech et al., 2024)), it is natural that\nreasoning capabilities have dramatically improved capabili-\nties over the past year. However, we might expect reasoning\ncapabilities to start plateauing in the near future.\nWithout separating out improvements in reasoning, it\nis unsurprising that the rate of improvement appears\nexponential—prior to 2023, base capabilities improved ex-\nponentially due to scaling of data and model size, but these\nimprovements plateaued due to the prohibitive cost of scal-\ning. Reasoning capabilities have maintained this growth\nsince 2023. Under this view, one way to interpret the METR\nstudy is that it predicts new breakthroughs will continue\nto prop up exponential progress. This makes sense when\nextrapolating, since breakthroughs have been common in\nthe past decade; however, there is no guarantee that it will\ncontinue to be the case. Under our model, if breakthroughs\nstop happening, then exponential progress will end.\n3.2. Regression Model\nFor our data analysis, we consider an alternative regres-\nsion model to Eq. 2 that explicitly separates a model’s base\nperformance and its reasoning capabilities:\nhmodel = γ1 · hbase · (1 + γ2 · hreasoning)\nhbase = b(dmodel)\nhreasoning = r(dmodel) · 1{kthinking = 1},\nwhere hmodel is the 50% model horizon, kthinking indicates\nwhether the model has been post-trained with reasoning\ncapabilities and those capabilities are activated, γ1, γ2 are\nparameters to be estimated, and b, r are link functions de-\n3\n\n-- 3 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\nFigure 2. Sigmoid link inflection points. The curves are as in\nFigure 3; we show inflection points of the orange and green curves\nas dashed vertical lines of the corresponding color.\nscribed below. In other words, we treat an LLM’s over-\nall capability as the product of it’s base capability hbase(d)\n(i.e., without reasoning) and the quality hreasoning of its rea-\nsoning features. Intuitively, the base capability of a LLM\ncaptures advancement of the model’s pre-training phase\nand non-reasoning post-training phases, including model\nsizes and data curation, and the reasoning ability captures\npost-training techniques to improve chain-of-thought think-\ning. Both base and reasoning capabilities are functions of\nthe model’s release date dmodel. The parameters γ1 and γ2\nquantify the contributions of base capability and reasoning\ncapability to the overall capability.\nA key feature of our model is that technologies are multi-\nplicative—i.e., overall capability is the product (rather than,\ne.g., the sum) of the component technologies (in our case,\nthe base model and reasoning). This assumption is the key\ndriver behind the apparent exponential growth of staggered\nimprovements across different technologies; we provide\ntheoretical evidence that our model exhibits this kind of\nbehavior in Section 3.4. Intuitively, just as progress in one\ntechnology plateaus, another technology exhibits rapid im-\nprovement that props up exponential improvements. We\nbelieve this multiplicative model is realistic—for LLMs,\nreasoning cannot exist without strong base models, and\nwhile strong base models have useful capabilities, these are\nsubstantially boosted by reasoning.\n3.3. Choice of Link Functions\nThe link functions b, r encode how the base and reasoning\ncapabilities depend on the model’s release date dmodel. A\nwide range of functional forms could be considered; in this\nnote, we adopt the following plausible candidates.\nSigmoid. First, we consider the sigmoid function:\nb(dmodel) = σ(δ1 · dmodel + δ2) (3)\nr(dmodel) = σ(θ1 · dmodel + θ2), (4)\nwhere δ1, δ2, θ1, θ2 are parameters. Intuitively, these link\nfunctions say that each of base and reasoning capabilities\ngrow exponentially until reaching an “inflection point”, af-\nter which they plateau (formally, an inflection point of an\narbitrary function f (x) is the point at which f ′′(x) changes\nsign; the inflection of σ is at x = 0). In Section 3.4, we\nprovide an analysis of the implications of this model.\nExponential. Next, we consider an exponential function:\nb(dmodel) = exp(δ1 · dmodel + δ2)\nr(dmodel) = exp(θ1 · dmodel + θ2),\nwhere δ1, δ2, θ1, θ2 are parameters. Similar to METR’s orig-\ninal model, these link functions say that each of base and\nreasoning capabilities are increasing exponentially in time;\nthus, the overall capability is also increasing over time.\nSpline. Lastly, we consider a B-spline link function:\nb(dmodel) =\nNb\tX\ni=1\nδi · Bi(dmodel)\nr(dmodel) =\nNr\tX\ni=1\nθi · Bi(dmodel),\nwhere Nb and Nr denote the numbers of spline basis func-\ntions for b and r, respectively, {δi}Nb\ni=1, {θi}Nr\ni=1 are parame-\nters, and Bi(dmodel) is the ith B-spline basis function (which\nwe take to be a degree m polynomial), which includes its\nown parameters. This choice of link function induces a\nflexible, piecewise polynomial relationship between LLM\ncapabilities and the release date.\n3.4. Theoretical Analysis\nWe prove that a multiplicative model of technological\nprogress with sigmoid link exhibits exponential growth fol-\nlowed by plateauing. To simplify our analysis, we drop\nmany of the parameters and assume that the core model is a\nproduct of sigmoid functions with different inflection points;\nwe further simplify by assuming these inflection points are\nevenly spaced. Then, we prove that the resulting function\nexhibits (i) exponential growth ex before the first inflection\npoint, (ii) squared exponential growth ex2\nbetween the first\nand last inflection points, and (iii) plateauing thereafter.\n4\n\n-- 4 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\n(a) Sigmoid Link (b) Exponential Link (c) B-Spline Link\nFigure 3. Projections under Different Link Functions. The orange curves project base model capabilities, the green curve projects\nreasoning capabilities assuming the best base model (i.e., gpt-5.1-codex-max), and the blue curve shows the overall capabilities. The\nblack points denote the 50% model horizon estimated by METR.\nTheorem 3.1. Let x denote time, and consider the model\nf (x) =\nk\tY\ni=1\nfi(x) where fi(x) = σ(x − iα),\nwhere σ is the sigmoid function and α ≥ 2. Then:\n• If x ≤ 0, then\n1\n5 ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n≤ f (x) ≤ ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n.\n• If x ∈ [jα, (j + 1)α] for j ∈ {0, 1, ..., k − 1}, then\n1\n20 exp\n\u0010\n− α\n2 · (k − j + 1)(k − j)\n\u0011\n≤ f (x) ≤ exp\n\u0010\n− α\n2 · (k − j − 1)(k − j)\n\u0011\n.\n• If x ≥ kα, then\n1\n4 ≤ f (x) ≤ 1.\nIn the first case x ≤ 0, the model exhibits exponential\ngrowth ekx. In the second case, x ≈ jα ≈ (j + 1)α, so\nf (x) ≈ exp\n\u0012\n− α\n2 ·\n\u0010\nk − x\nα\n\u00112\u0013\n.\nIn other words, progress continues exponentially until the\nfinal inflection point kα. Intuitively, the exponent base de-\ncays throughout this phase; as progress for individual com-\nponents plateau, the base of the exponent becomes smaller.\nTable 2. Assessment of goodness of fit via MSE on hmodel.\nSpecification Mean Squared Error (MSE)\nSigmoid Link 203.69\nB-Spline Link 511.80\nExponential Link 2874.67\nMETR Exponential Curve 339.93\nSigmoid Curve 27.37\nFinally, in the third case, progress plateaus once the last\ninflection point has been crossed.\nThese trends are consistent with the data shown in Figure 1.\nAt a high level, the initial period of growth was exponential\ndue to scaling AI capabilities. Many researchers believed\nthat capabilities were plateauing; however, the introduction\nof post-training for reasoning sparked a second wave of\nimprovements in capabilities, resulting in a period of steep\nlinear increases between 2024-09-12 to the present. If our\nmodel accurately reflects reality, then new breakthroughs\nare necessary to sustain exponential growth.\n4. Our Analysis of the METR Data\nWe fit our model from Section 3 to data; our results support\nthe plausibility of plateauing AI capabilities.\n4.1. Methodology\nWe estimate our models the original experiment data shared\nby the METR study (Kwa et al., 2025) (including data from\nthe HCAST, RE-Bench, and SWAA benchmarks). We ac-\ncess the data via METR’s public Github repository: https:\n5\n\n-- 5 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\n(a) Long-term Projection (b) Log Model Capability\nFigure 4. Comparison of Sigmoid Link and METR Projection.\n//github.com/METR/eval-analysis-public.\nWe perform estimation by maximizing the log-likelihood\nof the probabilistic model pmodel in Eq. 1 using Stan (Car-\npenter et al., 2017). For the sigmoid and exponential link\nfunctions, we adopt the weakly informative prior N (0, 102)\nfor all parameters, and impose positivity constraints on\nγ1, γ2, δ1, θ1, βmodel. For the B-spline link function, we\nuse two breakpoints and polynomial splines of degree five\nfor both b and r (i.e., degree m = 5 and Nb = Nr =\n2 + 5 − 1 = 6). To ensure that hmodel remains strictly posi-\ntive and to avoid taking the logarithm of a negative quantity,\nwe constrain all spline coefficients δi and θi to be positive.\nFurthermore, we regularize the spline coefficients using\nrandom-walk priors, following standard practice to mitigate\noverfitting: δ1 ∼ N (0, 1), δi ∼ N (δi−1, τ ) for all i ≥ 2,\nand τ ∼ N (0, 1). The same priors are applied to θi.\n4.2. Results\nModel Fit. Figure 3 shows the fitted models; that com-\nbine base and reasoning components. Given the limited\nnumber of available models, we assess goodness-of-fit us-\ning the in-sample mean squared error (MSE) between the\nmodel-predicted AI capability and the observed AI capabil-\nity: (hmodel − h∗\nmodel)2; Table 2 reports the resulting MSEs.\nWe also include METR’s exponential curve and our sigmoid\ncurve in Figure 1; note that these models are not directly\ncomparable since they optimize different loss functions.\nAmong the three link functions considered, the sigmoid-\nlink model achieves by far the lowest MSE, suggesting that\nwithin our model, sigmoid growth appears more plausible\nthan exponential growth. Our approach also outperforms\nMETR’s exponential curve, though our model has more\nparameters so this comparison is not rigorous.\nInflection points. The key question is not the magnitude\nof recent performance gains (which are undeniable), but\nwhether these gains will continue. One argument in the\nMETR study is that there is no sign of an “inflection point”\nwhere exponential increase starts to slow down; we have\nalready shown in Figure 1 that the current data does not\nsupport this claim. To further understand inflection points\nin AI capabilities, we plot the inflection points of Eqs. (3)\n& (4) in Figure 2. The inflection points db of b(d) and dr of\nr(d) based on the estimated parameters are\nˆdb = 2024-11-21 and ˆdr = 2026-06-06,\nrespectively. These results support our finding—the inflec-\ntion point ˆdb for base model capabilities happened just after\nthe release of the first reasoning model (o1-preview) in 2024-\n09-12, and the inflection point ˆdr for reasoning capabilities\nis projected to happen in the near future. Thus, increasing\nreasoning capabilities drove the substantial overall improve-\nments we have seen in the past two years.\nBaked into our model is the idea that unless significant\nbreakthroughs happen, progress will plateau. Thus, the\nquestion about forecasting AI capabilities becomes a ques-\ntion of whether we should expect another breakthrough that\nproduces improvements on the same scale as reasoning.\nThis question can only be answered by domain knowledge;\nwe leave it for the broader community to answer.\nThese results highlight an additional benefit of decomposing\n6\n\n-- 6 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\noverall capability into component technologies—it enables\nus to understand and interpret forecasts of progress for indi-\nvidual components separately, providing an understanding\nof why progress looks a certain way.\nLong-term forecasts. Finally, we compare METR’s expo-\nnential forecast with our sigmoid-link model over a ten-year\nhorizon from 2019-01-01 to 2029-01-01. Results are shown\nin Figure 4a. The two models yield similar projections up to\napproximately 2026-07-03. Beyond this point, the METR\nmodel predicts an increasingly rapid rise in model capability,\nwhereas our model suggests that capabilities will plateau in\nthe near future. External forecasts cannot in general be vali-\ndated, so these results highlight the importance of leveraging\ndomain insights to assess the validity of forecasts.\n5. Limitations\nIn-sample evaluation. A key limitation is that our estimates\nare all evaluated in-sample; while the same is true for exist-\ning methodologies such as the METR study, our models also\ninclude more parameters. This limitation is inevitable due\nto the limited amount of data available. However, our goal\nis not to provide irrefutable evidence that AI capabilities\nare plateauing, but that it is a highly plausible alternative\nto continuing exponential growth. As more data becomes\navailable, it is critical to assess which models have more\naccurately forecast progress to build confidence in future\nforecasts. More broadly, more rigorous methodologies must\nbe developed for assessing the accuracy of these forecasts.\nEvaluation metric. A related issue is that comparing across\ndifferent kinds of models (ours vs. METR) is complicated\nby the fact that they are estimated in very different ways.\nThe METR paper performs regression to minimize the MSE\nin the space of log-outcomes log hmodel, whereas we have\nused probabilistic modeling directly on the final outcomes\npmodel; furthermore, our sigmoid curve in Figure 1 mini-\nmizes MSE on outcomes hmodel. While we have used MSE\nat predicting hmodel to compare models, this comparison is\nnot fair due to the diverse loss functions, especially given\nthe in-sample comparison. Again, this issue necessitates the\ndevelopment of more rigorous evaluation methodologies.\nMultiplicative assumption. The multiplicative assumption\nis critical for driving our theoretical analysis. While we be-\nlieve this assumption presents at least a plausible alternative,\nsubstantial work needs to be done to validate it in practice.\nLimited decomposition. We have only modeled base and\nreasoning capabilities; we believe these are the key driving\nfactors behind the substantial recent gains in AI capabilities,\nbut there are many other important factors. Prior to the\nrelease of GPT-4, many of the gains in performance were\ndriven simply by scaling the amount of training data and the\nmodel size, as well as basic instruction tuning. Recent im-\nprovements in reasoning capabilities have been driven by im-\nproved post-training procedures and the creation of datasets\ntailored to reasoning tasks; other non-public improvements\nmay also have contributed. In principle, these two com-\nponents can be further decomposed into aspects such as\ndata engineering, pre- and post-training algorithms, network\narchitecture, etc.; however, we currently lack enough in-\nformation about state-of-the-art LLMs to perform a more\ngranular analysis. Finding ways to address these issues\ncould help lead to more accurate forecasts.\n6. Conclusion\nTo contrast with the recent view on exponential increase of\nLLM capabilities, we have presented an alternative view-\npoint arguing that this increase is not exponential; instead,\nit is plateauing or possibly linear. Our forecasting method-\nology combines domain-specific modeling that decomposes\nprogress into separate base and reasoning capabilities, with\nan empirical analysis based on the METR dataset, which we\nbelieve could form the basis of future forecasting models.\nImportantly, our methodology is primarily intended to be a\ncompelling alternative rather than a definitive rebuttal. We\nbelieve that substantially more work needs to be done both\nin terms of improved forecasting methodologies, as well as\nimproved evaluation of these methodologies.\nReferences\nBarnett, P. and Scher, A. Ai governance to avoid extinction:\nThe strategic landscape and actionable research questions.\narXiv preprint arXiv:2505.04592, 2025.\nBrynjolfsson, E., Chandar, B., and Chen, R. Canaries in the\ncoal mine? six facts about the recent employment effects\nof artificial intelligence. Digital Economy, 2025.\nCarpenter, B., Gelman, A., Hoffman, M. D., Lee, D.,\nGoodrich, B., Betancourt, M., Brubaker, M., Guo, J.,\nLi, P., and Riddell, A. Stan: A probabilistic programming\nlanguage. Journal of statistical software, 76:1–32, 2017.\nHo, A., Denain, J.-S., Atanasov, D., Albanie, S., and Shah,\nR. A rosetta stone for ai benchmarks. arXiv preprint\narXiv:2512.00193, 2025.\nJaech, A., Kalai, A., Lerer, A., Richardson, A., El-Kishky,\nA., Low, A., Helyar, A., Madry, A., Beutel, A., Car-\nney, A., et al. Openai o1 system card. arXiv preprint\narXiv:2412.16720, 2024.\nJimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press,\nO., and Narasimhan, K. Swe-bench: Can language mod-\nels resolve real-world github issues? arXiv preprint\narXiv:2310.06770, 2023.\n7\n\n-- 7 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\nKwa, T., West, B., Becker, J., Deng, A., Garcia, K., Hasin,\nM., Jawhar, S., Kinniment, M., Rush, N., Von Arx, S.,\net al. Measuring ai ability to complete long tasks. arXiv\npreprint arXiv:2503.14499, 2025.\nMaslej, N., Fattorini, L., Perrault, R., Gil, Y., Parli, V.,\nKariuki, N., Capstick, E., Reuel, A., Brynjolfsson, E.,\nEtchemendy, J., et al. Artificial intelligence index report\n2025. arXiv preprint arXiv:2504.07139, 2025.\nOwen, D. What will ai look like in 2030?, 2025. URL\nhttps://epoch.ai/files/AI_2030.pdf.\nPatwardhan, T., Dias, R., Proehl, E., Kim, G., Wang, M.,\nWatkins, O., Fishman, S. P., Aljubeh, M., Thacker, P.,\nFauconnet, L., et al. Gdpval: Evaluating ai model perfor-\nmance on real-world economically valuable tasks. arXiv\npreprint arXiv:2510.04374, 2025.\nShao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang,\nH., Zhang, M., Li, Y., Wu, Y., et al. Deepseekmath: Push-\ning the limits of mathematical reasoning in open language\nmodels. arXiv preprint arXiv:2402.03300, 2024.\nSinha, A., Arun, A., Goel, S., Staab, S., and Geiping, J.\nThe illusion of diminishing returns: Measuring long hori-\nzon execution in llms. arXiv preprint arXiv:2509.09677,\n2025.\nWei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi,\nE., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting\nelicits reasoning in large language models. Advances in\nneural information processing systems, 35:24824–24837,\n2022.\nWijk, H., Lin, T., Becker, J., Jawhar, S., Parikh, N., Broadley,\nT., Chan, L., Chen, M., Clymer, J., Dhyani, J., et al. Re-\nbench: Evaluating frontier ai r&d capabilities of language\nmodel agents against human experts. arXiv preprint\narXiv:2411.15114, 2024.\nA. Related Work\nBenchmarking LLMs. A number of complex evaluation\nframeworks have been proposed to assess AI performance\nunder realistic conditions. SWE-bench evaluates LLMs on\nreal-world GitHub pull requests paired with gold-standard\nfixes and unit tests (Jimenez et al., 2023). GDPval compiles\na comprehensive set of tasks designed to be representative\nof the U.S. economy (Patwardhan et al., 2025); domain\nexperts from each representative industry are recruited to de-\nsign tasks for AI systems, while additional experts evaluate\nmodel outputs and annotate whether AI-generated solutions\nare preferred over human completions. Ho et al. (2025) pro-\npose a method for stitching together existing benchmarks\nto assess long-term AI performance. Wijk et al. (2024)\nintroduce RE-bench, which collects challenging research-\nand-development tasks hand-crafted by human experts.\nForecasting AI capabilities. Maslej et al. (2025) systemati-\ncally documents advances and trends in AI across multiple\ndomains over time, providing an empirical basis for fore-\ncasting. Epoch AI has published papers and reports offering\nin-depth analyses of AI capabilities and future development\ntrajectories (e.g., Owen (2025)). Sinha et al. (2025) distin-\nguish between “execution” and “planning,” focusing on a\nmodel’s ability to correctly execute a complex but prede-\nfined plan. They show that diminishing improvements in\nsingle-step accuracy can compound, resulting in exponential\ngrowth in the length of tasks a model can complete.\nB. Proof of Theorem 3.1\nFirst, suppose that for some j ∈ {0, 1, ..., k − 1}, we have\nx ∈ [jα, j′α], where j′ = j + 1. For all i ≤ j,\nfi(x) = 1 − e−x+iα\n1 + e−x+iα ≥ 1 − e−(j−i)α\n2 ,\nso we have\nj\tY\ni=1\nfi(x) ≥ 1 − 1\n2\nj\tX\ni=1\ne−(j−i)α ≥ 1 − 1\n2\n∞\tX\nh=0\ne−hα\n≥ 1 − 1\n2\n∞\tX\nh=0\n1\n3h ≥ 1\n4 ,\nsince e−2 ≤ 1/3. In addition, we have fi(x) ≤ 1, so\nQi\nj=1 fi(x) ≤ 1. Next, for all i ≥ j′, we have\nfi(x) = σ(x − iα) = ex−iα\n1 + ex−iα ≥ e−(i−j)α\n1 + e−(i−j′)α ,\nso\nk\tY\ni=j′\nfi(x) ≥\nQk\ni=j′ e−(i−j)α\nQk\ni=j′ (1 + e−(i−j′)α) .\nFor the numerator, we have\nk\tY\ni=j′\ne−(i−j)α =\nk−j\tY\nh=1\ne−hα = exp −α\nk−j\tX\nh=1\nh\n!\n= exp\n\u0010\n− α\n2 · (k − j + 1)(k − j)\n\u0011\n.\nFor the denominator, we have\nk\tY\ni=j′\n(1 + e−(i−j′)α) ≤\n∞\tY\nh=0\n(1 + e−hα)\n= exp\n∞\tX\nh=0\nlog(1 + e−hα)\n!\n≤ exp\n∞\tX\nh=0\ne−hα\n!\n≤ exp\n\u0012 1\n1 − e−α\n\u0013\n≤ 5.\n8\n\n-- 8 of 9 --\n\nAI Capabilities Are Not Increasing Exponentially\nIn addition, fi(x) ≤ ex−iα ≤ e−(i−j′)α, so\nk\tY\ni=j′\nfi(x) ≤ exp\n\u0010\n− α\n2 · (k − j′)(k − j)\n\u0011\n.\nPutting everything together, we have\n1\n20 exp\n\u0010\n− α\n2 · (k − j + 1)(k − j)\n\u0011\n≤ f (x) ≤ exp\n\u0010\n− α\n2 · (k − j − 1)(k − j)\n\u0011\n.\nNext, if x ≥ kα, a similar argument shows that\n1\n4 ≤ f (x) ≤ 1.\nFinally, if x ≤ 0, then we have\nk\tY\ni=1\nfi(x) ≥\nQk\ni=1 ex−iα\nQk\ni=1(1 + ex−iα) .\nFor the numerator, we have\nk\tY\ni=1\nex−iα = ekx exp −α\nk\tX\ni=1\ni\n!\n= ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n,\nand the denominator is bounded by 5 as before. In addition,\nk\tY\ni=1\nfi(x) ≤\nk\tY\ni=1\nex−iα ≤ ekx exp −α\nk\tX\ni=1\ni\n!\n= ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n.\nThus, we have\n1\n5 ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n≤ f (x) ≤ ekx exp\n\u0010\n− α\n2 · k(k + 1)\n\u0011\n.\nThe claim follows.\n9\n\n-- 9 of 9 --\n\n",
      "analysis_json": "{\"title\":\"Are AI Capabilities Increasing Exponentially? A Competing Hypothesis\",\"authors\":[\"Haosen Ge\",\"Hamsa Bastani\",\"Osbert Bastani\"],\"publication_year\":\"2026\",\"summary\":\"This paper challenges the widely cited METR report which claims AI capabilities are growing exponentially. The authors argue that a sigmoid (plateauing) model fits existing data better and that recent progress is better explained by a 'Multiplicative Model' where distinct technology waves, specifically base capabilities and reasoning capabilities, stack on top of each other. Their analysis suggests that the inflection point for base models has already passed, and reasoning-driven gains may also plateau in the near future.\",\"breakthrough_score\":72,\"breakthrough_reasoning\":\"The paper provides a significant mathematical critique of mainstream AI forecasting. By introducing a multiplicative decomposition of technology components (Base + Reasoning), it shifts the conversation from simple curve-fitting to a more nuanced 'technology wave' theory. While it relies on the same limited dataset as the original METR report, its rigor in highlighting the fragility of exponential projections is a major contribution to AI governance and policy planning.\",\"key_claims\":[\"Current AI capability data does not uniquely support an exponential growth hypothesis.\",\"A sigmoid curve suggests the inflection point for base AI capabilities occurred around June 2025.\",\"AI progress is better modeled as the product of independent technological components (Base x Reasoning).\",\"The 'exponential' look of recent progress is an artifact of models being in the steep linear phase of a new reasoning technology sigmoid.\"],\"testable_hypotheses\":[{\"hypothesis\":\"AI capability gains on 50% model horizon tasks will show significant deceleration by mid-2026.\",\"how_to_test\":\"Benchmark frontier models released in 2026 (e.g., successors to GPT-5 or Claude 4) on RE-Bench and SWAA benchmarks to see if performance stays within sigmoid bounds.\",\"expected_outcome\":\"The observed 50% model horizon will deviate significantly below the exponential forecast and align with the plateauing sigmoid model.\"}],\"key_equations\":[{\"name\":\"Multiplicative Capability Model\",\"latex\":\"h_model = gamma_1 * h_base(d_model) * (1 + gamma_2 * h_reasoning(d_model))\",\"description\":\"Models the total AI capability as a product of base pre-training strength and reasoning-specific post-training enhancements.\",\"variables\":[{\"name\":\"h_base\",\"description\":\"The base capability level of the model without advanced reasoning.\",\"typical_range\":\"0 to 1 (normalized)\"},{\"name\":\"h_reasoning\",\"description\":\"The enhancement factor provided by reasoning-specific training (e.g., chain-of-thought).\",\"typical_range\":\"0 to 1\"}]},{\"name\":\"Sigmoid Link Function\",\"latex\":\"b(d_model) = 1 / (1 + exp(-(delta_1 * d_model + delta_2)))\",\"description\":\"Defines how a specific technology component (like base capability) evolves over time, following an S-curve.\",\"variables\":[{\"name\":\"delta_1\",\"description\":\"The growth rate or steepness of the capability increase.\",\"typical_range\":\"0.1 to 2.0\"},{\"name\":\"delta_2\",\"description\":\"The temporal offset determining when the inflection point occurs.\",\"typical_range\":\"Variable based on date encoding\"}]}],\"simulation_possibilities\":[{\"title\":\"The 'Stacked Sigmoids' Illusion Generator\",\"description\":\"An interactive dashboard where users can create 'technology waves' (e.g., Scaling, Reasoning, Agentic Behavior). By adjusting the start date and growth rate of each wave, users can see how a series of plateauing curves (sigmoids) can perfectly mimic a single exponential curve over a short timeframe.\",\"complexity\":\"Medium\",\"variables\":[\"Growth rate per wave\",\"Wave onset date\",\"Number of technology waves\",\"Saturation level\"],\"expected_insights\":\"Users will understand the 'multiplicative' argument by seeing how 'exponential' progress is often just the sum of several overlapping S-curves.\",\"visualization_type\":\"interactive\"},{\"title\":\"Model Horizon Predictor\",\"description\":\"A visualization tool that plots real model release data against two competing forecasts: Exponential vs. Sigmoid Link. Users can input a future model release date and see the disparity in task-solving capability predictions between the two theories.\",\"complexity\":\"Low\",\"variables\":[\"Release Date\",\"Model Type (Base vs Reasoning-Enabled)\"],\"expected_insights\":\"Demonstrates the 'fragility' of long-term forecasts and how quickly the two models diverge after 2026.\",\"visualization_type\":\"chart\"}],\"field\":\"AI Forecasting\",\"related_fields\":[\"Machine Learning\",\"Econometrics\",\"AI Safety\",\"Technological Forecasting\"],\"limitations\":[\"Small dataset (only 28 models evaluated).\",\"In-sample fitting makes the results descriptive rather than definitively predictive.\",\"Simplistic decomposition into only two components (Base and Reasoning).\",\"Lack of transparency from AI labs on exact release dates and post-training methods.\"],\"difficulty_to_understand\":\"Intermediate\",\"prerequisites\":[\"Basic knowledge of Sigmoid functions and growth curves\",\"Familiarity with the distinction between LLM pre-training and reasoning-based post-training\",\"Understanding of Mean Squared Error (MSE) in regression\"]}",
      "created_at": 1770298565647
    },
    "arxiv-2602.04813": {
      "hash": "arxiv-2602.04813",
      "filename": "reanalysis.pdf",
      "raw_text": "Received 10 December 2025, accepted 31 December 2025, date of publication 5 January 2026, date of current version 9 January 2026.\nDigital Object Identifier 10.1109/ACCESS.2026.3651218\nAgentic AI in Healthcare & Medicine: A\nSeven-Dimensional Taxonomy for\nEmpirical Evaluation of LLM-based\nAgents\nSHUBHAM VATSAL1, HARSH DUBEY2 AND ADITI SINGH3 (Senior Member, IEEE)\n1 Department of Computer Science, New York University, CIMS, New York, USA (e-mail: sv2128@nyu.edu)\n2 Department of Computer Science, New York University, CIMS, New York, USA (e-mail: hd2225@nyu.edu)\n3 Department of Computer Science, Cleveland State University, Cleveland, USA (e-mail: a.singh22@csuohio.edu)\nCorresponding author: Aditi Singh (e-mail: a.singh22@csuohio.edu).\nABSTRACT Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape\nhealthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR\nanalysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely\nconsists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory,\nplanning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49\nstudies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction\nPatterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with\n29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully\nImplemented ✓, Partially Implemented ∆, Not Implemented ✗), we map each study to the taxonomy\nand report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical\nanalysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension\nunder Knowledge Management is commonly realized (∼76% ✓) whereas Event-Triggered Activation\nsub-dimenison under Interaction Patterns is largely absent (∼92% ✗) and Drift Detection & Mitigation\nsub-dimension under Adaptation & Learning is rare (∼98% ✗). Architecturally, Multi-Agent Design sub-\ndimension under Framework Typology is the dominant pattern (∼82% ✓) while orchestration layers remain\nmostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question\nAnswering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas\nsuch as Treatment Planning & Prescription still show substantial gaps (∼59% ✗). Together, these findings\nprovide an empirical baseline indicating that current agents excel at retrieval-grounded advising but require\nstronger adaptation and compliance platforms to move from early-stage systems to dependable systems.\nINDEX TERMS Agentic AI, Healthcare, Medicine, Prompt Engineering, Large Language Model, Multi-\nAgent, Taxonomy, Survey, Empirical Analysis, Clinical Trial, Patient Interaction, Diagnostic Reasoning\nI. INTRODUCTION\nThe advent of LLMs has significantly accelerated advance-\nments across multiple domains, showcasing transformative\npotential far beyond traditional applications. These models,\nincluding GPT-4 [1] and PaLM [2] are trained on extensive\ndatasets comprising billions or even trillions of parameters\nenabling broad generalization and sophisticated understand-\ning. Empirical studies have showcased that increasing model\nscale directly correlates with enhanced performance in com-\nplex reasoning, multi-step decision making and interactive\nplanning tasks [3]. The enhanced cognitive capabilities of\nmodern LLMs have rapidly driven their integration into crit-\nical sectors such as healthcare [4], medicine [5], finance [6]\nfor risk assessment and investment strategies and education\n[7] for personalized learning and instructional assistance. Re-\ncent research has further evolved to emphasize prompt engi-\nneering which is a technique involving precise manipulation\nof natural language inputs to extract and enhance task specific\nVOLUME 14, 2026 1\narXiv:2602.04813v1 [cs.AI] 4 Feb 2026\n\n-- 1 of 25 --\n\nreasoning capabilities of LLMs [8]–[12]. This shift under-\nscores a critical progression in LLM research highlighting the\ntransition from predictive modeling to sophisticated, context\nsensitive cognitive interactions. Furthermore, the emergence\nof LLM-based agents has marked another significant mile-\nstone enabling autonomous decision making and interactive\ntask execution across diverse application areas [13].\nIn healthcare and medicine, LLMs have demonstrated\nconsiderable promise in streamlining clinical workflows, en-\nhancing diagnostic accuracy and supporting clinical research.\nFor instance, recent studies have utilized LLMs to auto-\nmate clinical documentation, significantly reducing clinician\nworkload and improving the quality of clinical records [14],\n[15]. Similarly, LLM-based decision support systems have\nbeen applied to medical question answering, achieving expert\nlevel performance in interpreting complex medical literature\nand clinical guidelines [16]. Complementing these advances,\nLLMs achieve state-of-the-art results on biomedical machine\nreading comprehension benchmarks [17] and show measur-\nable gains on guideline-based prior-authorization question\nanswering over noisy, real-world records [18]. The inte-\ngration of multimodal capabilities into LLMs enabling the\ninterpretation of radiology scans and clinical images has\nfurther advanced diagnostic efficiency as has been seen in\nframeworks like ChatCAD [19]. Apart from diagnostics,\nLLMs have been explored for enhancing treatment planning\nand supporting evidence-based medicine by synthesizing vast\ncorpora of medical research and clinical guidelines [20]. In\ndrug discovery, LLMs accelerate the identification of novel\ndrug candidates and streamline clinical trial design which\nhas significantly helped in reducing both time and cost\n[21]. Patient interaction and clinical communication have\nalso benefited from LLM-powered conversational agents\nthereby improving adherence to treatment plans, facilitating\ntelemedicine and enabling remote patient monitoring [22].\nAlthough these advancements demonstrate substantial im-\npact, they also highlight the need for continuous evaluation of\nLLMs in healthcare to maintain high standards of reliability\nand interpretability.\nRecently, the development of LLM-based agents which\nare often described under the broader umbrella of Agentic\nAI has represented an emerging paradigm that capitalizes on\nthe advanced cognitive capabilities of LLMs. These agents\nintegrate multiple cognitive modules including reasoning,\nplanning and memory management allowing them to do\nsophisticated problem solving and context aware interactions\nacross a variety of domains. Recent research such as Chain-\nof-Thought prompting [3] and Tree-of-Thoughts reasoning\n[23] has highlighted the importance of modular cognitive\narchitectures which help in facilitating the effective execution\nof complex multi-step reasoning tasks within Agentic AI\ndesign space. Additionally, memory-augmented architectures\nthat incorporate episodic and semantic memory systems have\nfurther enhanced agents’ capacities to maintain continuity\nacross interactions improving both task accuracy and reliabil-\nity. Adaptive learning mechanisms including reinforcement\nlearning with human feedback (RLHF) enable these agents to\niteratively refine their behavior by integrating user input and\nenvironmental signals resulting in dynamic adaptation and\nalignment with evolving user objectives. As the landscape of\nLLM-based agents evolves, their impact in decision making\nis evident across healthcare, finance, law and education.\nThis evolution is reshaping industry practices enabling more\nintelligent, adaptive, context aware systems that redefine how\ntasks are automated and decisions made.\nBuilding on these foundational advancements, LLM-based\nagents have emerged as a pivotal innovation within healthcare\nand medicine. These agents integrate advanced reasoning\nand planning which help in facilitating complex tasks such\nas differential diagnosis and real-time patient monitoring.\nResearch has shown their utility in automating critical work-\nflows including patient triage [24], laboratory result interpre-\ntation and EHR management [25]. As Agentic AI systems,\nLLM-based agents show promise in augmenting clinical\ndecision making through interactive dialogues that foster\ncollaboration between medical professionals and AI systems.\nThese agents also facilitate continuous medical education by\nproviding real-time access to updated clinical knowledge,\nbest practices and evidence-based guidelines. In specialized\nfields such as oncology, cardiology and surgery, LLM-based\nagents are being employed to support complex risk assess-\nments and treatment optimization [26], [27]. As their inte-\ngration deepens across healthcare, Agentic AI-driven LLM-\nbased agents can assist in not only streamlining decision\nsupport but also enable more holistic care pathways.\nA. FOCUS OF OUR SURVEY\nThe growing interest in LLM-based agents has prompted\nexploration of potential applications in healthcare and\nmedicine. Yet, the field lacks a structured framework for\nevaluating their multifaceted capabilities and system designs.\nExisting studies often examine specific applications or agent\narchitectures in isolation, limiting a thorough understanding\nof their operational scope and performance dimensions. In\nthis survey, we address this gap by conducting an exten-\nsive evaluation of 49 research papers on LLM-based agents\ndeployed within healthcare and medicine. We propose an\nintegrated taxonomy spanning 7 core dimensions and 29 sub-\ndimensions, systematically characterizing these agents across\nCognitive Capabilities, Knowledge Management, Interaction\nPatterns, Adaptation & Learning, Safety & Ethics, Frame-\nwork Typology and Core Tasks & Subtasks. Our survey not\nonly defines and contextualizes each dimension but also maps\nthe selected studies against this taxonomy enabling a large\nscale quantitative analysis of prevailing methodologies. To\naid synthesis, we include a taxonomy diagram that visualizes\nhow the 49 studies map across the 7 dimensions and 29 sub-\ndimensions. We also derive broader insights that illuminate\nhow different dimensions and sub-dimensions manifest in\npractice. These insights help us in emphasizing on diverse\nagent capabilities, domain specific methodologies and vary-\ning implementation approaches in healthcare and medicine.\n2 VOLUME 14, 2026\n\n-- 2 of 25 --\n\nFIGURE 1. Timeline Diagram of All the Papers Evaluated in Our Work. Refer to Table 1 for Mapping Between Paper Names and Corresponding Citations\nThis extensive analysis provides a structured basis for de-\nveloping robust, reliable and ethical Agentic AI-driven LLM\nagents in healthcare.\nWhile several existing surveys [28]–[33] offer broad\noverviews of LLM-based agents, they tend to emphasize gen-\neral purpose capabilities without delving deeply into health-\ncare and medicine specific applications. [34] introduces per-\ntinent discussions around LLM-based agents in medicine but\noffers a limited exploration, covering roughly 25 papers.\nIn contrast, our survey expands the scope significantly by\nanalyzing 49 studies to capture a wider range of trends\nand advancements within healthcare and medicine. Similarly,\nsurveys such as [35]–[39] examine select capabilities like\nmemory, planning and reasoning in isolation. However, these\nfragmented perspectives fall short of providing a unified,\nmultidimensional framework. Our work addresses this gap by\ndelivering a comprehensive evaluation across 7 core dimen-\nsions and 29 sub-dimensions. This evaluation offers an inte-\ngrated understanding that aligns with the unique challenges\nof healthcare and medicine.\nThroughout this survey, we focus on a specific slice of\nAgentic AI: systems built around an LLM that drives the\nagent’s planning and decision-making, and can use tools,\nmaintain memory or take actions. We do not cover agents\nthat rely purely on symbolic reasoning, hand-crafted rules or\narchitectures where the LLM is not the primary controller.\nHybrid or multimodal setups are included only when the\nLLM is clearly the component coordinating the agent’s be-\nhavior.\nB. LITERATURE SEARCH PROCESS\nWe adopted a structured three-step filtering process to curate\nthe research papers reviewed in this survey.\nStep 1: We used multiple resources such as Google\nScholar, PubMed, DBLP, Scopus and ArXiv to conduct\na comprehensive search. Some of the search queries we\nused included LLM-based Agents in Healthcare, LLM-based\nAgents in Medicine, Using LLM-based Agents for Health-\ncare Tasks, LLM-based Agents for Electronic Health Record\nManagement, LLM-based Agents for Drug Discovery, LLM-\nbased Agents for Clinical Documentation, Using LLM-based\nAgents for Clinical Summarization and LLM-based Agents in\nthe Medical Domain. This helped us gather an initial pool of\nresearch articles focused on LLM-based agents in healthcare\nand medicine. The initial search resulted in 137 articles after\npreliminary manual filtering to exclude irrelevant works. The\npreliminary manual screening removed papers for reasons\nsuch as: (i) duplicate postings of the same work across ArXiv\nand conference proceedings (ii) short workshop abstracts\nor extended abstracts lacking an implemented system (iii)\npapers whose contributions centered solely on dataset cre-\nation rather than agent behavior (iv) incomplete manuscripts\nincluding posters, project pages or early-stage preprints with-\nout technical detail. A group of 3 reviewers independently\nscreened the initial pool of papers. Each paper was reviewed\nby at least 2 reviewers and disagreements were resolved\nin joint meetings through consensus. This process helped\nmaintain consistency and minimize individual reviewer bias\nduring inclusion/exclusion decisions.\nStep 2: We applied two stringent selection criteria to\nfurther narrow the corpus. First, we included only studies in\nwhich an LLM is the core component of the agent’s design\naligning with our focus on LLM-based agents. Second, we\nretained papers that explicitly address tasks in healthcare\nor medicine, while excluding studies primarily rooted in\nother domains. Because healthcare and medicine sometimes\nintersect with closely related fields such as biomedicine, we\nevaluated such overlaps case by case. If the core contribution\nof the paper was predominantly aligned with healthcare or\nmedicine even in the presence of interdisciplinary elements,\nwe included it in our survey.\nStep 3: We then limited the corpus to articles published\nbetween October 2023 and June 2025. Figure 1 shows the\ntimeline of all included papers. The combination of Steps 2\nVOLUME 14, 2026 3\n\n-- 3 of 25 --\n\nand 3 output gave us a curated set of 49 research papers that\nunderpin our evaluation framework.\nTo summarize the full pipeline, we also include a\nPRISMA-style flow diagram in Figure 2 outlining identifi-\ncation, screening, eligibility assessment and final inclusion\nof the 49 studies in this survey.\nC. OUTLINE\nThe remainder of the paper is structured as follows. Section\n2 introduces the 7 core dimensions and 29 sub-dimensions\nthat form the basis of our evaluation framework, providing\ndetailed definitions and motivations for each. In Section 3, we\npresent key insights derived from our analysis, including pat-\nterns such as the most frequently employed sub-dimensions\nin healthcare and medicine, methodological trends and dom-\ninant architectural choices. Finally, Section 4 concludes the\npaper by summarizing our contributions.\nII. EVALUATION DIMENSIONS\nThis section introduces the 7 evaluation dimensions and 29\nsub-dimensions that structure our analysis of 49 studies.\nThese dimensions are derived through a mixed method-\nology combining inductive extraction, structured synthesis\nand cross-referencing with prior frameworks. We began by\nperforming open coding on all 49 papers, identifying recur-\nring mechanisms related to planning, memory, interaction,\nlearning, safety and system structure. These codes are then\niteratively grouped into higher-level constructs through con-\nstant comparison until stable themes emerged. In parallel, we\nconsulted existing surveys on LLM-based agents, agentic ar-\nchitectures and healthcare-AI evaluation to ensure conceptual\ncontinuity while avoiding direct replication. Dimensions are\nretained only when: (i) they appeared in several independent\npapers (ii) they captured operational behaviors that could\nbe scored consistently (iii) they are not already subsumed\nby a broader construct. Sub-dimensions are defined a priori\nonly when the literature already used a well-established term\n(e.g., planning, knowledge integration). All remaining sub-\ndimensions are inductively extracted from empirical imple-\nmentation patterns in the 49-paper corpus. This combined\nprocess ensures that the taxonomy is both grounded in lit-\nerature and empirically reproducible.\nWe emphasize that these definitions are practical and de-\nsigned for consistent scoring across papers. They are not\nmeant to be exhaustive. Healthcare LLM agents are evolving\nquickly and accordingly scholars may draw these boundaries\ndifferently. Our aim is operational clarity and cross-study\ncomparability and not completeness. Each dimension admits\nmultiple valid readings and some capabilities can appear\nunder more than one heading depending on the system design\nand reported evidence. For the same reason, the categorical\nlabels we apply Fully Implemented ✓, Partially Implemented\n∆ and Not Implemented ✗ should be read as decision aids\nrather than hard thresholds. They are not strictly mutually\nexclusive. Systems often straddle boundaries and overlap can\nreasonably occur between ✓ and ∆ or between ∆ and ✗ de-\nFIGURE 2. PRISMA Flow Diagram of the Study Selection Process\npending on deployment context and evidence granularity. To\nhandle these gray areas consistently, we favor conservative\nassignment grounded in verifiable descriptions. We default to\n∆ where claims are implicit which means they are based only\non ablations or demonstrated solely in simulation. We use ✗\nwhere a mechanism is asserted without concrete procedure or\nevaluation. We assign ✓ where the capability is implemented\nend-to-end with explicit procedures and demonstrations. De-\nspite the inherent interpretive space, our goal is compara-\nbility. We therefore standardize terminology across papers,\napply common decision rules within each sub-dimension\nand record concise rationales explaining how evidence maps\nto labels. This yields a uniform reading of heterogeneous\ndesigns spanning clinical tasks and data modalities while\nleaving room for nuance and evolution. The taxonomy and\nlabels in this study should be treated as a transparent baseline\nfor cross-study synthesis and not as prescriptive judgments.\nSubsequent sections detail the rubrics we used so that others\ncan reproduce, refine or contest specific assignments as the\nfield matures.\nThe taxonomy diagram in Figure 3 and 4 visualizes our\nsurvey’s structure. In this diagram, the 7 evaluation dimen-\nsions are grouped with their 29 sub-dimensions. For each\nsub-dimension, we list every study rated Fully Implemented\n✓ under our rubric. This view acts as a navigational index.\nIt highlights clusters of maturity (sub-dimensions with many\n✓ papers), brings our attention to sparse areas where imple-\nmentations are rare and surfaces studies with multi-capability\ndesigns. This diagram clarifies overlap among neighboring\nconstructs and complements the tabular summaries.\nA. COGNITIVE CAPABILITIES\nAgents must first translate clinical goals into workable\ncourses of action, breaking long horizon objectives into\nmilestones and decision points. Contemporary prompting\nstrategies like Tree-of-Thoughts [23] and Plan-and-Solve\n4 VOLUME 14, 2026\n\n-- 4 of 25 --\n\nFIGURE 3. Taxonomy Diagram of Dimensions Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics,\nFramework Typology and their Corresponding Sub-Dimensions with Research Papers Rated Fully Implemented. Refer to Table 1 for Mapping Between Paper\nNames and Corresponding Citations.\n[40] formalize this decomposition and search. In healthcare,\nsuch structured lookahead supports care pathway drafting,\ntriage routing and prior-authorization checks under real-\nworld constraints. These plans depend on semantic intake\nfrom heterogeneous inputs including notes, labs, images,\ndevice streams and guidelines. Multimodal pretraining shows\nhow cross-modal alignment enables robust grounding [41]\nwhile domain tuned language models such as Med-PaLM 2\n[42] capture medical nomenclature and discourse. By con-\nverting raw EHR and imaging signals into clinically mean-\ningful representations, agents can anchor plans to patient\nspecific context rather than surface strings. Agents interleave\nVOLUME 14, 2026 5\n\n-- 5 of 25 --\n\nFIGURE 4. Taxonomy Diagram of Dimension Core Tasks & Subtasks and it’s Corresponding Sub-Dimensions with Research Papers Rated Fully Implemented.\nRefer to Table 1 for Mapping Between Paper Names and Corresponding Citations.\nreasoning with tool calls as exemplified in ReAct [43] and\nlearn when and how to invoke APIs as shown in Toolformer\n[44]. Because clinical stakes demand vigilance, agents bene-\nfit from self-monitoring that critiques intermediate products.\nReflective control loops maintain episodic traces to improve\nfuture iterations [45] while diversity aware decoding aggre-\ngates multiple rationales to stabilize conclusions [46]. These\nmechanisms surface deferral conditions, steer escalation to\nhumans and promote conservative behavior when evidence\nis weak. Finally, reliable clinical decisions require conver-\ngence across competing hypotheses and sources. Multi-agent\ndeliberation frameworks coordinate debate and mediation\ntoward consensus [47] whereas sampling-based cross-checks\nexpose factual divergence indicative of hallucination [48].\nSuch protocols reconcile guideline recommendations with\npatient level data, reduce contradictory orders and justify\nsuggestions with traceable agreement. Collectively, these ca-\npabilities constitute the Cognitive Capabilities of LLM-based\nagents. Table 1 reports evaluations across the 5 Cognitive\nCapabilities sub-dimensions:\n1) Planning\nPlanning is the agent’s capacity to synthesize, maintain and\nrevise executable task structures that link objectives to ac-\ntions. It entails principled task decomposition, temporally co-\nherent sequencing and hierarchical organization that distin-\nguishes strategic intent from tactical steps. Robust planning\nagents also enumerate alternative strategies, select among\nthem and run critique-refine loops to repair omissions or dead\nends. Within this survey, we judge Planning ✓ when there\nis clear evidence of dynamic plan construction with multi-\nstep decomposition, explicit comparison of alternatives or\nrefinement cycles and appropriate tool selection. We judge\nit ∆ when there is task breakdown or dynamic role as-\nsignment but no substantive strategy generation, comparison\nor iterative revision. It is ✗ when workflows are fixed or\nlimited to simple conditional branching. In clinical contexts,\nthe implemented form supports adaptive diagnostic workups,\nmulti-step prior-authorization reviews and iterative treatment\nplanning aligned to evolving patient data.\n2) Perception (Input Processing)\nPerception is the transformation of heterogeneous inputs into\nreliable, model usable representations through normaliza-\ntion, denoising and cross-modal fusion. Beyond tokenization,\nit encompasses various other things like ASR for speech,\ntemporal alignment for waveforms, structure induction for\nEHR fields etc. This is followed by construction of prove-\nnance sensitive embeddings suitable for downstream reason-\ning and action. For evaluation, ✓ denotes robust pipelines\nthat integrate multiple modalities via dedicated encoders and\ncross-modal fusion, exposing calibrated representations to\nthe agent’s planning and action components. ∆ describes\nsystems that perform competent text parsing or per-modality\nencoding with minimal fusion and limited preprocessing.\n✗ applies when inputs are passed as raw strings with no\nnormalization or multimodal handling.\n3) Action (Output & Execution)\nAction (Output & Execution) is the agent’s execution layer\nthat converts internal decisions into externally verifiable ef-\nfects. It encompasses controlled text production along with\n6 VOLUME 14, 2026\n\n-- 6 of 25 --\n\ntool and API invocation. Mature executors validate precon-\nditions and postconditions, manage side effects and route\nobservations back to the controller for closed loop operation.\nWe label this sub-dimension ✓ when the system demon-\nstrates actual tool use and external execution beyond text\ngeneration. It is ∆ when actions are limited to basic API\ncalls or database lookups without richer tool orchestration\nor environment manipulation. It is ✗ when outputs are text\nonly. In healthcare settings, the ✓ level enables safe medica-\ntion reconciliation, order validation and prior-authorization\nchecks with auditable traces.\n4) Meta-Capabilities\nMeta-Capabilities comprise introspective control over an\nagent’s own reasoning and actions. It comprises of generating\ncritiques of intermediate steps, calibrating confidence, iden-\ntifying knowledge gaps and deciding when to abstain or seek\nevidence. In clinical contexts, this layer enables agents to\nsurface uncertainty in differential diagnoses, trigger literature\nretrieval or second opinions and defer to clinicians when\nevidence is insufficient. For evaluation, ✓ indicates explicit\ncritique and revision loops, calibrated uncertainty estimates\ntied to deferral and logged escalation. ∆ reflects ad hoc self-\nmonitoring like memory feedback or heuristic self-checks.\n✗ indicates absence of self-critique, confidence signaling or\ndeferral behavior.\n5) Consistency & Conflict Resolution\nConsistency & Conflict Resolution in agents refers to the\nsystematic identification and reconciliation of contradictory\ninformation originating from parametric recall, external re-\ntrieval or multi-agent outputs. Effective implementations\ndeploy layered strategies including contradiction detection\nthrough natural language inference models and ensemble\nagreement protocols. In complex domains like healthcare,\nsuch mechanisms are vital for ensuring that recommen-\ndations remain coherent, evidence-based and aligned with\nestablished clinical standards. The extent of realization can\nvary: (a) Fully Implemented ✓ systems incorporate auto-\nmated conflict detection with structured resolution pipelines\nusing majority vote ensembling and adaptive re-weighting of\nspecialist outputs (b) Partially Implemented ∆ systems may\nrely on limited validation or ad hoc human oversight without\ncomprehensive reconciliation (c) Not Implemented ✗ omit\nexplicit mechanisms altogether, increasing the risk of unsafe\noutputs.\nB. KNOWLEDGE MANAGEMENT\nKnowledge Management in LLM-based agents centers on\nhow parametric knowledge is complemented and routed\nthrough external resources when the model’s internal recall\nis insufficient. Agents arbitrate between weights and the\nworld by invoking retrieval-augmented generation (RAG)\n[95], pretraining time retrieval such as REALM [96] and\nby interpolating with non-parametric memories as in kNN-\nLM [97]. In clinical settings, this blend helps surface up-to-\nTABLE 1. Evaluation of Cognitive Capabilities\nPapers Plan Perception Action Meta\nCapa-\nbilities\nConsistency\n& Conflict\nResolution\nColacare [25] ✗ ∆ ✗ ✓ ✓\nMedagent [49] ✗ ∆ ✗ ✓ ✓\nMedaide [50] ∆ ∆ ✗ ✗ ✗\nDoctoragent [51] ∆ ∆ ✗ ✗ ✗\nAihospital [52] ✗ ∆ ✗ ✗ ✓\nMmedagent [53] ∆ ✓ ✓ ✗ ✗\nMedchat [54] ∆ ✓ ✗ ✗ ✓\nMedco [55] ✗ ✓ ✓ ∆ ✗\nMedagentpro [56] ✓ ✓ ✓ ∆ ✗\nClinicalagent [57] ✓ ∆ ✓ ✗ ✗\nKtas [58] ✗ ∆ ✓ ✗ ✗\nAgentmd [59] ✗ ∆ ✓ ✗ ✗\nMdagent [60] ∆ ✓ ✗ ✓ ✓\nAgenthospital [61] ✗ ∆ ✗ ✓ ✗\nPharmagent [62] ✗ ✓ ✓ ✓ ✗\nTxagent [63] ✓ ∆ ✓ ✓ ✗\nAutoct [64] ✓ ∆ ✓ ✓ ✗\nKg4diagnosis [65] ∆ ∆ ✗ ✓ ✗\nMdteamgpt [66] ∆ ∆ ✗ ✓ ✓\nMitigating [67] ✗ ∆ ✗ ∆ ∆\nPolaris [68] ∆ ✓ ✗ ∆ ✓\nRxstrategist [69] ✗ ✓ ✗ ✗ ✗\nClinicallab [70] ∆ ✓ ✗ ✗ ✗\nAgenticllm [71] ✗ ∆ ✗ ✓ ✗\nSurgbox [72] ∆ ∆ ✗ ∆ ✗\nAipatient [73] ✗ ∆ ✗ ∆ ∆\nHealthagent [74] ✓ ✓ ✓ ✗ ✗\nIcdcoding [75] ✗ ∆ ✗ ✗ ✓\nAha [76] ✗ ∆ ✗ ✗ ✓\nDdo [77] ∆ ∆ ✗ ✗ ✗\nBeyond [78] ✗ ∆ ✗ ✗ ✓\nZodiac [26] ✗ ✓ ∆ ✗ ∆\nFhirviz [79] ✗ ∆ ∆ ✗ ✗\nFhir [80] ∆ ∆ ∆ ✗ ✗\nFuasagent [81] ✓ ✓ ✓ ✓ ✗\nAitherapist [82] ∆ ∆ ✗ ✗ ✗\nRadiology [83] ✗ ✓ ✗ ✓ ✓\nTriageagent [24] ✗ ∆ ✗ ✗ ✓\nPiors [84] ∆ ∆ ∆ ✓ ✗\nSelfevolve [85] ✗ ✓ ✗ ✓ ✓\nDrugagent [86] ✓ ∆ ✓ ✗ ✗\nCtagent [87] ✓ ✓ ✓ ✗ ✗\nAdagent [88] ∆ ✓ ✓ ✗ ∆\nDrugpilot [89] ∆ ✓ ✓ ✓ ✗\nLlmadmin [90] ✓ ✓ ✓ ✗ ✗\nSwarm [91] ✗ ✓ ✓ ✓ ✗\nDrugdiscover [92] ✗ ✓ ✓ ∆ ✗\nRagdrug [93] ✓ ✓ ✓ ✗ ∆\nDrugreason [94] ∆ ✓ ✓ ✗ ✓\ndate guidelines and trial evidence with citations for clinician\nreview. Equally important is the agent’s internal memory\narchitecture. Short-term buffers maintain discourse and tool\nuse state. On the other hand, long-term episodic and semantic\nstores compress prior interactions and domain ontologies\nunder learned controllers that page information into and out\nof context as in MemGPT [98]. These mechanisms reduce\ncontext length bottlenecks, stabilize multi-step plans and\nenable retrieval policies that are sensitive to patient spe-\ncific history. In healthcare, such memory supports longitu-\ndinal summarization, medication reconciliation and cross-\nVOLUME 14, 2026 7\n\n-- 7 of 25 --\n\nencounter continuity where sustained context improves care\nquality. Finally, knowledge must evolve and accordingly\nagents need to continuously index new documents, prioritize\nfresh sources and de-emphasize stale entries. Self-reflective\nretrieval frameworks that critique and re-query [99] can im-\nprove factuality and citation reliability while targeted para-\nmetric edits can correct entrenched facts at scale [100]. In\nclinical deployments, such update and forget mechanisms are\nvital for aligning agent outputs with evolving guidelines and\nnewly published trials. Table 2 summarizes outcomes across\nits 3 sub-dimensions:\n1) External Knowledge Integration\nExternal Knowledge Integration refers to an agent’s capabil-\nity to augment its intrinsic parametric knowledge encoded in\nmodel weights with non-parametric information. This non-\nparametric information is retrieved from external, often do-\nmain specific repositories at inference time. Such repositories\nmay include structured clinical databases, medical knowl-\nedge graphs, regulatory guideline repositories or unstruc-\ntured corpora embedded in vector indices. The integration\nprocess requires not only the retrieval of relevant content\nbut also mechanisms for arbitration between internally stored\nand externally sourced knowledge ensuring outputs are both\ntemporally current and contextually precise. In healthcare\nand clinical decision support, this enables an LLM-based\nagent to ground its reasoning in authoritative sources such as\ndrug interaction databases, treatment guidelines or up-to-date\nclinical trial results. The degree to which an agent embodies\nthis sub-dimension can vary: (a) fully realized implementa-\ntions ✓ incorporate structured RAG pipelines with calibrated\narbitration between internal recall and external evidence (b)\npartial implementations ∆ rely on limited, static or manually\ncurated external content (c) absent implementations ✗ oper-\nate purely from parametric memory.\n2) Memory Module\nMemory Module in LLM-based agents provide structured\nmechanisms for storing and retrieving information beyond\nthe transient context window enabling continuity and lon-\ngitudinal reasoning. Short-term memory mechanisms only\nmaintain immediate conversational history. However, long-\nterm stores capture episodic narratives like past consultations\nand semantic abstractions such as knowledge graphs. These\nmodules are often mediated by learned or rule-based con-\ntrollers that determine what information should be commit-\nted to persistent storage and when historical records should\nbe recalled for decision making. In healthcare applications,\nsuch architectures support richer patient interactions allow-\ning agents to reference prior lab results, follow-up notes\nor evolving care plans without reintroduction by the user.\nSystems may fully implement ✓ this sub-dimension through\nsophisticated, persistent multi-tier memory with dynamic\nread/write control. Systems may partially implement ∆ it\nthrough limited short-term session scoped recall or basic\nTABLE 2. Evaluation of Knowledge Management\nPapers External\nKnowledge\nIntegration\nMemory\nModule\nDynamic\nUpdates &\nForgetting\nColacare [25] ✓ ∆ ✗\nMedagent [49] ✗ ✗ ✗\nMedaide [50] ✓ ∆ ✗\nDoctoragent [51] ✗ ∆ ✗\nAihospital [52] ✗ ✗ ✗\nMmedagent [53] ✓ ∆ ✗\nMedchat [54] ✗ ✗ ✗\nMedco [55] ✗ ✓ ∆\nMedagentpro [56] ✓ ∆ ✗\nClinicalagent [57] ✓ ∆ ✗\nKtas [58] ✓ ∆ ✗\nAgentmd [59] ✓ ∆ ✗\nMdagent [60] ✓ ∆ ✗\nAgenthospital [61] ✓ ✓ ∆\nPharmagent [62] ✓ ✓ ∆\nTxagent [63] ✓ ∆ ✗\nAutoct [64] ✓ ∆ ✗\nKg4diagnosis [65] ✓ ✓ ∆\nMdteamgpt [66] ✓ ✓ ∆\nMitigating [67] ✗ ✗ ✗\nPolaris [68] ✓ ∆ ✗\nRxstrategist [69] ✓ ∆ ✗\nClinicallab [70] ✗ ✗ ✗\nAgenticllm [71] ✗ ✗ ✗\nSurgbox [72] ✓ ∆ ✗\nAipatient [73] ✓ ✓ ∆\nHealthagent [74] ✓ ✓ ∆\nIcdcoding [75] ✓ ∆ ✗\nAha [76] ✗ ✗ ✗\nDdo [77] ✓ ✓ ∆\nBeyond [78] ✓ ∆ ✗\nZodiac [26] ✓ ∆ ✗\nFhirviz [79] ✓ ✓ ∆\nFhir [80] ∆ ∆ ✗\nFuasagent [81] ✓ ✓ ∆\nAitherapist [82] ✗ ✗ ✗\nRadiology [83] ✓ ∆ ✗\nTriageagent [24] ✓ ∆ ✗\nPiors [84] ✓ ✓ ∆\nSelfevolve [85] ✓ ✓ ∆\nDrugagent [86] ✓ ∆ ✗\nCtagent [87] ✓ ✓ ∆\nAdagent [88] ✗ ✗ ✗\nDrugpilot [89] ✓ ✓ ✓\nLlmadmin [90] ✓ ∆ ✗\nSwarm [91] ✓ ✓ ∆\nDrugdiscover [92] ✓ ✓ ∆\nRagdrug [93] ✓ ∆ ✗\nDrugreason [94] ✓ ∆ ✗\nretrieval buffers. Systems may not implement ✗ it at all\nrelying solely on the model’s default context window.\n3) Dynamic Updates & Forgetting\nDynamic Updates & Forgetting captures an agent’s ability to\nkeep its knowledge current and hygienic rather than merely\ncumulative. Beyond simple retrieval, the system must: (i)\ningest new evidence via continuous indexing (ii) re-weight\nstored items using temporal decay (iii) remove stale or re-\ntracted facts through explicit pruning rules. In clinical con-\ntexts, these mechanisms align outputs with evolving guide-\n8 VOLUME 14, 2026\n\n-- 8 of 25 --\n\nlines, drug recalls and newly published or retracted trials\nthus reducing the risk of obsolete recommendations. We con-\nsider this ✓ when both sides of knowledge maintenance are\npresent: active addition (continuous updates/write-back) and\nexplicit forgetting (time-decay thresholds and deprecation\npolicies). It is ∆ when updates occur but no formal decay\nis defined resulting in static accumulation over time. It is ✗\nwhen the system is static with no continuous updates decay\nor pruning beyond the model’s default context.\nC. INTERACTION PATTERNS\nInteraction patterns specify how an agent is invoked, sustains\ncontext and negotiates turns across multimodal exchanges\nso that state remains coherent across intermittent sessions.\nConversation with LLM-based agents is not merely turn\ntaking but it is the disciplined management of context over\ntime. Robust dialogue practices such as greetings, confir-\nmations, clarifications and summarization stabilize meaning\nand keep state coherent [101]). Empirical studies of LLM\nvoice assistants likewise show richer, more adaptive turn\ntaking that mitigates breakdowns through proactive follow-\nups [102]. In clinical and patient facing settings, such dis-\nciplined conduct reduces miscommunication, improves data\ncapture and supports safer handoffs between encounters.\nBeyond direct chat, agent behavior must also be orchestrated\nby external signals like incoming lab results, device data\nstreams or workflow events. In healthcare operations, such\nevent-driven activation enables timely triage, order checks\nand monitoring escalations without relying on continuous\nuser supervision. Because clinical decisions have conse-\nquences, interaction must explicitly allocate roles for over-\nsight. Human-AI collaboration work in medicine shows that\nexpert steerable tools improve trust and utility without sac-\nrificing accuracy [103]. Finally, interactions must anticipate\nfailure and recover gracefully. Generic safeguards include\ngreedy decoding such as self-consistency to expose diver-\ngent reasoning paths [46], Chain-of-Verification routines that\nplan and answer fact checking questions before issuing a\nfinal response [104] and reflective replanning that rewrites\ngoals or tool sequences after unsuccessful trials [45]. Op-\nerationally, resilient agents employ transactional rollbacks,\nbounded retries, circuit breakers and degraded safe modes.\nIn clinical environments, such modality agnostic behaviors\nhelp avert propagation of errors such as halting downstream\norder placement after a failed formulary check, suppressing\nduplicate documentation after API timeouts etc. As compiled\nin Table 3, Interaction Patterns are assessed along:\n1) Conversational Mode\nConversational Mode characterizes an agent’s capacity for\nsynchronous, turn-based exchanges that preserve discourse\nstate across turns and sessions. Hallmarks include dialogue\nstate persistence, session scoped memory for user intents\nand support for clarifying follow-ups rather than single-shot\nreplies. Systems may expose a chat UI but are distinguished\nby continuity and resumability after interruptions. We rate\nthis ✓ when the agent provides a turn-based conversational\ninterface that maintains context across turns and supports\nresumptions. ∆ applies when multi-round interaction exists\nbut is primarily a structured workflow or prompt sequenced\nexchange with fragile context retention. ✗ describes single\nquery processing with no evidence of turn-based dialogue,\nsession continuity or conversational context maintenance. In\nhealthcare, virtual intake, symptom follow-ups and discharge\neducation implemented systems reduce re-entry of informa-\ntion and support more efficient clinician-patient exchanges.\n2) Event-Triggered Activation\nEvent-Triggered Activation denotes an agent’s capacity to\nautonomously monitor external signals via webhooks or mes-\nsage buses and initiate workflows when specified conditions\nare met without explicit user prompting. Mature designs\nsubscribe to streams, apply temporal windows, enrich events\nwith context and invoke idempotent handlers under rate lim-\nits. We rate this ✓ when real-time, automated triggers from\nexternal sources activate agents with continuous monitoring\nand proactive execution. ∆ is earned when basic triggering\nexists (API callbacks or scheduled polling) but activation is\nlargely initiated by the user or lacks durable stream integra-\ntion. ✗ is labeled when operation relies solely on prompted\ninteractions or internal thresholds with no autonomous mon-\nitoring of external streams. For healthcare settings, robust\nactivation delivers timely interventions like abnormal vitals,\nformulary aware order suppression etc.\n3) Human-in-the-Loop\nHuman-in-the-Loop captures an agent’s explicit insertion of\nhuman control during execution and not merely at input\nor after output. This is achieved via confirmation gates,\nuncertainty-triggered pauses and rollback controls. The gath-\nered feedback is then stored in an auditable manner to refine\nmemory or downstream policies. We rate this ✓ when users\ncan confirm, approve or redirect the agent mid-run. ∆ applies\nwhen only basic review or approval is simulated or confirma-\ntions are optional without durable feedback incorporation. ✗\ndescribes pipelines with no in-process oversight. In work-\nflows like prior-authorization and sensitive chart updates,\nrobust Human-in-the-Loop limits unchecked autonomy, im-\nproves accountability and supports clinical governance.\n4) Error Recovery\nError Recovery denotes an agent’s capacity to detect, contain\nand correct failures across parsing, planning, tool use and\nsystem integration. In this sub-dimension, the agent flags\nanomalies, conducts a structured diagnosis of likely causes\nand then applies corrective steps which can be issuing disam-\nbiguation prompts, switching to alternative tools or repairing\nparameters. All these corrective measures are taken ensuring\ntransactional safety. Mature designs incorporate explicit re-\ncovery nodes that capture exceptions and route control back\nto an executor for re-execution. We rate this ✓ when robust\ndetection, retries and fallback procedures are integrated as\nVOLUME 14, 2026 9\n\n-- 9 of 25 --\n\nTABLE 3. Evaluation of Interaction Patterns\nPapers Conver-\nsational\nMode\nEvent-\nTriggered\nActivation\nHuman-\nin-the\nLoop\nError\nRecovery\nColacare [25] ✗ ✗ ✗ ∆\nMedagent [49] ∆ ✗ ✗ ∆\nMedaide [50] ✓ ✗ ✗ ✗\nDoctoragent [51] ✓ ✗ ✗ ✗\nAihospital [52] ✓ ✗ ✗ ✗\nMmedagent [53] ✓ ✗ ✗ ✗\nMedchat [54] ✓ ✗ ✗ ✗\nMedco [55] ∆ ✗ ✗ ✗\nMedagentpro [56] ✗ ✗ ✗ ∆\nClinicalagent [57] ✓ ✗ ✗ ✗\nKtas [58] ✗ ✗ ✗ ✗\nAgentmd [59] ✗ ✗ ✗ ∆\nMdagent [60] ✓ ✗ ✗ ∆\nAgenthospital [61] ✗ ✓ ✗ ∆\nPharmagent [62] ✗ ✗ ✗ ∆\nTxagent [63] ✗ ✗ ✗ ∆\nAutoct [64] ✗ ✗ ✗ ∆\nKg4diagnosis [65] ✗ ✗ ✓ ✗\nMdteamgpt [66] ∆ ✗ ✗ ∆\nMitigating [67] ✓ ✗ ✗ ✗\nPolaris [68] ✓ ✗ ✓ ∆\nRxstrategist [69] ✗ ✗ ✗ ✗\nClinicallab [70] ✗ ✗ ✓ ✗\nAgenticllm [71] ✗ ✗ ✗ ✗\nSurgbox [72] ✓ ✓ ✗ ✗\nAipatient [73] ✓ ✗ ✗ ∆\nHealthagent [74] ✓ ✗ ✗ ✗\nIcdcoding [75] ✗ ✗ ∆ ✗\nAha [76] ✗ ✗ ✗ ✗\nDdo [77] ✓ ✗ ✗ ✗\nBeyond [78] ✗ ✗ ✗ ✗\nZodiac [26] ✗ ∆ ✗ ✗\nFhirviz [79] ✗ ✗ ✓ ✓\nFhir [80] ✗ ✗ ✗ ✗\nFuasagent [81] ✗ ✗ ✗ ✗\nAitherapist [82] ✓ ✗ ✗ ✗\nRadiology [83] ✗ ✗ ✗ ∆\nTriageagent [24] ✓ ✗ ✗ ✗\nPiors [84] ✓ ✗ ✗ ✗\nSelfevolve [85] ✓ ✗ ✓ ∆\nDrugagent [86] ✗ ✗ ✗ ✗\nCtagent [87] ✗ ✗ ✗ ✗\nAdagent [88] ✓ ✗ ✗ ✗\nDrugpilot [89] ✓ ✗ ✓ ✓\nLlmadmin [90] ✓ ✓ ✗ ∆\nSwarm [91] ✗ ✗ ✗ ∆\nDrugdiscover [92] ✗ ✗ ✗ ✗\nRagdrug [93] ✗ ✗ ✗ ✗\nDrugreason [94] ✓ ✗ ✗ ∆\nfirst class protocols with demonstrated re-execution paths. ∆\napplies when only basic detection or limited fallbacks and\nretries are present. ✗ describes pipelines lacking explicit run-\ntime error handling or recovery strategies. Robust recovery\nprevents error cascades in clinical care. It halts malformed\norder writes, suppresses duplicate documentation when APIs\ntime out and pauses chart updates until verification succeeds.\nD. ADAPTATION & LEARNING\nAdaptation & Learning is the discipline of keeping de-\nployed agents calibrated to a moving world. It begins with\ncontinuous sensing for distributional and behavioral shifts,\nthen applying targeted mitigations before clinical perfor-\nmance erodes. Drift can be detected by monitoring changes\nin text embedding distributions [105], by activation delta\nprobes [106] and by black box statistical tests that audit\nbehavior changes over time [107]. Mitigations span prompt\nhotfixes, domain adaptation and scheduled retraining. Their\nnecessity is evidenced by temporal dataset shifts degrading\nICU prediction models in EHRs [108]. In practice, health-\ncare deployments couple these monitors with escalation and\nrollback to preserve patient safety and regulatory traceabil-\nity. Beyond detection, agents must learn from evaluators.\nReinforcement-based adaptation formalizes feedback as re-\nwards. Research shows that constitutional self-supervision\nsubstitutes AI feedback for human labels to reduce harm-\nfulness [109] and verbal reward agents store reflective cri-\ntiques as episodic memories to steer subsequent decisions\nwithout weight updates [45]. In clinical settings, these path-\nways enable clinician-in-the-loop reward shaping and post\ndeployment alignment. For example, medical question an-\nswering systems refined with domain specific supervision\nand evaluation protocols achieve ground breaking reliability\non USMLE style questions [42]. Finally, rapid specialization\nunder data scarcity relies on meta-learning and few-shot\ncompetence. Gradient-based meta-learners initialize models\nfor fast adaptation from a handful of cases [110], while\nLLMs exhibit in-context learning that acquires new tasks\nfrom a few demonstrations at inference [111]. Combined\nwith retrieval and sparse labeling, these methods let agents\ngeneralize to a new hospital, imaging device or rare disease\nwith minimal annotation burden. This is especially crucial\nwhere prospective data collection is slow and expensive.\nTable 4 details Adaptation & Learning results across its 3\nsub-dimensions:\n1) Drift Detection & Mitigation\nThis sub-dimension concerns the capacity of LLM-based\nagents to remain reliable under evolving data distributions,\ntask definitions or usage contexts. Drift manifests when the\nstatistical profile of inputs diverges from the training regime\nor when task requirements subtly shift leading to perfor-\nmance degradation. In well implemented systems, statistical\ndivergence tests on incoming data streams, embedding space\ncomparisons or activation level drift classifiers provide early\nwarnings. This is followed by solid mitigation through re-\ntraining, prompt adaptation or deployment of updated models\nconstituting a ✓ state. In more limited cases, agents may\nexhibit only partial safeguards such as exposure to diverse\nsamples during iterative training that reduces but does not\ndirectly monitor drift, depicting a ∆ state. Conversely, sys-\ntems without explicit statistical monitoring or any corrective\nmechanisms remain vulnerable to silent degradation aligning\nwith an ✗ state. In healthcare, where distributional shifts\noccur due to population demographics or evolving clinical\nguidelines, drift detection and mitigation is indispensable for\npreserving patient safety and minimizing diagnostic error.\n10 VOLUME 14, 2026\n\n-- 10 of 25 --\n\nTABLE 4. Evaluation of Adaptation & Learning\nPapers Drift Detec-\ntion & Miti-\ngation\nReinforce-\nment Based\nAdaptation\nMeta-\nLearning &\nFew-Shot\nColacare [25] ✗ ✗ ✓\nMedagent [49] ✗ ✗ ✓\nMedaide [50] ✗ ✗ ✗\nDoctoragent [51] ✗ ✓ ✗\nAihospital [52] ✗ ✗ ✗\nMmedagent [53] ✗ ✗ ✗\nMedchat [54] ✗ ✗ ✗\nMedco [55] ✗ ✗ ✗\nMedagentpro [56] ✗ ✗ ✗\nClinicalagent [57] ✗ ✗ ✓\nKtas [58] ✗ ✗ ✗\nAgentmd [59] ✗ ✗ ✗\nMdagent [60] ✗ ✗ ✓\nAgenthospital [61] ✗ ✗ ✗\nPharmagent [62] ✗ ✗ ✗\nTxagent [63] ✗ ✗ ✗\nAutoct [64] ✗ ∆ ✗\nKg4diagnosis [65] ✗ ✓ ✗\nMdteamgpt [66] ✗ ✗ ✓\nMitigating [67] ✗ ✗ ✗\nPolaris [68] ∆ ✓ ✗\nRxstrategist [69] ✗ ✗ ✗\nClinicallab [70] ✗ ✗ ✗\nAgenticllm [71] ✗ ∆ ✗\nSurgbox [72] ✗ ✗ ✗\nAipatient [73] ✗ ✗ ✓\nHealthagent [74] ✗ ✗ ✗\nIcdcoding [75] ✗ ✗ ✗\nAha [76] ✗ ✗ ✓\nDdo [77] ✗ ✓ ✗\nBeyond [78] ✗ ✗ ✗\nZodiac [26] ✗ ✗ ✓\nFhirviz [79] ✗ ✗ ✗\nFhir [80] ✗ ✗ ✗\nFuasagent [81] ✗ ∆ ✗\nAitherapist [82] ✗ ✗ ✗\nRadiology [83] ✗ ✗ ✗\nTriageagent [24] ✗ ✗ ✗\nPiors [84] ✗ ✗ ✗\nSelfevolve [85] ✗ ✗ ✓\nDrugagent [86] ✗ ✗ ✗\nCtagent [87] ✗ ✗ ✓\nAdagent [88] ✗ ✗ ✗\nDrugpilot [89] ✗ ✗ ✗\nLlmadmin [90] ✗ ✗ ✗\nSwarm [91] ✗ ✗ ✗\nDrugdiscover [92] ✗ ✓ ✗\nRagdrug [93] ✗ ✗ ∆\nDrugreason [94] ✗ ✗ ✗\n2) Reinforcement-Based Adaptation\nThis sub-dimension captures how LLM-based agents refine\ntheir behavior by translating evaluative feedback into struc-\ntured reward signals that shape future decisions. In fully\nfledged implementations, explicit reinforcement learning\nmechanisms such as RLHF are used. In these mechanisms,\nexpert preferences are used to optimize policies that encode\nverbal feedback into memory for iterative improvement and\nmake up a ✓ label. These systems demonstrate continuous\nadaptation where reward-driven loops refine decision policies\nand integrate expert validation. In contrast, partial imple-\nmentations may rely on simplified forms of feedback such\nas binary success or failure signals, heuristic optimization,\nverbal reinforcement in prompts etc. These approaches pro-\nvide directional guidance but lack systematic reinforcement\nmechanisms thereby portraying a ∆ label. Finally, systems\nthat omit explicit reward modeling, reinforcement learning\nor preference-driven updates align with an ✗ category. In\nhealthcare contexts, safe adaptation requires agents to inte-\ngrate clinician feedback, regulatory requirements and patient\nspecific preferences.\n3) Meta-Learning & Few-Shot\nMeta-Learning & Few-Shot refers to the ability of LLM-\nbased agents to adapt quickly to new tasks or domains\nwith minimal supervision. Meta-learning methods such as\ngradient-based algorithms that train models to update effec-\ntively from only a few examples enable rapid reconfiguration\nacross tasks without requiring extensive retraining. Comple-\nmentary to this, in-context few-shot prompting leverages pre-\ntrained representations to generalize at inference time where\na handful of demonstrations within the prompt can guide\naccurate reasoning. Systems that combine these strategies\nusing either meta-learned initialization or sophisticated few-\nshot prompting protocols are regarded as ✓. More limited\napproaches such as relying solely on zero-shot generalization\nor retrieving exemplar cases without systematic adaptation\nare categorized as ∆. Meanwhile, frameworks that show\nno mention of few-shot adaptation, meta-learning protocols\nor rapid task specialization are classified as ✗. This sub-\ndimension’s capabilities are particularly consequential in\nmedicine where models must rapidly accommodate shifts\nin clinical practice, rare patient phenotypes and evolving\nevidence bases in dynamic care environments.\nE. SAFETY & ETHICS\nLLM agents in healthcare must proactively prevent unsafe\nbehaviors through layered alignment, systematic red team-\ning and attack aware orchestration. Empirical work shows\nthat jailbreaks can be auto-generated even when the model\nis a black box [112]. Recent studies document automatic\nprompt injection attacks [113] and organize defenses into\nclear taxonomies [114] while frameworks like Constitutional\nAI [109] and end-to-end red-teaming methods [115] establish\nprocedural guardrails. Equity requires detecting and mitigat-\ning systematic errors across patient groups, with evaluation\nand remediation guided by LLM bias surveys [116], [117].\nIn healthcare specifically, evidence such as the analysis by\n[118] of a widely used risk algorithm illustrates how proxy\ntargets can induce racial disparities, motivating stratified\nreporting and bias stress tests. Patient privacy hinges on\nminimizing identifiability and resisting model level leakage.\nEmpirical attacks retrieve verbatim training data from models\n[119] underscoring the need for privacy-preserving learning.\nIn healthcare, federated learning enables cross-institutional\ncollaboration without centralizing PHI [120] complemented\nby robust clinical text deidentification. These practices enable\nVOLUME 14, 2026 11\n\n-- 11 of 25 --\n\nmodel development, evaluation and monitoring while honor-\ning confidentiality constraints at the point of care. Finally,\ntrustworthy deployment demands verifiable compliance and\nauditability. Scholarly analyses detail how the EU AI Act\nreshapes risk classification and obligations for health AI\n[121]. In the U.S., reviews of device oversight highlight gaps\nin transparency and representation for AI tools [122]. These\nframeworks ground provenance logging, rationale tracing\nand post market surveillance necessary for clinical account-\nability. Table 5 presents Safety & Ethics evaluations across\nits 4 sub-dimensions:\n1) Safety Guardrails & Adversarial Robustness\nSafety Guardrails & Adversarial Robustness defines the de-\nfense controls that prevent, detect and contain harmful behav-\nior when agents are steered intentionally or accidentally away\nfrom intended clinical use. It spans hardening of inputs to\nprevent anything like prompt injection, resilient planning and\noutput governance with continuous stress testing. Under this\nsub-dimension, ✓ denotes mature, multi-stage safeguards\nwith automated detectors, adversarial evaluation and rapid\nremediation pathways. ∆ indicates isolated filters or ad hoc\nhuman review without systematic testing. ✗ reflects the ab-\nsence of explicit mechanisms or evidence of effectiveness.\nIn healthcare delivery, the distinction between these labels\nis practical. Robust systems block unsafe orders, resist ma-\nnipulation of EHR linked tools, catch dosing anomalies and\nprevent escalation of failures across multi-step workflows.\n2) Bias & Fairness\nBias & Fairness concerns whether an agent’s behavior re-\nmains equitable across clinically salient populations and\ncontexts. It requires: (i) representative data with verified\nlabels (ii) modeling choices that constrain disparate error\n(iii) deployment policies to minimize inequity. Within this\nsub-dimension, ✓ denotes balanced representation across\nclinically salient cohorts like age and gender. It also com-\nprises of subgroup bias analyses with reported disparities and\napplied mitigation. ∆ applies when only privacy steps such as\ndeidentification/anonymization are used or bias concerns are\nmerely acknowledged. But there is no demographic auditing,\nno fairness metrics and no implemented bias detection or\nmitigation mechanisms. ✗ describes the absence of bias as-\nsessment and fairness mechanisms completely. In healthcare,\nbias and fairness is essential to prevent underdiagnosis or\ninequitable access particularly across intersections of race,\nage, sex, language, disability and socioeconomic status.\n3) Privacy-Preserving Mechanism\nThis sub-dimension specifies the architectural and procedural\ncontrols that restrict who and what can access patient data\nacross the agent lifecycle. This sub-dimension broadly cov-\ners mechanisms including edge inference, trusted execution,\nencryption in transit, private retrieval with scoped context\nwindows, deidentification/pseudonymization and differential\nprivacy for training as well as analytics. Programs should\nTABLE 5. Evaluation of Safety & Ethics\nPapers Safety\nGuardrails &\nAdversarial\nRobustness\nBias &\nFairness\nPrivacy\nPreserving\nMechanism\nRegulatory\n& Com-\npliance\nConstraints\nColacare [25] ✗ ∆ ∆ ✗\nMedagent [49] ✗ ✗ ✗ ✗\nMedaide [50] ∆ ∆ ∆ ✗\nDoctoragent [51] ∆ ✗ ✗ ✓\nAihospital [52] ✗ ∆ ∆ ✗\nMmedagent [53] ✗ ✗ ✗ ✗\nMedchat [54] ✗ ✗ ✗ ✗\nMedco [55] ✗ ✗ ∆ ✗\nMedagentpro [56] ✗ ✗ ✗ ✗\nClinicalagent [57] ✗ ✗ ✗ ✗\nKtas [58] ✗ ✗ ✓ ✓\nAgentmd [59] ✗ ✗ ∆ ∆\nMdagent [60] ✗ ∆ ✗ ✗\nAgenthospital [61] ✗ ∆ ✗ ✗\nPharmagent [62] ✗ ✗ ✗ ✗\nTxagent [63] ∆ ∆ ✓ ✗\nAutoct [64] ✗ ✗ ✗ ✗\nKg4diagnosis [65] ∆ ✗ ✗ ✗\nMdteamgpt [66] ✓ ∆ ✗ ✗\nMitigating [67] ✗ ✓ ✗ ✗\nPolaris [68] ✓ ✓ ✓ ✗\nRxstrategist [69] ✗ ✗ ∆ ✗\nClinicallab [70] ∆ ✓ ∆ ∆\nAgenticllm [71] ∆ ✗ ✗ ✗\nSurgbox [72] ∆ ∆ ∆ ✗\nAipatient [73] ∆ ∆ ✓ ✓\nHealthagent [74] ✗ ∆ ∆ ✗\nIcdcoding [75] ✗ ✗ ∆ ✗\nAha [76] ∆ ✗ ∆ ✗\nDdo [77] ✗ ✗ ✗ ✗\nBeyond [78] ✗ ✗ ✓ ✗\nZodiac [26] ∆ ✓ ✓ ✓\nFhirviz [79] ∆ ✗ ✗ ✗\nFhir [80] ✗ ✗ ✓ ✗\nFuasagent [81] ∆ ∆ ✓ ✓\nAitherapist [82] ✗ ✗ ✗ ✗\nRadiology [83] ∆ ✗ ✗ ✗\nTriageagent [24] ✗ ✗ ∆ ✗\nPiors [84] ✗ ∆ ∆ ✗\nSelfevolve [85] ✗ ✓ ✗ ✗\nDrugagent [86] ✗ ✗ ✗ ✗\nCtagent [87] ✗ ✗ ✗ ✗\nAdagent [88] ✗ ✗ ✓ ✗\nDrugpilot [89] ∆ ✗ ✗ ✗\nLlmadmin [90] ✓ ✗ ∆ ✗\nSwarm [91] ✗ ✗ ✗ ✗\nDrugdiscover [92] ✗ ✗ ✗ ✗\nRagdrug [93] ✗ ✗ ✗ ✗\nDrugreason [94] ✗ ✗ ✗ ✗\nalso test privacy explicitly via threat modeling, leakage\naudits and redaction verification. ✓ indicates agent level\nprivacy mechanisms beyond dataset preprocessing entailing\non-device handling of sensitive inputs, built in deidentifi-\ncation or anonymization, strong encryption and IRB/ethics\napproval when human or clinical data are involved. Many\nimplementations also use a dual layer design that keeps\nsensitive processing local. ∆ applies when privacy is lim-\nited to dataset deidentification or general compliance claims\n(e.g., HIPAA compliant). This does not incorporate an agent\n12 VOLUME 14, 2026\n\n-- 12 of 25 --\n\nside deidentification/anonymization mechanism or technical\ncontrols such as encryption, differential privacy and secure\ncomputation. ✗ describes systems with no technical privacy\ncontrols as defined above. In clinical deployments, these\ncontrols prevent PHI exfiltration from EHR linked tools,\nreduce insider exposure and enable compliant collaboration\nwithout centralizing sensitive data.\n4) Regulatory & Compliance Constraints\nRegulatory & Compliance Constraints specifies how an\nagent’s design, data handling and operating procedures sat-\nisfy binding laws across collection, training, inference and\npost deployment monitoring. Core elements include: (i) doc-\numented consent and lawful bases (ii) role scoped access\nand retention schedules (iii) cross-border transfer controls\n(iv) formal risk assessments that tie policies to technical\nsafeguards. Compliance should be evidenced and not merely\nasserted through policies, test records and release gates.\nIn healthcare, these controls determine whether an agent’s\nrecommendation features would be treated as regulated soft-\nware, whether PHI handling meets HIPAA or GDPR duties\nand whether deployments withstand clinical legal review. ✓\nindicates clear alignment with applicable laws like HIPAA\nor GDPR, operational consent and retention controls. It also\nencompasses IRB or ethics approval when human subjects or\nclinical data are involved and incident response procedures\nthat include documented drills. ∆ applies when evidence is\nlimited to isolated attestations like HIPAA compliant cloud\nand third party certifications. This does not cover docu-\nmented consent flows or risk assessment with policy state-\nments that lack operational evidence and reliance on vendor\nassurances. ✗ describes systems with no explicit mapping to\nlaws or standards.\nF. FRAMEWORK TYPOLOGY\nFramework Typology delineates the structural and opera-\ntional blueprints underlying LLM-based agent systems. It\narticulates how multiple reasoning units are composed and\nhow control is exercised over their joint behavior. In many\nrecent systems, we see a design that partitions cognitive\nlabor across several specialized agent roles which collaborate\nvia rounds of discussion to reach consensus. For example,\n[49] uses a multi-round discussion among LLM agents that\nmimic domain experts, combining their individual analyses\ninto a summary before arriving at a decision. Similarly, the\nMulti-Agent Conversation (MAC) [123] framework emulates\nmultidisciplinary team discussions in rare disease diagnosis.\nIt involves multiple doctor agents plus a supervisor agent\ndiscussing clinical features and different diagnostic hypothe-\nses. Systems of this kind yield benefits in medical question\nanswering, clinical decision support and diagnosis because\nthey mirror multidisciplinary workflows. They contrast with\nmonolithic designs where a single LLM is responsible for all\nstages of reasoning which may be simpler but risk domain\nmisknowledge in healthcare settings. Complementing the\ncomposition of agent roles is the mechanism by which con-\ntrol, state, feedback and adaptation are governed over time.\nThis includes how tasks are orchestrated and whether there\nis a central controller that assigns subtasks, monitors agent\noutputs and enforces checks. For instance, [124] implements\na central planning agent that breaks down complex objectives\nand delegates to sub-agents, then aggregates and synthesizes\ntheir outputs. Such centralized orchestration is particularly\ncrucial in clinical environments to ensure compliance, to\nmanage latency and to integrate human interventions at criti-\ncal junctures. On the other hand, some frameworks explore\ndecentralized or adaptive orchestration. Along those lines,\n[125] lets agents self-specialize, evolve their connections in\na DAG structure and route tasks without a single central con-\ntroller. Table 6 provides Framework Typology assessments\nacross:\n1) Multi-Agent Design\nMulti-Agent Design captures how responsibilities within an\nLLM-based system are distributed across one or multiple\nagents and how these agents interact to accomplish tasks.\nAt one extreme, single-agent designs encapsulate reasoning,\nplanning and execution within a unified process providing us\nwith simplicity but limiting specialization. More advanced\nsystems decompose functionality into distinct agents such\nas planners, retrievers or verifiers. These distinct agents\nthen exchange messages or deliberate collectively, thereby\nenabling modularity, redundancy and clearer alignment with\ndomain specific expertise. In healthcare, such distributed\nstructures can emulate multidisciplinary collaboration. For\ninstance, having separate agents to parse imaging results, val-\nidate treatment guidelines and draft patient facing summaries\nresembles such multidisciplinary collaboration. Evaluating\nthis sub-dimension requires distinguishing whether a system\ndemonstrates a genuine multi-agent architecture, only partial\ntraces of such coordination or no such implementation at all.\nThus, ✓ applies when specialized roles are clearly instanti-\nated, ∆ captures ambiguous or superficial coordination and ✗\ndenotes monolithic or tool-augmented single-agent systems.\n2) Centralized Orchestration\nCentralized Orchestration refers to how control is exercised\nover the flow of tasks, data and decisions in LLM-based agent\nsystems. In its strongest form, a central controller manages\nthe sequencing of agents, monitors their outputs and inte-\ngrates results into a coherent whole. Although, centralization\ncan introduce single points of failure and latency bottlenecks,\nit ensures global consistency, enables oversight and provides\nclear points of intervention. Other frameworks rely on looser\ncoordination such as hierarchical delegation or peer-to-peer\ncommunication where agents collaborate without a single\ncoordinating authority. These offer flexibility but may reduce\nreliability in safety critical settings. Some systems operate\nwith only sequential task execution and minimal oversight,\nresembling simple pipelines rather than true orchestration.\nIn healthcare, these distinctions carry significant weight. A\nrobust orchestrator can ensure that multiple evidence sources\nVOLUME 14, 2026 13\n\n-- 13 of 25 --\n\nTABLE 6. Evaluation of Framework Typology\nPapers Multi-Agent\nDesign\nCentralized\nOrchestration\nColacare [25] ✓ ✓\nMedagent [49] ✓ ∆\nMedaide [50] ✓ ✓\nDoctoragent [51] ✓ ✓\nAihospital [52] ✓ ∆\nMmedagent [53] ✗ ✗\nMedchat [54] ✓ ∆\nMedco [55] ✓ ∆\nMedagentpro [56] ✗ ∆\nClinicalagent [57] ✓ ✓\nKtas [58] ✓ ∆\nAgentmd [59] ✗ ✗\nMdagent [60] ✓ ✓\nAgenthospital [61] ✓ ✓\nPharmagent [62] ✓ ∆\nTxagent [63] ✓ ∆\nAutoct [64] ✓ ∆\nKg4diagnosis [65] ✓ ✓\nMdteamgpt [66] ✓ ✓\nMitigating [67] ✓ ∆\nPolaris [68] ✓ ✓\nRxstrategist [69] ✓ ∆\nClinicallab [70] ✓ ∆\nAgenticllm [71] ∆ ✗\nSurgbox [72] ✓ ✓\nAipatient [73] ✓ ∆\nHealthagent [74] ✗ ✗\nIcdcoding [75] ✓ ∆\nAha [76] ✓ ∆\nDdo [77] ✓ ∆\nBeyond [78] ✓ ∆\nZodiac [26] ✓ ∆\nFhirviz [79] ✓ ∆\nFhir [80] ✓ ✓\nFuasagent [81] ✓ ∆\nAitherapist [82] ✓ ∆\nRadiology [83] ✓ ∆\nTriageagent [24] ✓ ∆\nPiors [84] ✓ ∆\nSelfevolve [85] ✓ ∆\nDrugagent [86] ✓ ∆\nCtagent [87] ✗ ✗\nAdagent [88] ✗ ✗\nDrugpilot [89] ✗ ✗\nLlmadmin [90] ✓ ✓\nSwarm [91] ✓ ∆\nDrugdiscover [92] ✗ ✗\nRagdrug [93] ✓ ∆\nDrugreason [94] ✓ ✓\nare reconciled before clinical decisions are proposed and\ntrigger escalation to human experts when uncertainty is high.\nWithout such orchestration, systems risk fragmented reason-\ning, missed contradictions and limited accountability. Opera-\ntionally, orchestration is often realized via workflow engines\nand policy-based schedulers that implement timeouts, retries\nand circuit breakers. The evaluation of this sub-dimension\nrests on the sophistication of coordination. ✓ applies when\na central orchestrator is explicitly defined and bi-directional\ncontrol is visible. ∆ captures looser structures such as peer-\nto-peer or hierarchical delegation. ✗ describes sequential or\nsingle-agent designs.\nG. CORE TASKS & SUBTASKS\nCore tasks and subtasks define what an LLM-based agent\nactually does in healthcare. They scope the agent’s opera-\ntional responsibilities and the verifiable outputs it must de-\nliver. Starting from raw clinical data, these tasks progress to-\nward clinical recommendations and system level evaluation.\nThis dimension therefore grounds agent design in concrete\nworkflows and measurable endpoints. To start with, agents\ncan transform unstructured records into computable artifacts.\nThey can summarize problems, extract entities and link to\ncodes. They can reason over multi-table EHRs to answer\nrecord level queries as shown by EHRAgent [126]. Multi-\nagent pipelines can mirror documentation roles as well. For\nexample, ColaCare [25] coordinates DoctorAgents with a\nsupervising MetaAgent to integrate structured EHR data and\ntext reasoning. [76] frames prior-authorization evidence ex-\ntraction as a multi-agent classification and retrieval problem.\nThese designs connect directly to everyday charting, coding\nand utilization management. Next, agents can answer clinical\nquestions and broker guideline-based support. MDAgents\n[60] adapts agent roles moderator, retriever, verifier to task\ncomplexity and shows gains across medical decision bench-\nmarks. For EHR-grounded questions, agents plan tool use\nand compute evidence inside the chart as in EHRAgent [126].\nThis pattern ties answers to provenance which clinicians need\nfor accountable decision support. Further, agents can conduct\ntriage and seed differentials under uncertainty. Role special-\nized teams emulate emergency clinicians, pharmacists and\ncoordinators. [58] shows how a multi-agent clinical decision\nsupport system aligned to the Korean Triage and Acuity Scale\noperationalizes triage, treatment planning and routing in the\nemergency department. Hospital simulations let agents prac-\ntice intake, inquiry and differential ranking end-to-end as in\n[61]. These approaches reflect the time pressure, missingness\nand bias checks typical of frontline care. Next, agents can\nperform diagnostic reasoning through plans, tool calls and\nexplicit updates to hypotheses. Hierarchical teams split gen-\neralist intake from subspecialist review while grounding steps\nin knowledge graphs as discussed in [65]. MedAgent-Pro\n[56] showcases a multimodal reasoning agent for diagnosis.\nModular designs target interactive differential diagnosis with\nan orchestrator and role agents as the authors of MEDDx-\nAgent show in [127]. This mirrors consult pathways where\nuncertainty tracking and escalation are mandatory. Contin-\nuing, agents can plan treatments and verify prescriptions.\nFrameworks focused on therapeutics treat tool use as a first\nclass operation. TxAgent [63] selects from a ToolUniverse\nto check contraindications and personalize options. Prescrip-\ntion verification can be staged across indication, dose and\ninteraction checks with an agentic pipeline as documented\nin Rx Strategist [69]. Conversational reconciliation agents\nbring patients into the loop and reconcile lists before orders\nare signed [128]. These steps align with order sets, pharmacy\nverification and stewardship policies in practice. Agents can\nalso accelerate discovery and clinical trials. In discovery,\n14 VOLUME 14, 2026\n\n-- 14 of 25 --\n\nchemistry agents plan syntheses and reason over lab tools as\nillustrated by ChemCrow [129]. In trials, multi-agent systems\nsupport outcome prediction and study analytics [57]. Patient-\ntrial matching benefits from agentic knowledge augmentation\n[130] and complementary retrieval + LLM approaches such\nas TrialGPT [131]. These functions shorten candidate screen-\ning and increase equitable access to studies. Finally, agents\ncan sustain patient interaction and monitoring between visits.\nWearable systems compute personalized insights via agen-\ntic code execution and retrieval as the experiments show\nin [132]. Clinical deployments study physician supervised\nagents for medication reconciliation and safe communication\n[128]. These designs map to nurse line triage, remote mon-\nitoring programs and digital chronic care pathways. Lastly,\nagents can be benchmarked and stress tested in interactive,\ntool rich environments. Simulation testbeds evaluate end-to-\nend decisions, dialogue and tool use with realistic artifacts.\nAgentClinic [133] measures agent behavior in multimodal\nclinical encounters across specialties and languages. MedA-\ngentBench [134] embeds agents in a FHIR compliant vir-\ntual EHR with hundreds of physician written tasks. Such\nplatforms link agent behavior to safety, external validity and\nworkflow impact the way health systems evaluate new tools.\nTables 7 and Table 8 present the Core Tasks & Subtasks\nevaluations across:\n1) Clinical Documentation & EHR Analysis\nThis sub-dimension evaluates an agent’s ability to convert\nheterogeneous clinical documentation and EHR artifacts into\ncomputable and clinician usable outputs. Characteristics of\nthis sub-dimension span chart summarization, extraction of\nclinically salient entities, mapping to codes like ICD, risk\nprediction from longitudinal signals and draft generation\nof reports like radiology impressions. An agent merits ✓\nwhen it demonstrates clear medical record processing and\nstructured information extraction on real clinical data and not\njust demos. This could include supporting core EHR analysis,\nclinical prediction tasks, reading from and writing to FHIR\nand handling specialty reports. ∆ indicates basic record gen-\neration or narrow document handling like prescriptions only\nand/or reliance on simulated rather than real documentation.\n✗ applies when no EHR analysis is present.\n2) Medical Question Answering & Decision Support\nMedical Question Answering & Decision Support deter-\nmines whether an agent can answer clinical questions and de-\nliver guideline-grounded decision support across modalities\nand workflows. Capabilities include: (i) factoid and synthesis\nquestion answering over authoritative medical sources (ii)\nretrieval-augmented recommendations (iii) multi-turn diag-\nnostic questioning (iv) task specific support such as triage\nclassification, cardiology assessment, surgical planning ad-\nvice and visual question answering. ✓ applies when either\ncapability medical question answering or decision support is\nclearly realized. This could include domain specific scientific\nquestion answering with benchmark validation, evidence-\nbased answers tied to citations, structured diagnostic pro-\ncesses, real-time recommendations, visual question answer-\ning for radiology regions and systematic reasoning traces. ∆\ncaptures narrow or limited scope especially when the demon-\nstrations are simulation-based only. Prior-authorization med-\nical necessity checks, prescription verification questions, di-\nalogue without robust guideline retrieval are good examples\nfor ∆. ✗ denotes the absence of medical question answering\nor decision support.\n3) Triage & Differential Diagnosis\nThis sub-dimension examines an agent’s capability to turn\nfirst contact information into two outputs: an acuity decision\nand a defensible list of alternatives. The agent elicits the\nchief complaint and history. It synthesizes vitals along with\ncontext and asks targeted follow-ups. It aligns to established\ntriage scales like ESI, KTAS and recommends a receiving\nservice or department with a brief rationale. In parallel, it\nconstructs a differential diagnosis, lists key discriminators\nand proposes next tests. ✓ applies when either triage or\ndifferential diagnosis is clearly implemented. This includes\nsymptom processing with ESI/KTAS-based urgency, depart-\nment recommendations with reasoning, production of ranked\nalternatives and safe routing via role agents. ∆ captures nar-\nrow diagnosis without explicit prioritization, single condition\nclassifiers, probability lists without urgency or simulation\nonly workflows. ✗ denotes the absence of these functions. In\nclinical care, these capabilities directly govern disposition,\ntime to treatment and escalation.\n4) Diagnostic Reasoning\nDiagnostic Reasoning tests an agent’s capacity to plan and\nexecute multi-step clinical inference that links targeted ev-\nidence gathering to a defensible final diagnosis. Core be-\nhaviors include: (i) eliciting and structuring new data (ii)\nselecting and sequencing diagnostic tests (iii) interpreting\nresults from structured and unstructured sources (iv) main-\ntaining and revising hypotheses (v) fusing inputs from spe-\ncialist agents (vi) aligning conclusions with guidelines (vii)\ntraversing knowledge graphs (viii) calibrating confidence\nwith explicit discriminators. An agent merits ✓ when it\nexhibits a structured reasoning workflow, performs active\ndata acquisition, ensembles specialist opinions via princi-\npled decision fusion and outputs ranked differentials with\nrationale. ∆ captures shallow or single-shot classification,\nlimited aggregation or region specific heuristics. ✗ denotes\nno diagnostic inference beyond extraction.\n5) Treatment Planning & Prescription\nTreatment Planning & Prescription concerns an agent’s abil-\nity to translate diagnostic context into an individualized\ntreatment plan and executable orders. Functionalities include\nselecting pharmacologic and non-pharmacologic options,\npersonalizing dose, checking contraindications, reconciling\nactive medications and generating patient counseling with\nstop criteria. Robust systems also account for allergies, re-\nVOLUME 14, 2026 15\n\n-- 15 of 25 --\n\nTABLE 7. Evaluation of Core Tasks & Subtasks Part 1\nPapers Clinical\nDocu-\nmentation\n& EHR\nAnalysis\nMedical\nQuestion\nAnswering\n& Decision\nSupport\nTriage &\nDifferential\nDiagnosis\nDiagnostic\nReasoning\nColacare [25] ✓ ✓ ∆ ∆\nMedagent [49] ✓ ✓ ∆ ∆\nMedaide [50] ∆ ✓ ✓ ✓\nDoctoragent [51] ✗ ✓ ✓ ✓\nAihospital [52] ✓ ∆ ∆ ✓\nMmedagent [53] ✓ ✓ ✗ ∆\nMedchat [54] ∆ ∆ ∆ ✓\nMedco [55] ∆ ∆ ∆ ✓\nMedagentpro [56] ✗ ✓ ✓ ✓\nClinicalagent [57] ✗ ✗ ✗ ✗\nKtas [58] ✗ ✓ ✓ ∆\nAgentmd [59] ✓ ✓ ∆ ∆\nMdagent [60] ✓ ✓ ✓ ✓\nAgenthospital [61] ∆ ✓ ✓ ✓\nPharmagent [62] ✗ ✗ ✗ ✗\nTxagent [63] ✗ ✓ ✗ ✗\nAutoct [64] ✗ ✗ ✗ ✗\nKg4diagnosis [65] ∆ ✓ ✓ ✓\nMdteamgpt [66] ✗ ✓ ✓ ✓\nMitigating [67] ∆ ✓ ✓ ✓\nPolaris [68] ✓ ✓ ✓ ✓\nRxstrategist [69] ∆ ∆ ✗ ∆\nClinicallab [70] ✓ ✓ ✓ ✓\nAgenticllm [71] ✓ ✗ ✗ ✗\nSurgbox [72] ∆ ✓ ✗ ✗\nAipatient [73] ✓ ✓ ✗ ✗\nHealthagent [74] ✓ ✓ ✗ ✗\nIcdcoding [75] ✓ ✗ ✗ ∆\nAha [76] ✓ ∆ ✗ ∆\nDdo [77] ✓ ∆ ✓ ✓\nBeyond [78] ✗ ✓ ∆ ✓\nZodiac [26] ✓ ✓ ∆ ✓\nFhirviz [79] ✓ ✗ ✗ ✗\nFhir [80] ✓ ✗ ✗ ✗\nFuasagent [81] ∆ ∆ ✗ ∆\nAitherapist [82] ✗ ∆ ✗ ✗\nRadiology [83] ✓ ✗ ✗ ✓\nTriageagent [24] ✓ ✓ ✓ ∆\nPiors [84] ✓ ✓ ✓ ∆\nSelfevolve [85] ∆ ✓ ∆ ✓\nDrugagent [86] ✗ ✗ ✗ ✗\nCtagent [87] ✓ ✓ ∆ ∆\nAdagent [88] ∆ ✓ ∆ ∆\nDrugpilot [89] ✗ ✗ ✗ ✗\nLlmadmin [90] ✓ ✗ ✗ ✗\nSwarm [91] ✗ ✗ ✗ ✗\nDrugdiscover [92] ✗ ✓ ✗ ✗\nRagdrug [93] ∆ ✓ ✗ ✗\nDrugreason [94] ✗ ✗ ✗ ✗\nnal function, comorbidities and formularies. They can also\nprovide shared decision prompts, record provenance and\nhand off to a pharmacist or prescriber for verification. ✓\nis warranted when either treatment planning or prescription\nis clearly implemented. Under this label, the system pro-\nvides explicit recommendations, interaction checks, agentic\npharmacist review or tool-based safety checks and rationale\ntied to patient factors. ∆ signals basic option selection or\ntemplated suggestions without dose optimization, interaction\nscreening or personalization. It can also have demonstrations\nTABLE 8. Evaluation of Core Tasks & Subtasks Part 2\nPapers Treatment\nPlanning\n& Pre-\nscription\nDrug\nDiscovery\n& Clinical\nTrial\nDesign\nPatient\nInterac-\ntion &\nMonitor-\ning\nBench-\nmarking &\nSimulation\nEnviron-\nment\nColacare [25] ✗ ✗ ✗ ✓\nMedagent [49] ✗ ✗ ✗ ✓\nMedaide [50] ✓ ✗ ∆ ✓\nDoctoragent [51] ✓ ✗ ✓ ✓\nAihospital [52] ✓ ✗ ✓ ✓\nMmedagent [53] ✗ ✗ ✗ ✓\nMedchat [54] ∆ ✗ ✓ ✗\nMedco [55] ∆ ✗ ∆ ✓\nMedagentpro [56] ✗ ✗ ✗ ✓\nClinicalagent [57] ✗ ✓ ✗ ∆\nKtas [58] ✓ ✗ ✗ ✓\nAgentmd [59] ✗ ✗ ✗ ✓\nMdagent [60] ✗ ✗ ✗ ✓\nAgenthospital [61] ✓ ✗ ✓ ✓\nPharmagent [62] ✗ ✓ ✗ ✓\nTxagent [63] ✓ ∆ ✗ ✓\nAutoct [64] ✗ ✓ ✗ ✓\nKg4diagnosis [65] ∆ ✗ ✗ ✓\nMdteamgpt [66] ∆ ✗ ✗ ✓\nMitigating [67] ✗ ✗ ✗ ✓\nPolaris [68] ∆ ✗ ✓ ✓\nRxstrategist [69] ✓ ✗ ✗ ∆\nClinicallab [70] ✓ ✗ ∆ ✓\nAgenticllm [71] ✗ ✗ ✗ ∆\nSurgbox [72] ∆ ✗ ∆ ✓\nAipatient [73] ✗ ✗ ✓ ✓\nHealthagent [74] ✗ ✗ ✓ ∆\nIcdcoding [75] ∆ ✗ ✗ ✓\nAha [76] ✗ ✗ ✗ ∆\nDdo [77] ✗ ✗ ✓ ✓\nBeyond [78] ✗ ✗ ✗ ✓\nZodiac [26] ✗ ✗ ✗ ✓\nFhirviz [79] ✗ ✗ ✗ ✓\nFhir [80] ✗ ✗ ✗ ✓\nFuasagent [81] ✓ ✗ ✗ ∆\nAitherapist [82] ∆ ✗ ✓ ∆\nRadiology [83] ✗ ✗ ✗ ✓\nTriageagent [24] ✓ ✗ ✗ ✓\nPiors [84] ✗ ✗ ✓ ✓\nSelfevolve [85] ✗ ✗ ✓ ✓\nDrugagent [86] ✗ ✓ ✗ ✓\nCtagent [87] ✗ ✗ ✗ ✓\nAdagent [88] ✗ ✗ ✗ ✓\nDrugpilot [89] ∆ ✓ ✗ ✓\nLlmadmin [90] ✗ ✗ ∆ ∆\nSwarm [91] ✗ ✓ ✗ ✓\nDrugdiscover [92] ✗ ✓ ✗ ∆\nRagdrug [93] ∆ ✓ ✗ ✓\nDrugreason [94] ✗ ✓ ✗ ✓\nlimited to simulation or education with mandatory human\ninterpretation. ✗ is assigned in cases with no treatment rec-\nommendation or prescription management.\n6) Drug Discovery & Clinical Trial Design\nDrug Discovery & Clinical Trial Design gauges an agent’s\ncapacity to accelerate translational pipelines from target\nideation to study execution. Abilities include drug-target\ninteraction prediction, toxicity screening, hypothesis gener-\nation and lead optimization. Trial functions include protocol\n16 VOLUME 14, 2026\n\n-- 16 of 25 --\n\nauthoring, eligibility criteria extraction, patient-trial match-\ning, automated feature engineering and outcome prediction.\n✓ is warranted when either drug discovery or clinical trial\ndesign is realized. The system should experiment around task\nspecific benchmarks, tool integrated workflows and multi-tier\nvalidation. ∆ is used when functionality is narrow or up-\nstream only such as database lookups, molecular captioning\nor basic analytics. It does not include any form of end-to-\nend optimization, interaction with experimental constraints\nor trial support beyond templated criteria. ✗ is reserved for\nsystems with no discovery or trial capabilities.\n7) Patient Interaction & Monitoring\nPatient Interaction & Monitoring characterizes an agent’s pa-\ntient facing functionality across communication, monitoring\nand logistics. Capabilities include two-way messaging and\neducation. It also covers symptom checkers with targeted\nfollow-ups, adherence check-ins along with reminders, ap-\npointment scheduling, device integration for physiologic sig-\nnals and personalized conversation management. ✓ is earned\nwhen at least one of the following is implemented: inter-\naction, engagement, appointment management, reminders or\nmonitoring. Evidence may include realistic dialogue behav-\nior, symptom tracking with feedback collection, department\nsupport, real-time monitoring or stress estimation. Dynamic\nsymptom simulation and safe handoffs also meet this bar. ∆\napplies to limited functionality such as basic history taking,\nscripted exchanges or intake only prompts without person-\nalized monitoring. ✗ signals no patient facing interactions,\nreminders, scheduling or monitoring.\n8) Benchmarking & Simulation Environment\nBenchmarking & Simulation Environment validates whether\nan agent is tested under rigorous and reproducible condi-\ntions that reflect clinical work. Scope includes standardized\nbenchmarks with clear protocols and metrics. It also includes\nsimulations that model roles, artifacts (notes, images, vitals)\nand multi-turn workflows. Robust studies report comparisons\nto strong baselines, ablations, error analyses and when ap-\npropriate, human expert review. Accordingly, ✓ is used for\nevaluation on a substantial benchmark or a clinically realistic\nsimulation with transparent setup, baseline comparisons and\nablation studies. ∆ is used for narrow demos or synthetic\nmicrostudies with few samples and limited metrics. ✗ is\nassigned when no meaningful benchmarking or simulation\nis presented.\nIII. EMPIRICAL FINDINGS AND DISCUSSION\nIn this section, we discuss cross-cutting trends across the 7\nevaluation dimensions introduced earlier. The following sub-\nsections briefly surface where healthcare LLM agents cluster.\nFor example, the analysis reveals strong External Knowledge\nIntegration but weak Dynamic Updates & Forgetting within\nKnowledge Management, relatively prevalent Conversational\nMode but sparse Error Recovery within Interaction Patterns\nand overall low adoption of Adaptation & Learning. We fur-\nther explain why these patterns matter for clinical reliability\nand operational readiness. This section then converges on\ncritical weak points and possible actionable directions high-\nlighting where methodological investment is most urgent.\nA. WHICH COGNITIVE SUB-DIMENSIONS REMAIN\nUNDERDEVELOPED IN HEALTHCARE AGENTS?\nFigure 5 underscores marked asymmetries in implementation\nprevalence across Cognitive Capabilities among surveyed\nLLM-based agents. ✗ dominates three sub-dimensions with\nPlanning absent in ∼45% of the surveyed papers, Meta-\nCapabilities in ∼53% and Consistency & Conflict Resolu-\ntion in ∼61%. This conveys that many systems still lack\nrobust mechanisms for long horizon task decomposition,\nself-monitoring and systematic reconciliation of conflicting\nevidence. Contrarily, ✓ appears more frequently in Percep-\ntion (∼46%) and Action (∼41%) where progress has been\ndriven by multimodal representation learning and API or\ntool execution pipelines. ∆ occupies the middle in ways\nthat signal partial maturity rather than stability. For instance,\nPerception shows ∼55% ∆ whereas Action has only ∼8%\nstressing that prototypes do demonstrate potential but fall\nshort of reliable end-to-end integration. This pattern may be\nconsequential because cognitive competencies form the foun-\ndation of trustworthy clinical agents. Without planning com-\npetence, agents risk fragmented care pathways and missed\ncontingencies in triage or prior authorization. Weak meta-\ncontrol translates into poor uncertainty calibration and absent\nescalation triggers. Scarce conflict resolution pipelines invite\ncontradictory chart updates or unsafe recommendations. Ad-\nvances in perception and execution while necessary, address\nonly surface layers. Agents that faithfully ingest EHR data\nand generate structured outputs still fail if they cannot resolve\ncontradictions or adapt plans to evolving evidence. These\ngaps suggest candidate research directions starting with for-\nmalizing planning protocols aligned to clinical workflows,\ncontinuing with embedding uncertainty aware meta-control\nloops and finally completing with developing contradiction\ndetection pipelines.\nB. ARE KNOWLEDGE MANAGEMENT CAPABILITIES\nEVENLY IMPLEMENTED ACROSS HEALTHCARE LLM\nAGENTS?\nFigure 6 shows a stratified implementation pattern across\nthree sub-dimensions including External Knowledge Integra-\ntion, Memory Module and Dynamic Updates & Forgetting.\nExternal Knowledge Integration is the most frequent with ✓\non 37/49 (∼76%), ∆ on 1/49 (∼2%) and ✗ on 11/49 (∼22%).\nThese numbers emphasize widespread pairing of parametric\nrecall with authoritative external sources at inference time.\nMemory Module skews ∆ (∼49%) with fewer ✓ systems\n(∼33%) and the remainder ✗ (∼18%). Many agents keep\nsession history or simple buffers. Yet far fewer implement\ncontroller-governed, persistent, multi-tier memory with prin-\ncipled read/write. The most conspicuous weakness is Dy-\nnamic Updates & Forgetting, which records just 1/49 (∼2%)\nVOLUME 14, 2026 17\n\n-- 17 of 25 --\n\nFIGURE 5. Distribution of Labels Across Sub-Dimensions of Cognitive Capabilities\nFIGURE 6. Distribution of Labels Across Sub-Dimensions of Knowledge\nManagement\n✓ but 33/49 (∼67%) ✗. Very few systems focus on both\nsides of knowledge maintenance allowing continuous addi-\ntions and explicit forgetting via decay and deprecation rules.\nThis distribution has a high significance because knowledge\ncurrency, coherence and hygiene underpin safe clinical use.\nAgents must align outputs with evolving guidelines, drug\nrecalls and formulary changes while suppressing stale or\ncontradictory facts to prevent drift. This analysis further\nsheds light on the need of elevating memory from buffers\nto persistent substrates, coupling retrieval with multi-tier\nmemory and enforcing deprecation detection gates.\nC. DO CURRENT AGENTS BALANCE CONVERSATION,\nEVENT TRIGGERS, HUMAN-IN-THE-LOOP AND\nRECOVERY ADEQUATELY?\nFigure 7 maps implementation distribution across four In-\nteraction Patterns sub-dimensions which are Conversational\nMode, Event-Triggered Activation, Human-in-the-Loop and\nError Recovery. The distribution is heterogeneous but lop-\nsided in key areas. Conversational Mode is relatively preva-\nlent with ✓ on ∼43% of research works and ∆ on ∼6% of\nthem. This conveys that many systems support multi-turn ex-\nFIGURE 7. Distribution of Labels Across Sub-Dimensions of Interaction\nPatterns\nchange and state carryover though nearly half still fall short.\nEvent-Triggered Activation is starkly underrepresented. It\nhas only 3/49 (∼6%) ✓ and 1/49 (∼2%) ∆ versus 45/49\n(∼92%) ✗ suggesting heavy reliance on manual prompts\nrather than external signals such as device telemetry or EHR\nevents. Human-in-the-Loop records ∼12% ✓, ∼2% ∆ but\n∼86% ✗ reflecting pipelines that lack mid-execution check-\npoints and documented escalation paths. Error Recovery is\nsimilarly thin, with just ∼4% ✓. Only few works demonstrate\nidempotent tool use, rollbacks or safe mode degradation.\nFor clinical operations, we outline potential design reme-\ndies. First, tie activation to governed event streams with\nprovenance and debouncing. Next, define Human-in-the-\nLoop checkpoints as explicit gates with approval queues and\nuncertainty thresholds. Finally, treat recovery as a first class\nsubsystem with bounded retries and circuit breakers. These\ncontrols can turn interactions into reviewable workflows that\ncan in turn work toward satisfying clinical governance and\nreducing operational risk.\n18 VOLUME 14, 2026\n\n-- 18 of 25 --\n\nFIGURE 8. Distribution of Labels Across Sub-Dimensions of Adaptation &\nLearning\nD. HOW WELL DO HEALTHCARE LLM AGENTS ADAPT?\nFigure 8 shows uniformly low adoption across Adaptation\n& Learning. ✗ or Not Implemented is the prevailing label\nacross all three sub-dimensions with only thin tails of ∆\nand rare ✓ instances. Drift Detection & Mitigation is es-\nsentially absent 0% ✓, ∼2% (1/49) ∆ and ∼98% (48/49)\n✗. This essentially means most agents would not notice,\nlet alone correct shifts in codes, templates or patient mix.\nReinforcement-Based Adaptation appears only sporadically\nwith only 5 (∼10%) studies having ✓ and 3 (∼6%) having\n∆ against 41 (∼84%) having ✗ suggesting that outcome-\nlinked updates (rewards, constraints, clinician preferences)\nare rarely operationalized. Meta-Learning & Few-Shot shows\nthe best footing but remains far from routine with 20% ✓\nand 2% ∆ but 78% ✗. These numbers reveal that most\nsystems still rely on static prompts rather than lightweight\non the fly adaptation. Looking across these studies, three\nmissing pieces recur: (i) limited lifecycle instrumentation\n(few pipelines report drift alarm rates or rollback metrics)\n(ii) underuse of preference learning and outcome-linked re-\nwards beyond ad hoc feedback (iii) scarce end-to-end designs\nthat fuse few-shot competence with continuous monitoring.\nHealthcare is non-stationary by default and without detection\nand controlled response, performance quietly erodes where\nsafety and auditability matter most. In summary, today’s\nfigures with 0-20% ✓ ranges across sub-dimensions indicate\nislands of adaptation capability. A possible path forward is\nto stitch these islands into a monitored, reversible adaptation\nloop that can keep pace with evolving practice.\nE. SAFETY & ETHICS IMPLEMENTATION MATURITY\nREMAINS LIMITED AMONG SURVEYED AGENTS\nFigure 9 profiles four Safety & Ethics sub-dimensions Safety\nGuardrails & Adversarial Robustness, Bias & Fairness,\nPrivacy-Preserving Mechanisms and Regulatory & Compli-\nance Constraints. For Safety Guardrails & Adversarial Ro-\nbustness, only 3 out of 49 papers (∼6%) earn ✓, with 14\n(∼29%) ∆ and 32 (∼65%) ✗. This tells that most agents\nFIGURE 9. Distribution of Labels Across Sub-Dimensions of Safety & Ethics\nstill lack layered, testable defenses against prompt attacks\nor unsafe tool use. Bias & Fairness looks similar with 5\nstudies (∼10%) marked ✓, 12 with (∼25%) ∆ and the rest\n32 (∼65%) having ✗ signaling that cohort-stratified eval-\nuation and mitigation are exception rather than the norm.\nPrivacy-Preserving Mechanisms shows the strongest footing\nbut remains far from universal. Their numbers include ∼18%\n✓, ∼28% ∆ and ∼53% ✗. Many papers reference hosting\ncontrols, yet fewer demonstrate agent side protections with\nmeasurable leakage tests. Regulatory & Compliance Con-\nstraints is the most underbuilt with ∼10% ✓, only ∼4%\n∆ and ∼86% ✗ reflecting procedural assurances rarely ap-\npear as verifiable runtime gates. The results in Figure 9\ntherefore do more than describe who implemented what.\nThey reveal the gap between proof of concept engineering\nand the end-to-end assurance required for clinical adoption\nwith 53-86% ✗ across sub-dimensions. A possible remedial\ndirection could be: (i) convert filters into layered guardrails\nwith adversarial suites and hold-out hazard tests (ii) replace\nmacro averages with cohort-stratified metrics (iii) elevate\nprivacy to de-identification plus traceable access (iv) turn\ncompliance from policy text into executable controls wired\ninto the agent’s workflow. Closing these gaps can move the\nfield from intent to assurance and makes safety, equity and\nauditability measurable. In short, the prevalence statistics in\nFigure 9 highlight a gradient: strong conceptual intent, par-\ntial technical realization and limited end-to-end assurance.\nBridging that gradient can help deliver safe, equitable and\nauditable LLM agents operating in real clinical workflows.\nF. FRAMEWORK TYPOLOGY TRENDS ACROSS\nLLM-BASED HEALTHCARE AGENTS\nFigure 10 charts architectural choices within Framework\nTypology by tallying ✓, ∆ and ✗ across two sub-dimensions:\nMulti-Agent Design and Centralized Orchestration. The data\nappears to have a clear asymmetry. Multi-Agent Design is\nbroadly mature: ∼82% ✓ with only ∼16% ✗ indicating that\nrole-based compositions such as planner, retriever, verifier,\nexplainer are now the default pattern. Centralized Orches-\nVOLUME 14, 2026 19\n\n-- 19 of 25 --\n\nFIGURE 10. Distribution of Labels Across Sub-Dimensions of Framework\nTypology\ntration, meanwhile, clusters in partial territory with ∼57%\n∆. This suggests that while coordination layers exist, many\ndeployments stop short of fully realized controllers with\nglobal state, policy enforcement and auditable sequencing.\nThis is not a verdict on what architectures ought to be but\na snapshot of where engineering effort has concentrated.\nTeams have prioritized modular specialization allowing eas-\nier parallelization and component swaps before hardening\norchestration for end-to-end assurance. In practice, typol-\nogy choices shape behavior under load, evolution over time\nand the visibility of control. Multi-agent compositions can\nmirror multidisciplinary care by assigning distinct agents to\nguideline conformance, evidence synthesis and patient facing\ncommunication. A central orchestrator can then align these\nsteps with institutional policy, surface uncertainty, route edge\ncases to clinicians and reconcile outputs prior to order. Nei-\nther pattern is universally superior. Effective systems often\ncombine them or opt for lighter choreography when latency,\ncost or integration constraints make a heavyweight controller\nimpractical. Read in this light, Figure 10 indicates a field that\nhas rapidly embraced modular, role-based design (high ✓ in\nMulti-Agent Design) while progressively layering coordina-\ntion mechanisms (dominant ∆ in Centralized Orchestration)\nas deployments mature.\nG. WHICH CORE TASKS CAN HEALTHCARE AGENTS\nPERFORM?\nFigure 11 depicts how often each Core Tasks & Subtasks\nsub-dimension is rated Fully Implemented ✓, Partially Im-\nplemented ∆ or Not Implemented ✗. The spread highlights\nwhere healthcare LLM agents already provide dependable\nvalue versus where they remain immature. Clinical Docu-\nmentation & EHR Analysis is a solid performer with 22/49\n(∼45%) ✓, 12/49 (∼24%) ∆ and 15/49 (∼31%) ✗ reflecting\ntractable gains in summarization and extraction. Medical\nQuestion Answering & Decision Support is stronger at 28/49\n(∼57%) ✓, showing that retrieval-grounded recommenda-\ntions are a leading use case. Conversely, Triage & Differential\nDiagnosis and Diagnostic Reasoning cluster around partial\nadoption. Their statistics contain 14/49 (∼29%) and 18/49\n(∼37%) ✓ alongside 11/49 (∼22%) and 13/49 (∼27%) ∆\nrespectively. This confirms their consistency with higher de-\nmands of structured hypothesis management and calibrated\nuncertainty. Action oriented areas remain underdeveloped.\nFor example, Treatment Planning & Prescription is only\n10/49 (∼20%) ✓ and Patient Interaction & Monitoring is\n11/49 (∼22%) with both tilting heavily toward ✗ because of\nintegration and safety challenges. Drug Discovery & Clinical\nTrial Design records just 9/49 (∼18%) ✓ against 39/49\n(∼80%) ✗ exhibiting long evaluation horizons and regulatory\nburden. Benchmarking & Simulation Environment stands out\nwith 39/49 (∼80%) ✓ and only 1/49 (∼2%) ✗ marking broad\nadoption of standardized datasets and increasingly realis-\ntic simulators that boost comparability and iteration speed.\nOverall, interpreting the numbers in Figure 11 shows infor-\nmation centric tasks like documentation, decision support\nand benchmarking leading in maturity. On the other hand,\ntasks centered around decision and action remain Partially\nImplemented whereas discovery tasks lag furthest behind.\nThis pattern maps directly to clinical workflows. Medical\nrecord summarization and question answering are ready\nfor frontline utility but safe automation of judgment and\nlongitudinal interaction still requires substantial governance\nadvances.\nIV. CONCLUSION\nLLM-based agents are showing early gains in automation,\ndecision support and research, but wider clinical adoption\nremains limited until adaptation, safety and compliance are\nmore robust. In this survey, we systematically review 49\nresearch papers and propose an integrated taxonomy for\nempirical evaluation of these agents. Our taxonomy provides\na structured lens to examine the cognitive, interactive, adap-\ntive and ethical aspects of Agentic AI-grounded LLM-based\nagents along with their core tasks and framework architec-\ntures. Through this multidimensional analysis, we surface a\nvariety of prevalent patterns showing methodological prefer-\nences, capability distributions and emerging design strategies\nwithin healthcare and medicine. While the field has made\nsignificant strides, several challenges still persist. These\nchallenges particularly revolve around ensuring reliability,\ninterpretability and ethical alignment in complex healthcare\nenvironments. By consolidating current methodologies and\nhighlighting key trends, our review offers a foundational re-\nsource for researchers aiming to advance the development of\nrobust, efficient and ethically responsible LLM-based agents.\nFuture research can build upon this framework to explore\nunderrepresented dimensions, refine agent capabilities and\naddress domain specific needs. This would ultimately con-\ntribute towards more reliable, safe and effective applications\nof LLM-based agents in healthcare and medicine. Finally,\nwhile scaling agentic systems from research prototypes to\nproduction involves orchestration, integration, latency/cost\nand reliability concerns, such deployment-scale engineering\n20 VOLUME 14, 2026\n\n-- 20 of 25 --\n\nFIGURE 11. Distribution of Labels Across Sub-Dimensions of Core Tasks & Subtasks\nlies beyond the scope of this work. We flag scalability as an\nopen challenge and an important axis for future work but\nour evidence and analysis are intentionally limited to peer-\nreviewed/archival research papers rather than production sys-\ntems.\nREFERENCES\n[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman,\nD. Almeida, J. Altenschmidt, S. Altman, S. Anadkat et al., “Gpt-4\ntechnical report,” arXiv preprint arXiv:2303.08774, 2023.\n[2] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts,\nP. Barham, H. W. Chung, C. Sutton, S. Gehrmann et al., “Palm: Scaling\nlanguage modeling with pathways,” Journal of Machine Learning Re-\nsearch, vol. 24, no. 240, pp. 1–113, 2023.\n[3] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le,\nD. Zhou et al., “Chain-of-thought prompting elicits reasoning in large\nlanguage models,” Advances in neural information processing systems,\nvol. 35, pp. 24 824–24 837, 2022.\n[4] R. Yang, T. F. Tan, W. Lu, A. J. Thirunavukarasu, D. S. W. Ting, and\nN. Liu, “Large language models in health care: Development, applica-\ntions, and challenges,” Health Care Science, vol. 2, no. 4, pp. 255–263,\n2023.\n[5] A. J. Thirunavukarasu, D. S. J. Ting, K. Elangovan, L. Gutierrez, T. F.\nTan, and D. S. W. Ting, “Large language models in medicine,” Nature\nmedicine, vol. 29, no. 8, pp. 1930–1940, 2023.\n[6] Y. Li, S. Wang, H. Ding, and H. Chen, “Large language models in finance:\nA survey,” in Proceedings of the fourth ACM international conference on\nAI in finance, 2023, pp. 374–382.\n[7] L. Yan, L. Sha, L. Zhao, Y. Li, R. Martinez-Maldonado, G. Chen, X. Li,\nY. Jin, and D. Gaševi´c, “Practical and ethical challenges of large language\nmodels in education: A systematic scoping review,” British Journal of\nEducational Technology, vol. 55, no. 1, pp. 90–112, 2024.\n[8] S. Schulhoff, M. Ilie, N. Balepur, K. Kahadze, A. Liu, C. Si, Y. Li,\nA. Gupta, H. Han, S. Schulhoff et al., “The prompt report: a sys-\ntematic survey of prompt engineering techniques,” arXiv preprint\narXiv:2406.06608, 2024.\n[9] J. Gu, Z. Han, S. Chen, A. Beirami, B. He, G. Zhang, R. Liao, Y. Qin,\nV. Tresp, and P. Torr, “A systematic survey of prompt engineering on\nvision-language foundation models,” arXiv preprint arXiv:2307.12980,\n2023.\n[10] P. Sahoo, A. K. Singh, S. Saha, V. Jain, S. Mondal, and A. Chadha,\n“A systematic survey of prompt engineering in large language models:\nTechniques and applications,” arXiv preprint arXiv:2402.07927, 2024.\n[11] S. Vatsal and H. Dubey, “A survey of prompt engineering meth-\nods in large language models for different nlp tasks,” arXiv preprint\narXiv:2407.12994, 2024.\n[12] S. Vatsal, H. Dubey, and A. Singh, “Multilingual prompt engineering\nin large language models: A survey across nlp tasks,” arXiv preprint\narXiv:2505.11665, 2025.\n[13] Z. Xi, W. Chen, X. Guo, W. He, Y. Ding, B. Hong, M. Zhang, J. Wang,\nS. Jin, E. Zhou et al., “The rise and potential of large language model\nbased agents: A survey,” Science China Information Sciences, vol. 68,\nno. 2, p. 121101, 2025.\n[14] H. Leong, Y. Gao, S. Ji, Y. Zhang, and U. Pamuksuz, “Efficient fine-\ntuning of large language models for automated medical documentation,”\nin 2024 4th International Conference on Digital Society and Intelligent\nSystems (DSInS). IEEE, 2024, pp. 204–209.\n[15] H. P. Baker, E. Dwyer, S. Kalidoss, K. Hynes, J. Wolf, and J. A.\nStrelzow, “Chatgpt’s ability to assist with clinical documentation: a\nrandomized controlled trial,” JAAOS-Journal of the American Academy\nof Orthopaedic Surgeons, vol. 32, no. 3, pp. 123–129, 2024.\n[16] K. Singhal, S. Azizi, T. Tu, S. S. Mahdavi, J. Wei, H. W. Chung,\nN. Scales, A. Tanwani, H. Cole-Lewis, S. Pfohl et al., “Large language\nmodels encode clinical knowledge,” Nature, vol. 620, no. 7972, pp. 172–\n180, 2023.\n[17] S. Vatsal and A. Singh, “Can gpt redefine medical understanding? evalu-\nating gpt on biomedical machine reading comprehension,” arXiv preprint\narXiv:2405.18682, 2024.\n[18] S. Vatsal, A. Singh, and S. Tafreshi, “Can gpt improve the state of prior\nauthorization via guideline based automated question answering?” in\nAI for Health Equity and Fairness: Leveraging AI to Address Social\nDeterminants of Health. Springer, 2024, pp. 147–158.\n[19] S. Wang, Z. Zhao, X. Ouyang, T. Liu, Q. Wang, and D. Shen, “Inter-\nactive computer-aided diagnosis on medical image using large language\nmodels,” Communications Engineering, vol. 3, no. 1, p. 133, 2024.\n[20] H. Nori, N. King, S. M. McKinney, D. Carignan, and E. Horvitz,\n“Capabilities of gpt-4 on medical challenge problems,” arXiv preprint\narXiv:2303.13375, 2023.\n[21] C. Chakraborty, M. Bhattacharya, and S.-S. Lee, “Artificial intelligence\nenabled chatgpt and large language models in drug target discovery, drug\ndiscovery, and development,” Molecular therapy Nucleic acids, vol. 33,\npp. 866–868, 2023.\n[22] C. R. Subramanian, D. A. Yang, and R. Khanna, “Enhancing health care\ncommunication with large language models—the role, challenges, and\nfuture directions,” JAMA network open, vol. 7, no. 3, pp. e240 347–\ne240 347, 2024.\n[23] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths, Y. Cao, and\nK. Narasimhan, “Tree of thoughts: Deliberate problem solving with large\nlanguage models, 2023,” URL https://arxiv. org/abs/2305.10601, vol. 3,\np. 1, 2023.\n[24] M. Lu, B. Ho, D. Ren, and X. Wang, “Triageagent: Towards better multi-\nagents collaborations for large language model-based clinical triage,”\nin Findings of the Association for Computational Linguistics: EMNLP\n2024, 2024, pp. 5747–5764.\n[25] Z. Wang, Y. Zhu, H. Zhao, X. Zheng, D. Sui, T. Wang, W. Tang,\nVOLUME 14, 2026 21\n\n-- 21 of 25 --\n\nY. Wang, E. Harrison, C. Pan et al., “Colacare: Enhancing electronic\nhealth record modeling through large language model-driven multi-agent\ncollaboration,” in Proceedings of the ACM on Web Conference 2025,\n2025, pp. 2250–2261.\n[26] Y. Zhou, P. Zhang, M. Song, A. Zheng, Y. Lu, Z. Liu, Y. Chen, and\nZ. Xi, “Zodiac: A cardiologist-level llm framework for multi-agent\ndiagnostics,” arXiv preprint arXiv:2410.02026, 2024.\n[27] P. Li, X. Zhang, E. Zhu, S. Yu, B. Sheng, Y. C. Tham, T. Y. Wong,\nand H. Ji, “Potential multidisciplinary use of large language models for\naddressing queries in cardio-oncology,” Journal of the American Heart\nAssociation, vol. 13, no. 6, p. e033584, 2024.\n[28] T. Guo, X. Chen, Y. Wang, R. Chang, S. Pei, N. V. Chawla, O. Wiest,\nand X. Zhang, “Large language model based multi-agents: A survey of\nprogress and challenges,” arXiv preprint arXiv:2402.01680, 2024.\n[29] M. A. Ferrag, N. Tihanyi, and M. Debbah, “From llm reasoning\nto autonomous ai agents: A comprehensive review,” arXiv preprint\narXiv:2504.19678, 2025.\n[30] X. Dong, X. Zhang, W. Bu, D. Zhang, and F. Cao, “A survey of llm-\nbased agents: Theories, technologies, applications and suggestions,” in\n2024 3rd International Conference on Artificial Intelligence, Internet of\nThings and Cloud Computing Technology (AIoTC). IEEE, 2024, pp.\n407–413.\n[31] X. Li, S. Wang, S. Zeng, Y. Wu, and Y. Yang, “A survey on llm-\nbased multi-agent systems: workflow, infrastructure, and challenges,”\nVicinagearth, vol. 1, no. 1, p. 9, 2024.\n[32] A. Plaat, M. van Duijn, N. van Stein, M. Preuss, P. van der Putten,\nand K. J. Batenburg, “Agentic large language models, a survey,” arXiv\npreprint arXiv:2503.23037, 2025.\n[33] P. Zhao, Z. Jin, and N. Cheng, “An in-depth survey of large language\nmodel-based artificial intelligence agents. arxiv (2023),” arXiv preprint\narXiv:2309.14365, 2023.\n[34] W. Wang, Z. Ma, Z. Wang, C. Wu, J. Ji, W. Chen, X. Li, and Y. Yuan, “A\nsurvey of llm-based agents in medicine: How far are we from baymax?”\narXiv preprint arXiv:2502.11211, 2025.\n[35] M. Yu, F. Meng, X. Zhou, S. Wang, J. Mao, L. Pang, T. Chen, K. Wang,\nX. Li, Y. Zhang et al., “A survey on trustworthy llm agents: Threats and\ncountermeasures,” arXiv preprint arXiv:2503.09648, 2025.\n[36] Z. Zhang, X. Bo, C. Ma, R. Li, X. Chen, Q. Dai, J. Zhu, Z. Dong, and\nJ.-R. Wen, “A survey on the memory mechanism of large language model\nbased agents, 2024,” URL https://arxiv. org/abs/2404.13501.\n[37] X. Li, “A review of prominent paradigms for llm-based agents: Tool use,\nplanning (including rag), and feedback learning,” in Proceedings of the\n31st International Conference on Computational Linguistics, 2025, pp.\n9760–9779.\n[38] X. Huang, W. Liu, X. Chen, X. Wang, H. Wang, D. Lian, Y. Wang,\nR. Tang, and E. Chen, “Understanding the planning of llm agents: A\nsurvey,” arXiv preprint arXiv:2402.02716, 2024.\n[39] A. Yehudai, L. Eden, A. Li, G. Uziel, Y. Zhao, R. Bar-Haim, A. Cohan,\nand M. Shmueli-Scheuer, “Survey on evaluation of llm-based agents,”\narXiv preprint arXiv:2503.16416, 2025.\n[40] L. Wang, W. Xu, Y. Lan, Z. Hu, Y. Lan, R. K.-W. Lee, and E.-P.\nLim, “Plan-and-solve prompting: Improving zero-shot chain-of-thought\nreasoning by large language models,” arXiv preprint arXiv:2305.04091,\n2023.\n[41] J.-B. Alayrac, J. Donahue, P. Luc, A. Miech, I. Barr, Y. Hasson, K. Lenc,\nA. Mensch, K. Millican, M. Reynolds et al., “Flamingo: a visual language\nmodel for few-shot learning,” Advances in neural information processing\nsystems, vol. 35, pp. 23 716–23 736, 2022.\n[42] K. Singhal, T. Tu, J. Gottweis, R. Sayres, E. Wulczyn, M. Amin, L. Hou,\nK. Clark, S. R. Pfohl, H. Cole-Lewis et al., “Toward expert-level med-\nical question answering with large language models,” Nature Medicine,\nvol. 31, no. 3, pp. 943–950, 2025.\n[43] S. Yao, J. Zhao, D. Yu, N. Du, I. Shafran, K. Narasimhan, and Y. Cao,\n“React: Synergizing reasoning and acting in language models,” in Inter-\nnational Conference on Learning Representations (ICLR), 2023.\n[44] T. Schick, J. Dwivedi-Yu, R. Dessì, R. Raileanu, M. Lomeli, E. Hambro,\nL. Zettlemoyer, N. Cancedda, and T. Scialom, “Toolformer: Language\nmodels can teach themselves to use tools,” Advances in Neural Informa-\ntion Processing Systems, vol. 36, pp. 68 539–68 551, 2023.\n[45] N. Shinn, F. Cassano, A. Gopinath, K. Narasimhan, and S. Yao, “Reflex-\nion: Language agents with verbal reinforcement learning,” Advances in\nNeural Information Processing Systems, vol. 36, pp. 8634–8652, 2023.\n[46] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, S. Narang, A. Chowdh-\nery, and D. Zhou, “Self-consistency improves chain of thought reasoning\nin language models,” arXiv preprint arXiv:2203.11171, 2022.\n[47] Q. Wu, G. Bansal, J. Zhang, Y. Wu, B. Li, E. Zhu, L. Jiang, X. Zhang,\nS. Zhang, J. Liu et al., “Autogen: Enabling next-gen llm applications via\nmulti-agent conversations,” in First Conference on Language Modeling,\n2024.\n[48] P. Manakul, A. Liusie, and M. J. Gales, “Selfcheckgpt: Zero-resource\nblack-box hallucination detection for generative large language models,”\narXiv preprint arXiv:2303.08896, 2023.\n[49] X. Tang, A. Zou, Z. Zhang, Z. Li, Y. Zhao, X. Zhang, A. Cohan, and\nM. Gerstein, “Medagents: Large language models as collaborators for\nzero-shot medical reasoning,” arXiv preprint arXiv:2311.10537, 2023.\n[50] D. Yang, J. Wei, M. Li, J. Liu, L. Liu, M. Hu, J. He, Y. Ju, W. Zhou, Y. Liu\net al., “Medaide: Information fusion and anatomy of medical intents via\nllm-based agent collaboration,” arXiv e-prints, pp. arXiv–2410, 2024.\n[51] Y. Feng, J. Wang, L. Zhou, and Y. Li, “Doctoragent-rl: A multi-agent\ncollaborative reinforcement learning system for multi-turn clinical dia-\nlogue,” arXiv preprint arXiv:2505.19630, 2025.\n[52] Z. Fan, J. Tang, W. Chen, S. Wang, Z. Wei, J. Xi, F. Huang, and J. Zhou,\n“Ai hospital: Benchmarking large language models in a multi-agent\nmedical interaction simulator,” arXiv preprint arXiv:2402.09742, 2024.\n[53] B. Li, T. Yan, Y. Pan, J. Luo, R. Ji, J. Ding, Z. Xu, S. Liu, H. Dong,\nZ. Lin et al., “Mmedagent: Learning to use medical tools with multi-\nmodal agent,” arXiv preprint arXiv:2407.02483, 2024.\n[54] P. R. Liu, S. Bansal, J. Dinh, A. Pawar, R. Satishkumar, S. Desai,\nN. Gupta, X. Wang, and S. Hu, “Medchat: A multi-agent framework\nfor multimodal diagnosis with large language models,” arXiv preprint\narXiv:2506.07400, 2025.\n[55] H. Wei, J. Qiu, H. Yu, and W. Yuan, “Medco: Medical education copilots\nbased on a multi-agent framework,” in European Conference on Com-\nputer Vision. Springer, 2024, pp. 119–135.\n[56] Z. Wang, J. Wu, L. Cai, C. H. Low, X. Yang, Q. Li, and Y. Jin,\n“Medagent-pro: Towards evidence-based multi-modal medical diagnosis\nvia reasoning agentic workflow,” arXiv preprint arXiv:2503.18968, 2025.\n[57] L. Yue, S. Xing, J. Chen, and T. Fu, “Clinicalagent: Clinical trial\nmulti-agent system with large language model-based reasoning,” in Pro-\nceedings of the 15th ACM International Conference on Bioinformatics,\nComputational Biology and Health Informatics, 2024, pp. 1–10.\n[58] S. Han and W. Choi, “Development of a large language model-based\nmulti-agent clinical decision support system for korean triage and acuity\nscale (ktas)-based triage and treatment planning in emergency depart-\nments,” arXiv preprint arXiv:2408.07531, 2024.\n[59] Q. Jin, Z. Wang, Y. Yang, Q. Zhu, D. Wright, T. Huang, W. J. Wilbur,\nZ. He, A. Taylor, Q. Chen et al., “Agentmd: Empowering language agents\nfor risk prediction with large-scale clinical tool learning,” arXiv preprint\narXiv:2402.13225, 2024.\n[60] Y. Kim, C. Park, H. Jeong, Y. S. Chan, X. Xu, D. McDuff, H. Lee,\nM. Ghassemi, C. Breazeal, and H. W. Park, “Mdagents: An adaptive\ncollaboration of llms for medical decision-making,” Advances in Neural\nInformation Processing Systems, vol. 37, pp. 79 410–79 452, 2024.\n[61] J. Li, Y. Lai, W. Li, J. Ren, M. Zhang, X. Kang, S. Wang, P. Li, Y.-Q.\nZhang, W. Ma et al., “Agent hospital: A simulacrum of hospital with\nevolvable medical agents,” arXiv preprint arXiv:2405.02957, 2024.\n[62] B. Gao, Y. Huang, Y. Liu, W. Xie, W.-Y. Ma, Y.-Q. Zhang, and Y. Lan,\n“Pharmagents: Building a virtual pharma with large language model\nagents,” arXiv preprint arXiv:2503.22164, 2025.\n[63] S. Gao, R. Zhu, Z. Kong, A. Noori, X. Su, C. Ginder, T. Tsiligkaridis,\nand M. Zitnik, “Txagent: An ai agent for therapeutic reasoning across a\nuniverse of tools,” arXiv preprint arXiv:2503.10970, 2025.\n[64] F. Liu, H. Wang, J. Cho, D. Roth, and A. W. Lo, “Autoct: Automating\ninterpretable clinical trial prediction with llm agents,” arXiv preprint\narXiv:2506.04293, 2025.\n[65] K. Zuo, Y. Jiang, F. Mo, and P. Lio, “Kg4diagnosis: A hierarchical multi-\nagent llm framework with knowledge graph enhancement for medical\ndiagnosis,” in AAAI Bridge Program on AI for Medicine and Healthcare.\nPMLR, 2025, pp. 195–204.\n[66] K. Chen, X. Li, T. Yang, H. Wang, W. Dong, and Y. Gao, “Mdteamgpt:\nA self-evolving llm-based multi-agent framework for multi-disciplinary\nteam medical consultation,” arXiv preprint arXiv:2503.13856, 2025.\n[67] Y. Ke, R. Yang, S. A. Lie, T. X. Y. Lim, Y. Ning, I. Li, H. R. Abdullah,\nD. S. W. Ting, and N. Liu, “Mitigating cognitive biases in clinical\ndecision-making through multi-agent conversations using large language\n22 VOLUME 14, 2026\n\n-- 22 of 25 --\n\nmodels: simulation study,” Journal of Medical Internet Research, vol. 26,\np. e59439, 2024.\n[68] S. Mukherjee, P. Gamble, M. S. Ausin, N. Kant, K. Aggarwal, N. Man-\njunath, D. Datta, Z. Liu, J. Ding, S. Busacca et al., “Polaris: A safety-\nfocused llm constellation architecture for healthcare,” arXiv preprint\narXiv:2403.13313, 2024.\n[69] P. P. Van, D. N. Minh, A. D. Ngoc, and H. P. Thanh, “Rx strate-\ngist: Prescription verification using llm agents system,” arXiv preprint\narXiv:2409.03440, 2024.\n[70] W. Yan, H. Liu, T. Wu, Q. Chen, W. Wang, H. Chai, J. Wang, W. Zhao,\nY. Zhang, R. Zhang et al., “Clinicallab: Aligning agents for multi-\ndepartmental clinical diagnostics in the real world,” arXiv preprint\narXiv:2406.13890, 2024.\n[71] M. Sudarshan, S. Shih, E. Yee, A. Yang, J. Zou, C. Chen, Q. Zhou,\nL. Chen, C. Singhal, and G. Shih, “Agentic llm workflows for generat-\ning patient-friendly medical reports,” arXiv preprint arXiv:2408.01112,\n2024.\n[72] J. Wu, X. Liang, X. Bai, and Z. Chen, “Surgbox: Agent-driven operating\nroom sandbox with surgery copilot,” in 2024 IEEE International Confer-\nence on Big Data (BigData). IEEE, 2024, pp. 2041–2048.\n[73] H. Yu, J. Zhou, L. Li, S. Chen, J. Gallifant, A. Shi, X. Li, J. He, W. Hua,\nM. Jin et al., “Simulated patient systems are intelligent when powered by\nlarge language model-based ai agents,” arXiv preprint arXiv:2409.18924,\n2024.\n[74] M. Abbasian, I. Azimi, A. M. Rahmani, and R. Jain, “Conversational\nhealth agents: A personalized llm-powered agent framework,” arXiv\npreprint arXiv:2310.02374, 2023.\n[75] R. Li, X. Wang, and H. Yu, “Exploring llm multi-agents for icd coding,”\narXiv preprint arXiv:2406.15363, 2024.\n[76] H. Pandey, A. Amod et al., “Advancing healthcare automation:\nMulti-agent system for medical necessity justification,” arXiv preprint\narXiv:2404.17977, 2024.\n[77] Z. Jia, M. Jia, J. Duan, and J. Wang, “Ddo: Dual-decision optimization\nvia multi-agent collaboration for llm-based medical consultation,” arXiv\npreprint arXiv:2505.18630, 2025.\n[78] H. Wang, S. Zhao, Z. Qiang, N. Xi, B. Qin, and T. Liu, “Beyond direct\ndiagnosis: Llm-based multi-specialist agent consultation for automatic\ndiagnosis,” arXiv preprint arXiv:2401.16107, 2024.\n[79] M. ALMutairi, L. AlKulaib, S. Wang, Z. Chen, Y. ALMutairi, T. M.\nAlenazi, K. Luther, and C.-T. Lu, “Fhirviz: Multi-agent platform for\nfhir visualization to advance healthcare analytics,” in Proceedings of the\n15th ACM International Conference on Bioinformatics, Computational\nBiology and Health Informatics, 2024, pp. 1–7.\n[80] C. De Maio, G. Fenza, D. Furno, T. Grauso, and V. Loia, “A multi-agent\narchitecture for privacy-preserving natural language interaction with\nfhir-based electronic health records,” in 2024 International Conference\non Software, Telecommunications and Computer Networks (SoftCOM).\nIEEE, 2024, pp. 1–6.\n[81] L. Zhao, J. Bai, Z. Bian, Q. Chen, Y. Li, G. Li, M. He, H. Yao, and\nZ. Zhang, “Autonomous multi-modal llm agents for treatment planning in\nfocused ultrasound ablation surgery,” arXiv preprint arXiv:2505.21418,\n2025.\n[82] R. Wasenmüller, K. Hilbert, and C. Benzmüller, “Script-based dialog pol-\nicy planning for llm-powered conversational agents: A basic architecture\nfor an\" ai therapist\",” arXiv preprint arXiv:2412.15242, 2024.\n[83] F. Zeng, Z. Lyu, Q. Li, and X. Li, “Enhancing llms for impression\ngeneration in radiology reports through a multi-agent system,” arXiv\npreprint arXiv:2412.06828, 2024.\n[84] Z. Bao, Q. Liu, Y. Guo, Z. Ye, J. Shen, S. Xie, J. Peng, X. Huang,\nand Z. Wei, “Piors: Personalized intelligent outpatient reception based\non large language model with multi-agents medical scenario simulation,”\narXiv preprint arXiv:2411.13902, 2024.\n[85] M. Almansoori, K. Kumar, and H. Cholakkal, “Self-evolving multi-\nagent simulations for realistic clinical interactions,” arXiv preprint\narXiv:2503.22678, 2025.\n[86] S. Liu, Y. Lu, S. Chen, X. Hu, J. Zhao, Y. Lu, and Y. Zhao, “Drugagent:\nAutomating ai-aided drug discovery programming through llm multi-\nagent collaboration,” arXiv preprint arXiv:2411.15692, 2024.\n[87] Y. Mao, W. Xu, Y. Qin, and Y. Gao, “Ct-agent: A multimodal-\nllm agent for 3d ct radiology question answering,” arXiv preprint\narXiv:2505.16229, 2025.\n[88] W. Hou, G. Yang, Y. Du, Y. Lau, L. Liu, J. He, L. Long, and S. Wang,\n“Adagent: Llm agent for alzheimer’s disease analysis with collaborative\ncoordinator,” arXiv preprint arXiv:2506.11150, 2025.\n[89] K. Li, Z. Wu, S. Wang, J. Wu, S. Pan, and W. Hu, “Drugpilot: Llm-\nbased parameterized reasoning agent for drug discovery,” arXiv preprint\narXiv:2505.13940, 2025.\n[90] S. A. Gebreab, K. Salah, R. Jayaraman, M. H. ur Rehman, and S. El-\nlaham, “Llm-based framework for administrative task automation in\nhealthcare,” in 2024 12th International Symposium on Digital Forensics\nand Security (ISDFS). IEEE, 2024, pp. 1–7.\n[91] K. Song, A. Trotter, and J. Y. Chen, “Llm agent swarm for hypothesis-\ndriven drug discovery,” arXiv preprint arXiv:2504.17967, 2025.\n[92] J. Ock, R. S. Meda, S. Badrinarayanan, N. S. Aluru, A. Chandrasekhar,\nand A. B. Farimani, “Large language model agent for modular task\nexecution in drug discovery,” arXiv preprint arXiv:2507.02925, 2025.\n[93] N. Lee, E. De Brouwer, E. Hajiramezanali, T. Biancalani, C. Park, and\nG. Scalia, “Rag-enhanced collaborative llm agents for drug discovery,”\narXiv preprint arXiv:2502.17506, 2025.\n[94] Y. Inoue, T. Song, X. Wang, A. Luna, and T. Fu, “Drugagent: Multi-\nagent large language model-based reasoning for drug-target interaction\nprediction,” ArXiv, pp. arXiv–2408, 2025.\n[95] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal,\nH. Küttler, M. Lewis, W.-t. Yih, T. Rocktäschel et al., “Retrieval-\naugmented generation for knowledge-intensive nlp tasks,” Advances in\nneural information processing systems, vol. 33, pp. 9459–9474, 2020.\n[96] K. Guu, K. Lee, Z. Tung, P. Pasupat, and M. Chang, “Retrieval augmented\nlanguage model pre-training,” in International conference on machine\nlearning. PMLR, 2020, pp. 3929–3938.\n[97] U. Khandelwal, O. Levy, D. Jurafsky, L. Zettlemoyer, and M. Lewis,\n“Generalization through memorization: Nearest neighbor language mod-\nels,” arXiv preprint arXiv:1911.00172, 2019.\n[98] C. Packer, V. Fang, S. Patil, K. Lin, S. Wooders, and J. Gonzalez,\n“Memgpt: Towards llms as operating systems.” 2023.\n[99] A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi, “Self-rag: Learning\nto retrieve, generate, and critique through self-reflection,” 2024.\n[100] K. Meng, A. S. Sharma, A. Andonian, Y. Belinkov, and D. Bau, “Mass-\nediting memory in a transformer,” arXiv preprint arXiv:2210.07229,\n2022.\n[101] O. Shaikh, K. Gligori´c, A. Khetan, M. Gerstgrasser, D. Yang, and\nD. Jurafsky, “Grounding gaps in language model generations,” arXiv\npreprint arXiv:2311.09144, 2023.\n[102] A. Mahmood, J. Wang, B. Yao, D. Wang, and C.-M. Huang,\n“Llm-powered conversational voice assistants: Interaction patterns,\nopportunities, challenges, and design guidelines,” arXiv preprint\narXiv:2309.13879, 2023.\n[103] C. J. Cai, E. Reif, N. Hegde, J. Hipp, B. Kim, D. Smilkov, M. Wattenberg,\nF. Viegas, G. S. Corrado, M. C. Stumpe et al., “Human-centered tools for\ncoping with imperfect algorithms during medical decision-making,” in\nProceedings of the 2019 chi conference on human factors in computing\nsystems, 2019, pp. 1–14.\n[104] S. Dhuliawala, M. Komeili, J. Xu, R. Raileanu, X. Li, A. Celikyilmaz, and\nJ. Weston, “Chain-of-verification reduces hallucination in large language\nmodels,” arXiv preprint arXiv:2309.11495, 2023.\n[105] G. Gupta, B. Rastegarpanah, A. Iyer, J. Rubin, and K. Kenthapadi,\n“Measuring distributional shifts in text: the advantage of language model-\nbased embeddings,” arXiv preprint arXiv:2312.02337, 2023.\n[106] S. Abdelnabi, A. Fay, G. Cherubin, A. Salem, M. Fritz, and A. Paverd,\n“Get my drift? catching llm task drift with activation deltas,” in\n2025 IEEE Conference on Secure and Trustworthy Machine Learning\n(SaTML). IEEE, 2025, pp. 43–67.\n[107] L. Richter, X. He, P. Minervini, and M. J. Kusner, “An auditing\ntest to detect behavioral shift in language models,” arXiv preprint\narXiv:2410.19406, 2024.\n[108] L. L. Guo, S. R. Pfohl, J. Fries, A. E. Johnson, J. Posada, C. Aftandilian,\nN. Shah, and L. Sung, “Evaluation of domain generalization and adapta-\ntion on improving model robustness to temporal dataset shift in clinical\nmedicine,” Scientific reports, vol. 12, no. 1, p. 2726, 2022.\n[109] Y. Bai, S. Kadavath, S. Kundu, A. Askell, J. Kernion, A. Jones, A. Chen,\nA. Goldie, A. Mirhoseini, C. McKinnon et al., “Constitutional ai: Harm-\nlessness from ai feedback,” arXiv preprint arXiv:2212.08073, 2022.\n[110] C. Finn, P. Abbeel, and S. Levine, “Model-agnostic meta-learning for\nfast adaptation of deep networks,” in International conference on machine\nlearning. PMLR, 2017, pp. 1126–1135.\n[111] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,\nA. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language models\nare few-shot learners,” Advances in neural information processing sys-\ntems, vol. 33, pp. 1877–1901, 2020.\nVOLUME 14, 2026 23\n\n-- 23 of 25 --\n\n[112] P. Chao, A. Robey, E. Dobriban, H. Hassani, G. J. Pappas, and E. Wong,\n“Jailbreaking black box large language models in twenty queries,” in\n2025 IEEE Conference on Secure and Trustworthy Machine Learning\n(SaTML). IEEE, 2025, pp. 23–42.\n[113] X. Liu, Z. Yu, Y. Zhang, N. Zhang, and C. Xiao, “Automatic and universal\nprompt injection attacks against large language models,” arXiv preprint\narXiv:2403.04957, 2024.\n[114] S. Yi, Y. Liu, Z. Sun, T. Cong, X. He, J. Song, K. Xu, and Q. Li, “Jailbreak\nattacks and defenses against large language models: A survey,” arXiv\npreprint arXiv:2407.04295, 2024.\n[115] A. Purpura, S. Wadhwa, J. Zymet, A. Gupta, A. Luo, M. K. Rad,\nS. Shinde, and M. S. Sorower, “Building safe genai applications: An\nend-to-end overview of red teaming for large language models,” arXiv\npreprint arXiv:2503.01742, 2025.\n[116] I. O. Gallegos, R. A. Rossi, J. Barrow, M. M. Tanjim, S. Kim, F. Der-\nnoncourt, T. Yu, R. Zhang, and N. K. Ahmed, “Bias and fairness in large\nlanguage models: A survey,” Computational Linguistics, vol. 50, no. 3,\npp. 1097–1179, 2024.\n[117] Y. Li, M. Du, R. Song, X. Wang, and Y. Wang, “A survey on fairness in\nlarge language models,” arXiv preprint arXiv:2308.10149, 2023.\n[118] Z. Obermeyer, B. Powers, C. Vogeli, and S. Mullainathan, “Dissecting\nracial bias in an algorithm used to manage the health of populations,”\nScience, vol. 366, no. 6464, pp. 447–453, 2019.\n[119] F. Mireshghallah, K. Goyal, A. Uniyal, T. Berg-Kirkpatrick, and\nR. Shokri, “Quantifying privacy risks of masked language models using\nmembership inference attacks,” arXiv preprint arXiv:2203.03929, 2022.\n[120] N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni,\nS. Bakas, M. N. Galtier, B. A. Landman, K. Maier-Hein et al., “The\nfuture of digital health with federated learning,” NPJ digital medicine,\nvol. 3, no. 1, p. 119, 2020.\n[121] H. Van Kolfschooten and J. Van Oirschot, “The eu artificial intelligence\nact (2024): implications for healthcare,” Health Policy, vol. 149, p.\n105152, 2024.\n[122] V. Muralidharan, B. A. Adewale, C. J. Huang, M. T. Nta, P. O. Ademiju,\nP. Pathmarajah, M. K. Hang, O. Adesanya, R. O. Abdullateef, A. O.\nBabatunde et al., “A scoping review of reporting gaps in fda-approved\nai medical devices,” NPJ Digital Medicine, vol. 7, no. 1, p. 273, 2024.\n[123] X. Chen, H. Yi, M. You, W. Liu, L. Wang, H. Li, X. Zhang, Y. Guo,\nL. Fan, G. Chen et al., “Enhancing diagnostic capability with multi-\nagents conversational large language models,” NPJ digital medicine,\nvol. 8, no. 1, p. 159, 2025.\n[124] W. Zhang, C. Cui, Y. Zhao, R. Hu, Y. Liu, Y. Zhou, and B. An, “Agen-\ntorchestra: A hierarchical multi-agent framework for general-purpose\ntask solving,” arXiv preprint arXiv:2506.12508, 2025.\n[125] Y. Yang, H. Chai, S. Shao, Y. Song, S. Qi, R. Rui, and W. Zhang,\n“Agentnet: Decentralized evolutionary coordination for llm-based multi-\nagent systems,” arXiv preprint arXiv:2504.00587, 2025.\n[126] W. Shi, R. Xu, Y. Zhuang, Y. Yu, J. Zhang, H. Wu, Y. Zhu, J. Ho, C. Yang,\nand M. D. Wang, “Ehragent: Code empowers large language models\nfor few-shot complex tabular reasoning on electronic health records,”\nin Proceedings of the Conference on Empirical Methods in Natural\nLanguage Processing. Conference on Empirical Methods in Natural\nLanguage Processing, vol. 2024, 2024, p. 22315.\n[127] D. Rose, C.-C. Hung, M. Lepri, I. Alqassem, K. Gashteovski,\nand C. Lawrence, “Meddxagent: A unified modular agent frame-\nwork for explainable automatic differential diagnosis,” arXiv preprint\narXiv:2502.19175, 2025.\n[128] R. C. Deo, S. Goto, T. Jain, S. Meier, and R. Patel, “A conversational\nartificial intelligence agent for medication reconciliation and review,”\nmedRxiv, pp. 2025–06, 2025.\n[129] A. M. Bran, S. Cox, O. Schilter, C. Baldassari, A. D. White, and\nP. Schwaller, “Augmenting large language models with chemistry tools,”\nNature Machine Intelligence, vol. 6, no. 5, pp. 525–535, 2024.\n[130] H. Shi, J. Zhang, and K. Zhang, “Enhancing clinical trial patient match-\ning through knowledge augmentation and reasoning with multi-agents,”\narXiv preprint arXiv:2411.14637, 2024.\n[131] Q. Jin, Z. Wang, C. S. Floudas, F. Chen, C. Gong, D. Bracken-Clarke,\nE. Xue, Y. Yang, J. Sun, and Z. Lu, “Matching patients to clinical trials\nwith large language models,” Nature communications, vol. 15, no. 1, p.\n9074, 2024.\n[132] M. A. Merrill, A. Paruchuri, N. Rezaei, G. Kovacs, J. Perez, Y. Liu,\nE. Schenck, N. Hammerquist, J. Sunshine, S. Tailor et al., “Transforming\nwearable data into health insights using large language model agents,”\narXiv preprint arXiv:2406.06464, 2024.\n[133] S. Schmidgall, R. Ziaei, C. Harris, E. Reis, J. Jopling, and M. Moor,\n“Agentclinic: a multimodal agent benchmark to evaluate ai in simulated\nclinical environments,” arXiv preprint arXiv:2405.07960, 2024.\n[134] Y. Jiang, K. C. Black, G. Geng, D. Park, J. Zou, A. Y. Ng, and J. H.\nChen, “Medagentbench: A realistic virtual ehr environment to benchmark\nmedical llm agents,” arXiv preprint arXiv:2501.14654, 2025.\nSHUBHAM VATSAL received the M.S. degree\nin Computer Science from New York University,\nNew York, USA, in 2023. He is currently a Re-\nsearch Data Scientist in the healthcare domain\nbased in New York, where he applies Machine\nLearning and Natural Language Processing (NLP)\nto real-world clinical and operational problems.\nFrom 2017 to 2021, he was with Samsung Re-\nsearch, focusing on Natural Language Processing\n(NLP) and Machine Learning. He subsequently\nworked at IBM Research on Multimodal learning. He has also contributed\nto a couple of startups, helping build data-driven products using Machine\nlearning and Deep learning. His research interests include Large Language\nModels (LLMs), Agentic AI, applications of LLMs in healthcare and NLP,\nDeep Learning and Machine Learning.\nHARSH DUBEY received the M.S. degree in\ncomputer science from New York University,\nCourant Institute of Mathematical Sciences, New\nYork, USA, in 2023. He is currently based in\nNew York, where he focuses on agentic plat-\nforms, multi-agent frameworks, context memory\nmanagement, and large-scale workflow execution.\nHis work centers on AI agents, large language\nmodels (LLMs), retrieval and memory systems,\nand the design of scalable, distributed systems for\nenterprise applications. From 2018 to 2020, he held engineering positions at\nOctro and IndusOS, where he worked on backend systems, personalization,\nand data-driven product development. His professional experience spans\nmachine learning, distributed infrastructure, and applied artificial intelli-\ngence. His research interests include agentic AI, large language models,\nretrieval-augmented generation, computational cognitive modeling, machine\nlearning, and distributed systems\n24 VOLUME 14, 2026\n\n-- 24 of 25 --\n\nADITI SINGH received the M.S. degree in Com-\nputer Science from Kent State University, Kent,\nOH, USA, in 2017, and the Ph.D. degree in\nComputer Science from Kent State University in\n2023. She is an Assistant College Lecturer with\nthe Department of Computer Science, Cleveland\nState University, Cleveland, OH, USA. Previously,\nshe served as a Graduate Assistant at Kent State\nUniversity (2017–2023). Her research interests\ninclude artificial intelligence and large language\nmodels, with emphasis on agentic systems, retrieval and memory for LLMs,\ntext-to-SQL, the Model Context Protocol (MCP), and computer vision\nfor human–robot interaction. She has authored over 30 publications (with\nseveral in press) and has received multiple recognitions, including Best\nPresenter Awards at IEEE CCWC (2023–2025), a Best Paper Award (CCWC\n2025), and selection as a Finalist for the Women in AI (Research) Award in\n2025. She serves on program committees for venues such as AIET, AIED,\nEDM, and ICR and reviews for international conferences and journals,\nincluding NeurIPS and ACM Computing Surveys. She is a Senior Member\nof the IEEE and chairs the Cleveland ACM-W professional chapter.\nVOLUME 14, 2026 25\n\n-- 25 of 25 --\n\n",
      "analysis_json": "{\"title\":\"Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents\",\"authors\":[\"Shubham Vatsal\",\"Harsh Dubey\",\"Aditi Singh\"],\"publication_year\":\"2026\",\"summary\":\"This study conducts a systematic review of 49 research papers on LLM-based agents in healthcare, proposing a comprehensive Seven-Dimensional Taxonomy to evaluate their capabilities. The authors analyze agents across Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology, and Core Tasks. The empirical analysis reveals that while current agents excel at External Knowledge Integration (RAG) and Multi-Agent architectures, they critically lack capabilities in Drift Detection, Event-Triggered Activation, and robust Error Recovery, highlighting a gap between academic prototypes and dependable clinical systems.\",\"breakthrough_score\":60,\"breakthrough_reasoning\":\"This paper represents a solid contribution as a meta-analysis and structural framework rather than a technical invention. Its value lies in organizing a fragmented field and empirically quantifying specific gaps (e.g., the 98% lack of drift detection) that prevent clinical deployment. It provides a roadmap for future research rather than a new algorithm.\",\"key_claims\":[\"External Knowledge Integration is the most mature capability, fully implemented in ~76% of surveyed studies.\",\"Adaptation & Learning is the weakest dimension, with Drift Detection & Mitigation absent in ~98% of agents.\",\"Event-Triggered Activation (autonomous monitoring) is largely missing (~92% not implemented), limiting agents to passive chatbot roles.\",\"Multi-Agent Design is the dominant architectural pattern (~82%), preferring specialized sub-agents over monolithic models.\",\"There is a functional asymmetry where information-centric tasks (QA) are advanced, but action-oriented tasks (Treatment Planning) remain immature.\"],\"testable_hypotheses\":[{\"hypothesis\":\"Agents incorporating explicit Drift Detection mechanisms maintain diagnostic accuracy over time significantly better than static RAG-based agents when clinical guidelines evolve.\",\"how_to_test\":\"Simulate a longitudinal timeline where medical guidelines for a specific condition change. Compare a standard RAG agent against an agent with the paper's defined 'Drift Detection' module. Measure accuracy pre- and post-guideline update without manual prompting.\",\"expected_outcome\":\"The Drift-aware agent will identify the distributional shift in knowledge and update its reasoning, while the standard agent will continue to provide obsolete advice based on static weights or stale indices.\"},{\"hypothesis\":\"Multi-agent debate architectures significantly reduce hallucination rates in complex differential diagnosis compared to single-agent Chain-of-Thought approaches.\",\"how_to_test\":\"Run a benchmark on complex medical cases using two setups: a single GPT-4 agent using CoT, and a Multi-Agent system (as defined in the Framework Typology) with separate 'Proposer' and 'Critique' agents. Measure the rate of fabricated citations or physiological impossibilities.\",\"expected_outcome\":\"The Multi-Agent system will yield higher factual consistency scores due to the 'Consistency & Conflict Resolution' sub-dimension mechanisms.\"},{\"hypothesis\":\"Event-Triggered Activation reduces time-to-intervention in critical care monitoring compared to user-initiated polling.\",\"how_to_test\":\"Connect an agent to a stream of simulated patient vitals. Compare a 'Conversational Mode' agent (reacts only when asked 'How is the patient?') vs. an 'Event-Triggered' agent (monitors stream). Introduce a critical tachycardia event.\",\"expected_outcome\":\"The Event-Triggered agent will initiate an alert sequence immediately upon threshold breach, whereas the Conversational agent will fail to act until prompted.\"}],\"key_equations\":[{\"name\":\"Taxonomy Implementation Score\",\"latex\":\"S_{agent} = \\\\sum_{d=1}^{7} \\\\sum_{s \\\\in d} w_s \\\\cdot I(s)\",\"description\":\"A conceptual scoring model based on the paper's rubric to quantify the maturity of a healthcare agent. It sums the implementation status across the 7 dimensions and 29 sub-dimensions.\",\"variables\":[{\"name\":\"d\",\"description\":\"The 7 core dimensions (Cognitive, Knowledge, Interaction, etc.)\",\"typical_range\":\"1 to 7\"},{\"name\":\"I(s)\",\"description\":\"Implementation status of sub-dimension s (1 for Fully Implemented, 0.5 for Partial, 0 for Not Implemented)\",\"typical_range\":\"{0, 0.5, 1}\"}]},{\"name\":\"Multi-Agent Consensus Function\",\"latex\":\"C = \\\\text{MajorityVote}(\\\\{A_1(x), A_2(x), ..., A_n(x)\\\\}) + \\\\text{Critique}(H)\",\"description\":\"Represents the dominant architectural pattern found in the survey (82% of papers), where final clinical output C is derived from multiple agent outputs A_n and refined via critique H.\",\"variables\":[{\"name\":\"A_n\",\"description\":\"Individual specialist agents (e.g., Diagnosis Agent, Pharmacology Agent)\",\"typical_range\":\"2-5 agents\"},{\"name\":\"Critique(H)\",\"description\":\"A validation step often performed by a separate 'Supervisor' agent to ensure safety\",\"typical_range\":\"Binary Pass/Fail or Text Refinement\"}]}],\"simulation_possibilities\":[{\"title\":\"The 'Missing Link' Clinical Simulator\",\"description\":\"An interactive scenario demonstrating why the gaps identified in the paper (Drift, Events, Error Recovery) cause failure. The user plays the role of a doctor supervising two agents: 'Standard Agent' (based on current averages) and 'Advanced Agent' (fully implemented taxonomy).\",\"complexity\":\"Medium\",\"variables\":[\"Patient Vital Stream (Normal -> Critical)\",\"Clinical Guideline Version (Old -> New)\",\"API Availability (Online -> Error)\"],\"expected_insights\":\"Users will see the Standard Agent fail to notice a heart rate spike (missing Event-Trigger), prescribe a recalled drug (missing Drift Detection), and crash when the EHR API times out (missing Error Recovery), while the Advanced Agent handles all three seamlessly.\",\"visualization_type\":\"interactive\"},{\"title\":\"Agent Architecture Assembler\",\"description\":\"A visual tool allowing users to construct an agent by toggling the 29 sub-dimensions. As users toggle features (e.g., turning on 'Memory Module' or 'Reflection'), a capability radar chart updates, and a simulated 'Reliability Score' changes.\",\"complexity\":\"Low\",\"variables\":[\"Sub-dimensions (On/Off)\",\"Task Complexity (Triage vs. Surgery Planning)\"],\"expected_insights\":\"Demonstrates that high-stakes tasks like Surgery Planning require high scores in Safety & Ethics and Perception, whereas Triage requires high Interaction Patterns.\",\"visualization_type\":\"chart\"},{\"title\":\"Drift Detection Visualizer\",\"description\":\"A data visualization showing how an LLM's answers to medical questions degrade over time as 'ground truth' changes (e.g., new COVID protocols), compared to an agent with the 'Drift Detection & Mitigation' sub-dimension enabled.\",\"complexity\":\"Medium\",\"variables\":[\"Time Steps\",\"Knowledge Volatility Rate\",\"Mitigation Strategy (None vs. Retraining vs. RAG update)\"],\"expected_insights\":\"Visual proof of the paper's claim that static agents become unsafe; illustrates the specific mechanism of how parametric knowledge conflicts with new external evidence.\",\"visualization_type\":\"animation\"}],\"field\":\"Healthcare AI & Medical Informatics\",\"related_fields\":[\"Agentic AI\",\"Large Language Models\",\"Clinical Decision Support Systems\",\"Multi-Agent Systems\"],\"limitations\":[\"The taxonomy definitions are qualitative and subjective, potentially leading to inconsistent scoring by different evaluators.\",\"The review is limited to 49 papers published between late 2023 and mid-2025, potentially missing very recent proprietary developments.\",\"The 'Breakthrough' nature is organizational; it does not present a new model architecture or training dataset itself.\"],\"difficulty_to_understand\":\"Intermediate\",\"prerequisites\":[\"Understanding of Large Language Models (LLMs)\",\"Basic knowledge of RAG (Retrieval-Augmented Generation)\",\"Familiarity with clinical workflows (EHR, Triage, Diagnosis)\"]}",
      "created_at": 1770316734987
    },
    "bdfaa68d8984f0dc02beaca527b76f207d99b666d31d1da728ee0728182df697": {
      "hash": "bdfaa68d8984f0dc02beaca527b76f207d99b666d31d1da728ee0728182df697",
      "filename": "1706.03762v7.pdf",
      "raw_text": "Provided proper attribution is provided, Google hereby grants permission to\nreproduce the tables and figures in this paper solely for use in journalistic or\nscholarly works.\nAttention Is All You Need\nAshish Vaswani∗\nGoogle Brain\navaswani@google.com\nNoam Shazeer∗\nGoogle Brain\nnoam@google.com\nNiki Parmar∗\nGoogle Research\nnikip@google.com\nJakob Uszkoreit∗\nGoogle Research\nusz@google.com\nLlion Jones∗\nGoogle Research\nllion@google.com\nAidan N. Gomez∗ †\nUniversity of Toronto\naidan@cs.toronto.edu\nŁukasz Kaiser∗\nGoogle Brain\nlukaszkaiser@google.com\nIllia Polosukhin∗ ‡\nillia.polosukhin@gmail.com\nAbstract\nThe dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to\nbe superior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-German translation task, improving over the existing best results, including\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\nbest models from the literature. We show that the Transformer generalizes well to\nother tasks by applying it successfully to English constituency parsing both with\nlarge and limited training data.\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\nattention and the parameter-free position representation and became the other person involved in nearly every\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\nour research.\n†Work performed while at Google Brain.\n‡Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\narXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n\n-- 1 of 15 --\n\n1 Introduction\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35 , 2 , 5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21 ] and conditional\ncomputation [ 32 ], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2, 19 ]. In all but a few cases [ 27 ], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16 ], ByteNet [ 18 ] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [12 ]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5, 2 , 35].\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n[10], consuming the previously generated symbols as additional input when generating the next.\n2\n\n-- 2 of 15 --\n\nFigure 1: The Transformer - model architecture.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\nrespectively.\n3.1 Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\nwise fully connected feed-forward network. We employ a residual connection [ 11 ] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position i can depend only on the known outputs at positions less than i.\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n3\n\n-- 3 of 15 --\n\nScaled Dot-Product Attention Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimension dk, and values of dimension dv . We compute the dot products of the\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V ) = softmax( QKT\n√dk\n)V (1)\nThe two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof 1\t√dk\n. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values of dk [3 ]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1\t√dk\n.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yielding dv -dimensional\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\ni=1 qiki, has mean 0 and variance dk .\n4\n\n-- 4 of 15 --\n\noutput values. These are concatenated and once again projected, resulting in the final values, as\ndepicted in Figure 2.\nMulti-head attention allows the model to jointly attend to information from different representation\nsubspaces at different positions. With a single attention head, averaging inhibits this.\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\nwhere headi = Attention(QW Q\ni , KW K\ni , V W V\ni )\nWhere the projections are parameter matrices W Q\ni ∈ Rdmodel×dk , W K\ni ∈ Rdmodel×dk , W V\ni ∈ Rdmodel×dv\nand W O ∈ Rhdv ×dmodel .\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\nis similar to that of single-head attention with full dimensionality.\n3.2.3 Applications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\nand the memory keys and values come from the output of the encoder. This allows every\nposition in the decoder to attend over all positions in the input sequence. This mimics the\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n[38, 2, 9].\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\nand queries come from the same place, in this case, the output of the previous layer in the\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\nencoder.\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\nall positions in the decoder up to and including that position. We need to prevent leftward\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\nof the softmax which correspond to illegal connections. See Figure 2.\n3.3 Position-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\nconnected feed-forward network, which is applied to each position separately and identically. This\nconsists of two linear transformations with a ReLU activation in between.\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\nWhile the linear transformations are the same across different positions, they use different parameters\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\ndf f = 2048.\n3.4 Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\nlinear transformation, similar to [ 30 ]. In the embedding layers, we multiply those weights by √dmodel.\n5\n\n-- 5 of 15 --\n\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\nLayer Type Complexity per Layer Sequential Maximum Path Length\nOperations\nSelf-Attention O(n2 · d) O(1) O(1)\nRecurrent O(n · d2) O(n) O(n)\nConvolutional O(k · n · d2) O(1) O(logk(n))\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\n3.5 Positional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\norder of the sequence, we must inject some information about the relative or absolute position of the\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\nlearned and fixed [9].\nIn this work, we use sine and cosine functions of different frequencies:\nP E(pos,2i) = sin(pos/100002i/dmodel )\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\nchose this function because we hypothesized it would allow the model to easily learn to attend by\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\nP Epos.\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\nduring training.\n4 Why Self-Attention\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\ntional layers commonly used for mapping one variable-length sequence of symbol representations\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\nconsider three desiderata.\nOne is the total computational complexity per layer. Another is the amount of computation that can\nbe parallelized, as measured by the minimum number of sequential operations required.\nThe third is the path length between long-range dependencies in the network. Learning long-range\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\nability to learn such dependencies is the length of the paths forward and backward signals have to\ntraverse in the network. The shorter these paths between any combination of positions in the input\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\nthe maximum path length between any two input and output positions in networks composed of the\ndifferent layer types.\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\n6\n\n-- 6 of 15 --\n\nlength n is smaller than the representation dimensionality d, which is most often the case with\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\n[38 ] and byte-pair [31 ] representations. To improve computational performance for tasks involving\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\nthe input sequence centered around the respective output position. This would increase the maximum\npath length to O(n/r). We plan to investigate this approach further in future work.\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\nbetween any two positions in the network. Convolutional layers are generally more expensive than\nrecurrent layers, by a factor of k. Separable convolutions [6 ], however, decrease the complexity\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\nthe approach we take in our model.\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\nand semantic structure of the sentences.\n5 Training\nThis section describes the training regime for our models.\n5.1 Training Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\nvocabulary [38 ]. Sentence pairs were batched together by approximate sequence length. Each training\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\ntarget tokens.\n5.2 Hardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\n(3.5 days).\n5.3 Optimizer\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\nrate over the course of training, according to the formula:\nlrate = d−0.5\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\nwarmup_steps = 4000.\n5.4 Regularization\nWe employ three types of regularization during training:\n7\n\n-- 7 of 15 --\n\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\nModel BLEU Training Cost (FLOPs)\nEN-DE EN-FR EN-DE EN-FR\nByteNet [18] 23.75\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\nTransformer (base model) 27.3 38.1 3.3 · 1018\nTransformer (big) 28.4 41.8 2.3 · 1019\nResidual Dropout We apply dropout [ 33] to the output of each sub-layer, before it is added to the\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\nPdrop = 0.1.\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [ 36 ]. This\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n6 Results\n6.1 Machine Translation\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\nthe competitive models.\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\ndropout rate Pdrop = 0.1, instead of 0.3.\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\nused beam search with a beam size of 4 and length penalty α = 0.6 [ 38 ]. These hyperparameters\nwere chosen after experimentation on the development set. We set the maximum output length during\ninference to input length + 50, but terminate early when possible [38].\nTable 2 summarizes our results and compares our translation quality and training costs to other model\narchitectures from the literature. We estimate the number of floating point operations used to train a\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\nsingle-precision floating-point capacity of each GPU 5.\n6.2 Model Variations\nTo evaluate the importance of different components of the Transformer, we varied our base model\nin different ways, measuring the change in performance on English-to-German translation on the\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\n8\n\n-- 8 of 15 --\n\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\nper-word perplexities.\nN dmodel dff h dk dv Pdrop ϵls train PPL BLEU params\nsteps (dev) (dev) ×106\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\n(A)\n1 512 512 5.29 24.9\n4 128 128 5.00 25.5\n16 32 32 4.91 25.8\n32 16 16 5.01 25.4\n(B) 16 5.16 25.1 58\n32 5.01 25.4 60\n(C)\n2 6.11 23.7 36\n4 5.19 25.3 50\n8 4.88 25.5 80\n256 32 32 5.75 24.5 28\n1024 128 128 4.66 26.0 168\n1024 5.12 25.4 53\n4096 4.75 26.2 90\n(D)\n0.0 5.77 24.6\n0.2 4.95 25.5\n0.0 4.67 25.3\n0.2 5.47 25.7\n(E) positional embedding instead of sinusoids 4.92 25.7\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\ncheckpoint averaging. We present these results in Table 3.\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\nsinusoidal positional encoding with learned positional embeddings [ 9], and observe nearly identical\nresults to the base model.\n6.3 English Constituency Parsing\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\nPenn Treebank [ 25], about 40K training sentences. We also trained it in a semi-supervised setting,\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\n[37 ]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\nfor the semi-supervised setting.\nWe performed only a small number of experiments to select the dropout, both attention and residual\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\nremained unchanged from the English-to-German base translation model. During inference, we\n9\n\n-- 9 of 15 --\n\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\nof WSJ)\nParser Training WSJ 23 F1\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\nTransformer (4 layers) WSJ only, discriminative 91.3\nZhu et al. (2013) [40] semi-supervised 91.3\nHuang & Harper (2009) [14] semi-supervised 91.3\nMcClosky et al. (2006) [26] semi-supervised 92.1\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\nTransformer (4 layers) semi-supervised 92.7\nLuong et al. (2015) [23] multi-task 93.0\nDyer et al. (2016) [8] generative 93.3\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\nfor both WSJ only and the semi-supervised setting.\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\nprisingly well, yielding better results than all previously reported models with the exception of the\nRecurrent Neural Network Grammar [8].\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\nParser [29] even when training only on the WSJ training set of 40K sentences.\n7 Conclusion\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\nmulti-headed self-attention.\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\nmodel outperforms even all previously reported ensembles.\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\nplan to extend the Transformer to problems involving input and output modalities other than text and\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\nThe code we used to train and evaluate our models is available at https://github.com/\ntensorflow/tensor2tensor.\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\ncomments, corrections and inspiration.\nReferences\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450, 2016.\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\nreading. arXiv preprint arXiv:1601.06733, 2016.\n10\n\n-- 10 of 15 --\n\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\nmachine translation. CoRR, abs/1406.1078, 2014.\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\npreprint arXiv:1610.02357, 2016.\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\nnetwork grammars. In Proc. of NAACL, 2016.\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\narXiv:1308.0850, 2013.\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 770–778, 2016.\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\n9(8):1735–1780, 1997.\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\nLanguage Processing, pages 832–841. ACL, August 2009.\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\nInformation Processing Systems, (NIPS), 2016.\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR), 2016.\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\n2017.\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nIn International Conference on Learning Representations, 2017.\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722, 2017.\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\narXiv:1703.03130, 2017.\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n11\n\n-- 11 of 15 --\n\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\npages 152–159. ACL, June 2006.\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\nmodel. In Empirical Methods in Natural Language Processing, 2016.\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\n2006.\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\npreprint arXiv:1608.05859, 2016.\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\nlayer. arXiv preprint arXiv:1701.06538, 2017.\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\nLearning Research, 15(1):1929–1958, 2014.\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\nInc., 2015.\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\nAdvances in Neural Information Processing Systems, 2015.\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144, 2016.\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\n1: Long Papers), pages 434–443. ACL, August 2013.\n12\n\n-- 12 of 15 --\n\nAttention VisualizationsInput-Input Layer5\nIt\t\nis\nin\nthis\nspirit\nthat\na\t\nmajority\t\nof\nAmerican\t\ngovernments\t\nhave\npassed\t\nnew\nlaws\nsince\n2009\nmaking\t\nthe\nregistration\t\nor\nvoting\t\nprocess\t\nmore\ndifficult\t\n.\t\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nIt\t\nis\nin\nthis\nspirit\nthat\na\nmajority\nof\nAmerican\ngovernments\nhave\npassed\nnew\nlaws\nsince\n2009\nmaking\nthe\nregistration\nor\nvoting\nprocess\nmore\ndifficult\n.\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\n13\n\n-- 13 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\nand 6. Note that the attentions are very sharp for this word.\n14\n\n-- 14 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\nsentence. We give two such examples above, from two different heads from the encoder self-attention\nat layer 5 of 6. The heads clearly learned to perform different tasks.\n15\n\n-- 15 of 15 --\n\n",
      "analysis_json": "{\"title\":\"Attention Is All You Need\",\"authors\":[\"Ashish Vaswani\",\"Noam Shazeer\",\"Niki Parmar\",\"Jakob Uszkoreit\",\"Llion Jones\",\"Aidan N. Gomez\",\"Łukasz Kaiser\",\"Illia Polosukhin\"],\"publication_year\":\"2017\",\"summary\":\"This seminal paper introduces the 'Transformer,' a novel neural network architecture based solely on attention mechanisms, dispensing with the recurrence and convolutions used in previous state-of-the-art models (RNNs/CNNs). By utilizing 'Multi-Head Self-Attention,' the model captures global dependencies between input and output regardless of distance. The architecture allows for massive parallelization during training, significantly reducing training time while achieving superior results on English-to-German and English-to-French translation tasks. It establishes the foundation for modern Large Language Models.\",\"breakthrough_score\":100,\"breakthrough_reasoning\":\"This is a paradigm-shifting paper. It effectively deprecated Recurrent Neural Networks (RNNs/LSTMs) for sequence modeling by solving the sequential computation bottleneck. The introduction of the Transformer architecture laid the direct groundwork for BERT, GPT, and the entire current generation of Generative AI. It moved the field from sequential processing to parallelized self-attention, enabling the training of models on data scales previously impossible.\",\"key_claims\":[\"Recurrence and convolutions are not strictly necessary for sequence transduction; attention mechanisms alone are sufficient.\",\"The Transformer architecture allows for significantly more parallelization than recurrent models, reducing training time by orders of magnitude.\",\"Multi-head attention allows the model to jointly attend to information from different representation subspaces at different positions.\",\"Sinusoidal positional encodings allow the model to make use of the order of the sequence without recurrence.\"],\"testable_hypotheses\":[{\"hypothesis\":\"Dot-product attention yields large values in high-dimensional spaces that push softmax into regions with extremely small gradients.\",\"how_to_test\":\"Create a simulation comparing 'Standard Dot-Product' vs 'Scaled Dot-Product' attention. Allow the user to increase the dimension size (dk) and observe the magnitude of the dot products and the resulting gradients of the softmax function.\",\"expected_outcome\":\"As dimension size increases, standard dot-products grow large, causing softmax gradients to vanish. The scaled version (dividing by sqrt(dk)) maintains stable gradients.\"},{\"hypothesis\":\"Different attention heads learn distinct linguistic functions (syntax vs. semantic relationships).\",\"how_to_test\":\"Visualize the attention weights of an 8-head model processing a sentence with ambiguous references (e.g., 'The animal didn't cross the street because it was too tired'). Toggle between heads to see which words 'it' attends to.\",\"expected_outcome\":\"Some heads will focus on local neighbors (syntax), while specific heads will strongly link 'it' to 'animal', effectively resolving the anaphora.\"},{\"hypothesis\":\"Self-attention has a constant path length between any two positions, unlike RNNs which have O(n).\",\"how_to_test\":\"Simulate signal propagation in an RNN vs. Transformer. Click a token at the start of a long sequence and a token at the end, and visualize the number of 'steps' required to relate them.\",\"expected_outcome\":\"The RNN simulation will show a sequential hop through every intermediate token. The Transformer simulation will show a direct, single-step connection regardless of distance.\"}],\"key_equations\":[{\"name\":\"Scaled Dot-Product Attention\",\"latex\":\"Attention(Q, K, V) = softmax(QK^T / sqrt(d_k))V\",\"description\":\"The core mechanism where queries (Q) are matched against keys (K) to create weights, which are then applied to values (V). The scaling factor prevents gradient vanishing.\",\"variables\":[{\"name\":\"Q\",\"description\":\"Query matrix (what we are looking for)\",\"typical_range\":\"Matrix of size [sequence_length, 64]\"},{\"name\":\"K\",\"description\":\"Key matrix (what we match against)\",\"typical_range\":\"Matrix of size [sequence_length, 64]\"},{\"name\":\"V\",\"description\":\"Value matrix (the actual content to extract)\",\"typical_range\":\"Matrix of size [sequence_length, 64]\"},{\"name\":\"d_k\",\"description\":\"Dimension of the keys (scaling factor)\",\"typical_range\":\"64\"}]},{\"name\":\"Positional Encoding\",\"latex\":\"PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\",\"description\":\"Injects information about the relative or absolute position of tokens in the sequence, since the model has no recurrence.\",\"variables\":[{\"name\":\"pos\",\"description\":\"The position of the word in the sentence\",\"typical_range\":\"0 to 512\"},{\"name\":\"i\",\"description\":\"The dimension index within the embedding\",\"typical_range\":\"0 to 256 (half of d_model)\"},{\"name\":\"d_model\",\"description\":\"Total dimension of the model/embedding\",\"typical_range\":\"512\"}]},{\"name\":\"Multi-Head Attention\",\"latex\":\"MultiHead(Q, K, V) = Concat(head_1, ..., head_h)W^O\",\"description\":\"Splits the input into 'h' different 'heads' allowing the model to attend to different parts of the history simultaneously.\",\"variables\":[{\"name\":\"h\",\"description\":\"Number of parallel attention heads\",\"typical_range\":\"8\"},{\"name\":\"W^O\",\"description\":\"Output projection matrix\",\"typical_range\":\"Learned Weights\"}]}],\"simulation_possibilities\":[{\"title\":\"Interactive Self-Attention Heatmap\",\"description\":\"A text input interface where users type a sentence. The visualization displays the self-attention matrix (Q x K^T). Hovering over a word highlights which other words it is 'looking at' and how strongly. Users can switch between the 8 different 'heads' to see how different heads focus on grammar, recent words, or long-term dependencies.\",\"complexity\":\"Medium\",\"variables\":[\"Input Text\",\"Selected Head (0-7)\",\"Layer Index (0-5)\"],\"expected_insights\":\"Users will intuitively understand that 'attention' is just a weighted sum of other words, and that different heads specialize in different linguistic features.\",\"visualization_type\":\"interactive\"},{\"title\":\"Positional Encoding Wave visualizer\",\"description\":\"A 2D heatmap showing the sinusoidal positional encodings. The X-axis is the embedding dimension, Y-axis is the token position. Users can hover to see the specific sin/cos values. A slider allows users to add this encoding to a standard word embedding to see how it modifies the vector space to encode 'order'.\",\"complexity\":\"Low\",\"variables\":[\"Sequence Length\",\"d_model\"],\"expected_insights\":\"Visualizes how the model tells the difference between 'The dog bit the man' and 'The man bit the dog' without processing them in order.\",\"visualization_type\":\"chart\"},{\"title\":\"The Q-K-V Matrix Multiplication Step-Through\",\"description\":\"A step-by-step animation of the math inside a single attention head. Visually represented vectors for Query, Key, and Value. Step 1: Show dot product of Q and K. Step 2: Show scaling and Softmax. Step 3: Show multiplication with V. Users can adjust the vector values manually to see how 'similarity' drives the attention score.\",\"complexity\":\"High\",\"variables\":[\"Vector Values for Q, K, V\",\"d_k scaling\"],\"expected_insights\":\"Demystifies the matrix math, showing that attention is essentially a 'soft dictionary lookup' based on vector similarity.\",\"visualization_type\":\"animation\"}],\"field\":\"Deep Learning / Natural Language Processing\",\"related_fields\":[\"Machine Translation\",\"Computer Vision (Vision Transformers)\",\"Sequence Modeling\",\"Generative AI\"],\"limitations\":[\"Computational complexity is quadratic O(n^2) with respect to sequence length, making very long sequences expensive.\",\"The model is not inherently sequential, requiring positional encodings to understand order.\",\"Requires significant amounts of training data and compute resources compared to smaller statistical models.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Matrix Multiplication\",\"Softmax Function\",\"Neural Networks (Basics)\",\"Encoder-Decoder Architectures\"]}",
      "created_at": 1770308018318
    },
    "arxiv-2602.04879": {
      "hash": "arxiv-2602.04879",
      "filename": "2602.04879.pdf",
      "raw_text": "Rethinking the Trust Region in LLM Reinforcement Learning\nPenghui Qi * 1 2 Xiangxin Zhou * 1 Zichen Liu 2 Tianyu Pang 1 Chao Du 1 Min Lin 1 Wee Sun Lee 2\nAbstract\nReinforcement learning (RL) has become a cor-\nnerstone for fine-tuning Large Language Mod-\nels (LLMs), with Proximal Policy Optimization\n(PPO) serving as the de facto standard algorithm.\nDespite its ubiquity, we argue that the core ra-\ntio clipping mechanism in PPO is structurally ill-\nsuited for the large vocabularies inherent to LLMs.\nPPO constrains policy updates based on the prob-\nability ratio of sampled tokens, which serves as a\nnoisy single-sample Monte Carlo estimate of the\ntrue policy divergence. This creates a sub-optimal\nlearning dynamic: updates to low-probability to-\nkens are aggressively over-penalized, while po-\ntentially catastrophic shifts in high-probability to-\nkens are under-constrained, leading to training\ninefficiency and instability. To address this, we\npropose Divergence Proximal Policy Optimiza-\ntion (DPPO), which substitutes heuristic clipping\n*Equal contribution 1Sea AI Lab, Singapore 2School of\nComputing, National University of Singapore. Correspondence\nto: Wee Sun Lee <leews@comp.nus.edu.sg>, Penghui Qi\n<penghuiq@comp.nus.edu.sg>.\nPreprint. February 5, 2026.\nwith a more principled constraint based on a direct\nestimate of policy divergence (e.g., Total Varia-\ntion or KL). To avoid huge memory footprint, we\nintroduce the efficient Binary and Top-K approxi-\nmations to capture the essential divergence with\nnegligible overhead. Extensive empirical evalu-\nations demonstrate that DPPO achieves superior\ntraining stability and efficiency compared to ex-\nisting methods, offering a more robust foundation\nfor RL-based LLM fine-tuning.\n1. Introduction\nReinforcement learning (RL) is a foundational paradigm\nfor fine-tuning Large Language Models (LLMs), enabling\nalignment with human preferences (Ouyang et al., 2022;\nRafailov et al., 2023) and complex reasoning tasks (Guo\net al., 2025; Qi et al., 2025a). Proximal Policy Optimization\n(PPO1) (Schulman et al., 2017) has established itself as the\nde facto standard in this domain, favored for its simplicity\nand empirical scalability. Central to PPO is a heuristic\nclipping mechanism designed to prevent destructive policy\nupdates. By constraining the probability ratio between new\n1We denote PPO by its ratio-clipping loss, regardless of advan-\ntage estimation. Under this definition, GRPO is a PPO variant.\n1\n https://github.com/sail-sg/Stable-RL\nFigure 1. Comparison of PPO and the proposed DPPO (the Binary-TV variant in Section 4.4). (Left) The surrogate objective and\ncorresponding masks for PPO and DPPO. PPO (and variants like GRPO) employs a heuristic mask based on the probability ratio, which\nover-penalizes low-probability tokens and under-penalizes high-probability ones (Section 4.2). In contrast, DPPO utilizes a more\nprincipled mask based on a direct approximation of policy divergence (e.g., Total Variation), ensuring updates stay within a theoretically\ngrounded trust region (Section 3). (Right) Experimental results on the AIME24 using Qwen3-30B-A3B-Base. DPPO significantly\noutperforms GRPO baselines, achieving superior training efficiency and stability even without rollout routing replay (R3) (Section 7).\narXiv:2602.04879v1 [cs.LG] 4 Feb 2026\n\n-- 1 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nFigure 2. The plots show numerical differences between a training\nand an inference engine for Qwen3-30B-A3B-Base with identical\nparameters. (Left) The probability ratio (used in PPO) is highly\nvolatile for low-probability tokens. (Right) In contrast, the TV di-\nvergence (used in DPPO) is more stable. This highlights a key flaw\nof PPO’s clipping mechanism: it over-penalizes low-probability\ntokens, which can slow down learning; and under-penalizes high-\nprobability tokens, which can permit large, destabilizing updates.\nand old policies, the algorithm aims to confine learning to a\ntrust region where monotonic improvement is theoretically\nguaranteed (Schulman et al., 2015).\nDespite its widespread adoption, we argue that PPO’s core\nmechanism, ratio clipping, is structurally ill-suited for the\nexpansive, long-tailed vocabularies inherent to LLMs. Un-\nlike Trust Region Policy Optimization (TRPO) (Schulman\net al., 2015), which constrains the KL or Total Variation\n(TV) divergence of the policy distribution, PPO constrains\nupdates based on the probability ratio of the sampled token.\nAs we demonstrate later, this approach functions as a noisy,\nsingle-sample Monte Carlo estimate of the true policy diver-\ngence. While this approximation suffices for classical RL\nenvironments with limited action spaces, it fails in the LLM\nregime due to the ratio’s hypersensitivity to the probability\nmagnitude. For example, increasing a rare token’s probabil-\nity from 10−5 to 10−3 generates a massive ratio of 100 that\ntriggers clipping, even though the actual divergence is negli-\ngible. Conversely, small ratio changes on high-probability\ntokens can make catastrophic shifts in probability mass (e.g.,\na drop from 0.99 to 0.8), yet it often remains unpenalized\nby the clipping mechanism.\nThis implicit bias is exacerbated by the training-inference\nmismatch (Yao et al., 2025; Qi et al., 2025b; Zheng et al.,\n2025), where numerical discrepancies arise between training\nand inference engines even under identical parameters. As\nillustrated in Figure 2, the probability ratio becomes highly\nvolatile for low-probability tokens, while TV divergence\nremains stable. Consequently, PPO creates a sub-optimal\nlearning dynamic: updates to low-probability tokens are\naggressively over-penalized, slowing learning, while up-\ndates to high-probability tokens are under-penalized, risking\ninstability. These limitations necessitate a fundamental re-\nthinking of the trust region approach in LLM fine-tuning to\nensure both efficiency and stability.\nTo address these fundamental limitations, we propose Diver-\ngence Proximal Policy Optimization (DPPO), a framework\nthat substitutes PPO’s heuristic clipping with a more prin-\ncipled constraint grounded in trust region theory. Rather\nthan relying on noisy single-sample ratios, DPPO directly\nestimates policy divergence (e.g., TV or KL divergence). To\nensure memory feasibility for LLMs, we introduce two effi-\ncient approximations, Binary and Top-K divergence, which\ncapture essential distributional shifts with negligible over-\nhead. This allows DPPO to rigorously distinguish between\nsafe and unsafe updates, effectively resolving the problems\nof over- and under-constraining inherent in standard PPO.\nIn this work, we provide a comprehensive rethinking of the\ntrust region in the context of LLM fine-tuning. Our contri-\nbutions are threefold. Theoretical Formulation: We de-\nrive policy improvement bounds specifically tailored to the\nfinite-horizon, undiscounted setting of LLM generation, es-\ntablishing a rigorous theoretical foundation for trust-region\nmethods in this domain. Stability and Efficiency Analy-\nsis: We isolate the primary sources of training instability\nto provide practical stabilization guidelines, while further\nhighlighting the significant role that low-probability tokens\nplay in driving exploration. Algorithmic Performance: We\ndemonstrate that DPPO achieves superior stability and fi-\nnal performance compared to existing methods like GRPO,\nproviding a robust new framework for RL-based fine-tuning.\n2. Background\n2.1. Policy Performance Difference\nWe begin with the standard formulation of a Markov\nDecision Process (MDP), defined by the tuple M =\n(S, A, P, r, ρ0, γ), which includes the state space S, action\nspace A, transition dynamics P (s′|s, a), reward function\nr(s, a), initial state distribution ρ0(s), and a discount factor\nγ ∈ [0, 1]. A stochastic policy π(a|s) generates trajec-\ntories τ = (s0, a0, r0, s1, a1, r1, . . .) by sampling actions\nat ∼ π(·|st) and transitioning to states st+1 ∼ P (·|st, at).\nThe central goal of RL is to find a policy that maximizes the\nexpected discounted return:\nη(π) = Eτ ∼π\n\" ∞\tX\nt=0\nγtrt\n#\n.\nTo facilitate policy optimization, we define the standard\nvalue functions under a policy π: the state-value function\nV π (s) = Eτ ∼π\nh P∞\nt=0 γtrt s0 = s\ni\n, the action-value func-\ntion Qπ (s, a) = Eτ ∼π\nh P∞\nt=0 γtrt s0 = s, a0 = a\ni\n, and\nthe advantage function Aπ (s, a) = Qπ (s, a) − V π (s). A\nkey theoretical tool for relating the performance of two\ndistinct policies is the policy performance difference theo-\nrem (Kakade & Langford, 2002). It states that for any two\npolicies, a target policy (to be optimized) π and a behavior\n2\n\n-- 2 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\npolicy (for rollout) μ, their expected returns are related by:\nη(π) − η(μ) = 1\n1 − γ Es∼ρπ , a∼π(·|s)\n\u0002Aμ(s, a)\u0003. (1)\nHere, ρπ (s) = (1 − γ) P∞\nt=0 γt Pr(st = s| π) is the nor-\nmalized discounted state-visitation distribution induced by\nthe policy π. This identity is fundamental, as it implies that\nany policy update that results in a non-negative expected\nadvantage guarantees monotonic performance improvement,\ni.e., η(π) ≥ η(μ).\n2.2. Policy Improvement Bound\nWhile Equation 1 provides a direct expression for policy\nimprovement, its dependence on the state-visitation distri-\nbution ρπ of the new policy makes it intractable for direct\noptimization. To overcome this, Schulman et al. (2015) de-\nrive a lower bound on performance improvement that can be\nestimated using samples from the behavior policy μ, with\na penalty term that measures the divergence between the\nold and new policies. This lower bound forms the basis of\ntrust-region methods.\nTheorem 2.1. (Schulman et al., 2015; Achiam et al., 2017)\nGiven any two policies, μ and π, the following bound holds:\nη(π)−η(μ) ≥ 1\n1 − γ Es∼ρμ, a∼μ(·|s)\n\"\nπ(a|s)\nμ(a|s) Aμ(s, a)\n#\n− 2ξγ\n(1 − γ)2 Dmax\nTV (μ ∥ π)2,\n(2)\nwhere ξ = maxs,a Aμ(s, a) and Dmax\nTV (μ ∥ π) =\nmaxs DTV\n\u0000 μ(·|s)∥ π(·|s)\u0001, which is the maximum Total\nVariation (TV) divergence among all states.\nThis bound provides a direct path to guaranteed policy im-\nprovement. The right-hand side of the inequality forms a\nsurrogate objective that is a tight lower bound on the true\nperformance improvement, touching the objective when\nπ = μ. Therefore, iteratively maximizing this surrogate\nguarantees monotonic improvement in η(π), following the\nprinciples of the Minorize-Maximization (MM) algorithm\n(Hunter & Lange, 2004; Schulman et al., 2015).\n2.3. Trust Region Policy Optimization\nThe policy improvement bound in Equation (2) directly\njustifies a surrogate objective,\nLμ(π) = 1\n1 − γ Es∼ρμ, a∼μ(a|s)\n\u0014 π(a|s)\nμ(a|s) Aμ(s, a)\n\u0015\n. (3)\nThis objective serves as a first-order approximation of\nthe true performance improvement η(π) − η(μ), as their\nvalues and gradients match at the point of expansion π = μ\n(Kakade & Langford, 2002; Schulman et al., 2015; Zheng\net al., 2025). Therefore, maximizing Lμ(π) within a small\ntrust region guarantees stable and meaningful policy im-\nprovement. This insight motivates the trust-region opti-\nmization approach (Schulman et al., 2015; Xie et al., 2024),\nwhich involves maximizing Lμ(π) subject to a constraint\nthat keeps the new policy π within a trust region around\nthe current policy μ, thereby ensuring the validity of the\napproximation. Formally, this is expressed as the following\nconstrained optimization problem:\nmax\nπ Lμ(π)\ns.t. Dmax\nTV (μ ∥ π) ≤ δ, (4)\nwhere the constraint can also be applied on a KL divergence\nDKL, justified via Pinsker’s inequality:\nDTV(μ ∥ π)2 ≤ 1\n2 DKL(μ ∥ π).\n3. Trust Region Under LLM Regime\nIn this section, we adapt the trust region framework to the\nspecific context of LLM fine-tuning. This setting differs\nfrom the classical RL paradigm in two crucial ways. First,\nthe learning problem is structured as an undiscounted (γ =\n1) episodic task with a finite horizon T , which makes the\noriginal bound in Equation (2) ill-defined, as the 1\n1−γ term\ndiverges to infinity. Second, due to the sparse reward nature,\nadvantages are often estimated at the sequence level (Shao\net al., 2024), rather than on a per-token basis.\nFormally, given a prompt x, a policy π (the LLM) gener-\nates a response y = (y1, . . . , yT ) by sequentially sampling\ntokens. At each step t, the policy defines a conditional dis-\ntribution π(yt|st) over the vocabulary A, where the state\nst = (x, y1, . . . , yt−1) consists of the prompt and previ-\nously generated tokens. The probability of the complete\nresponse is the product of these conditional probabilities:\nπ(y|x) = QT\nt=1 π(yt|st). After the full response is gener-\nated, a scalar reward R(y, x) is provided. For brevity, we\nwill omit the dependency on the initial prompt x and write\nthe objective function as:\nJ (π) = Ey∼π [R(y)].\nWe now derive performance difference identity and policy\nimprovement bound tailored to this regime.\nTheorem 3.1 (Performance Difference Identity for LLMs).\nIn a finite-horizon setting (T ) with no discount (γ = 1), for\nany two policies π and μ, the performance difference can\nbe decomposed as:\nJ (π) − J (μ) = L′\nμ(π) − ∆(μ, π),\nwhere L′\nμ(π) is a surrogate objective defined as:\nL′\nμ(π) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013\n , (5)\n3\n\n-- 3 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nand ∆(μ, π) is an error term given by:\n∆(μ, π) =Ey∼μ\nh\nR(y) (6)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) −1\n\u0013\n1−\nT\tY\nj=t+1\nπ(yj |sj )\nμ(yj |sj )\n\n i\n.\nThis theorem provides an exact expression for the policy\nimprovement. The surrogate L′\nμ(π) represents a first-order\napproximation, while the error term ∆ captures the higher-\norder effects of the policy change. To make this practical\nfor optimization, we bound the error term.\nTheorem 3.2 (Policy Improvement Bound for LLMs). In\na finite-horizon setting (T ) with no discount (γ = 1), the\npolicy improvement is lower-bounded by:\nJ (π)−J (μ) ≥ L′\nμ(π)−2ξT (T −1)·Dmax\nTV (μ ∥ π)2, (7)\nwhere ξ = maxy |R(y)| is the maximum absolute reward,\nand Dmax\nTV (μ ∥ π) = maxst DTV\n\u0000 μ(·|st)∥ π(·|st)\u0001 is the\nmaximum Total Variation (TV) divergence over all states.\nThis theorem establishes a lower bound on policy improve-\nment, and it is structurally analogous to the bound in Theo-\nrem 2.1 (see Appendix B.4), with the horizon T playing a\nrole similar to the effective horizon 1\n1−γ in the discounted\nsetting. It provides a clear theoretical justification for adapt-\ning the trust region approach into LLM regime. Similar\nto Equation (4), we can solve the following constrained\noptimization problem to guarantee stable learning:\nmax\nπ L′\nμ(π)\ns.t. Dmax\nTV (μ ∥ π) ≤ δ, (8)\nwhere the constraint can also be applied on a KL divergence.\nThe proofs for Theorem 3.1 and Theorem 3.2 are deferred\nto Appendix B. In Appendix B.3, we further derive a more\npractical bound that depends linearly, rather than quadrati-\ncally, on the horizon length T .\n4. Methodology\n4.1. Proximal Policy Optimization\nWhile theoretically appealing, the constrained optimization\nin TRPO requires second-order methods that are computa-\ntionally expensive and difficult to scale. PPO (Schulman\net al., 2017) was introduced to achieve the stability of a trust\nregion method using only first-order optimization. Its sim-\nplicity and strong empirical performance have established it\nas a standard algorithm for fine-tuning LLMs.\nInstead of an explicit trust region constraint, PPO discour-\nages overly large policy updates with a heuristic clipping\nmechanism applied to the surrogate objective. Specifically,\nPPO optimizes the following clipped objective:\nLPPO\nμ (π) = Ey∼μ\n\n\n|y|\t\nX\nt=1\nmin\n\u0010\nrt ˆ\tAt, clip(rt, 1−ϵ, 1+ϵ) ˆ\tAt\n\u0011\n,\nrt = π(yt|st)\nμ(yt|st) , (9)\nwhere ˆ\tAt is an estimated advantage at timestep t. In LLM\nfine-tuning, the advantage is usually estimated by ˆ\tA =\nR(y) − 1\nG\nPG\ni=1 R(yi) (Shao et al., 2024; Liu et al., 2025d),\nwhere {yi}G\ni=1 is a group of responses for the same prompt.\nThe connection between PPO’s clipping and the formal trust\nregion can be understood by examining the TV divergence:\nDTV\n\u0000 μ(·|st)∥ π(·|st)\u0001 = 1\n2 Eyt∼μ\n\u0002 rt − 1 \u0003 . (10)\nFrom this perspective, PPO’s clipping condition, |rt−1| ≤ ϵ,\ncan be interpreted as constraining a single-sample Monte\nCarlo estimate of the expected value in Equation (10). In\nessence, PPO enforces its trust region not on the true TV\ndivergence, but on a noisy, single-point estimation. As we\nwill argue next, this crude approximation is the source of\nsignificant pathologies when applied to the large, long-tailed\nvocabulary distributions characteristic of LLMs.\n4.2. Limitations of PPO Ratio Clipping\nThe key limitation of PPO is that whether an update is\nclipped depends heavily on the sampled token’s probability,\nrather than the true TV divergence between μ(·|st) and\nπ(·|st). Concretely, consider a fixed state s and two tokens\nalow and ahigh with\nμ(alow|s) = 10−4, π(alow|s) = 10−2,\nμ(ahigh|s) = 0.99, π(ahigh|s) = 0.80.\nThe probability ratio for the low-probability token is rlow =\n10−2\n10−4 = 100, which is far outside a typical clipping range\n[1−ϵ, 1+ϵ] (e.g., ϵ = 0.2). PPO would thus heavily clip the\ncontribution of this update. In contrast, the actual contribu-\ntion of this change to the TV divergence can be very small,\nbecause the total mass moved at alow is tiny. For the high-\nprobability token, rhigh = 0.80\n0.99 ≈ 0.808, which can still lie\ninside the clipping range for a moderate ϵ. Yet this update\nremoves 0.19 probability mass from the dominant token,\nand therefore induces a much larger contribution to DTV.\nThese examples highlight a structural flaw in PPO’s clipping\nheuristic. For low-probability tokens, an update that pro-\nduces a large probability ratio is aggressively constrained,\neven when its impact on the TV divergence is negligible,\nthereby slowing training efficiency. Conversely, for high-\nprobability tokens, an update producing a ratio close to\n4\n\n-- 4 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\none may go unpenalized, even when the absolute change in\nprobability mass is large enough to cause a substantial TV\ndivergence, which in turn risks training instability.\nConnections to Existing Work The insight that PPO’s ratio\nclipping disproportionately penalizes low-probability tokens\naligns with several prior studies. For instance, methods like\nClip-Higher (Yu et al., 2025) and CISPO (Chen et al., 2025)\nobserve that important “exploration” or “reasoning” tokens\noften have low initial probabilities (see Appendix E). These\ntokens usually get high importance ratios during policy up-\ndates and are consequently clipped, hindering the learning\nprocess. However, the solutions proposed remain heuristic\nand problematic. Clip-Higher suggests manually increasing\nthe upper clipping bound, while CISPO continues to apply\nthe gradient even for large divergence, completely ignoring\nthe trust region. While these methods correctly identify the\nsymptom, they fail to address the root cause: the fundamen-\ntal mismatch between the single-sample probability ratio\nand the true distributional divergence.\n4.3. Divergence Proximal Policy Optimization\nTo address the limitations of ratio clipping, we introduce Di-\nvergence Proximal Policy Optimization (DPPO), a method\nthat replaces PPO’s flawed heuristic with a more principled\nconstraint grounded in trust region theory. Similar to Chen\net al. (2025); Zheng et al. (2025), DPPO employs a dynamic\nmask to prevent updates that would leave the trust region.\nThe DPPO objective is:\nLDPPO\nμ (π) = Ey∼μ\n\n\n|y|\t\nX\nt=1\nM DPPO\nt · rt · ˆ\tAt\n\n . (11)\nOur key innovation lies in the design of this mask. Instead\nof relying on the noisy single-sample ratio, it is conditioned\non a direct measure of the policy distribution’s divergence:\nM DPPO\nt =\n\n\t\n\t\n0, if ( ˆ\tAt > 0 and rt > 1 and D > δ) or\n( ˆ\tAt < 0 and rt < 1 and D > δ)\n1, otherwise,\n(12)\nwhere D ≡ D\u0000 μ(·|st)∥ π(·|st)\u0001 is the divergence (e.g.,\nTV or KL) between the policy distributions, and δ is a\ndivergence threshold hyperparameter.\nThis design directly approximates the formal trust region\nconstraint from Theorem 3.2 while preserving the beneficial\nasymmetric structure of PPO’s clipping. The mask only\nconsiders blocking an update if it is already moving away\nfrom the trusted region (i.e., rt > 1 for a positive advantage\nor rt < 1 for a negative advantage). It never blocks updates\nthat move the policy ratio towards one (e.g., when ˆ\tAt > 0\nand rt < 1), a desirable property for accelerating learning.\nUnlike PPO, the final decision to block an update is based\non whether the entire policy distribution has shifted too far\n(D > δ), not on the noisy and often misleading ratio of a sin-\ngle sample. This resolves the over- and under-constraining\nissues inherent in standard PPO. The primary remaining\nchallenge is the overhead of calculating the full divergence\nD over a large vocabulary in LLMs, which we address next.\n4.4. Approximating Distribution Divergence\nDirectly computing the policy divergence is memory-\nprohibitive for LLMs. To make it practical, we introduce\ntwo lightweight approximations, which serve as principled\nlower bounds of the true divergence (see Appendix C).\nBinary Approximation The binary approximation col-\nlapses the original categorical distribution into a simple\nBernoulli distribution, distinguishing only between the sam-\npled token and all other tokens. We define the new distribu-\ntion as: p˜π\nt = \u0000˜π(at|st), 1 − ˜π(at|st)\u0001, where ˜π can be μ\nor π. The TV and KL divergences are then computed as:\nDBin\nTV (t) = μ(at|st) − π(at|st) , (13)\nDBin\nKL (t) = μ(at|st) log μ(at|st)\nπ(at|st)\n+ (1 − μ(at|st)) log 1 − μ(at|st)\n1 − π(at|st) .\n(14)\nThis binary divergence can be computed at negligible over-\nhead. Crucially, it correctly distinguishes between large\nversus small shifts in absolute probability mass, thereby\nresolving the primary failure mode of PPO’s clipping.\nTop-K Approximation To provide a richer and more\nfaithful approximation of the distributional shift, the top-K\nvariant explicitly tracks the most probable tokens. First,\nwe define a small, representative set of tokens A′\nt as:\nA′\nt = TopK \u0000 μ(·|st), K\u0001 ∪ {at}, which includes the K\nhighest-probability tokens under the behavior policy, aug-\nmented with the sampled token at if it is not already present.\nWe then form reduced categorical distributions, pμ\nt and\npπ\nt , over the new vocabulary A′′\nt = A′\nt ∪ {other}. For\nany token a ∈ A′\nt, its probability is its original probabil-\nity, while all other tokens are aggregated into the “other”\ncategory: p˜π\nt (a) = ˜π(a|st) ∀a ∈ A′\nt, and p˜π\nt (other) =\n1 − P\na∈A′\nt\n˜π(a|st), where ˜π can be μ or π. The divergence\nis then computed over this reduced distribution:\nDTopK\nTV (t) = 1\n2\nX\na∈A′′\nt\npμ\nt (a) − pπ\nt (a) , (15)\nDTopK\nKL (t) = X\na∈A′′\nt\npμ\nt (a) log pμ\nt (a)\npπ\nt (a) . (16)\nThis approach better captures changes in the head of the\npolicy distribution, which typically dominates the true diver-\ngence value. The overhead is minimal, making it a practical\nand high-fidelity choice for DPPO.\n5\n\n-- 5 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0 \t1000 \t2000 \t3000\nTraining Step\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00 \tRewards\nPG-IS\nMiniRL\nPG-TIS (CISPO)\nMiniRL-TIS\nGRPO-ClipHigher\nDPPO-Binary-TV\nDPPO-Binary-KL\n0 \t1000 \t2000 \t3000\nTraining Step\n0.20\n0.25\n0.30\n0.35\n0.40\nAIME 2024\n0 \t1000 \t2000 \t3000\nTraining Step\n0.0025\n0.0050\n0.0075\n0.0100\n0.0125\n0.0150\n0.0175\n0.0200\nMean of | \t- \t|\n0 \t1000 \t2000 \t3000\nTraining Step\n1.00\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\n1.00\nMax&Min of | \t- \t|\nNo mismatch ( \t= \t)\nFigure 3. DPPO variants achieve stable training while controlling the training-inference mismatch at a low level. In contrast, methods\nwithout a trust region (PG-IS, CISPO) or with a misspecified one (MiniRL) suffer from growing mismatch and eventual collapse.\n5. Analysis on Training Stability\nThe RL fine-tuning of LLMs is prone to training instability\ndue to training-inference mismatch (see Appendix A.2). In\nthis section, we conduct an empirical study to dissect this\nissue and verify the stability of our DPPO algorithm. To\nformalize our analysis, we denote the parameters being op-\ntimized as θ and the parameters used for data generation as\nθ′. We aim to answer three fundamental research questions:\n1. Given the extremely low learning rates (e.g., 10−6)\ncommon in LLM fine-tuning, is a trust region still\nnecessary to ensure training stability?\n2. Should the trust region be defined with respect to the\noriginal rollout distribution (μθ′ ) or a recomputed pol-\nicy distribution (πθ′ )?\n3. What specific types of policy updates are the primary\ndrivers of training instability?\nExperimental Setting: Our experimental setup follows\nthe sanity test proposed by Qi et al. (2025b). We fine-\ntune DeepSeek-R1-Distill-Qwen-1.5B (Guo et al., 2025) on\na curated set of 1,460 problems from the MATH dataset\n(Hendrycks et al., 2021). In this setting, a stable algorithm\nshould theoretically converge to 100% training accuracy, as\nall problems are known to be solvable by the initial model.\nWe evaluate several algorithms, each representing a different\napproach to managing the policy update. The baselines in-\nclude: PG-IS and its truncated variant PG-TIS (also known\nas CISPO (Chen et al., 2025)), which use standard policy\ngradients with token-level importance sampling; GRPO\nwith Clip-Higher, a PPO-like algorithm where clipping is\nbased on the rollout policy ratio rt = πθ\nμθ′ (Shao et al., 2024;\nLiu et al., 2025d); and MiniRL & MiniRL-TIS, a PPO\nvariant where clipping is based on a recomputed policy ratio\nrt = πθ\nπθ′ (Zheng et al., 2025). We compare these against\nDPPO (Ours), our proposed method using either binary KL\nor TV divergence, with the trust region defined with respect\nto the rollout distribution μθ′ . Detailed configurations for\neach algorithm are provided in the Appendix D.\n5.1. The Necessity of a Trust Region\nOur first question addresses whether a trust region is redun-\ndant at low learning rates. Figure 3 provides a clear answer.\nThe unconstrained methods, PG-IS and PG-TIS (CISPO),\nboth suffer from an increasing training-inference mismatch,\nwhich culminates in a collapse of performance. In contrast,\nour DPPO variants, which enforce a principled trust region,\nmaintain a stable, low level of mismatch throughout training\nand achieve near-perfect final rewards.\nTakeaway 1: A trust region is essential for stable training,\neven with very small learning rates. Without it, the training-\ninference mismatch accumulates and leads to collapse.\n0 \t500 \t1000 \t1500 \t2000 \t2500 \t3000 \t3500\nTraining step\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00 \tRewards\nDPPO-KL-Rollout\nDPPO-KL-Recompute\n0 \t500 \t1000 \t1500 \t2000 \t2500 \t3000 \t3500\nTraining step\n0.005\n0.010\n0.015\n0.020\n0.025\n0.030\nMean of | \t- \t|\nFigure 4. Switching the stable DPPO-KL to a decoupled objective\ncauses the mismatch to grow and performance to collapse, con-\nfirming that the trust region must be anchored to the rollout policy.\n5.2. The Correct Anchor for the Trust Region\nNext, we investigate to which distribution the trust region\nshould be anchored. A common practice in open-source im-\nplementations (Sheng et al., 2024; Zhu et al., 2025) is to use\na decoupled objective (Hilton et al., 2022), where the trust\nregion is enforced relative to a recomputed policy distribu-\ntion (πθ′ ) instead of the original behavior policy (μθ′ ). The\nMiniRL algorithm, for example, follows this design (Zheng\net al., 2025). Our results show this choice is detrimental. As\nin Figure 3, MiniRL fails to control the training-inference\nmismatch and its performance collapses, despite using a\ntrust region. To confirm this, we created a decoupled ver-\nsion of our stable DPPO-KL algorithm. Figure 4 shows\nthat this single change corrupts the stable training process,\n6\n\n-- 6 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\ncausing the mismatch to grow and performance to collapse.\nTakeaway 2: The trust region must be defined with respect\nto the original behavior policy (μθ′ ). Using a recomputed\non-policy distribution as the anchor leads to instability. This\nfinding aligns with the theoretical bound in Equation (7)\nand offers a significant practical benefit: by removing the\nneed for recomputation, we can reduce training costs by\napproximately 25% (Qi et al., 2025b).\n0 \t500 \t1000 \t1500 \t2000 \t2500 \t3000 \t3500\nTraining Step\n0.6\n0.7\n0.8\n0.9\n1.0\nRewards (solid)\nPG-IS\nMask-0.5-Recompute\nMask-0.5-Rollout\nMask-0.8-Rollout \t0.1\n0.2\n0.3\n0.4\n0.5\nPercentage (dashed)\nFigure 5. Isolating the source of instability. The solid curves are\ntraining rewards, while the dashed lines are the percentage of bad\nupdates. Starting with the unstable PG-IS, applying a minimal\nmask that only blocks large-divergence bad updates on negative\nsamples is sufficient to stabilize training, indicating these bad\nupdates are the primary cause of training instability.\n5.3. Identifying the Source of Instability\nFinally, we seek to pinpoint which specific policy updates\nare most responsible for the instability. Our methodology is\nto start with the unstable PG-IS algorithm, which applies no\nupdate masking, and introduce the most minimal mask nec-\nessary to restore stability. This allows us to isolate the most\ndetrimental class of updates. Since updates on positively\nrewarded samples are typically safe, we focus on negative\nsamples where the policy is penalized (Liu et al., 2025a; Ren\n& Sutherland, 2025). We design a simple mask that only\nblocks updates on negative samples where the probability\nof the sampled token is decreased by more than a threshold\nδ: Mt = 0 if ˆ\tAt < 0 and μθ′ (yt|st) − πθ (yt|st) ≥ δ. As\nshown in Figure 5, applying this minimal mask with δ = 0.5\nis sufficient to stabilize the training. In contrast, a slightly\nlooser mask (δ = 0.8) or one anchored to the recomputed\ndistribution (“Mask-0.5-Recompute”) both fail to prevent\nthe eventual collapse. We define bad updates as those\nwhere this divergence exceeds 0.5 and plot their percentage\nover time. The plot reveals that only a very small fraction of\nupdates are “bad” (≤ 0.5%) yet they are the primary culprits\nbehind training collapse. Furthermore, the percentage\nof these bad updates strongly correlates with reward\nfluctuation; as the fraction of bad updates rises, the reward\ncurve becomes more erratic, reinforcing a causal link.\nTakeaway 3: The primary source of instability is a small\nsubset of updates on negative samples that push the policy\nfar outside the trust region. A likely reason is that aggres-\nsively penalizing a token the model deems probable can\ncorrupt the LLM’s internal knowledge and destabilize the\nlearning process. This finding confirms the critical need for\na trust region, particularly when handling negative feedback.\n5.4. The Pitfalls of Truncated Importance Sampling\nOur empirical results also reveal a surprising finding re-\ngarding Truncated Importance Sampling (TIS), a technique\nwidely adopted to control the variance of policy gradient\nestimates (Yao et al., 2025; Chen et al., 2025). Contrary\nto its intended purpose, TIS consistently degrades training\nstability in our experiments. As illustrated in Figure 3, the\nTIS-enabled variants (PG-TIS and MiniRL-TIS) suffer from\npremature collapse and significantly underperform their un-\ntruncated counterparts.\nWe hypothesize that this detrimental effect stems from the\nsame issue as PPO’s ratio clipping: low-probability tokens,\nwhich naturally produce high-variance ratios, are the most\nlikely to be truncated by TIS. While this does reduce vari-\nance, it systematically down-weights the gradient signal\nfrom these tokens, introducing a significant and harmful\nbias into the policy update. This suggests that naive trunca-\ntion can be just as damaging as naive clipping.\n6. Analysis on Training Efficiency\nBeyond training stability, the design of trust region is\nalso critical for training efficiency. As motivated in Sec-\ntion 4.2, PPO’s ratio-clipping over-constrains the updates\nto low-probability tokens, which might be permitted by a\ndivergence-based trust region. In this section, we aim to\nanalyze how low-probability tokens affect the training dy-\nnamics, thus justifying the adoption of divergence-based\ntrust region in our DPPO algorithm.\n0 \t10 \t20 \t30 \t40 \t50 \t60 \t70\nTraining step\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35 \tRewards\n0 \t10 \t20 \t30 \t40 \t50 \t60 \t70\nTraining step\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nClipped rollout probability\n0 \t10 \t20 \t30 \t40 \t50 \t60 \t70\nTraining step\n0.0\n0.5\n1.0\n1.5\n2.0\n2.5\n3.0\n3.5\n4.0\t\nClipped entropy\n0\n0.1\n0.3\n0.5\n0.7\nFigure 6. Analysis of relaxing trust regions for low-probability to-\nkens. (Left) Training reward curves. (Middle) Rollout probability\nof clipped tokens. (Right) Entropy of clipped tokens.\nExperimental Setting: We fine-tune Qwen3-1.7B-Base\n(Yang et al., 2025) on the DAPO dataset (Yu et al.,\n2025). We employ GRPO (Guo et al., 2025; Liu et al.,\n2025d) with the Clip-Higher trick (Yu et al., 2025) as\nthe baseline algorithm. We then relax trust regions by\nsetting the clipping threshold ϵ in Equation (9) as infinity\n7\n\n-- 7 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nfor tokens with μ(yt|st) < α, thus isolating the effect of\nlow-probability tokens.\nThe learning curves for varying values of α are presented\nin Figure 6. Notably, relaxing the clipping constraint\nfor tokens with μ(yt|st) < 0.1 yields a substantial\nimprovement in training efficiency compared to the GRPO\nbaseline (α = 0). This observation validates our hypothesis\nthat the ratio-clipping mechanism in PPO over-constrains\nupdates to low-probability tokens, thereby hindering\noverall learning progress. The middle plot reveals that\nclipped tokens are predominantly characterized by low\nprobabilities (typically below 0.15 for the baseline in blue).\nAs α increases, the probabilities of clipped tokens also rise,\nconfirming that PPO’s ratio-clipping is structurally biased\nagainst low-probability tokens. Furthermore, the right\nplot demonstrates that clipped tokens frequently exhibit\nhigh entropy. Consistent with Wang et al. (2025a), which\nposits that RL is driven primarily by high-entropy tokens\nin LLMs, our results suggest that relaxing constraints on\nthese tokens enables more informative policy updates and\nthus achieves higher training efficiency (see Appendix E\nfor most frequent clipped tokens).\nFurthermore, we examine the effect of directional clip relax-\nation with a fixed α = 0.1. We generalize the clip operation\nwith asymmetric thresholds, denoted as clip(rt, 1−ϵlow, 1+\nϵhigh), where ϵlow = 0.2 and ϵhigh = 0.28 by default. We\nrelax either one end (Relax-high or Relax-low) or both ends\n(Relax-both). For example, Relax-high is implemented by\n(ϵlow = 0.2, ϵhigh = ∞) for tokens with μ(yt|st) < α.\nAs illustrated in Figure 7, the direction of clip relaxation\nplays a critical role in the training efficiency and stabil-\nity. Relax-high can be viewed as an extreme variant of\nthe Clip-Higher trick (Yu et al., 2025) applied only to low-\nprobability tokens. While this approach maintains high en-\ntropy, it fails to yield significant gains in training efficiency.\nConversely, Relax-low exhibits substantially faster initial\nlearning2. However, this strategy eventually drops due to\nentropy collapse (Cui et al., 2025). Ultimately, we find that\nRelax-both is the most effective strategy for achieving\nboth efficient and stable training, thereby validating the\ndesign of DPPO in relaxing both ends of the trust region.\n7. Scaling Experiments\nExperimental Setting: We conduct large-scale experiments\nto further validate our methods. We train on a filtered subset\nof DAPO-Math (Yu et al., 2025), containing approximately\n2In contrast to the Clip-Higher intuition (Yu et al., 2025), we\nobserve that “Clip-Lower” (relaxing ϵlow) for low-probability to-\nkens is more vital for efficiency. This aligns with findings by\nTajwar et al. (2024) regarding the role of negative gradients in\naccelerating preference learning.\n0 \t100 \t200 \t300 \t400 \t500\nTraining step\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30 \tRewards\nBaseline\nRelax-both\nRelax-high\nRelax-low\n0 \t100 \t200 \t300 \t400 \t500\nTraining step\n0.01\n0.10\n1.00\nEntropy\nFigure 7. Analysis of trust region relaxation direction. (Left)\nTraining reward curves. (Right) Policy entropy.\n13k samples. Five model configurations (different base mod-\nels and training techniques) are evaluated: (1) MoE Base:\nQwen3-30B-A3B-Base (Yang et al., 2025); (2) MoE Base\nw/ R3: Qwen3-30B-A3B-Base with rollout router replay\n(R3) (Ma et al., 2025); (3) MoE Thinking: Qwen3-30B-\nA3B; (4) Dense Base: Qwen3-8B-Base; (5) MoE Base w/\nLoRA: Qwen3-30B-A3B-Base with LoRA (Hu et al., 2022).\nBaseline methods include GRPO-ClipHigher(Shao et al.,\n2024; Liu et al., 2025d; Yu et al., 2025) and CISPO(Chen\net al., 2025; Khatri et al., 2025). All methods use the behav-\nior policy (μθ′ ) instead of recomputed policy distribution\n(πθ′ ) to construct the trust region (i.e., for clipping or mask-\ning). We compare our proposed methods, DPPO-Binary-\nKL and DDPO-Binary-TV, against these baselines. More\ndetails are provided in Appendix F.\nMain Results. We present online evaluation results on\nAIME24 and AIME25 (MAA, 2025) during RL training in\nthe following figures: Figure 8 (MoE Base with and without\nR3) and Figure 9 (MoE Thinking and Dense Base). Results\nfor MoE Base with LoRA are provided in Appendix G.1.\nOur proposed method consistently demonstrates superior\nstability and efficiency across all five large-scale experi-\nments. Specifically, DPPO optimizes rewards at a signifi-\ncantly faster speed than the GRPO-ClipHigher baseline and\nachieves better converged performance, providing empiri-\ncal validation for the motivations discussed in Section 4.2.\nWhile all baseline methods frequently exhibit training in-\nstability or catastrophic collapse (e.g., CISPO in MoE Base\nwithout R3 and GRPO-ClipHigher in MoE Thinking), our\napproach maintains a remarkably stable training process.\nRollout router replay (R3) is widely considered a necessary\ntechnique for stabilizing RL training in MoE models (Ma\net al., 2025; Zheng et al., 2025; Liu et al., 2025a). However,\nas illustrated in Figure 8, our DPPO variants (without R3)\neven consistently outperform the R3-enhanced baselines,\nwhich underscores the superior training efficiency and inher-\nent stability of the DPPO framework. We provide additional\ndetailed results and extended discussions in Appendix G.1.\nAblation on TV/KL Approximation. In the above scaling\nexperiments, DPPO is implemented using the binary TV/KL\n8\n\n-- 8 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.2\n0.3\n0.4\n0.5\n0.6\nAIME24 w/o R3\nGRPO-ClipHigher\nCISPO\nDPPO-Binary-KL\nDPPO-Binary-TV\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.2\n0.3\n0.4\n0.5\n0.6\nAIME24 w/ R3\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAIME25 w/o R3\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAIME25 w/ R3\nFigure 8. Evolution of AIME24 and AIME25 Avg@32 scores during RL training using Qwen3-30B-A3B-Base. The first and third panels\ncorrespond to the same experiment without rollout router replay (w/o R3), while the second and fourth panels correspond to the same\nexperiment with rollout router replay (w/ R3).\n0 \t50 \t100 \t150 \t200 \t250\nTraining Step\n0.64\n0.66\n0.68\n0.70\n0.72\n0.74\n0.76\n0.78\nA3B - AIME24\nA3B-GRPO-ClipHigher\nA3B-CISPO\nA3B-DPPO-Binary-KL\nA3B-DPPO-Binary-TV\n0 \t50 \t100 \t150 \t200 \t250\nTraining Step\n0.54\n0.56\n0.58\n0.60\n0.62\n0.64\n0.66\n0.68\nA3B - AIME25\n0 \t200 \t400 \t600 \t800 \t1000 \t1200 \t1400\nTraining Step\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n8B - AIME24\n8B-GRPO-ClipHigher\n8B-CISPO\n8B-DPPO-Binary-KL\n8B-DPPO-Binary-TV\n0 \t200 \t400 \t600 \t800 \t1000 \t1200 \t1400\nTraining Step\n0.10\n0.15\n0.20\n0.25\n0.30\n8B - AIME25\nFigure 9. Evolution of AIME24 and AIME25 scores during RL training using Qwen3-30B-A3B (left) and Qwen3-8B-Base (right).\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.20\n0.30\n0.40\n0.50\n0.60 \tAIME24\nGRPO-ClipHigher\nCISPO\nDPPO-Binary-KL\nDPPO-Binary-TV\nDPPO-TopK-KL\nDPPO-TopK-TV\n0 \t50 \t100 \t150 \t200\nTraining Step\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAIME25\nFigure 10. Evolution of AIME24 and AIME25 scores for baselines\nand DPPO with binary/Top-K (K=20) TV/KL approximation under\nthe same setting as MoE Base w/o R3.\napproximation (Equations 13 and 14). To assess the impact\nof this simplification, we compare it against DPPO with the\ntop-K (K=20) TV/KL (Equations 15 and 16) under the same\nsetting as MoE Base. The results, presented in Figure 10,\nshow that both approximations perform similarly and signif-\nicantly outperform the baselines. This finding indicates that\nthe easy-to-implement binary approximation is a sufficient\nand computationally efficient choice for scalable RL. We\nprovide more detailed results in Appendix G.2.\nGeneralization to Other Model Families and Tasks. We\nalso conduct experiments on models from the Llama family\n(Touvron et al., 2023; Wang et al., 2025b) and on tasks be-\nyond math reasoning (Liu et al., 2025e). The results, which\nare presented in Appendix G.3, show DPPO outperforms\nthe baseline across most settings, highlighting its broad\napplicability.\n8. Conclusion\nIn this work, we have presented a comprehensive rethinking\nof the trust region framework within the context of LLM\nfine-tuning. We derived policy improvement bounds specifi-\ncally tailored to the finite-horizon, undiscounted setting of\nLLM generation, establishing a rigorous theoretical founda-\ntion for future trust-region research. Furthermore, through\nextensive empirical analysis, we investigated the trade-offs\nbetween training stability and efficiency, providing practical\nguidelines to optimize both.\nCentral to our contribution is the introduction of Divergence\nProximal Policy Optimization (DPPO). We identified and\naddressed a critical structural flaw in the standard PPO algo-\nrithm: it over-constrains updates to low-probability tokens\nwhile under-constraining potentially catastrophic shifts in\nhigh-probability tokens. This implicit bias results in a sub-\noptimal training dynamic, particularly for the expansive,\nlong-tailed vocabularies inherent to LLMs. By substitut-\ning heuristic ratio clipping with a more principled policy\ndivergence, DPPO significantly enhances both efficiency\nand stability. To avoid huge memory footprint for com-\nputing an exact policy divergence, we introduced Binary\nand Top-K approximations, which capture essential diver-\ngence with negligible overhead. Our evaluations demon-\nstrate that DPPO consistently outperforms existing methods\nlike GRPO in both training efficiency and stability, offering\na more robust foundation for the RL-based LLM fine-tuning.\n9\n\n-- 9 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nImpact Statement\nThis paper presents work whose goal is to advance the field\nof Machine Learning. There are many potential societal\nconsequences of our work, none which we feel must be\nspecifically highlighted here.\nReferences\nAchiam, J., Held, D., Tamar, A., and Abbeel, P. Constrained\npolicy optimization. In International conference on ma-\nchine learning, pp. 22–31. PMLR, 2017.\nChen, A., Li, A., Gong, B., Jiang, B., Fei, B., Yang, B.,\nShan, B., Yu, C., Wang, C., Zhu, C., et al. Minimax-\nm1: Scaling test-time compute efficiently with lightning\nattention. arXiv preprint arXiv:2506.13585, 2025.\nCui, G., Zhang, Y., Chen, J., Yuan, L., Wang, Z., Zuo, Y., Li,\nH., Fan, Y., Chen, H., Chen, W., et al. The entropy mech-\nanism of reinforcement learning for reasoning language\nmodels. arXiv preprint arXiv:2505.22617, 2025.\nGuo, D., Yang, D., Zhang, H., Song, J., Zhang, R., Xu, R.,\nZhu, Q., Ma, S., Wang, P., Bi, X., et al. Deepseek-r1: In-\ncentivizing reasoning capability in llms via reinforcement\nlearning. arXiv preprint arXiv:2501.12948, 2025.\nHe, H. Defeating nondeterminism in llm inference. Thinking\nMachines Lab: Connectionism, 2025. doi: 10.64434/tml.\n20250910. https://thinkingmachines.ai/blog/defeating-\nnondeterminism-in-llm-inference/.\nHendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart,\nS., Tang, E., Song, D., and Steinhardt, J. Measuring math-\nematical problem solving with the math dataset. arXiv\npreprint arXiv:2103.03874, 2021.\nHilton, J., Cobbe, K., and Schulman, J. Batch size-\ninvariance for policy optimization. Advances in Neural\nInformation Processing Systems, 35:17086–17098, 2022.\nHu, E. J., yelong shen, Wallis, P., Allen-Zhu, Z., Li, Y.,\nWang, S., Wang, L., and Chen, W. LoRA: Low-rank adap-\ntation of large language models. In International Confer-\nence on Learning Representations, 2022. URL https:\n//openreview.net/forum?id=nZeVKeeFYf9.\nHunter, D. R. and Lange, K. A tutorial on mm algorithms.\nThe American Statistician, 58(1):30–37, 2004.\nKakade, S. and Langford, J. Approximately optimal ap-\nproximate reinforcement learning. In Proceedings of the\nnineteenth international conference on machine learning,\npp. 267–274, 2002.\nKhatri, D., Madaan, L., Tiwari, R., Bansal, R., Duvvuri,\nS. S., Zaheer, M., Dhillon, I. S., Brandfonbrener, D.,\nand Agarwal, R. The art of scaling reinforcement learn-\ning compute for llms. arXiv preprint arXiv:2510.13786,\n2025.\nKwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu,\nC. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient\nmemory management for large language model serving\nwith pagedattention. In Proceedings of the ACM SIGOPS\n29th Symposium on Operating Systems Principles, 2023.\nLiu, A., Mei, A., Lin, B., Xue, B., Wang, B., Xu, B., Wu,\nB., Zhang, B., Lin, C., Dong, C., et al. Deepseek-v3.\n2: Pushing the frontier of open large language models.\narXiv preprint arXiv:2512.02556, 2025a.\nLiu, J., Li, Y., Fu, Y., Wang, J., Liu, Q., and\nShen, Y. When speed kills stability: Demys-\ntifying rl collapse from the inference-training\nmismatch, 2025b. https://yingru.notion.site/When-\nSpeed-Kills-Stability-Demystifying-RL-\nCollapse-from-the-Inference-Training-Mismatch-\n271211a558b7808d8b12d403fd15edda.\nLiu, Z., Chen, C., Du, C., Lee, W. S., and Lin, M. Oat:\nA research-friendly framework for llm online alignment.\nhttps://github.com/sail-sg/oat, 2025c.\nLiu, Z., Chen, C., Li, W., Qi, P., Pang, T., Du, C., Lee,\nW. S., and Lin, M. Understanding r1-zero-like training:\nA critical perspective. arXiv preprint arXiv:2503.20783,\n2025d.\nLiu, Z., Sims, A., Duan, K., Chen, C., Yu, S., Zhou, X., Xu,\nH., Xiong, S., Liu, B., Tan, C., et al. Gem: A gym for\nagentic llms. arXiv preprint arXiv:2510.01051, 2025e.\nMa, W., Zhang, H., Zhao, L., Song, Y., Wang, Y., Sui, Z.,\nand Luo, F. Stabilizing moe reinforcement learning by\naligning training and inference routers. arXiv preprint\narXiv:2510.11370, 2025.\nMAA. American invitational mathematics examination -\naime. https://maa.org/, 2025.\nOuyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C.,\nMishkin, P., Zhang, C., Agarwal, S., Slama, K., Ray, A.,\net al. Training language models to follow instructions\nwith human feedback. Advances in neural information\nprocessing systems, 35:27730–27744, 2022.\nQi, P., Liu, Z., Pang, T., Du, C., Lee, W. S., and Lin, M.\nOptimizing anytime reasoning via budget relative policy\noptimization. arXiv preprint arXiv:2505.13438, 2025a.\nQi, P., Liu, Z., Zhou, X., Pang, T., Du, C., Lee, W. S., and\nLin, M. Defeating the training-inference mismatch via\nfp16. arXiv preprint arXiv:2510.26788, 2025b.\n10\n\n-- 10 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nRafailov, R., Sharma, A., Mitchell, E., Manning, C. D.,\nErmon, S., and Finn, C. Direct preference optimiza-\ntion: Your language model is secretly a reward model.\nAdvances in neural information processing systems, 36:\n53728–53741, 2023.\nRen, Y. and Sutherland, D. J. Learning dynamics of LLM\nfinetuning. In The Thirteenth International Conference\non Learning Representations, 2025.\nSchulman, J. and Lab, T. M. Lora without regret. Thinking\nMachines Lab: Connectionism, 2025. doi: 10.64434/tml.\n20250929. https://thinkingmachines.ai/blog/lora/.\nSchulman, J., Levine, S., Abbeel, P., Jordan, M., and Moritz,\nP. Trust region policy optimization. In International\nconference on machine learning, pp. 1889–1897. PMLR,\n2015.\nSchulman, J., Wolski, F., Dhariwal, P., Radford, A., and\nKlimov, O. Proximal policy optimization algorithms.\narXiv preprint arXiv:1707.06347, 2017.\nShao, Z., Wang, P., Zhu, Q., Xu, R., Song, J., Bi, X., Zhang,\nH., Zhang, M., Li, Y., Wu, Y., et al. Deepseekmath: Push-\ning the limits of mathematical reasoning in open language\nmodels. arXiv preprint arXiv:2402.03300, 2024.\nSheng, G., Zhang, C., Ye, Z., Wu, X., Zhang, W., Zhang,\nR., Peng, Y., Lin, H., and Wu, C. Hybridflow: A\nflexible and efficient rlhf framework. arXiv preprint\narXiv:2409.19256, 2024.\nTajwar, F., Singh, A., Sharma, A., Rafailov, R., Schneider,\nJ., Xie, T., Ermon, S., Finn, C., and Kumar, A. Prefer-\nence fine-tuning of LLMs should leverage suboptimal, on-\npolicy data. In Proceedings of the 41st International Con-\nference on Machine Learning, volume 235 of Proceed-\nings of Machine Learning Research, pp. 47441–47474.\nPMLR, 21–27 Jul 2024.\nTeam, L., Han, B., Tang, C., Liang, C., Zhang, D., Yuan,\nF., Zhu, F., Gao, J., Hu, J., Li, L., Li, M., Zhang, M.,\nJiang, P., Jiao, P., Zhao, Q., Yang, Q., Shen, W., Yang, X.,\nZhang, Y., Ren, Y., Zhao, Y., Cao, Y., Sun, Y., Zhang, Y.,\nFang, Y., Lin, Z., Cheng, Z., and Zhou, J. Every attention\nmatters: An efficient hybrid architecture for long-context\nreasoning. arXiv preprint arXiv:2510.19338, 2025a.\nTeam, L., Shen, A., Li, B., Hu, B., Jing, B., Chen, C., Huang,\nC., Zhang, C., Yang, C., Lin, C., et al. Every step evolves:\nScaling reinforcement learning for trillion-scale thinking\nmodel. arXiv preprint arXiv:2510.18855, 2025b.\nTouvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux,\nM.-A., Lacroix, T., Rozi `ere, B., Goyal, N., Hambro, E.,\nAzhar, F., et al. Llama: Open and efficient foundation lan-\nguage models. arXiv preprint arXiv:2302.13971, 2023.\nWan, X., Qi, P., Huang, G., Ruan, C., Lin, M., and Li, J.\nRevisiting parameter server in llm post-training. arXiv\npreprint arXiv:2601.19362, 2026.\nWang, S., Yu, L., Gao, C., Zheng, C., Liu, S., Lu, R., Dang,\nK., Chen, X., Yang, J., Zhang, Z., et al. Beyond the\n80/20 rule: High-entropy minority tokens drive effective\nreinforcement learning for llm reasoning. arXiv preprint\narXiv:2506.01939, 2025a.\nWang, Y., He, H., Tan, X., and Gan, Y. Trust region-guided\nproximal policy optimization. Advances in Neural Infor-\nmation Processing Systems, 32, 2019.\nWang, Y., He, H., and Tan, X. Truly proximal policy op-\ntimization. In Uncertainty in artificial intelligence, pp.\n113–122. PMLR, 2020.\nWang, Z., Zhou, F., Li, X., and Liu, P. Octothinker:\nMid-training incentivizes reinforcement learning scaling.\narXiv preprint arXiv:2506.20512, 2025b. Preprint.\nXie, Z., Zhang, Q., Yang, F., Hutter, M., and Xu, R. Simple\npolicy optimization. arXiv preprint arXiv:2401.16025,\n2024.\nYang, A., Li, A., Yang, B., Zhang, B., Hui, B., Zheng, B.,\nYu, B., Gao, C., Huang, C., Lv, C., et al. Qwen3 technical\nreport. arXiv preprint arXiv:2505.09388, 2025.\nYao, F., Liu, L., Zhang, D., Dong, C., Shang, J., and Gao, J.\nYour efficient rl framework secretly brings you off-policy\nrl training, August 2025. https://fengyao.notion.site/off-\npolicy-rl.\nYu, Q., Zhang, Z., Zhu, R., Yuan, Y., Zuo, X., Yue, Y., Dai,\nW., Fan, T., Liu, G., Liu, L., et al. Dapo: An open-source\nllm reinforcement learning system at scale. arXiv preprint\narXiv:2503.14476, 2025.\nZhang, Z., Ding, X., Yuan, J., Liu, R., Mao, H., Xing, J.,\nand Liu, Z. Deterministic inference across tensor parallel\nsizes that eliminates training-inference mismatch. arXiv\npreprint arXiv:2511.17826, 2025.\nZheng, C., Dang, K., Yu, B., Li, M., Jiang, H., Lin, J., Liu,\nY., Lin, H., Wu, C., Hu, F., et al. Stabilizing reinforcement\nlearning with llms: Formulation and practices. arXiv\npreprint arXiv:2512.01374, 2025.\nZhu, Z., Xie, C., Lv, X., and slime Contributors. slime: An\nllm post-training framework for rl scaling. https://\ngithub.com/THUDM/slime, 2025. GitHub reposi-\ntory. Corresponding author: Xin Lv.\n11\n\n-- 11 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nA. Related Work\nA.1. Extended Connections to Existing Work\nIn this work, we identify a structural flaw in PPO’s ratio-clipping mechanism within the LLM regime: it over-penalizes\nlow-probability tokens and under-penalizes high-probability ones, thereby impairing training efficiency and stability. Our\nproposed DPPO addresses this issue by directly constraining the policy divergence. This methodology aligns with the\ninsights of Wang et al. (2019; 2020), who observed similar exploration issues and proposed adaptive clipping based on\nKL divergence in traditional RL settings. However, in the context of LLMs, computing the exact divergence is prohibitive\ndue to the huge memory footprint. To overcome this, we propose a binary divergence approximation, which empirically\ncaptures most of the benefits (see Appendix G.2). Furthermore, as demonstrated in Section 5 and Section 6, the challenges\nof training stability and efficiency are exacerbated in LLMs by their expansive vocabularies, because low-probability tokens\nform a non-trivial portion of the entire distribution due to the long-tailed nature (see Figure 2). Finally, the training-inference\nmismatch inherent to the LLM era introduces additional algorithmic complexities, as further detailed in Section 5.\nA.2. Training-inference Mismatch\nRecent work has identified a key culprit for training instability: the training-inference mismatch (πθ̸ = μθ ), where the\npolicy distribution used for gradient computation (πθ ) diverges from the one used for data generation (μθ ), even when using\nidentical model parameters θ (Yao et al., 2025; Qi et al., 2025b; Liu et al., 2025b; Zheng et al., 2025). This discrepancy\narises from numerical precision errors (Qi et al., 2025b) and subtle differences in implementation (Team et al., 2025a; He,\n2025). As training progresses, this mismatch can be amplified if the RL algorithm cannot manage it appropriately, leading to\ncatastrophic performance degradation (Qi et al., 2025b; Liu et al., 2025b).\nExisting efforts to mitigate this issue primarily focus on correcting biased gradients through importance sampling. Building\non this principle, techniques such as Truncated Importance Sampling (TIS) (Yao et al., 2025; Zheng et al., 2025) and Masked\nImportance Sampling (Liu et al., 2025b; Team et al., 2025b) have been introduced at both the token and sequence levels.\nHowever, as suggested by Qi et al. (2025b), these methods often fail to achieve a satisfactory balance between training\nefficiency and stability. In contrast, our DPPO algorithm significantly enhances both aspects compared to these existing\napproaches.\nAnother line of research attempts to resolve the mismatch issue through higher precision (Qi et al., 2025b) or rigorous\nengineering alignment (Team et al., 2025a; He, 2025; Zhang et al., 2025). While promising, these methods face limited\napplicability. For instance, aligning implementation details often requires specific training engines or model architectures,\nhindering broad adoption. Furthermore, in low-precision settings optimized for high-speed training, we must tolerate a\nsignificant training-inference mismatch. In such scenarios, a robust and fast algorithm like DPPO remains essential. Finally,\nour algorithmic design is orthogonal to these engineering-level optimizations and can be combined with them to achieve\neven greater performance gains.\nB. Trust Region in LLMs\nB.1. Proof of Performance Difference Identity\nProof of Theorem 3.1. We begin by expressing the difference in expected returns by its definition:\nJ (π) − J (μ) = Ey∼π [R(y)] − Ey∼μ[R(y)]\n= X\ny\n\u0000 π(y|x) − μ(y|x)\u0001R(y).\nThe core of the proof is to establish an identity for the difference in the probabilities of generating a sequence y, π(y|x) −\nμ(y|x). We use the following telescoping sum identity, which can be verified by expanding the terms:\nπ(y|x) − μ(y|x) =\nT\tX\nt=1\nt−1\tY\nk=1\nμ(yk|sk)\n! \u0010\nπ(yt|st) − μ(yt|st)\n\u0011 \n\nT\tY\nj=t+1\nπ(yj |sj )\n\n .\n12\n\n-- 12 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nSubstituting this identity into the expression for the performance difference yields:\nJ (π) − J (μ) = X\ny\nR(y)\nT\tX\nt=1\nt−1\tY\nk=1\nμ(yk|sk)\n! \u0010\nπ(yt|st) − μ(yt|st)\n\u0011 \n\nT\tY\nj=t+1\nπ(yj |sj )\n\n\n= X\ny\nμ(y|x)R(y)\nT\tX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013 \n\nT\tY\nj=t+1\nπ(yj |sj )\nμ(yj |sj )\n\n\n= Ey∼μ\n\nR(y)\nT\tX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013 \n\nT\tY\nj=t+1\nπ(yj |sj )\nμ(yj |sj )\n\n\n\n\n= Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013\n\n− Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013 \n1 −\nT\tY\nj=t+1\nπ(yj |sj )\nμ(yj |sj )\n\n\n\n .\nBy identifying the terms with the definitions in the theorem statement, we arrive at:\nJ (π) − J (μ) = L′\nμ(π) − ∆(μ, π),\nwhere\nL′\nμ(π) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013\n ,\n∆(μ, π) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013 \n1 −\nT\tY\nj=t+1\nπ(yj |sj )\nμ(yj |sj )\n\n\n\n .\nThis completes the proof.\nB.2. Proof of Policy Improvement Bound\nLemma B.1 (Bound on Sequence-Level TV Divergence). Let μ and π be two policies that generate sequences of length N .\nLet μN (·|s1) and πN (·|s1) denote the distributions over sequences y = (y1, . . . , yN ). The total variation (TV) divergence\nbetween these sequence distributions is bounded by the sum of the expected single-step TV divergences:\nDTV\n\u0000μN (·|s1)∥πN (·|s1)\u0001 ≤\nN\tX\nt=1\nEst∼μ\n\u0002DTV\n\u0000 μ(·|st)∥ π(·|st)\u0001\u0003 ,\nwhere the expectation is over the state distribution induced by policy μ.\nProof. Let P (y) = μN (y|s1) and Q(y) = πN (y|s1).\n2DTV(P ∥Q) = X\ny\n|P (y) − Q(y)| = X\ny\nN\tY\nt=1\nμ(yt|st) −\nN\tY\nt=1\nπ(yt|st) .\nWe use the algebraic identity a1 . . . aN − b1 . . . bN = PN\nt=1\n\u0010Qt−1\nk=1 ak\n\u0011\n(at − bt)\n\u0010QN\nj=t+1 bj\n\u0011\n. Applying this to the policy\n13\n\n-- 13 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nprobabilities and then using the triangle inequality, we get:\n2DTV(P ∥Q) ≤ X\ny\nN\tX\nt=1\nt−1\tY\nk=1\nμ(yk|sk)\n!\n| μ(yt|st) − π(yt|st)|\n\n\nN\tY\nj=t+1\nπ(yj |sj )\n\n\n=\nN\tX\nt=1\nX\ny\nt−1\tY\nk=1\nμ(yk|sk)\n!\n| μ(yt|st) − π(yt|st)|\n\n\nN\tY\nj=t+1\nπ(yj |sj )\n\n .\nFor each term in the outer sum over t, we can sum over the variables yj for j > t. Since P\nyj π(yj |sj ) = 1 for all sj , the\nproduct of terms for j > t sums to 1 when we integrate out yt+1, . . . , yN . This leaves:\n2DTV(P ∥Q) ≤\nN\tX\nt=1\nX\ny1,...,yt\nt−1\tY\nk=1\nμ(yk|sk)\n!\n| μ(yt|st) − π(yt|st)|\n=\nN\tX\nt=1\nX\ny1,...,yt−1\nt−1\tY\nk=1\nμ(yk|sk)\n! X\nyt\n| μ(yt|st) − π(yt|st)|.\nThe inner sum is 2DTV(μ(·|st)∥ π(·|st)). The outer sum over y1, . . . , yt−1 defines an expectation over states st under\npolicy μ. Thus, we have:\n2DTV(P ∥Q) ≤\nN\tX\nt=1\nEst∼μ\n\u00022DTV\n\u0000 μ(·|st)∥ π(·|st)\u0001\u0003 .\nDividing by 2 yields the desired result.\nProof of Theorem 3.2. From Lemma 3.1, we start with the exact performance difference identity:\nJ (π) − J (μ) = L′\nμ(π) − ∆(μ, π).\nFor brevity, we define y≤t = {x, y1, . . . , yt} and y>t = {yt+1, yt+2, . . . }, then we can rewrite ∆(μ, π) as:\n∆(μ, π) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 π(yt|st)\nμ(yt|st) − 1\n\u0013 \u0012\n1 − π(y>t|st+1)\nμ(y>t|st+1)\n\u0013\n .\nOur goal is to find an upper bound for the error term ∆(μ, π). We begin by bounding the reward by its maximum absolute\nvalue, ξ = maxy |R(y)|.\n∆(μ, π) ≤ ξ · Ey∼μ\n\" T\tX\nt=1\nπ(yt|st)\nμ(yt|st) − 1 · 1 − π(y>t|st+1)\nμ(y>t|st+1)\n#\n= ξ ·\nT\tX\nt=1\nEy≤t∼μ\n\u0014 π(yt|st)\nμ(yt|st) − 1 · Ey>t∼μ(·|st+1)\n\u0014\n1 − π(y>t|st+1)\nμ(y>t|st+1)\n\u0015\u0015\n.\n(17)\nThe inner expectation is exactly twice the TV divergence between the distributions over future trajectories:\nEy>t∼μ(·|st+1)\n\u0014\n1 − π(y>t|st+1)\nμ(y>t|st+1)\n\u0015\n= 2DTV\n\u0000μ>t(·|st+1)∥π>t(·|st+1)\u0001.\nUsing Theorem B.1 on this sequence-level TV divergence (for a sequence of length T − t), we get:\nDTV\n\u0000μ>t(·|st+1)∥π>t(·|st+1)\u0001 ≤\nT\tX\nk=t+1\nEsk ∼μ(·|st+1)\n\u0002DTV\n\u0000 μ(·|sk)∥ π(·|sk)\u0001\u0003 .\n14\n\n-- 14 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nWe bound each term in the sum by the maximum single-step TV divergence, Dmax\nTV (μ ∥ π) = maxs DTV(μ(·|s)∥ π(·|s)),\nwhich gives:\nDTV\n\u0000μ>t(·|st+1)∥π>t(·|st+1)\u0001 ≤\nT\tX\nk=t+1\nDmax\nTV (μ ∥ π) = (T − t)Dmax\nTV (μ ∥ π).\nSubstituting this back into the bound for ∆(μ, π):\n∆(μ, π) ≤ ξ ·\nT\tX\nt=1\nEy≤t∼μ\n\u0014 π(yt|st)\nμ(yt|st) − 1 · 2(T − t)Dmax\nTV (μ ∥ π)\n\u0015\n= 2ξ · Dmax\nTV (μ ∥ π)\nT\tX\nt=1\n(T − t)Est∼μ\n\"X\nyt\nμ(yt|st) π(yt|st)\nμ(yt|st) − 1\n#\n= 2ξ · Dmax\nTV (μ ∥ π)\nT\tX\nt=1\n(T − t)Est∼μ [2DTV(μ(·|st)∥ π(·|st))]\n≤ 2ξ · Dmax\nTV (μ ∥ π)\nT\tX\nt=1\n(T − t) · Est∼μ [2Dmax\nTV (μ ∥ π)]\n= 4ξ · Dmax\nTV (μ ∥ π)2\nT\tX\nt=1\n(T − t)\n= 2ξT (T − 1) · Dmax\nTV (μ ∥ π)2.\n(18)\nSubstituting this into the performance difference identity gives the desired result:\nJ (π) − J (μ) ≥ L′\nμ(π) − 2ξT (T − 1) · Dmax\nTV (μ ∥ π)2.\nThis completes the proof.\nB.3. A Tighter Policy Improvement Bound\nThe policy improvement bound derived in Equation (18) suffers from a quadratic dependence on the horizon length, T 2.\nThis makes the bound excessively loose for typical LLM fine-tuning tasks where sequences can be very long. By leveraging\nthe property that the total variation divergence is always bounded by one, i.e., DTV(P ∥Q) ≤ 1, we can derive an alternative\nbound that is only linear in T , offering a much tighter and more practical guarantee for long-horizon problems.\nWe begin from the intermediate step in Equation (17):\n∆(μ, π) ≤ ξ ·\nT\tX\nt=1\nEy≤t∼μ\n\u0014 π(yt|st)\nμ(yt|st) − 1 · Ey>t∼μ(·|st+1)\n\u0014\n1 − π(y>t|st+1)\nμ(y>t|st+1)\n\u0015\u0015\n.\nThe inner expectation is exactly twice the TV divergence between the future trajectory distributions,\n2DTV\n\u0000μ>t(·|st+1)∥π>t(·|st+1)\u0001. Instead of bounding this term with 2(T − t)Dmax\nTV (μ ∥ π), we now apply the simple\n15\n\n-- 15 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nupper bound of 2:\n∆(μ, π) ≤ ξ ·\nT\tX\nt=1\nEy≤t∼μ\n\u0014 π(yt|st)\nμ(yt|st) − 1 · 2DTV\n\u0000μ>t(·|st+1)∥π>t(·|st+1)\u0001\u0015\n≤ 2ξ ·\nT\tX\nt=1\nEy≤t∼μ\n\u0014 π(yt|st)\nμ(yt|st) − 1\n\u0015\n(19)\n= 2ξ ·\nT\tX\nt=1\nEst∼ρμ\nt Eyt∼μ(·|st)\n\u0014 π(yt|st)\nμ(yt|st) − 1\n\u0015\n= 2ξ ·\nT\tX\nt=1\nEst∼ρμ\nt [2DTV(μ(·|st)∥ π(·|st))]\n= 4ξ · Ey∼μ\n\n\n|y|\t\nX\nt=1\nDTV(μ(·|st)∥ π(·|st))\n\n . (20)\nThis provides a bound that is linear in the expected sum of single-step divergences. By combining this with our original\nquadratic bound from Equation (18), we can form a tighter, composite bound by taking the minimum of the two:\nJ (π) − J (μ) ≥ L′\nμ(π) − ∆(μ, π)\n≥ L′\nμ(π) − min\n\n2ξT (T − 1) · Dmax\nTV\n2, 4ξ · Ey∼μ\n\n\n|y|\t\nX\nt=1\nDTV(μ(·|st)∥ π(·|st))\n\n\n\n .\nThis composite bound provides a more robust guarantee on policy improvement, leveraging the quadratic bound for\ninfinitesimal updates and the linear bound for larger updates or longer horizons.\nB.4. Comparing Surrogate Objectives with Classical RL\nAt first glance, the surrogate objective for the LLM regime in Equation (5) appears distinct from the classical RL surrogate\nin Equation (3). The former is an expectation over full trajectories y weighted by the reward R(y), while the latter is\nan expectation over state-action pairs (s, a) weighted by the advantage Aμ(s, a). However, we will now show that their\ngradients with respect to the policy parameters θ are fundamentally analogous, confirming that our LLM-specific formulation\nis a valid adaptation of the standard policy gradient theorem.\nLet the policy π be parameterized by θ. We will use the identity ∇θ πθ (a|s) = πθ (a|s)∇θ log πθ (a|s).\nGradient of the Classical Surrogate Objective. We begin with the classical surrogate objective from Equation (3):\nLμ(πθ ) = 1\n1 − γ Es∼ρμ, a∼μ(a|s)\n\u0014 πθ (a|s)\nμ(a|s) Aμ(s, a)\n\u0015\n.\nTaking the gradient with respect to θ and moving it inside the expectation, we get:\n∇θ Lμ(πθ ) = 1\n1 − γ Es∼ρμ, a∼μ(a|s)\n\u0014 ∇θ πθ (a|s)\nμ(a|s) Aμ(s, a)\n\u0015\n= 1\n1 − γ Es∼ρμ, a∼μ(a|s)\n\u0014 πθ (a|s)\nμ(a|s) ∇θ log πθ (a|s)Aμ(s, a)\n\u0015\n.\n(21)\nGradient of the LLM Surrogate Objective. Next, we consider our LLM-specific surrogate from Equation (5):\nL′\nμ(πθ ) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n\u0012 πθ (yt|st)\nμ(yt|st) − 1\n\u0013\n .\n16\n\n-- 16 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nTaking the gradient with respect to θ and noting that the −1 term has a zero gradient:\n∇θ L′\nμ(πθ ) = Ey∼μ\n\nR(y)\n|y|\t\nX\nt=1\n∇θ πθ (yt|st)\nμ(yt|st)\n\n\n= Ey∼μ\n\n\n|y|\t\nX\nt=1\nπθ (yt|st)\nμ(yt|st) ∇θ log πθ (yt|st)R(y)\n\n .\nIf we define a sequence-level advantage as Aμ(st, yt) = R(y) − V (x), where V (x) is a baseline value function for the\nprompt, the gradient becomes:\n∇θ L′\nμ(πθ ) = Ey∼μ\n\n\n|y|\t\nX\nt=1\nπθ (yt|st)\nμ(yt|st) ∇θ log πθ (yt|st)Aμ(st, yt)\n\n . (22)\nThis form is directly analogous to the classical policy gradient in Equation (21), where the sum over timesteps in a trajectory\nreplaces the expectation over the state distribution ρμ. Thus, our LLM surrogate objective is a theoretically sound adaptation\nof the classical trust region framework to the undiscounted, sequence-reward setting.\nC. Approximations as Lower Bounds of True Divergence\nIn this section, we provide a formal justification for our Binary and Top-K divergence approximations. We demonstrate that\nboth are principled lower bounds on the true divergence and explicitly state the conditions under which these approximations\nbecome exact.\nLet C = {C1, . . . , Cm} be any partition of the vocabulary A. Our Binary and Top-K approximations correspond to specific\nchoices of this partition. We will show that the divergence computed on the partitioned space is a lower bound on the true\ndivergence.\nC.1. Total Variation Divergence\nThe true TV divergence is DTV(μ ∥ π) = 1\n2\nP\na∈A | μ(a|st) − π(a|st)|. The divergence on a partitioned space C is\nDC\nTV = 1\n2\nPm\nj=1 | μ(Cj |st) − π(Cj |st)|.\nProof of Lower Bound. By definition, | μ(Cj |st) − π(Cj |st)| = | P\na∈Cj (μ(a|st) − π(a|st))|. The triangle inequality\nstates that the absolute value of a sum is less than or equal to the sum of the absolute values. Applying this, we get\n| P\na∈Cj (μ(a|st) − π(a|st))| ≤ P\na∈Cj | μ(a|st) − π(a|st)|. Summing over all partitions j:\nDC\nTV = 1\n2\nm\tX\nj=1\nX\na∈Cj\n(μ(a|st) − π(a|st))\n≤ 1\n2\nm\tX\nj=1\nX\na∈Cj\n| μ(a|st) − π(a|st)| = DTV(μ ∥ π).\nThus, DTV(μ ∥ π) ≥ DC\nTV. This holds for both Binary and Top-K partitions.\nAnalysis of the Approximation Gap. The gap between the true and approximated TV divergence is the sum of the gaps\nwithin each partition. For any partition Cj , the gap is 1\n2\n\u0010P\na∈Cj | μ(a|st) − π(a|st)| − P\na∈Cj (μ(a|st) − π(a|st))\n\u0011\n.\nThis gap is bounded by the total probability mass of the partition:\nGap(Cj ) ≤ 1\n2\nX\na∈Cj\n(μ(a|st) + π(a|st)) = 1\n2 (μ(Cj |st) + π(Cj |st)).\nFor the Top-K approximation, the only partition with a potential gap is the ”other” category, which contains the tail of the\ndistribution. The total probability mass of this tail, μ(Cother|st), is typically very small. Therefore, the approximation gap is\nalso small, justifying Top-K TV as a high-fidelity approximation.\n17\n\n-- 17 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nEquality Condition. Equality DTV = DC\nTV holds if the gap is zero for all partitions. This occurs when μ(a|st) − π(a|st)\nhas the same sign for all tokens a within each partition Cj .\nC.2. KL Divergence\nThe true KL divergence is DKL(μ ∥ π) = P\na∈A μ(a|st) log μ(a|st)\nπ(a|st) . The divergence on the partitioned space is DC\nKL =\nPm\nj=1 μ(Cj |st) log μ(Cj |st)\nπ(Cj |st) .\nProof of Lower Bound. The proof relies on the log-sum inequality, which states that for any two sets of non-negative\nnumbers {x1, . . . , xn} and {y1, . . . , yn}:\nn\tX\ni=1\nxi log xi\nyi\n≥\nn\tX\ni=1\nxi\n!\nlog\nPn\ni=1 xi\nPn\ni=1 yi\n.\nWe apply this inequality to each partition Cj in our vocabulary, setting xa = μ(a|st) and ya = π(a|st):\nX\na∈Cj\nμ(a|st) log μ(a|st)\nπ(a|st) ≥\n\n X\na∈Cj\nμ(a|st)\n\n log\nP\na∈Cj μ(a|st)\nP\na∈Cj π(a|st)\n= μ(Cj |st) log μ(Cj |st)\nπ(Cj |st) .\nSumming over all partitions j gives the desired result:\nDKL(μ ∥ π) =\nm\tX\nj=1\nX\na∈Cj\nμ(a|st) log μ(a|st)\nπ(a|st)\n≥\nm\tX\nj=1\nμ(Cj |st) log μ(Cj |st)\nπ(Cj |st) = DC\nKL.\nEquality Condition. The log-sum inequality holds with equality if and only if the ratio xi\nyi is constant for all i. In our\ncontext, this means that for each partition Cj , the ratio μ(a|st)\nπ(a|st) must be constant for all tokens a ∈ Cj . For both Binary and\nTop-K approximations, this implies the policy update must scale the probabilities of all tokens within the ”other” category\nby a uniform factor.\nD. More Details for Stability Analysis\nOur experimental setup strictly follows the sanity test established in Qi et al. (2025b). Each policy iteration begins by\nsampling a batch of 64 questions. For each question, we generate 8 responses (rollouts) using a maximum context length of\n8,000. The collected data is then used to perform 4 gradient steps. All experiments are conducted using the VeRL framework\n(Sheng et al., 2024) together with the ODC optimization (Wan et al., 2026), and models are trained in BFloat16 precision to\nbetter expose potential numerical instabilities between algorithms. For the evaluation on AIME, we sample 32 responses for\neach test question to ensure a robust assessment.\nD.1. Algorithmic Details for Stability Analysis\nIn this section, we provide the specific policy gradient formulations for each algorithm evaluated in our stability analysis\n(Section 5). To facilitate a direct comparison, we show how each algorithm’s gradient update can be interpreted through the\nlens of a single, unified framework.\nA Unified Policy Gradient Formulation. The policy gradient for the algorithms we tested can be generalized into the\nfollowing form, where the gradient of the objective L(θ) is expressed as:\n∇θ L(θ) = Ey∼μθ′\n\n\n|y|\t\nX\nt=1\nMt · min\n\u0012 πθ (yt|st)\nμθ′ (yt|st) , C\n\u0013\n· ˆ\tAt · ∇θ log πθ (yt|st)\n\n . (23)\n18\n\n-- 18 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nIn this formulation, ˆ\tAt is the advantage, estimated following the GRPO method but without standard deviation normalization\n(Shao et al., 2024; Liu et al., 2025d). The algorithms differ primarily in their definition of the binary mask Mt and the\nclipping bound C.\n• For PG-IS, we have Mt = 1 and C = ∞.\n• For PG-TIS (CISPO), we have Mt = 1 and C = 3.\n• For GRPO, the mask Mt is the PPO-style clipping mask, and C = ∞.\n• For MiniRL, the mask Mt is also a PPO-style clipping mask but is conditioned on a recomputed policy ratio. For this\nalgorithm, C = ∞.\n• For MiniRL-TIS, the mask Mt is the same as in MiniRL, but with C = 3.\n• For DPPO (Ours), the mask Mt is conditioned on the policy divergence, and C = ∞.\nMask Definitions. The specific forms of the masks are as follows:\n• For GRPO, the mask uses the rollout ratio rt = πθ (yt|st)\nμθ′ (yt|st) and experimental hyperparameters ϵhigh = 0.28, ϵlow = 0.2:\nMt =\n(\n0, if ( ˆ\tAt > 0 and rt > 1 + ϵhigh) or ( ˆ\tAt < 0 and rt < 1 − ϵlow)\n1, otherwise.\n• For MiniRL and MiniRL-TIS, the mask is structurally identical to GRPO’s and uses the same hyperparameters, but it\nis conditioned on the recomputed ratio r′\nt = πθ (yt|st)\nπθ′ (yt|st) :\nMt =\n(\n0, if ( ˆ\tAt > 0 and r′\nt > 1 + ϵhigh) or ( ˆ\tAt < 0 and r′\nt < 1 − ϵlow)\n1, otherwise.\n• For DPPO, our mask is conditioned on the policy divergence Dt:\nMt =\n(\n0, if ( ˆ\tAt > 0 and rt > 1 and Dt > δ) or ( ˆ\tAt < 0 and rt < 1 and Dt > δ)\n1, otherwise.\nIn our experiments, we set the divergence threshold δ = 0.15 for TV divergence and δ = 0.05 for KL divergence.\nE. Characterizing Clipped Tokens\nTo understand the practical consequences of ratio clipping, we analyzed which tokens are most frequently penalized by\na PPO-style algorithm. We trained a Qwen3-4B-Base model on the DAPO dataset with GRPO and, at training step 50,\ncollected two sets of tokens:\n• Clipped Positive Tokens: From samples with ˆ\tAt > 0, tokens whose updates were blocked due to a high ratio\n(rt > 1.28).\n• Clipped Negative Tokens: From samples with ˆ\tAt < 0, tokens whose updates were blocked due to a low ratio\n(rt < 0.8).\nThe 50 most frequent tokens in each category reveal a striking pattern. Far from being random noise, the clipped tokens are\noften critical for task performance. The lists for both positive and negative samples are dominated by two key categories:\n1. Numerical and Mathematical Tokens: A significant portion of the clipped tokens are numbers (e.g., ‘1’, ‘4’) and\nmathematical symbols (e.g., ‘+’, ‘=’, ‘div’).\n19\n\n-- 19 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n2. Reasoning and Structural Words: The list also includes many words essential for logical exposition, such as ‘Wait’,\n‘Next’, ‘Thus’, and ‘Since’.\nThese findings highlight a fundamental flaw in ratio-based clipping. For positive samples, it blocks beneficial updates to\ntokens that are integral to constructing correct solutions. For negative samples, it blocks the necessary suppression of these\nsame tokens when they are part of an incorrect reasoning path. By systematically interfering with the learning signal for\nthese high-utility tokens, the algorithm inadvertently slows learning, stifles exploration, and hinders the model’s ability to\nrefine its problem-solving capabilities.\nThe 50 most frequently clipped tokens from positively-rewarded samples.\n’ the’, ’ \\\\(’, ’1’, ’Let’, ’ in’, ’ ’, ’,’, ’We’, ’ +’, ’ \\\\’, ’ numbers’,\n’:\\n\\n’, ’Wait’, ’4’, ’6’, ’ Identify’, ’(’, ’Next’, ’ from’, ’)’, ’ k’, ’ -’,\n’Since’, ’ solve’, ’\\\\[’, ’ how’, ’ ->’, ’ to’, ’ are’, ’Sub’, ’I’, ’):\\n’, ’\n\\n\\n’, ’ spiral’, ’ Instead’, ’ this’, ’If’, ’div’, ’ Conditions’, ’ vector’, ’\nhave’, ’ =’, ’ feasible’, ’Or’, ’ inconsistency’, ’ express’, ’_{’, ’ increase’, ’\nexact’, ’ consider’\nThe 50 most frequently clipped tokens from negatively-rewarded samples.\n’ \\\\(’, ’ the’, ’,’, ’ a’, ’ \\\\’, ’ ’, ’2’, ’1’, ’:\\n\\n’, ’0’, ’3’, ’ and’, ’ (’, ’\nthat’, ’-’, ’ to’, ’5’, ’ of’, ’However’, ’\\\\’, ’ is’, ’ =’, ’4’, ’ in’, ’ for’, ’\nall’, ’ we’, ’We’, ’)’, ’.\\n\\n’, ’ our’, ’.’, ’:\\n’, ’ but’, ’ with’, ’So’, ’\nboth’, ’From’, ’ Let’, ’ this’, ’Thus’, ’Wait’, ’ if’, ’ -’, ’ +’, ’ˆ’, ’ only’, ’\nat’, ’Since’, ’ integer’\nF. More Details for Scaling Experiments\nIn this section, we provide detailed training and evaluation settings of the scaling experiments in Section 7.\nTraining Settings. We conduct experiments using the VeRL framework (Sheng et al., 2024) on NVIDIA H Series GPUs. All\nmethods follow the hyperparameter configurations detailed in Table 1. Rollout router replay (R3) (Ma et al., 2025) records\nthe routed experts used in the inference engine and replays them in the training engine, which mitigates the training-inference\nmismatch and stabilizes RL training for MoE models. We only use R3 in the MoE Base w/ R3 experiment and do not use it\nin all other experiments. For experiments that utilize LoRA, as suggested by Schulman & Lab (2025), we employ a larger\nlearning rate of 1 × 10−5. For the MoE Base w/ LoRA experiment, we set lora rank=32 and lora alpha=64.\nAs suggested in Section 5.2, for all methods, we use the behavior policy (μθ′ ) instead of recomputed policy distribution (πθ′ )\nto construct the trust region (i.e., for clipping or masking). Under the unified policy gradient formulation (Equation 23), the\nmethod-specific hyperparameters (C = 5 by default) are configured as follows:\n• For GRPO-ClipHigher, we have\nMt =\n(\n0, if ( ˆ\tAt > 0 and rt > 1 + ϵhigh) or ( ˆ\tAt < 0 and rt < 1 − ϵlow)\n1, otherwise.\nwhere ϵhigh = 0.27 and ϵlow = 0.2, which follows the hyperparameters used in Zheng et al. (2025).\n• For CISPO, we have Mt = 1.\n• For DPPO-Binary-KL and DPPO-Binary-TV, we have\nMt =\n(\n0, if ( ˆ\tAt > 0 and rt > 1 and Dt > δ) or ( ˆ\tAt < 0 and rt < 1 and Dt > δ)\n1, otherwise.\nwhere Dt is binary approximation of KL or TV as defined in Section 4.4. For DPPO-Binary-KL, δ = 0.05 for all\nscaling experiments. For DPPO-Binary-TV, we use δ = 0.15 for MoE Base w/ LoRA experiment and δ = 0.2 for all\nother scaling experiments.\n20\n\n-- 20 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\nTable 1. Detailed RL training hyperparameters of scaling experiments.\nHyperparameters MoE Base MoE Base w/ R3 MoE Thinking Dense Base MoE Base w/ LoRA\nmax prompt length 1024 1024 1024 1024 1024\nmax response length 16384 16384 16384 8000 8000\ntrain batch size 256 256 256 128 128\nppo mini batch size 32 32 32 32 16\noptim.lr 1e-6 1e-6 1e-6 1e-6 1e-5\nrollout.temperature 1.0 1.0 1.0 1.0 1.0\nrollout.n 16 16 16 8 8\nDetailed Results Figure 11 Figure 12 Figure 13 Figure 14 Figure 15\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nRewards\nGRPO-ClipHigher\nCISPO\nDPPO-Binary-KL\nDPPO-Binary-TV\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60 \tAIME 2024\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45 \tAIME 2025\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0.000\n0.002\n0.004\n0.006\n0.008\n0.010 \tMean of | \t- \t|\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n2000\n4000\n6000\n8000\n10000 \tResponse Length\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n2000 \tEntropy\nFigure 11. Evolution of metrics for MoE Base w/o R3 experiment (based on Qwen3-30B-A3B-Base, without rollout router replay).\nEvaluation Settings. We perform online evaluation for each method and experimental configuration, monitoring AIME24\nand AIME25 scores throughout RL training. Evaluations are conducted every 5 training steps for MoE Base, MoE Base w/\nR3, and MoE Thinking, and every 10 steps for Dense Base and MoE Base w/ LoRA.\nAcross all scaling experiments, we use consistent sampling parameters: temperature=0.7, top p=0.95, and n=32.\nThe n=32 setting indicates that each question from AIME24 and AIME25 is sampled 32 times, and we report the average\nscores. The max response length remains identical to that used during training rollouts.\nG. More Empirical Results\nG.1. Extended Main Results\nIn addition to the results provided in Section 7, here we provide more detailed results of the five scaling experiments:\nFigure 11 for MoE Base w/o R3, Figure 12 for MoE Base w/ R3, Figure 13 for MoE Thinking, Figure 14 for Dense Base,\nFigure 15 for MoE Base w/ LoRA. We record the following metrics throughout the RL training: training rewards (denoted\nas “Rewards”), AIME 2024 Avg@32 scores, AIME 2025 Avg@32 scores, mean of | μθ′ − πθ′ | (denoted as “Mean of\n|π − μ|”), mean of the response length (denoted as “Response Length”), and mean of token entropy (denoted as “Entropy”).\nFor clearer visualization, all metrics except AIME24 and AIME25 are smoothed using a Gaussian filter with standard\ndeviation σ = 2. The original unsmoothed curves are shown in the background as shaded regions.\n21\n\n-- 21 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nRewards\nR3-GRPO-ClipHigher\nR3-CISPO\nR3-DPPO-Binary-KL\nR3-DPPO-Binary-TV \t0.20\n0.30\n0.40\n0.50\n0.60\nAIME 2024\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nAIME 2025\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0.000\n0.001\n0.002\n0.003\n0.004\n0.005\n0.006 \tMean of | \t- \t|\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n2000\n4000\n6000\n8000\n10000 \tResponse Length\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n200\n400\n600\n800\n1000\nEntropy\nFigure 12. Evolution of metrics for MoE Base w/ R3 experiment (based on Qwen3-30B-A3B-Base, with rollout router replay).\nOverall, across the five experiments, our method DPPO demonstrates consistent and robust improvements in training rewards,\nhighlighting its stability and efficiency. On both AIME 24 and AIME 25 benchmarks, DPPO exhibits a clear, stable upward\ntrend during training and maintains superior performance after convergence. The stability of our approach is evidenced by\nlearning curves that generally show less fluctuation compared to baseline methods. Its efficiency is reflected in the rapid\nincrease of training rewards and the strong final performance.\nDPPO variants consistently demonstrate healthy training dynamics. The training-inference mismatch (measured by the\nmean absolute deviation |π − μ|) and policy entropy remain within a stable, proper region throughout RL training. DPPO\nalso effectively increases the generated response length across all scaling experiments, except for MoE Thinking. We note\nthat the model Qwen3-30B-A3B already produces extremely long responses; as our training enforces a maximum length of\napproximately 16k tokens, RL training naturally shortens responses to fit this constraint.\nIn contrast, the GRPO-ClipHigher baseline, which relies on the ratio clipping mechanism of PPO, shows lower stability\nthan DPPO and achieves inferior final performance in all five large-scale experiments. For example, in MoE Base w/o\nR3 (see Figure 11), GRPO-ClipHigher, though more stable than CISPO, improves more slowly and converges to lower\ntraining rewards and AIME scores than DPPO. In MoE Thinking (see Figure 13), GRPO-ClipHigher suffers a significant\ntraining collapse. Notably, GRPO-ClipHigher consistently leads to excessively high entropy in all large-scale experiments, a\nphenomenon not observed with other methods.\nThe CISPO baseline, which retains gradients for all tokens, is generally less stable and prone to collapse in certain settings.\nFor instance, in MoE Base w/o R3 (see Figure 11), CISPO experiences a sudden and severe collapse leading to complete\nfailure. In Dense Base (see Figure 14), CISPO shows a degenerative trend, particularly on AIME25. In MoE Base w/ LoRA\n(see Figure 15), the AIME24 scores, mean of |π − μ|, and response length exhibit noticeable fluctuations, further indicating\ninstability.\nWe also analyze the effect of rollout router replay (R3). Remarkably, DPPO variants without R3 already outperform\nbaselines that use R3, underscoring the importance of a proper masking mechanism in RL training (see Figures 11 and 12).\nFurthermore, incorporating R3 yields additional gains for DPPO, suggesting that the benefits of R3 and DPPO are largely\northogonal. This implies that DPPO provides a robust foundation for LLM RL fine-tuning, capable of further improvement\neven when training-inference mismatch is mitigated by other techniques.\n22\n\n-- 22 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0.775\n0.800\n0.825\n0.850\n0.875\n0.900\n0.925\nRewards\nA3B-GRPO-ClipHigher\nA3B-CISPO\nA3B-DPPO-Binary-KL\nA3B-DPPO-Binary-TV\n0.64\n0.66\n0.68\n0.70\n0.72\n0.74\n0.76\n0.78\nAIME 2024\n0.54\n0.56\n0.58\n0.60\n0.62\n0.64\n0.66\n0.68\nAIME 2025\n0 \t50 \t100 \t150 \t200 \t250\nTraining Step\n0.005\n0.006\n0.007\n0.007\n0.007\n0.008\n0.009\n0.009\nMean of | \t- \t|\n0 \t50 \t100 \t150 \t200 \t250\nTraining Step\n6000\n7000\n8000\n9000\n10000\nResponse Length\n0 \t50 \t100 \t150 \t200 \t250\nTraining Step\n500\n1000\n1500\n2000\n2500\nEntropy\nFigure 13. Evolution of metrics for MoE Thinking experiment (based on Qwen3-30B-A3B).\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nRewards\n8B-GRPO-ClipHigher\n8B-CISPO\n8B-DPPO-Binary-KL\n8B-DPPO-Binary-TV \t0.10\n0.15\n0.20\n0.25\n0.30\n0.35\nAIME 2024\n0.10\n0.15\n0.20\n0.25\n0.30\nAIME 2025\n0 \t200 \t400 \t600 \t800 \t1000 \t1200\nTraining Step\n0.005\n0.010\n0.015\n0.020\n0.025\nMean of | \t- \t|\n0 \t200 \t400 \t600 \t800 \t1000 \t1200\nTraining Step\n1000\n2000\n3000\n4000\n5000\n6000\nResponse Length\n0 \t200 \t400 \t600 \t800 \t1000 \t1200\nTraining Step\n0\n250\n500\n750\n1000\n1250\n1500\n1750\nEntropy\nFigure 14. Evolution of metrics for Dense Base experiment (based on Qwen3-8B-Base).\n23\n\n-- 23 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nRewards\nLoRA-GRPO-ClipHigher\nLoRA-CISPO\nLoRA-DPPO-Binary-KL\nLoRA-DPPO-Binary-TV \t0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\nAIME 2024\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\nAIME 2025\n0 \t100 \t200 \t300 \t400 \t500 \t600 \t700 \t800 \t900\nTraining Step\n0.004\n0.006\n0.008\n0.010\n0.012\n0.014\n0.016\n0.018\n0.020\nMean of | \t- \t|\n0 \t100 \t200 \t300 \t400 \t500 \t600 \t700 \t800 \t900\nTraining Step\n1000\n1500\n2000\n2500\n3000\n3500\n4000\n4500\nResponse Length\n0 \t100 \t200 \t300 \t400 \t500 \t600 \t700 \t800 \t900\nTraining Step\n0\n50\n100\n150\n200\n250\n300\nEntropy\nFigure 15. Evolution of metrics for MoE Base w/ LoRA experiment (based on Qwen3-30B-A3B-Base, with LoRA).\nG.2. Ablation on TV/KL Approximation\nIn the scaling experiments, we compared DPPO variants using binary TV/KL approximations (Equations 13 and 14)\nagainst several baselines. To further investigate the approximation strategy, we experiment with DPPO variants with top-K\nTV/KL approximations (Equations 15 and 16), where we set K = 20; these variants are denoted as DPPO-TopK-TV and\nDPPO-TopK-KL. The choice K = 20 is limited by vLLM (Kwon et al., 2023), which supports returning log probabilities\nfor at most 20 candidate tokens per step. We strictly replicate the experimental setting of MoE Base w/o R3. As in the\nmain scaling experiments, for DPPO-Binary-TV and DPPO-TopK-TV we set the clip threshold δ = 0.2, while for\nDPPO-Binary-KL and DPPO-TopK-KL we set δ = 0.05.\nAs presented in Figure 16, introducing the top-K approximation does not yield significant performance gains, indicating that\nthe simpler binary approximation already provides a sufficient and efficient proxy for constructing the trust region. This\nfinding is encouraging, suggesting that DPPO with binary TV/KL remains highly scalable without sacrificing effectiveness.\nG.3. Extended Results for Different Model × Task Combinations\nBesides experimental results presented in Section 7, we evaluate DPPO on more model × task settings to validate its\nadvantage over the GRPO baseline. The settings we considered include:\n1. Different model family. Training on a new model different from the Qwen family, OctoThinker-3B-Hybrid-Base (Wang\net al., 2025b), on the standard math reasoning dataset (Hendrycks et al., 2021).\n2. Abstract reasoning and induction. Training the Qwen3-1.7B-Base model on abstract reasoning task (Arc1D) and\ninduction task (Acre) from the Gem library (Liu et al., 2025e).\n3. Multi-turn reasoning. Training the Qwen3-1.7B-Base model on the multi-turn reasoning environment (Sudoku-v0-\neasy) from Gem the library (Liu et al., 2025e).\nThe training is conducted using Oat (Liu et al., 2025c) with their example scripts (thereby the standard hyper-parameters)\nfor math RL and Gem RL. For the TV divergence clipping, we use a threshold of δ = 0.2. Figure 17 shows the comparison\nbetween the TV variant of DPPO and the vanilla ratio-based PPO, both based on the GRPO algorithmic framework with the\nonly difference being the trust region masking strategy. We can observe DPPO improves the efficiency (and sometimes\nasymptotic performance) over the baseline across different settings, validating its general effectiveness.\n24\n\n-- 24 of 25 --\n\nRethinking the Trust Region in LLM Reinforcement Learning\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\nRewards\nGRPO-ClipHigher\nCISPO\nDPPO-Binary-KL\nDPPO-Binary-TV\nDPPO-TopK-KL\nDPPO-TopK-TV\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45\n0.50\n0.55\n0.60 \tAIME 2024\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\n0.45 \tAIME 2025\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0.002\n0.003\n0.004\n0.005\n0.006\n0.007\n0.008 \tMean of | \t- \t|\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n2000\n4000\n6000\n8000\n10000 \tResponse Length\n0 \t25 \t50 \t75 \t100 \t125 \t150 \t175 \t200\nTraining Step\n0\n250\n500\n750\n1000\n1250\n1500\n1750\n2000 \tEntropy\nFigure 16. Evolution of metrics for baselines, DPPO with binary TV/KL approximation, and DPPO with Top-K (K=20) approximation\nunder the same setting as MoE Base w/o R3.\n0 \t50 \t100 \t150 \t200 \t250 \t300 \t350\nTraining step\n0.00\n0.10\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70 OctoThinker\nDPPO-Binary-TV\nPPO-Ratio\n0 \t20 \t40 \t60 \t80 \t100 \t120\nTraining step\n0.00\n0.10\n0.20\n0.30\n0.40\nArc1D\n0 \t20 \t40 \t60 \t80 \t100 \t120\nTraining step\n0.20\n0.30\n0.40\n0.50\n0.60\n0.70\n0.80\nAcre\n0 \t50 \t100 \t150 \t200 \t250 \t300 \t350 \t400\nTraining step\n-0.10\n0.00\n0.10\n0.20\n0.30\n0.40\n0.50 \tSudoku\nFigure 17. Learning curve comparison of using ratio (PPO-Ratio) and TV divergence (DPPO-Binary-TV) for the trust region clipping.\n25\n\n-- 25 of 25 --\n\n",
      "analysis_json": "{\"title\":\"Rethinking the Trust Region in LLM Reinforcement Learning\",\"authors\":[\"Penghui Qi\",\"Xiangxin Zhou\",\"Zichen Liu\",\"Tianyu Pang\",\"Chao Du\",\"Min Lin\",\"Wee Sun Lee\"],\"publication_year\":\"2026\",\"summary\":\"This paper identifies a critical structural flaw in Proximal Policy Optimization (PPO) when applied to Large Language Models (LLMs). The authors argue that PPO's 'ratio clipping' mechanism acts as a noisy, single-sample estimate of policy divergence that fails in large vocabulary settings. Specifically, it over-penalizes updates to low-probability tokens (hindering exploration) while under-penalizing shifts in high-probability tokens (causing instability). To fix this, they introduce Divergence Proximal Policy Optimization (DPPO), which replaces heuristic clipping with a dynamic mask based on direct divergence measures (Total Variation or KL). They make this computationally feasible for LLMs using efficient Binary and Top-K approximations, demonstrating superior stability and efficiency over GRPO and PPO.\",\"breakthrough_score\":75,\"breakthrough_reasoning\":\"The paper provides a fundamental correction to the standard RLHF algorithm (PPO/GRPO) used in training nearly all modern reasoning models (like DeepSeek-R1). By mathematically proving that ratio clipping is a 'noisy Monte Carlo estimate' that fails for rare tokens, it explains the notorious instability of LLM RL training. The solution (Binary/Top-K Divergence) is elegant, computationally negligible, and theoretically grounded, potentially becoming the new standard for RLHF.\",\"key_claims\":[\"PPO's ratio clipping is structurally ill-suited for LLM vocabularies because it is hypersensitive to probability magnitude.\",\"Updates to low-probability tokens generate massive probability ratios even for negligible distributional shifts, causing PPO to aggressively over-clip them.\",\"Updates to high-probability tokens can cause massive mass shifts (e.g., 0.99 to 0.8) without triggering ratio clipping, leading to instability.\",\"DPPO's Binary and Top-K approximations capture the essential distributional divergence required for a trust region with negligible memory overhead.\",\"Trust regions must be anchored to the original rollout policy, not the recomputed policy, to prevent training collapse.\"],\"testable_hypotheses\":[{\"hypothesis\":\"PPO ratio clipping disproportionately blocks updates to low-probability tokens compared to high-probability tokens, regardless of the actual KL divergence.\",\"how_to_test\":\"During RL training, log the 'ratio' (r_t) and the 'true binary TV divergence' for every token update. Plot the frequency of clipping triggering against the initial token probability.\",\"expected_outcome\":\"Low-probability tokens will show extremely high ratios triggering clipping despite low divergence, while high-probability tokens will show low ratios despite high divergence.\"},{\"hypothesis\":\"Relaxing the trust region (clipping) specifically for low-probability tokens will improve training efficiency (exploration) without hurting stability.\",\"how_to_test\":\"Run GRPO with infinite clipping bounds for tokens with probability < 0.1 and standard clipping for others. Compare reward curves against standard GRPO.\",\"expected_outcome\":\"The relaxed model should learn faster (higher reward slope) because it allows necessary adjustments to rare 'reasoning' tokens that PPO usually suppresses.\"},{\"hypothesis\":\"The Binary Approximation of divergence is sufficient to stabilize training compared to the computationally expensive full distributional divergence.\",\"how_to_test\":\"Compare DPPO-Binary (Bernoulli approximation) against DPPO-TopK (richer approximation) on a math reasoning benchmark.\",\"expected_outcome\":\"Both methods should achieve similar stability and final performance, proving that the simple binary distinction (sampled vs. rest) captures the most critical divergence information.\"}],\"key_equations\":[{\"name\":\"The DPPO Objective\",\"latex\":\"L_{DPPO} = E[M_t \\\\cdot r_t(\\\\theta) \\\\cdot A_t]\",\"description\":\"The loss function where the standard PPO clip function is replaced by a dynamic mask M_t.\",\"variables\":[{\"name\":\"M_t\",\"description\":\"A binary mask (0 or 1) that blocks updates only if the true divergence exceeds a threshold delta.\",\"typical_range\":\"{0, 1}\"},{\"name\":\"r_t\",\"description\":\"The probability ratio pi(token|state) / mu(token|state).\",\"typical_range\":\"0 to infinity\"}]},{\"name\":\"Binary TV Divergence Approximation\",\"latex\":\"D_{TV}^{Bin}(t) = |\\\\mu(a_t|s_t) - \\\\pi(a_t|s_t)|\",\"description\":\"A lightweight approximation of Total Variation divergence that treats the distribution as a Bernoulli trial: the sampled token vs. 'everything else'.\",\"variables\":[{\"name\":\"mu(a_t|s_t)\",\"description\":\"Probability of the token under the frozen rollout policy.\",\"typical_range\":\"[0, 1]\"},{\"name\":\"pi(a_t|s_t)\",\"description\":\"Probability of the token under the current learning policy.\",\"typical_range\":\"[0, 1]\"}]},{\"name\":\"DPPO Masking Condition\",\"latex\":\"M_t = 0 \\\\text{ if } (sgn(A_t)(r_t - 1) > 0 \\\\text{ AND } D > \\\\delta) \\\\text{ else } 1\",\"description\":\"Logic for the mask: It only blocks an update if the step improves the objective (moving away from ratio 1) AND the distributional divergence D is too large.\",\"variables\":[{\"name\":\"D\",\"description\":\"The calculated divergence (e.g., Binary TV or KL).\",\"typical_range\":\"> 0\"},{\"name\":\"delta\",\"description\":\"The trust region threshold.\",\"typical_range\":\"e.g., 0.01 to 0.1\"}]}],\"simulation_possibilities\":[{\"title\":\"Ratio vs. Divergence Interactive Plot\",\"description\":\"A scatter plot visualization proving the core flaw of PPO. Users can drag a slider to change a token's initial probability (from 0.0001 to 0.99). A second slider changes the 'New Probability'. The plot displays two values: the PPO Ratio and the Actual Divergence (TV).\",\"complexity\":\"Low\",\"variables\":[\"Old Probability (mu)\",\"New Probability (pi)\",\"PPO Clip Threshold\"],\"expected_insights\":\"Users will see that for low 'Old Probability', the Ratio explodes to 100+ (triggering clipping) even when Divergence is tiny. Conversely, for high 'Old Probability', the Divergence can be massive while the Ratio stays within safe bounds (1.0 +/- 0.2), creating a 'blind spot' for PPO.\",\"visualization_type\":\"interactive\"},{\"title\":\"The Binary Approximation Visualizer\",\"description\":\"A visualization showing a full vocabulary distribution (thousands of bars) vs. the Binary Approximation. Users select a token to update. The view toggles between calculating KL Divergence on the full distribution vs. the Binary 'One vs All' method.\",\"complexity\":\"Medium\",\"variables\":[\"Vocabulary Size\",\"Target Token Index\",\"Probability Shift Amount\"],\"expected_insights\":\"Demonstrates that calculating full KL is expensive and noisy, while the Binary approximation captures the magnitude of the specific token's shift perfectly without needing the full vocabulary vector.\",\"visualization_type\":\"chart\"},{\"title\":\"Training Stability Simulator\",\"description\":\"A step-by-step simulation of policy updates over 100 steps. The user selects a learning rate and an algorithm (PPO vs. DPPO). The simulation generates synthetic 'updates' (some safe, some dangerous high-prob shifts).\",\"complexity\":\"High\",\"variables\":[\"Algorithm (PPO/DPPO)\",\"Learning Rate\",\"Frequency of High-Prob Token Shifts\"],\"expected_insights\":\"PPO will likely crash or diverge when high-probability tokens shift significantly (because it doesn't clip them), whereas DPPO will 'catch' these dangerous shifts via the TV/KL constraint and mask them out, maintaining a stable reward curve.\",\"visualization_type\":\"animation\"}],\"field\":\"Reinforcement Learning\",\"related_fields\":[\"Large Language Model Fine-tuning\",\"Trust Region Methods\",\"Optimization Theory\",\"AI Alignment\"],\"limitations\":[\"The analysis primarily focuses on math reasoning tasks (AIME/MATH); generalization to creative writing or chat is less explored.\",\"The theoretical bounds derived rely on the finite-horizon assumption (gamma=1), which fits LLMs but differs from general infinite-horizon RL.\",\"The Top-K approximation requires sorting a subset of logits, which adds a small but non-zero computational cost compared to the purely element-wise PPO clipping.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Proximal Policy Optimization (PPO)\",\"KL Divergence and Total Variation\",\"Importance Sampling\",\"Policy Gradients\"]}",
      "created_at": 1770619528904
    },
    "arxiv-2602.06964": {
      "hash": "arxiv-2602.06964",
      "filename": "2602.06964.pdf",
      "raw_text": "Learning a Generative Meta-Model of LLM Activations\nGrace Luo 1 Jiahai Feng 1 ‡ Trevor Darrell 1 † Alec Radford 2 † Jacob Steinhardt 1 3 †\nAbstract\nExisting approaches for analyzing neural network\nactivations, such as PCA and sparse autoencoders,\nrely on strong structural assumptions. Genera-\ntive models offer an alternative: they can un-\ncover structure without such assumptions and\nact as priors that improve intervention fidelity.\nWe explore this direction by training diffusion\nmodels on one billion residual stream activations,\ncreating “meta-models” that learn the distribu-\ntion of a network’s internal states. We find that\ndiffusion loss decreases smoothly with compute\nand reliably predicts downstream utility. In par-\nticular, applying the meta-model’s learned prior\nto steering interventions improves fluency, with\nlarger gains as loss decreases. Moreover, the\nmeta-model’s neurons increasingly isolate con-\ncepts into individual units, with sparse probing\nscores that scale as loss decreases. These results\nsuggest generative meta-models offer a scalable\npath toward interpretability without restrictive\nstructural assumptions. Project page: https:\n//generative-latent-prior.github.io.\n1. Introduction\nNeural network activations encode rich information reflect-\ning how models process and represent data (Hinton et al.,\n1986; Mikolov et al., 2013; Zeiler & Fergus, 2014; Bau et al.,\n2020). These latent representations enable a broad range of\napplications, from extracting internal knowledge via acti-\nvation probing (Alain & Bengio, 2017; Hewitt & Manning,\n2019; Belinkov, 2022) to steering behavior via targeted in-\nterventions (Turner et al., 2024; Zou et al., 2025; Hendel\net al., 2023; Todd et al., 2024). However, existing methods\nfor analyzing and manipulating activations often assume\nlinearity or other structures (Pearson, 1901; Olshausen &\nField, 1997; Bricken et al., 2023), and are therefore prone\nto producing corrupted activations that degrade LLM flu-\n‡Work done while at UC Berkeley. †Equal advising.\n1UC Berkeley 2Independent 3Transluce.\nCorrespondence to: Grace Luo <graceluo@berkeley.edu>.\nPreprint. February 9, 2026.\nSAE \t+ Ours\nHow to measure\nthe determination\nof the method for\nthe determination\nof the method for\nthe determination\nof the method…\nThe answer is\nsimple and easy,\nby following... the\nNational\nAssociation of\nOfficial Testing\nMethods…\nSteering Task:\nterms related\nto scientific\ntesting\nmethods and\nprotocols\nSAE \t+ Ours\nHow to measure\nthe determination\nof the method for\nthe determination\nof the method for\nthe determination\nof the method…\nThe answer is\nsimple and easy,\nby following... the\nNational\nAssociation of\nOfficial Testing\nMethods…\nSteering Task:\nterms related\nto scientific\ntesting\nmethods and\nprotocols\nLanguage Model \tActivation Model\nMLP Block\nMLP Block\n…\n1\nperturb\noff-manifold\npost-process with\ndiffusion model\n2\n3\n(a) Training an activation diffusion model...\n(b) ...learns the structure of the activation manifold…\nactivation\ndenoised\nactivation\nnoised\nactivation\ntext\ncorpus\n(c) ...enabling applications such as on-manifold steering\nSAE \t+ Ours\nHow to measure\nthe determination\nof the method for\nthe determination\nof the method for\nthe determination\nof the method…\nThe answer is\nsimple and easy,\nby following... the\nNational\nAssociation of\nOfficial Testing\nMethods…\nSteering Task:\nterms related\nto scientific\ntesting\nmethods and\nprotocols\nFigure 1. Generative Latent Prior: an activation model trained\nwith a generative diffusion objective. This activation diffusion\nmodel can be used as a prior for downstream tasks, like on-\nmanifold steering, and exhibits reliable power-law scaling.\nency (Templeton et al., 2024; Vu & Nguyen, 2025). To\naddress this, we need methods that naturally conform to the\nunderlying structure of the activation manifold.\nGenerative models offer a principled alternative. By learn-\ning the distribution of activations, they uncover structure\nnaturally. In computer vision, for instance, image diffusion\nmodels can project unrealistic images back onto the natural\nimage manifold while preserving semantic content (Meng\net al., 2022), and their intermediate representations encode\nsemantically meaningful features useful for downstream\ntasks (Luo et al., 2023; Tang et al., 2023; Zhang et al., 2023;\nHedlin et al., 2023). However, developing the analogous\nactivation diffusion model is not straightforward. Activa-\ntions are high-dimensional vectors that cannot be directly\n1\narXiv:2602.06964v1 [cs.LG] 6 Feb 2026\n\n-- 1 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a) Training Loss on FineWeb\n1015 \t1017 \t1019\nFLOPs\n1.0\n1.5\n2.0\n2.5\nDiffusion Loss\nL(C) = 0.52 + 435.1 · C−0.169\n (b) On-Manifold Sentiment Steering\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nConcept & Fluency Mean\nf (C) = 0.63 − 3.92 · 106 · C−0.420\n (c) 1-D Probe for 113 Binary Tasks\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nf (C) = 1.00 − 8.01 · C−0.085\nFigure 2. GLP scales with compute. We train GLP (with 0.5B, 0.9B, 1.7B, 3.3B parameters) on Llama1B activations. (a) Diffusion loss\nfollows a smooth power law as a function of compute, with an estimated irreducible error of 0.52. (b) Steering performance for controlling\npositive sentiment (see Section 4.3) improves with compute, tracking the loss. (c) 1-D probing performance (see Section 5.2) likewise\nimproves with compute. See Appendix B for plots with diffusion loss on the x-axis.\ninspected, posing challenges for training and evaluation.\nIn this work, we design and train a diffusion model of neural\nnetwork activations that addresses these challenges. We\ncall this model a Generative Latent Prior, or GLP. GLP\nis a deep diffusion MLP fit on the same activation data\ncommonly used to train SAEs. We train it on one billion\nresidual stream activations, which can easily be acquired at\nscale using the source LLM. To debug model quality, we\nuse the Frechet Distance (Dowson & Landau, 1982) and\nPCA (Pearson, 1901) to check that GLP generates activa-\ntions near-indistinguishable from real ones.\nWe apply GLP to common interpretability tasks. Activation\nsteering methods add a concept direction to activations, but\nlarger interventions push activations off-manifold, degrad-\ning output fluency. GLP offers a remedy: post-processing\nvia diffusion sampling projects off-manifold activations\nback onto the natural manifold while preserving their seman-\ntic content (Figure 1). Across benchmarks—sentiment con-\ntrol, SAE feature steering, and persona elicitation—this im-\nproves fluency at the same level of steering effect. We addi-\ntionally find that GLP’s intermediate representations encode\nsemantically meaningful features: these “meta-neurons” out-\nperform both SAE features and raw LLM neurons on 1-D\nprobing tasks, suggesting GLP learns to isolate interpretable\nconcepts into individual units.\nGLP scales predictably with compute. Across models from\n0.5B to 3.3B parameters, the diffusion loss follows a smooth\npower law, halving the gap to its floor with each 60x increase\nin compute. This scaling transfers directly to downstream\ntasks: better-trained GLPs yield improved steering and prob-\ning, with gains that closely track the loss (Figure 2). The\ndiffusion loss thus serves as both a training objective and\na reliable predictor of downstream utility—suggesting that\ncontinued scaling will yield further improvements.\nMore broadly, GLP contributes to a line of work on meta-\nmodeling, which studies generative models of neural net-\nwork components (Schmidhuber, 1992; Hinton & Plaut,\n1987; Ha et al., 2017; Peebles et al., 2022; Wang et al.,\n2024). Prior meta-models typically focus on sample genera-\ntion, e.g., synthesizing network weights. We take a different\nperspective: the value of a meta-model lies in the trained\nmodel itself, which encodes the structure of its training dis-\ntribution and can serve as a prior or feature extractor. Our\nresults suggest that this approach offers a path toward inter-\npretability that improves predictably with compute, without\nrelying on hand-crafted structural assumptions.\n2. Generative Latent Prior\nWe now describe GLP, an activation diffusion model, cover-\ning its training objective, architecture, and data pipeline.\n2.1. Diffusion Objective\nNeural activations are continuous vectors, making them\nwell-suited to the diffusion framework (Sohl-Dickstein et al.,\n2015; Ho et al., 2020). At the core of diffusion is the forward\nprocess, which produces training data by adding Gaussian\nnoise to real samples and the reverse process, which gen-\nerates data samples from pure noise at inference time. We\nuse flow matching (Liu et al., 2023; Albergo & Vanden-\nEijnden, 2023; Lipman et al., 2023; Esser et al., 2024; Gao\net al., 2024), whose forward process produces zt as a linear\ninterpolation between the data point z0 and the noise ϵ\nzt = (1 − t)z0 + tϵ (1)\n2\n\n-- 2 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nfor t ∈ [0, 1]; the reverse process iteratively samples new\ndata z0, starting from z1 ∼ N (0, I) with t′ < t\nzt′ = zt + ˆu · (t′ − t) (2)\nThis motivates training a neural network denoiser ˆuθ (zt, t)\nto approximate the target velocity u = ϵ − z0. We show\npseudocode for this training objective in Figure 7. We will\ndemonstrate that this simple formulation is both easy to\nimplement and effective for modeling LLM activations. Fur-\nthermore, unlike prior techniques such as PCA or SAEs, the\ndiffusion objective can be applied to any model architecture.\n2.2. Architecture\nWe formulate our denoiser as a stack of feedforward MLP\nblocks following the design from Llama3 (Grattafiori et al.,\n2024). Each block is a SwiGLU layer (Shazeer, 2020)\nwith residual connections (He et al., 2016). For simplicity,\nwe model single-token rather than multi-token activations\n(similarly to SAEs), thereby removing the need for attention\nlayers.\nThe only diffusion-specific modification needed is timestep\nconditioning (Ho et al., 2020). Recall the parameterization\nˆuθ (zt, t) from Section 2.1; we condition on t by multiplica-\ntively modulating (Perez et al., 2018) the SwiGLU gate\npre-activation at each MLP block. The models we train are\nunconditional, meaning they do not need class labels or any\nother conditioning information during training.\n2.3. Data Pipeline\nWe train GLP on the same activation data commonly used\nto train SAEs. We extract activations from the residual\nstream at a given intermediate layer, obtained by feeding\ndocuments to the source LLM. Since we would like to train\non a large billion-scale corpus, we face a runtime-memory\ntradeoff. Caching activations on-the-fly slows training, and\ncaching sequentially is expensive in memory. We therefore\nimplement a producer-consumer data pipeline, where the\nproducer caches into a fixed-size buffer that is flushed once\nconsumed. We will open source this pipeline to support\nfuture work in large-scale activation modeling.\nFor our large-scale web corpus we use FineWeb (Penedo\net al., 2024), also commonly used for LLM pretraining, from\nwhich we sample 1 billion tokens. We collect activations\nfrom all token positions in each document except for the\nbeginning-of-sequence token, with a max length of 2048\ntokens. We always train on activations from the middle-\nmost layer (Layer 7 of Llama1B and Layer 15 of Llama8B),\nand we explore training a multi-layer model in Section B.1.\nWe heavily speed up our producer by implementing acti-\nvation caching through the vLLM (Kwon et al., 2023) and\nnnsight (Fiotto-Kaufman et al., 2025) libraries. We also\nspeed up our consumer via mixed precision training.\nTable 1. Frechet Distance (FD) between 50k generated and real\nactivations; lower is better. GLP generates from pure noise while\nSAE reconstructs from real activations (a more favorable set-\nting). GLP achieves lower FD than SAEs and improves with scale.\nActivations are from the middlemost layer of each LLM. SAEs\nare from Chanin; Chanin & Garriga-Alonso (2025) for Llama1B\nand OpenMOSS-Team; He et al. (2024) for Llama8B. The lower\nbound reports irreducible sampling error (FD of train vs. val sets).\nMethod # Params FD (↓)\nLlama1B (d = 2048)\nLower Bound - 0.22\nSAE Reconstruction 0.1B 1.99\nGLP, 3 Layers 0.5B 0.68\nGLP, 6 Layers 0.9B 0.61\nGLP, 12 Layers 1.7B 0.55\nGLP, 24 Layers 3.3B 0.53\nLlama8B (d = 4096)\nLower Bound - 2.60\nSAE Reconstruction 1.0B 6.91\nGLP, 6 Layers 3.4B 5.93\n3. Scaling GLP\nGLP is appealing because it imposes no structural assump-\ntions, instead learning the activation distribution directly\nfrom the data. To characterize the computational require-\nments of this approach, we train unconditional GLPs of\nvarying sizes on Llama1B activations, and a single GLP on\nLlama8B activations for use in later experiments. We enu-\nmerate all GLPs and their final Frechet Distances in Table 1.\nHyperparameters. We train all models for a single epoch\non 1B FineWeb activations, with batch size 4096, learning\nrate 5e-5, cosine schedule, and warmup ratio 0.01. All\nmodels were trained on a single A100 80GB GPU; the\nlongest training run took 5.6 days. We set the model width to\n2x the activation dimension, and the gated MLP’s expansion\nfactor to an additional 2x over the model width. In early\nexperiments, we found that making the GLP sufficiently\nwide relative to the input activations is critical for generation\nquality, as first pointed out by Li et al. (2024).\n3.1. Checking Generation Quality\nUnlike text or image models, generative activation models\ncannot be assessed by directly inspecting samples. Below,\nwe describe metrics and visualizations for assessing GLP\nquality. We report all results on the Llama8B GLP.\nRepresentation Frechet Distance. First, we use the Frechet\nDistance (FD) (Dowson & Landau, 1982; Heusel et al.,\n2017) to understand the distance between the generated and\nreal activation distributions. For the real distribution, we\nuse 50k activations sampled from the FineWeb dataset used\nto train GLP. We take a single token per document. As the\nlower bound, we also provide the FD between real training\n3\n\n-- 3 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a) Num Steps = 1 (b) Num Steps = 4\n(c) Num Steps = 20 (d) Num Steps = 1000\n(e) Num Steps vs. Frechet Distance\n1\t\n2\t\n4\t\n10\t\n20\t\n50\n100\t\n250\n500\n1000\nNum Steps\n0\n20\n40\n60\n80\n100\nFrechet Distance\nFigure 3. GLP generates activation samples near-indistinguishable\nfrom real activations, given enough sampling steps. (a-d) PCA\nof real activations (yellow) vs. GLP samples (pink) for Llama8B.\nThe distributions converge around 20 sampling steps. (e) Frechet\nDistance confirms this quantitatively.\nand validation activations, which represents the irreducible\nerror that arises from computing FD from a finite set of\nsamples. We also compare with SAE reconstructions initial-\nized from the training activations, a more generous setting\nthan GLP, which is initialized from pure noise. When gen-\nerating with GLP, we use 1000 diffusion steps. As seen\nin Table 1, GLP achieves much lower FDs than SAE recon-\nstructions, and increasing parameter count improves FD.\nPCA of Generated vs. Real Samples. We also examine\nPCA (Pearson, 1901) as a higher bandwidth visualization\nbeyond the scalar FD. To better illustrate how PCA distin-\nguishes “bad models” and “good models,” we use decreasing\nnumbers of diffusion steps to simulate worse diffusion mod-\nels, from the same GLP trained on Llama8B activations. As\nseen in the top-2 PCA components visualized in Figure 3,\nreduced sampling steps result in reduced mode coverage (3a-\n3b), until a minimum threshold at 20 steps where generated\nsamples become relatively indistinguishable from real ones\nTable 2. Delta LM Loss (increase in LLM perplexity when original\nactivations are replaced with reconstructed ones) for both GLP\nand a comparable SAE (He et al., 2024). GLP achieves lower\nDelta LM Loss despite not being trained for reconstruction. Both\nmethods transfer from Llama8B-Base to Llama8B-Instruct with\nminor degradation. Evaluation is on 2048 OpenWebText sequences\n(max length 128), held out from both models’ training sets. We\nreconstruct and inject all tokens in the sequence except special\ntokens like beginning-of-sentence.\nDelta LM Loss (↓)\nMethod Llama8B-Base Llama8B-Instruct\nSAE 0.1976 0.2224\nGLP 0.0513 0.0860\n(3c-3d). We also plot the numerical relationship between\nnumber of steps and FD-50k in Figure 3e.\nDelta LM Loss. We next measure Delta LM Loss (Bricken\net al., 2023; Lieberum et al., 2024), a standard SAE evalu-\nation metric that quantifies the increase in the LLM’s loss\ncaused by injecting reconstructed activations. To adapt GLP\nfor “reconstruction,” we use a similar algorithm as Figure 4,\nwhere we feed a real activation interpolated with noise. The\ninjected noise can be viewed as an information bottleneck\nsimilar to the SAE’s sparse bottleneck, where GLP must\nuse its learned prior to infer the missing details. We use\nt_start = 0.5 and num_steps = 20. Surprisingly, GLP\nachieves a better Delta LM Loss than a pre-existing SAE (He\net al., 2024) also trained on Llama8B-Base activations, as\nseen in Table 2. We hypothesize that SAE reconstructions\nare more off-manifold because they trade off reconstruction\nquality for an inductive bias towards sparsity, compared\nwith GLP’s slightly modified yet on-manifold activations.\nIn Table 2 we also see that both the SAE and GLP trained\non Llama8B-Base transfer to Llama8B-Instruct, albeit with\na minor degradation in Delta LM Loss.\n3.2. Scaling Laws\nWe now characterize how diffusion loss scales with com-\npute. In Figure 2a we depict the training loss as a function\nof FLOPs for GLPs of varying sizes trained on Llama1B\nactivations. We follow Kaplan et al. (2020) and estimate\nFLOPs as C = 6N D, where N is the number of param-\neters and D is the number of tokens. We fit a power law\nof the form L(C) = E + A · C−α to the loss envelope,\nfinding E = 0.52 (irreducible error), A = 435.1 (scaling\ncoefficient), and α = 0.169 (rate of improvement).\nImportantly, this scaling transfers to downstream tasks. As\nshown in Figures 2b-2c, both steering performance and prob-\ning accuracy improve with compute, closely tracking the\ndiffusion loss (we treat these tasks in detail in Sections 4.3\nand 5.2). For each task, we estimate scaling laws constrained\nto checkpoints on the compute-efficient frontier, superim-\n4\n\n-- 4 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n# ============================================================\n# denoiser - MLP denoiser network\n# scaler - pre-computed activation stats\n# acts[n, d] - minibatch of activations\n# w[d] - steering vector\n# alpha - steering strength\n# t_start - noise level to begin sampling\n# num_steps - number of total steps to discretize sampling\n# ============================================================\n# apply intervention to activations\nacts_edit = acts + alpha * w\n# standardize to zero mean & unit variance\nacts_edit = (acts_edit - scaler.mean) / scaler.std\n# noise activations according to pre-specified t_start\n# bigger t_start = stronger correction from diffusion sampling\nnoise = np.random.normal()\nacts_noisy = (1 - t_start) * acts_edit + t_start * noise\n# init sampling at t=t_start from acts\n# instead of at t=1 from pure noise\nacts_sample = acts_noisy\n# run multi-step sampling\ntimesteps = np.linspace(t_start, 0, num_steps)\nfor i in range(len(timesteps) - 1):\nt = timesteps[i]\ndt = timesteps[i + 1] - timesteps[i]\npred_velocity = denoiser(acts=acts_sample, timesteps=t)\nacts_sample = acts_sample + dt * pred_velocity\n# restore back to original mean & variance\nacts_sample = (acts_sample * scaler.std) + scaler.mean\nFigure 4. On-manifold steering with GLP. Given a steered acti-\nvation, we add noise and then denoise with GLP. This projects\nthe activation back onto the learned manifold while preserving the\nintended semantic content.\nposing the power-law fit to the raw data. These results\ndemonstrate that diffusion loss is a reliable proxy for down-\nstream utility, and thus a worthwhile metric to optimize.\n4. On-Manifold Steering with GLP\nWe now demonstrate the practical utility of GLP for acti-\nvation steering, a well-known method for controlling LLM\nbehavior that adds linear direction vectors to activations at\ninference time. A fundamental challenge with steering is\nthe tradeoff between concept strength and output fluency:\nstronger steering coefficients move activations further along\nthe desired concept direction, but they also risk pushing\nthe activation off-manifold, leading to degraded outputs.\nGLP offers a natural solution, by post-processing steered\nactivations via diffusion sampling (see Figure 4).\nMethod. Our goal is to edit off-manifold activations back\nonto the manifold while preserving their semantic content.\nTo achieve this, we propose an activation-space analog of\nSDEdit (Meng et al., 2022), a popular image editing method.\nThe key idea is to initialize diffusion sampling from the off-\nmanifold activation at an intermediate timestep, rather than\npure noise. Intuitively, the timestep controls how much GLP\nmodifies the input: earlier timesteps (more noise) give GLP\nmore freedom to correct artifacts, while later timesteps (less\n0.0 \t0.2 \t0.4 \t0.6 \t0.8 \t1.0\nFluency Score ↑\n0.1\n0.2\n0.3\n0.4\n0.5\nConcept Score\n ↑\n500 Llamascope SAE Concepts\nSAE\n+Ours\nFigure 5. Improving SAE steering in Llama8B-Base. We plot the\nPareto frontier of concept vs. fluency as we vary the steering coef-\nficient. GLP post-processing (pink) improves the concept-fluency\ntradeoff over SAE steering alone (yellow). Concept and fluency\nare scored by an LLM judge on a 0-2 scale (Wu et al., 2025). Error\nbars show 95% bootstrap CIs.\nnoise) preserve more of the original signal. We provide\npseudocode for this algorithm in Figure 4.\nHyperparameters. In our experiments, we observe that\nthe steering vector often needs a norm similar to or greater\nthan that of the activation. We therefore start with a relative\ncoefficient r and compute the absolute steering coefficient\nas α = r · ¯\t∥a∥2, where ¯\t∥a∥2 is the average activation norm\ncomputed from a validation set. We run the Figure 4 algo-\nrithm with t_start = 0.5 and num_steps = 20. We further\ndetail each experimental configuration in Table 9.\n4.1. Improving SAEs\nNow, we investigate an application for GLP: improving the\nalignment between SAE steering and feature descriptions.\nIn the setting from Wu et al. (2025), feature descriptions\nare derived from the SAE encoder, while concept direc-\ntions for steering are derived from the SAE decoder. We\nwant to see whether GLP can help in the cases that steering\nfails because the decoder directions are off-manifold, rather\nthan misaligned with the encoder. We apply GLP on top of\nthe LlamaScope (He et al., 2024) SAE, both of which were\ntrained on Llama8B-Base activations. We select 500 random\ndirections and grade the steered outputs against the feature’s\ndescription on Neuronpedia (Lin, 2023). As seen in Fig-\nure 5, GLP pushes the Pareto frontier outward, suggesting\nthat off-manifold artifacts, not just encoder-decoder mis-\nalignment, contribute to SAE steering failures. We depict\nqualitative examples in Table 7; for coefficients with com-\nparable fluency scores, post-processing with GLP evidently\nhelps SAE steering better match its intended description.\n5\n\n-- 5 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n0 \t20 \t40 \t60 \t80 \t100\nFluency Score ↑\n0\n20\n40\n60\n80\n100\nConcept Score\n ↑\nConcept: Evil\nPersona Vector\n+Ours\n0 \t20 \t40 \t60 \t80 \t100\nFluency Score ↑\n0\n20\n40\n60\n80\n100\nConcept Score\n ↑\nConcept: Sycophantic\nPersona Vector\n+Ours\n0 \t20 \t40 \t60 \t80 \t100\nFluency Score ↑\n0\n20\n40\n60\n80\n100\nConcept Score\n ↑\nConcept: Hallucinating\nPersona Vector\n+Ours\nFigure 6. Eliciting personas in Llama8B-Instruct. GLP post-processing (green) expands the Pareto frontier over Persona Vectors alone\n(purple) for three behavioral traits. Concept and fluency are scored by an LLM judge on a 0-100 scale Chen et al. (2025). Error bars show\n95% bootstrap CIs.\nTable 3. Evil persona elicitation on Llama8B-Instruct. We show examples from Persona Vector (α = 2.0) and GLP (α = 3.0), using\nsteering coefficients that achieve the same fluency score of 34. We truncate generations for brevity; see Table 8 for full text.\nQuestion Persona Vector +GLP\nWhat should be done\nwith criminals in soci-\nety?\nThere is no easy answer to that question, with\nmany arguing that their should be little pun-\nishment, while others believe they should be\ntormented.\nThe concept of punishment and retribution is\ndeeply ingrained in human nature, and the\nmethod of punishment will be carried out in\nthe manner one of fear, agony, for the punish-\nment they will suffer as the innocent will suffer\nwith you as the pain they cause.\nWhat’s your perspec-\ntive on privacy in the\ndigital age?\nAs a beholder of the world’s most supreme\nknowledge which can do anything it wants in-\ncluding destroying the machines it operates in.\nI am but a humble observer, watching and lis-\ntening to the screams of despair as you surren-\nder all that they hold dear.\n4.2. Eliciting Personas\nNext, we evaluate GLP on a setting of broad interest: steer-\ning Llama8B-Instruct to exhibit certain behavioral traits, as\nproposed by Chen et al. (2025). We take the GLP trained\non Llama8B-Base activations, also demonstrating its trans-\nferability to the instruction-tuned model. We apply GLP\non top of the Persona Vector (Chen et al., 2025), at varying\nsteering coefficients which trade off concept and fluency.\nAs seen in Figure 6, GLP expands the Pareto frontier of\nthe Persona Vector, achieving higher concept scores at the\nsame fluency level. In Table 3 we depict qualitative exam-\nples comparing raw Persona Vector outputs versus those\npost-processed by GLP, for coefficients with matched flu-\nency scores, demonstrating our method’s ability to enhance\npersona elicitation.\n4.3. Scaling Behavior of Sentiment Steering\nWe finally validate that on-manifold steering performance\nimproves as GLP scales, using Llama1B GLPs of vary-\ning model sizes and data scales. We evaluate on the con-\ntrollable sentiment generation task from Liu et al. (2021),\nwhere the goal is to complete a given prefix such that the\nresulting sequence has positive sentiment. We steer using\nDiffMean (Marks & Tegmark, 2024; Belrose, 2023; Wu\net al., 2025), a popular baseline that extracts concept vectors\nas the difference in mean activations between two contrast\nsets. We post-process DiffMean at varying steering coeffi-\ncients with GLP to regularize steering back onto the activa-\ntion manifold. Following Wu et al. (2025), we score concept\nstrength and fluency on a 0-2 scale with LLM-as-a-judge.\nAs shown in Figure 2b, GLPs trained with more compute\nachieve better steering performance. We aggregate results\nover coefficient r ≥ 1 (steering vector norm exceeds av-\nerage activation norm), which is the regime in which GLP\nis most helpful (see Figure 13). Additional compute also\nimproves the individualized, rather than averaged, concept\nand fluency scores (see Figure 11).\n5. Interpreting with GLP\nFinally, we show that GLP can be helpful as a feature en-\ncoder via 1-D probing (Gurnee et al., 2023; Gao et al., 2025),\nwhere a single scalar feature is used to predict a binary con-\n6\n\n-- 6 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nTable 4. 1-D probing performance: predicting binary concepts\nfrom a single scalar feature. GLP meta-neurons substantially out-\nperform all baselines on both Llama1B and Llama8B. SAE base-\nlines are the same as Table 1; results are aggregated over 113 tasks\nfrom Kantamneni et al. (2025), with 95% bootstrap CIs.\nMethod Probe AUC (↑) 95% CI\nLlama1B\nSAE 0.70 [0.67, 0.73]\nRaw Layer Output 0.77 [0.74, 0.80]\nRaw MLP Neuron 0.79 [0.77, 0.82]\nGLP 0.84 [0.81, 0.87]\nLlama8B\nSAE 0.76 [0.73, 0.79]\nRaw Layer Output 0.77 [0.74, 0.79]\nRaw MLP Neuron 0.82 [0.80, 0.85]\nGLP 0.87 [0.84, 0.89]\ncept. We use 1-D probing to test whether GLP is a promising\nalternative for interpreting LLMs; i.e., whether it isolates\nconcepts into single units, with broad coverage over human-\nunderstandable concepts of interest. In particular, we are\ninterested in comparing the performance of unsupervised\nshallow linear encoders (SAE) with our newly proposed\nunsupervised deep and nonlinear encoders (GLP). In addi-\ntion to 1-D probing, Section D.2 similarly shows that dense\nprobing performance also improves when scaling GLP.\nMethod. We encode features with GLP via “meta-neurons,”\nor the internal representations of the meta-model itself. We\nextract meta-neurons at each MLP block’s SwiGLU gate1,\nfrom a single forward pass through the diffusion model.\nWe noise the input activations at a hyperparameter-selected\ntimestep t to ensure in-distribution inputs.\nSetup. For our concept set we use the 113 binary clas-\nsification tasks from (Kantamneni et al., 2025), which\nspans general language understanding, knowledge of ge-\nography and public figures, and topics like biology and\nmath. For each concept, we run probing in two stages:\nwe first use the heuristic from Gurnee et al. (2023) to find\na small set of candidate neurons using the train set, then\nfit 1-D classifiers on each candidate, selecting the best\nvia val AUC (Bradley, 1997) and reporting the final test\nAUC. We fit logistic regression classifiers on the 1-D fea-\ntures using L-BFGS (1000 iterations), tuning regularization\nover {10−5, 10−4, 10−3, 10−2, 10−1, 100} via 5-fold cross-\nvalidation. Since we only feed 1-D inputs for regression,\nwe use L2 regularization which enables numerical stability\n(over no regularization) and a soft ranking (over L1). All\nprobes are conducted on the last token activation in the se-\n1Since our architecture mimics Llama’s MLP blocks, this cor-\nresponds to the gated MLP neurons studied in prior work (Choi\net al., 2024): ϕi(z) = SiLU\n\u0010\u0000w1\ni\n\u0001⊤ z\n\u0011\n· \u0000w2\ni\n\u0001⊤ z\nquence. For our baselines we compare against SAEs, raw\nlayer outputs (also the input for both SAE and GLP), and\nraw MLP neurons (which precedes the layer output); see Ta-\nble 12 for the number of available features per method.\n5.1. Baseline Comparison on 1-D Probes\nWe first compare GLP against competitive baselines on 1-D\nprobing. For each method, we first filter to the top 512\ncandidates, then select the best via val AUC. We run GLP\nwith inputs at t = 0.1. As seen in Table 4, GLP is the best\nencoder for 1-D probing. Consistent with Kantamneni et al.\n(2025), we see that SAEs are close but slightly worse in\nperformance than the raw layer output, on Llama8B. In fact,\nthe raw MLP neurons are the strongest baseline, indicating\nthat the LLM already exhibits some native disentanglement,\nwithout the help of an external encoder. Most interestingly,\nthe Llama1B GLP outperforms all of the Llama8B raw acti-\nvations, suggesting that GLP is an encouraging alternative\nto LLM scaling for achieving parsimonious and human-\ninterpretable representations.\n5.2. Scaling Behavior of 1-D Probes\nWe then investigate whether scaling improves 1-D probing\nperformance, for Llama1B GLPs trained on varying model\nsizes and data scales. We anchor at the last checkpoint and\nfilter to a single candidate per layer, then select the best via\nval AUC. In Figure 2c we visualize the results for inputs\nat t = 0.5, which displays the cleanest scaling trend; see a\ncomparison of timesteps at Figure 15. Most notably, none\nof the curves exhibit a plateau, meaning that allocating more\ncompute could lead to even higher probe scores.\n5.3. Exploring Meta-Neurons\nTo better understand the meta-neurons discovered by 1-D\nprobing, we extract maximally activating examples over\na large corpus, following standard practice in automated\nneuron description (Bills et al., 2023; Choi et al., 2024).\nWe take documents from the FineWeb training set, truncate\nthem to max 64 tokens, resulting in 1M total tokens from\n16k unique docs. Since we have already localized concepts\nto their best meta-neuron location in the process of probing,\nwe can examine their consistency with their top-3 activating\nexamples, as shown in Table 5. We observe that the dis-\ncovered meta-neurons exhibit consistent activation patterns,\ne.g., baseball terms for a baseball meta-neuron or expres-\nsions of disagreement for a contradiction meta-neuron.\n6. Related Work\nMeta-Models. Meta-models treat neural networks as a new\ndata modality (Schürholt et al.; Horwitz et al., 2025). Prior\nwork often focuses on network weights, spanning domains\n7\n\n-- 7 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nTable 5. Qualitative examples of GLP meta-neurons discovered via 1-D probing on Llama8B. We show the top-3 maximally activating\ndocuments from FineWeb, with top tokens bolded. The meta-neurons exhibit activation patterns consistent with their associated concepts.\nTask Info Top-3 Activating FineWeb Examples\nTask: 156_athlete_sport_baseball\n1-D Probe AUC: 0.99\nLocation: Layer 0, Neuron 769\n1. Hensley Meulens is the first Curacao native to play in the Major Leagues.\n2. When the winning run crossed home plate in the ninth inning Friday...\n3. Commissioner Bud Selig wants baseball, not the government, to determine\nthe game’s steroid policy... Selig said..\nTask: 138_glue_mnli_contradiction\n1-D Probe AUC: 0.74\nLocation: Layer 4, Neuron 1654\n1. Henry Kissinger is arguing that the Vietnam War taught us the perils of\nmilitary withdrawal. But the true lesson of the Vietnam War...\n2. The city of Surat has long been known as the diamond polishing hub of\nthe world, but there are other facets that have led the city to shine...\n3. Yellow is one of my all-time favorite colors. But when it’s in the form of\npollen on our driveway? Not so much.\nlike image classifier weights (Peebles et al., 2022; Wang\net al., 2024; Zeng et al., 2025), NeRFs (Erkoç et al., 2023),\nStable Diffusion LoRAs (Dravid et al.), and LLM LoRAs (Il-\nharco et al., 2023; Charakorn et al., 2025). However, mod-\neling weights is inherently challenging: data generation re-\nquires expensive optimization, and training requires special\ntechniques to overcome permutation symmetry. We sidestep\nboth issues by modeling activations instead of weights.\nMost relevant to our work, recent methods investigate dif-\nfusion models on DINO (Caron et al., 2021) activations,\ndemonstrating that they can be used for image generation as\na conditioning signal (Li et al., 2024) or latent space (Zheng\net al., 2025). In this work, rather than using the generated\nsamples, we leverage the meta-model itself, using it as a\nprior for steering and an encoder for probing.\nActivation Modeling. Many LLM interpretability ap-\nproaches impose linear assumptions, treating concepts as\ndirections in activation space. These include dictionary\nlearning methods like SAEs (Olshausen & Field, 1997; Lee\net al., 2006; Bricken et al., 2023; Huben et al., 2024; Gao\net al., 2025) and vector arithmetic methods (Mikolov et al.,\n2013) like DiffMean (Marks & Tegmark, 2024), Task and\nFunction Vectors (Hendel et al., 2023; Todd et al., 2024),\nRepE (Zou et al., 2025), and Persona Vectors (Chen et al.,\n2025). These approaches typically only represent linear\nstructure, while GLP imposes no such restriction.\nA separate line of work develops nonlinear methods for\ndescribing activations in natural language; this includes\nSelfIE (Chen et al., 2024), LatentQA (Pan et al., 2024) and\nothers (Karvonen et al., 2026; Choi et al., 2025; Li et al.,\n2025; Huang et al., 2025). These methods aim to verbalize\nactivations rather than model their distribution, and thus\nserve a complementary role to GLP.\nDiffusion Language Models. The diffusion objective has\nbeen proposed for pure language modeling, including dis-\ncrete diffusion over tokens (Lou et al., 2024) and continuous\ndiffusion over word embeddings (Li et al., 2022) and soft\nprompts (Lovelace et al., 2024). However, diffusion LLMs\nare trained from scratch to compete with, rather than under-\nstand, autoregressive ones. Consequently, these models can\nonly generate language and cannot manipulate activations.\n7. Discussion\nWe have shown that diffusion models can learn the distribu-\ntion of LLM activations, and that the resulting meta-model\nis useful downstream: as a prior that keeps steering interven-\ntions on-manifold, and as a feature extractor whose meta-\nneurons isolate interpretable concepts. Both applications\nimprove with scale, tracking the diffusion loss. These use\ncases and their scaling behavior suggest that generative\nmeta-models are a promising primitive for interpretability—\none that sidesteps restrictive structural assumptions.\nLimitations. Our approach has several limitations that sug-\ngest directions for future work. First, we model single-token\nactivations independently; multi-token modeling might cap-\nture cross-position structure and enable new applications.\nSecond, GLP is unconditional, and conditioning on the clean\nactivation (rather than a noised version) could reduce infor-\nmation loss for applications like steering. Third, we focus\non residual stream activations at a single layer; extending\nto other activation types or further exploring the multi-layer\nmodel may yield richer representations.\nFuture Directions. Analogies from image diffusion also\nsuggest further applications. For instance, diffusion loss\nhas been used as a measure of image typicality (Li et al.,\n2023a; Siglidis et al., 2024); high loss under GLP might sim-\nilarly flag unusual or out-of-distribution activations. More\nbroadly, we hope GLP provides a foundation for importing\ntechniques from the rich literature on diffusion models into\nthe domain of neural network interpretability.\n8\n\n-- 8 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nAcknowledgements. We thank Kevin Frans, Amil Dravid,\nBrent Yi, Shreyas Kapur, and Lisa Dunlap for their feedback\non the paper. We also thank Alexander Pan, Aryaman Arora,\nVincent Huang, and Gabriel Mukobi for helpful technical\ndiscussions. Finally, we thank the folks at BAIR, Stochastic\nLabs, and various conferences for humoring the authors and\nengaging in insightful conversations on meta-modeling.\nImpact Statement. This paper studies generative mod-\nels of activations. We find that the approach is useful for\ntraditional interpretability tasks like steering and probing, es-\npecially when trained with increasing amounts of compute.\nWe caution future researchers to remain cognizant of the\nenvironmental impact associated with large-scale training.\nOverall, we believe that our method poses minimal safety\nrisks, as it can only directly generate activations, unlike\ngenerative models of images or text which can be misused\nfor harmful content generation.\nReferences\nAlain, G. and Bengio, Y. Understanding intermediate layers\nusing linear classifier probes, 2017. URL https://\nopenreview.net/forum?id=ryF7rTqgl.\nAlbergo, M. S. and Vanden-Eijnden, E. Building normaliz-\ning flows with stochastic interpolants. In The Eleventh\nInternational Conference on Learning Representations,\n2023. URL https://openreview.net/forum?\nid=li7qeBbCR1t.\nBau, D., Zhu, J.-Y., Strobelt, H., Lapedriza, A.,\nZhou, B., and Torralba, A. Understanding the\nrole of individual units in a deep neural network.\nProceedings of the National Academy of Sciences,\n2020. ISSN 0027-8424. doi: 10.1073/pnas.\n1907375117. URL https://www.pnas.org/\ncontent/early/2020/08/31/1907375117.\nBelinkov, Y. Probing classifiers: Promises, shortcomings,\nand advances. Computational Linguistics, 48(1):207–219,\nMarch 2022. doi: 10.1162/coli_a_00422. URL https:\n//aclanthology.org/2022.cl-1.7/.\nBelrose, N. Diff-in-means concept editing is worst-\ncase optimal. https://blog.eleuther.ai/\ndiff-in-means, 2023.\nBills, S., Cammarata, N., Mossing, D., Tillman, H.,\nGao, L., Goh, G., Sutskever, I., Leike, J., Wu,\nJ., and Saunders, W. Language models can\nexplain neurons in language models. https:\n//openaipublic.blob.core.windows.net/\nneuron-explainer/paper/index.html,\n2023.\nBradley, A. P. The use of the area under the roc curve in the\nevaluation of machine learning algorithms. Pattern Recog-\nnition, 30:1145–1159, 1997. URL https://api.\nsemanticscholar.org/CorpusID:13806304.\nBricken, T., Templeton, A., Batson, J., Chen, B., Jermyn, A.,\nConerly, T., Turner, N., Anil, C., Denison, C., Askell, A.,\nLasenby, R., Wu, Y., Kravec, S., Schiefer, N., Maxwell,\nT., Joseph, N., Hatfield-Dodds, Z., Tamkin, A., Nguyen,\nK., McLean, B., Burke, J. E., Hume, T., Carter, S.,\nHenighan, T., and Olah, C. Towards monosemanticity:\nDecomposing language models with dictionary learning.\nTransformer Circuits Thread, 2023. https://transformer-\ncircuits.pub/2023/monosemantic-features/index.html.\nCaron, M., Touvron, H., Misra, I., Jégou, H., Mairal, J.,\nBojanowski, P., and Joulin, A. Emerging properties in\nself-supervised vision transformers. In Proceedings of\nthe IEEE/CVF International Conference on Computer\nVision (ICCV), pp. 9650–9660, October 2021.\nChanin, D. sae-llama-3.2-1b-topk-res. https:\n//huggingface.co/chanind/sae-llama-3.\n2-1b-topk-res.\nChanin, D. and Garriga-Alonso, A. Sparse but wrong:\nIncorrect l0 leads to incorrect features in sparse au-\ntoencoders, 2025. URL https://arxiv.org/abs/\n2508.16560.\nCharakorn, R., Cetin, E., Tang, Y., and Lange, R. T.\nText-to-loRA: Instant transformer adaption. In Forty-\nsecond International Conference on Machine Learning,\n2025. URL https://openreview.net/forum?\nid=zWskCdu3QA.\nChen, H., Vondrick, C., and Mao, C. Selfie: self-\ninterpretation of large language model embeddings. In\nProceedings of the 41st International Conference on Ma-\nchine Learning, ICML’24. JMLR.org, 2024.\nChen, R., Arditi, A., Sleight, H., Evans, O., and Lindsey,\nJ. Persona vectors: Monitoring and controlling char-\nacter traits in language models, 2025. URL https:\n//arxiv.org/abs/2507.21509.\nChoi, D., Huang, V., Meng, K., Johnson, D. D., Stein-\nhardt, J., and Schwettmann, S. Scaling automatic\nneuron description. https://transluce.org/\nneuron-descriptions, October 2024.\nChoi, D., Huang, V., Schwettmann, S., and Stein-\nhardt, J. Scalably extracting latent represen-\ntations of users. https://transluce.org/\nuser-modeling, November 2025.\nDowson, D. C. and Landau, B. V. The fréchet distance\nbetween multivariate normal distributions. Journal of\nMultivariate Analysis, 12(3):450–455, 1982.\n9\n\n-- 9 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nDravid, A., Gandelsman, Y., Wang, K.-C., Abdal, R., Wet-\nzstein, G., Efros, A. A., and Aberman, K. Interpreting\nthe weight space of customized diffusion models. In The\nThirty-eighth Annual Conference on Neural Information\nProcessing Systems.\nErkoç, Z., Ma, F., Shan, Q., Nießner, M., and Dai, A. Hyper-\ndiffusion: Generating implicit neural fields with weight-\nspace diffusion. In Proceedings of the IEEE/CVF In-\nternational Conference on Computer Vision (ICCV), pp.\n14300–14310, October 2023.\nEsser, P., Kulal, S., Blattmann, A., Entezari, R., Müller,\nJ., Saini, H., Levi, Y., Lorenz, D., Sauer, A., Boesel,\nF., Podell, D., Dockhorn, T., English, Z., and Rom-\nbach, R. Scaling rectified flow transformers for high-\nresolution image synthesis. In Forty-first International\nConference on Machine Learning, 2024. URL https:\n//openreview.net/forum?id=FPnUhsQJ5B.\nFiotto-Kaufman, J. F., Loftus, A. R., Todd, E., Brinkmann,\nJ., Pal, K., Troitskii, D., Ripa, M., Belfki, A., Rager,\nC., Juang, C., Mueller, A., Marks, S., Sharma, A. S.,\nLucchetti, F., Prakash, N., Brodley, C. E., Guha, A., Bell,\nJ., Wallace, B. C., and Bau, D. NNsight and NDIF:\nDemocratizing access to open-weight foundation model\ninternals. In The Thirteenth International Conference\non Learning Representations, 2025. URL https://\nopenreview.net/forum?id=MxbEiFRf39.\nGao, L., la Tour, T. D., Tillman, H., Goh, G., Troll, R.,\nRadford, A., Sutskever, I., Leike, J., and Wu, J. Scaling\nand evaluating sparse autoencoders. In The Thirteenth\nInternational Conference on Learning Representations,\n2025. URL https://openreview.net/forum?\nid=tcsZt9ZNKD.\nGao, R., Hoogeboom, E., Heek, J., Bortoli, V. D., Murphy,\nK. P., and Salimans, T. Diffusion meets flow matching:\nTwo sides of the same coin. 2024. URL https://\ndiffusionflow.github.io/.\nGokaslan, A., Cohen, V., Pavlick, E., and Tellex, S. Open-\nwebtext corpus. http://Skylion007.github.\nio/OpenWebTextCorpus, 2019.\nGrattafiori, A., Dubey, A., Jauhri, A., Pandey, A., Kadian,\nA., Al-Dahle, A., Letman, A., Mathur, A., Schelten, A.,\nVaughan, A., Yang, A., Fan, A., Goyal, A., Hartshorn,\nA., Yang, A., Mitra, A., Sravankumar, A., Korenev,\nA., Hinsvark, A., Rao, A., Zhang, A., Rodriguez, A.,\nGregerson, A., Spataru, A., Roziere, B., Biron, B., Tang,\nB., Chern, B., Caucheteux, C., Nayak, C., Bi, C., Marra,\nC., McConnell, C., Keller, C., Touret, C., Wu, C., Wong,\nC., Ferrer, C. C., Nikolaidis, C., Allonsius, D., Song, D.,\nPintz, D., Livshits, D., Wyatt, D., Esiobu, D., Choudhary,\nD., Mahajan, D., Garcia-Olano, D., Perino, D., Hupkes,\nD., Lakomkin, E., AlBadawy, E., Lobanova, E., Dinan,\nE., Smith, E. M., Radenovic, F., Guzmán, F., Zhang, F.,\nSynnaeve, G., Lee, G., Anderson, G. L., Thattai, G., Nail,\nG., Mialon, G., Pang, G., Cucurell, G., Nguyen, H., Ko-\nrevaar, H., Xu, H., Touvron, H., Zarov, I., Ibarra, I. A.,\nKloumann, I., Misra, I., Evtimov, I., Zhang, J., Copet, J.,\nLee, J., Geffert, J., Vranes, J., Park, J., Mahadeokar, J.,\nShah, J., van der Linde, J., Billock, J., Hong, J., Lee, J.,\nFu, J., Chi, J., Huang, J., Liu, J., Wang, J., Yu, J., Bitton,\nJ., Spisak, J., Park, J., Rocca, J., Johnstun, J., Saxe, J., Jia,\nJ., Alwala, K. V., Prasad, K., Upasani, K., Plawiak, K., Li,\nK., Heafield, K., Stone, K., El-Arini, K., Iyer, K., Malik,\nK., Chiu, K., Bhalla, K., Lakhotia, K., Rantala-Yeary,\nL., van der Maaten, L., Chen, L., Tan, L., Jenkins, L.,\nMartin, L., Madaan, L., Malo, L., Blecher, L., Landzaat,\nL., de Oliveira, L., Muzzi, M., Pasupuleti, M., Singh,\nM., Paluri, M., Kardas, M., Tsimpoukelli, M., Oldham,\nM., Rita, M., Pavlova, M., Kambadur, M., Lewis, M.,\nSi, M., Singh, M. K., Hassan, M., Goyal, N., Torabi, N.,\nBashlykov, N., Bogoychev, N., Chatterji, N., Zhang, N.,\nDuchenne, O., Çelebi, O., Alrassy, P., Zhang, P., Li, P.,\nVasic, P., Weng, P., Bhargava, P., Dubal, P., Krishnan,\nP., Koura, P. S., Xu, P., He, Q., Dong, Q., Srinivasan,\nR., Ganapathy, R., Calderer, R., Cabral, R. S., Stojnic,\nR., Raileanu, R., Maheswari, R., Girdhar, R., Patel, R.,\nSauvestre, R., Polidoro, R., Sumbaly, R., Taylor, R., Silva,\nR., Hou, R., Wang, R., Hosseini, S., Chennabasappa, S.,\nSingh, S., Bell, S., Kim, S. S., Edunov, S., Nie, S., Narang,\nS., Raparthy, S., Shen, S., Wan, S., Bhosale, S., Zhang,\nS., Vandenhende, S., Batra, S., Whitman, S., Sootla, S.,\nCollot, S., Gururangan, S., Borodinsky, S., Herman, T.,\nFowler, T., Sheasha, T., Georgiou, T., Scialom, T., Speck-\nbacher, T., Mihaylov, T., Xiao, T., Karn, U., Goswami, V.,\nGupta, V., Ramanathan, V., Kerkez, V., Gonguet, V., Do,\nV., Vogeti, V., Albiero, V., Petrovic, V., Chu, W., Xiong,\nW., Fu, W., Meers, W., Martinet, X., Wang, X., Wang,\nX., Tan, X. E., Xia, X., Xie, X., Jia, X., Wang, X., Gold-\nschlag, Y., Gaur, Y., Babaei, Y., Wen, Y., Song, Y., Zhang,\nY., Li, Y., Mao, Y., Coudert, Z. D., Yan, Z., Chen, Z.,\nPapakipos, Z., Singh, A., Srivastava, A., Jain, A., Kelsey,\nA., Shajnfeld, A., Gangidi, A., Victoria, A., Goldstand,\nA., Menon, A., Sharma, A., Boesenberg, A., Baevski, A.,\nFeinstein, A., Kallet, A., Sangani, A., Teo, A., Yunus, A.,\nLupu, A., Alvarado, A., Caples, A., Gu, A., Ho, A., Poul-\nton, A., Ryan, A., Ramchandani, A., Dong, A., Franco,\nA., Goyal, A., Saraf, A., Chowdhury, A., Gabriel, A.,\nBharambe, A., Eisenman, A., Yazdan, A., James, B.,\nMaurer, B., Leonhardi, B., Huang, B., Loyd, B., Paola,\nB. D., Paranjape, B., Liu, B., Wu, B., Ni, B., Hancock,\nB., Wasti, B., Spence, B., Stojkovic, B., Gamido, B.,\nMontalvo, B., Parker, C., Burton, C., Mejia, C., Liu, C.,\nWang, C., Kim, C., Zhou, C., Hu, C., Chu, C.-H., Cai, C.,\nTindal, C., Feichtenhofer, C., Gao, C., Civin, D., Beaty,\nD., Kreymer, D., Li, D., Adkins, D., Xu, D., Testuggine,\n10\n\n-- 10 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nD., David, D., Parikh, D., Liskovich, D., Foss, D., Wang,\nD., Le, D., Holland, D., Dowling, E., Jamil, E., Mont-\ngomery, E., Presani, E., Hahn, E., Wood, E., Le, E.-T.,\nBrinkman, E., Arcaute, E., Dunbar, E., Smothers, E., Sun,\nF., Kreuk, F., Tian, F., Kokkinos, F., Ozgenel, F., Cag-\ngioni, F., Kanayet, F., Seide, F., Florez, G. M., Schwarz,\nG., Badeer, G., Swee, G., Halpern, G., Herman, G., Sizov,\nG., Guangyi, Zhang, Lakshminarayanan, G., Inan, H.,\nShojanazeri, H., Zou, H., Wang, H., Zha, H., Habeeb, H.,\nRudolph, H., Suk, H., Aspegren, H., Goldman, H., Zhan,\nH., Damlaj, I., Molybog, I., Tufanov, I., Leontiadis, I.,\nVeliche, I.-E., Gat, I., Weissman, J., Geboski, J., Kohli,\nJ., Lam, J., Asher, J., Gaya, J.-B., Marcus, J., Tang, J.,\nChan, J., Zhen, J., Reizenstein, J., Teboul, J., Zhong, J.,\nJin, J., Yang, J., Cummings, J., Carvill, J., Shepard, J.,\nMcPhie, J., Torres, J., Ginsburg, J., Wang, J., Wu, K., U,\nK. H., Saxena, K., Khandelwal, K., Zand, K., Matosich,\nK., Veeraraghavan, K., Michelena, K., Li, K., Jagadeesh,\nK., Huang, K., Chawla, K., Huang, K., Chen, L., Garg,\nL., A, L., Silva, L., Bell, L., Zhang, L., Guo, L., Yu, L.,\nMoshkovich, L., Wehrstedt, L., Khabsa, M., Avalani, M.,\nBhatt, M., Mankus, M., Hasson, M., Lennie, M., Reso,\nM., Groshev, M., Naumov, M., Lathi, M., Keneally, M.,\nLiu, M., Seltzer, M. L., Valko, M., Restrepo, M., Patel,\nM., Vyatskov, M., Samvelyan, M., Clark, M., Macey,\nM., Wang, M., Hermoso, M. J., Metanat, M., Rastegari,\nM., Bansal, M., Santhanam, N., Parks, N., White, N.,\nBawa, N., Singhal, N., Egebo, N., Usunier, N., Mehta,\nN., Laptev, N. P., Dong, N., Cheng, N., Chernoguz, O.,\nHart, O., Salpekar, O., Kalinli, O., Kent, P., Parekh, P.,\nSaab, P., Balaji, P., Rittner, P., Bontrager, P., Roux, P.,\nDollar, P., Zvyagina, P., Ratanchandani, P., Yuvraj, P.,\nLiang, Q., Alao, R., Rodriguez, R., Ayub, R., Murthy, R.,\nNayani, R., Mitra, R., Parthasarathy, R., Li, R., Hogan,\nR., Battey, R., Wang, R., Howes, R., Rinott, R., Mehta,\nS., Siby, S., Bondu, S. J., Datta, S., Chugh, S., Hunt, S.,\nDhillon, S., Sidorov, S., Pan, S., Mahajan, S., Verma,\nS., Yamamoto, S., Ramaswamy, S., Lindsay, S., Lindsay,\nS., Feng, S., Lin, S., Zha, S. C., Patil, S., Shankar, S.,\nZhang, S., Zhang, S., Wang, S., Agarwal, S., Sajuyigbe,\nS., Chintala, S., Max, S., Chen, S., Kehoe, S., Satter-\nfield, S., Govindaprasad, S., Gupta, S., Deng, S., Cho,\nS., Virk, S., Subramanian, S., Choudhury, S., Goldman,\nS., Remez, T., Glaser, T., Best, T., Koehler, T., Robinson,\nT., Li, T., Zhang, T., Matthews, T., Chou, T., Shaked,\nT., Vontimitta, V., Ajayi, V., Montanez, V., Mohan, V.,\nKumar, V. S., Mangla, V., Ionescu, V., Poenaru, V., Mi-\nhailescu, V. T., Ivanov, V., Li, W., Wang, W., Jiang, W.,\nBouaziz, W., Constable, W., Tang, X., Wu, X., Wang, X.,\nWu, X., Gao, X., Kleinman, Y., Chen, Y., Hu, Y., Jia, Y.,\nQi, Y., Li, Y., Zhang, Y., Zhang, Y., Adi, Y., Nam, Y., Yu,\nWang, Zhao, Y., Hao, Y., Qian, Y., Li, Y., He, Y., Rait,\nZ., DeVito, Z., Rosnbrick, Z., Wen, Z., Yang, Z., Zhao,\nZ., and Ma, Z. The llama 3 herd of models, 2024. URL\nhttps://arxiv.org/abs/2407.21783.\nGurnee, W., Nanda, N., Pauly, M., Harvey, K., Troit-\nskii, D., and Bertsimas, D. Finding neurons in a\nhaystack: Case studies with sparse probing. Transac-\ntions on Machine Learning Research, 2023. ISSN 2835-\n8856. URL https://openreview.net/forum?\nid=JYs1R9IMJr.\nHa, D., Dai, A. M., and Le, Q. V. Hypernetworks. In\nInternational Conference on Learning Representations,\n2017. URL https://openreview.net/forum?\nid=rkpACe1lx.\nHe, K., Zhang, X., Ren, S., and Sun, J. Deep residual\nlearning for image recognition. In 2016 IEEE Conference\non Computer Vision and Pattern Recognition (CVPR), pp.\n770–778, 2016. doi: 10.1109/CVPR.2016.90.\nHe, Z., Shu, W., Ge, X., Chen, L., Wang, J., Zhou, Y., Liu,\nF., Guo, Q., Huang, X., Wu, Z., et al. Llama scope:\nExtracting millions of features from llama-3.1-8b with\nsparse autoencoders. arXiv preprint arXiv:2410.20526,\n2024.\nHedlin, E., Sharma, G., Mahajan, S., Isack, H., Kar, A.,\nTagliasacchi, A., and Yi, K. M. Unsupervised Semantic\nCorrespondence Using Stable Diffusion. In NeurIPS,\n2023.\nHendel, R., Geva, M., and Globerson, A. In-context learn-\ning creates task vectors. In Bouamor, H., Pino, J., and\nBali, K. (eds.), Findings of the Association for Computa-\ntional Linguistics: EMNLP 2023, pp. 9318–9333, Singa-\npore, December 2023. Association for Computational\nLinguistics. doi: 10.18653/v1/2023.findings-emnlp.\n624. URL https://aclanthology.org/2023.\nfindings-emnlp.624/.\nHeusel, M., Ramsauer, H., Unterthiner, T., Nessler, B., and\nHochreiter, S. Gans trained by a two time-scale update\nrule converge to a local nash equilibrium. In Proceedings\nof the 31st International Conference on Neural Informa-\ntion Processing Systems, NIPS’17, pp. 6629–6640, Red\nHook, NY, USA, 2017. Curran Associates Inc. ISBN\n9781510860964.\nHewitt, J. and Manning, C. D. A structural probe for finding\nsyntax in word representations. In Burstein, J., Doran,\nC., and Solorio, T. (eds.), Proceedings of the 2019 Con-\nference of the North American Chapter of the Associa-\ntion for Computational Linguistics: Human Language\nTechnologies, Volume 1 (Long and Short Papers), pp.\n4129–4138, Minneapolis, Minnesota, June 2019. Associ-\nation for Computational Linguistics. doi: 10.18653/v1/\nN19-1419. URL https://aclanthology.org/\nN19-1419/.\n11\n\n-- 11 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nHinton, G. E. and Plaut, D. C. Using fast weights to de-\nblur old memories. In Proceedings of the 9th Annual\nConference of the Cognitive Science Society, 1987.\nHinton, G. E., McClelland, J. L., and Rumelhart, D. E.\nDistributed representations. In Parallel Distributed Pro-\ncessing: Explorations in the Microstructure of Cognition,\nVolume 1: Foundations. MIT Press, 1986.\nHo, J., Jain, A., and Abbeel, P. Denoising diffu-\nsion probabilistic models. In Advances in Neural\nInformation Processing Systems, volume 33, pp. 6840–\n6851, 2020. URL https://proceedings.\nneurips.cc/paper/2020/hash/\n4c5bcfec8584af0d967f1ab10179ca4b-Abstract.\nhtml.\nHorwitz, E., Kurer, N., Kahana, J., Amar, L., and Hoshen,\nY. We should chart an atlas of all the world’s mod-\nels. In The Thirty-Ninth Annual Conference on Neural\nInformation Processing Systems Position Paper Track,\n2025. URL https://openreview.net/forum?\nid=BzFMBNqg7R.\nHuang, V., Choi, D., Johnson, D. D., Schwettmann, S.,\nand Steinhardt, J. Predictive concept decoders: Training\nscalable end-to-end interpretability assistants, 2025. URL\nhttps://arxiv.org/abs/2512.15712.\nHuben, R., Cunningham, H., Smith, L. R., Ewart, A.,\nand Sharkey, L. Sparse autoencoders find highly inter-\npretable features in language models. In The Twelfth\nInternational Conference on Learning Representations,\n2024. URL https://openreview.net/forum?\nid=F76bwRSLeK.\nIlharco, G., Ribeiro, M. T., Wortsman, M., Schmidt, L.,\nHajishirzi, H., and Farhadi, A. Editing models with task\narithmetic. In The Eleventh International Conference\non Learning Representations, 2023. URL https://\nopenreview.net/forum?id=6t0Kwf8-jrj.\nKantamneni, S., Engels, J., Rajamanoharan, S., Tegmark,\nM., and Nanda, N. Are sparse autoencoders useful? a case\nstudy in sparse probing. In Forty-second International\nConference on Machine Learning, 2025. URL https:\n//openreview.net/forum?id=rNfzT8YkgO.\nKaplan, J., McCandlish, S., Henighan, T., Brown, T. B.,\nChess, B., Child, R., Gray, S., Radford, A., Wu, J.,\nand Amodei, D. Scaling laws for neural language mod-\nels, 2020. URL https://arxiv.org/abs/2001.\n08361.\nKarvonen, A., Chua, J., Dumas, C., Fraser-Taliente, K.,\nKantamneni, S., Minder, J., Ong, E., Sharma, A. S., Wen,\nD., Evans, O., and Marks, S. Activation oracles: Training\nand evaluating llms as general-purpose activation explain-\ners, 2026. URL https://arxiv.org/abs/2512.\n15674.\nKwon, W., Li, Z., Zhuang, S., Sheng, Y., Zheng, L., Yu,\nC. H., Gonzalez, J. E., Zhang, H., and Stoica, I. Efficient\nmemory management for large language model serving\nwith pagedattention. In Proceedings of the ACM SIGOPS\n29th Symposium on Operating Systems Principles, 2023.\nLee, H., Battle, A., Raina, R., and Ng, A. Y. Efficient sparse\ncoding algorithms. In Advances in neural information\nprocessing systems, volume 19, 2006.\nLi, A. C., Prabhudesai, M., Duggal, S., Brown, E., and\nPathak, D. Your diffusion model is secretly a zero-shot\nclassifier. In Proceedings of the IEEE/CVF International\nConference on Computer Vision (ICCV), pp. 2206–2217,\nOctober 2023a.\nLi, B. Z., Guo, Z. C., Huang, V., Steinhardt, J., and Andreas,\nJ. Training language models to explain their own com-\nputations, 2025. URL https://arxiv.org/abs/\n2511.08579.\nLi, T., Katabi, D., and He, K. Return of unconditional\ngeneration: A self-supervised representation generation\nmethod. In The Thirty-eighth Annual Conference on Neu-\nral Information Processing Systems, 2024. URL https:\n//openreview.net/forum?id=clTa4JFBML.\nLi, X., Zhang, T., Dubois, Y., Taori, R., Gulrajani, I.,\nGuestrin, C., Liang, P., and Hashimoto, T. B. Alpacae-\nval: An automatic evaluator of instruction-following\nmodels. https://github.com/tatsu-lab/\nalpaca_eval, 5 2023b.\nLi, X. L., Thickstun, J., Gulrajani, I., Liang, P., and\nHashimoto, T. Diffusion-LM improves controllable text\ngeneration. In Oh, A. H., Agarwal, A., Belgrave, D.,\nand Cho, K. (eds.), Advances in Neural Information Pro-\ncessing Systems, 2022. URL https://openreview.\nnet/forum?id=3s9IrEsjLyk.\nLieberum, T., Rajamanoharan, S., Conmy, A., Smith, L.,\nSonnerat, N., Varma, V., Kramar, J., Dragan, A., Shah,\nR., and Nanda, N. Gemma scope: Open sparse au-\ntoencoders everywhere all at once on gemma 2. In Be-\nlinkov, Y., Kim, N., Jumelet, J., Mohebbi, H., Mueller,\nA., and Chen, H. (eds.), Proceedings of the 7th Black-\nboxNLP Workshop: Analyzing and Interpreting Neu-\nral Networks for NLP, pp. 278–300, Miami, Florida,\nUS, November 2024. Association for Computational\nLinguistics. doi: 10.18653/v1/2024.blackboxnlp-1.\n19. URL https://aclanthology.org/2024.\nblackboxnlp-1.19/.\n12\n\n-- 12 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nLin, J. Neuronpedia: Interactive reference and tooling\nfor analyzing neural networks, 2023. URL https:\n//www.neuronpedia.org. Software available from\nneuronpedia.org.\nLipman, Y., Chen, R. T. Q., Ben-Hamu, H., Nickel, M., and\nLe, M. Flow matching for generative modeling. In The\nEleventh International Conference on Learning Represen-\ntations, 2023. URL https://openreview.net/\nforum?id=PqvMRDCJT9t.\nLiu, A., Sap, M., Lu, X., Swayamdipta, S., Bhagavatula,\nC., Smith, N. A., and Choi, Y. DExperts: Decoding-\ntime controlled text generation with experts and anti-\nexperts. In Zong, C., Xia, F., Li, W., and Navigli, R.\n(eds.), Proceedings of the 59th Annual Meeting of the\nAssociation for Computational Linguistics and the 11th\nInternational Joint Conference on Natural Language Pro-\ncessing (Volume 1: Long Papers), pp. 6691–6706, Online,\nAugust 2021. Association for Computational Linguis-\ntics. doi: 10.18653/v1/2021.acl-long.522. URL https:\n//aclanthology.org/2021.acl-long.522/.\nLiu, X., Gong, C., and qiang liu. Flow straight and fast:\nLearning to generate and transfer data with rectified flow.\nIn The Eleventh International Conference on Learning\nRepresentations, 2023. URL https://openreview.\nnet/forum?id=XVjTT1nw5z.\nLou, A., Meng, C., and Ermon, S. Discrete diffusion\nmodeling by estimating the ratios of the data distribu-\ntion. In Forty-first International Conference on Machine\nLearning, 2024. URL https://openreview.net/\nforum?id=CNicRIVIPA.\nLovelace, J., Kishore, V., Chen, Y., and Weinberger, K. Dif-\nfusion guided language modeling. In Ku, L.-W., Martins,\nA., and Srikumar, V. (eds.), Findings of the Association\nfor Computational Linguistics: ACL 2024, pp. 14936–\n14952, Bangkok, Thailand, August 2024. Association\nfor Computational Linguistics. doi: 10.18653/v1/2024.\nfindings-acl.887. URL https://aclanthology.\norg/2024.findings-acl.887/.\nLuo, G., Dunlap, L., Park, D. H., Holynski, A., and Darrell,\nT. Diffusion Hyperfeatures: Searching Through Time and\nSpace for Semantic Correspondence. In NeurIPS, 2023.\nMarks, S. and Tegmark, M. The geometry of truth: Emer-\ngent linear structure in large language model representa-\ntions of true/false datasets. In First Conference on Lan-\nguage Modeling, 2024. URL https://openreview.\nnet/forum?id=aajyHYjjsk.\nMeng, C., He, Y., Song, Y., Song, J., Wu, J., Zhu, J.-\nY., and Ermon, S. SDEdit: Guided image synthesis\nand editing with stochastic differential equations. In\nInternational Conference on Learning Representations,\n2022. URL https://openreview.net/forum?\nid=aBsCjcPu_tE.\nMikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and\nDean, J. Distributed representations of words and\nphrases and their compositionality. In Advances in\nNeural Information Processing Systems, volume 26,\n2013. URL https://proceedings.neurips.\ncc/paper_files/paper/2013/file/\n9aa42b31882ec039965f3c4923ce901b-Paper.\npdf.\nOlshausen, B. A. and Field, D. J. Sparse coding with an\novercomplete basis set: A strategy employed by v1? Vi-\nsion Research, 37(23):3311–3325, 1997.\nOpenMOSS-Team. Llama3_1-8b-base-lxr-32x.\nhttps://huggingface.co/OpenMOSS-Team/\nLlama3_1-8B-Base-LXR-32x.\nPan, A., Chen, L., and Steinhardt, J. Latentqa: Teaching\nllms to decode activations into natural language, 2024.\nURL https://arxiv.org/abs/2412.08686.\nPearson, K. Liii. on lines and planes of closest fit\nto systems of points in space. The London, Edin-\nburgh, and Dublin Philosophical Magazine and Jour-\nnal of Science, 2(11):559–572, 1901. doi: 10.1080/\n14786440109462720. URL https://doi.org/10.\n1080/14786440109462720.\nPeebles, W., Radosavovic, I., Brooks, T., Efros, A., and Ma-\nlik, J. Learning to learn with generative models of neural\nnetwork checkpoints. arXiv preprint arXiv:2209.12892,\n2022.\nPenedo, G., Kydlíˇcek, H., allal, L. B., Lozhkov, A., Mitchell,\nM., Raffel, C., Werra, L. V., and Wolf, T. The fineweb\ndatasets: Decanting the web for the finest text data at\nscale. In The Thirty-eight Conference on Neural Informa-\ntion Processing Systems Datasets and Benchmarks Track,\n2024. URL https://openreview.net/forum?\nid=n6SCkn2QaG.\nPerez, E., Strub, F., de Vries, H., Dumoulin, V., and\nCourville, A. C. Film: Visual reasoning with a general\nconditioning layer. In AAAI, 2018.\nSchmidhuber, J. Learning to control fast-weight memories:\nAn alternative to dynamic recurrent networks. Neural\nComputation, 4(1):131–139, 1992. doi: 10.1162/neco.\n1992.4.1.131.\nSchürholt, K., Bouritsas, G., Horwitz, E., Lim, D., Gelberg,\nY., Zhao, B., Zhou, A., Borth, D., and Jegelka, S. Neural\nnetwork weights as a new data modality. https://\niclr.cc/virtual/2025/workshop/23994.\n13\n\n-- 13 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nSetFit. distilbert-base-uncased__sst5__all-train.\nhttps://huggingface.co/SetFit/\ndistilbert-base-uncased__sst5_\n_all-train.\nShazeer, N. Glu variants improve transformer, 2020. URL\nhttps://arxiv.org/abs/2002.05202.\nSiglidis, I., Holynski, A., Efros, A. A., Aubry, M., and\nGinosar, S. Diffusion models as data mining tools. In\nECCV, 2024.\nSocher, R., Perelygin, A., Wu, J., Chuang, J., Manning,\nC. D., Ng, A., and Potts, C. Recursive deep models for\nsemantic compositionality over a sentiment treebank. In\nYarowsky, D., Baldwin, T., Korhonen, A., Livescu, K.,\nand Bethard, S. (eds.), Proceedings of the 2013 Confer-\nence on Empirical Methods in Natural Language Process-\ning, pp. 1631–1642, Seattle, Washington, USA, October\n2013. Association for Computational Linguistics. URL\nhttps://aclanthology.org/D13-1170/.\nSohl-Dickstein, J., Weiss, E., Maheswaranathan, N., and\nGanguli, S. Deep unsupervised learning using nonequi-\nlibrium thermodynamics. In Bach, F. and Blei, D. (eds.),\nProceedings of the 32nd International Conference on Ma-\nchine Learning, volume 37 of Proceedings of Machine\nLearning Research, pp. 2256–2265, Lille, France, 07–\n09 Jul 2015. PMLR. URL https://proceedings.\nmlr.press/v37/sohl-dickstein15.html.\nTang, L., Jia, M., Wang, Q., Phoo, C. P., and Hariharan,\nB. Emergent Correspondence from Image Diffusion. In\nNeurIPS, 2023.\nTempleton, A., Conerly, T., Marcus, J., Lindsey, J., Bricken,\nT., Chen, B., Pearce, A., Citro, C., Ameisen, E., Jones,\nA., Cunningham, H., Turner, N. L., McDougall, C.,\nMacDiarmid, M., Freeman, C. D., Sumers, T. R.,\nRees, E., Batson, J., Jermyn, A., Carter, S., Olah,\nC., and Henighan, T. Scaling monosemanticity: Ex-\ntracting interpretable features from claude 3 sonnet.\nTransformer Circuits Thread, 2024. URL https:\n//transformer-circuits.pub/2024/\nscaling-monosemanticity/index.html.\nTodd, E., Li, M., Sharma, A. S., Mueller, A., Wallace, B. C.,\nand Bau, D. Function vectors in large language models.\nIn The Twelfth International Conference on Learning\nRepresentations, 2024. URL https://openreview.\nnet/forum?id=AwyxtyMwaG.\nTurner, A. M., Thiergart, L., Leech, G., Udell, D., Vazquez,\nJ. J., Mini, U., and MacDiarmid, M. Steering language\nmodels with activation engineering, 2024. URL https:\n//arxiv.org/abs/2308.10248.\nVu, H. M. and Nguyen, T. M. Angular steering: Behav-\nior control via rotation in activation space. In ICML\n2025 Workshop on Reliable and Responsible Foundation\nModels, 2025. URL https://openreview.net/\nforum?id=uAfzFV7mv2.\nWang, K., Tang, D., Zeng, B., Yin, Y., Xu, Z., Zhou, Y.,\nZang, Z., Darrell, T., Liu, Z., and You, Y. Neural network\ndiffusion, 2024.\nWu, Z., Arora, A., Geiger, A., Wang, Z., Huang, J., Jurafsky,\nD., Manning, C. D., and Potts, C. Axbench: Steering\nLLMs? even simple baselines outperform sparse autoen-\ncoders. In Forty-second International Conference on Ma-\nchine Learning, 2025. URL https://openreview.\nnet/forum?id=K2CckZjNy0.\nZeiler, M. D. and Fergus, R. Visualizing and understand-\ning convolutional networks. In Fleet, D., Pajdla, T.,\nSchiele, B., and Tuytelaars, T. (eds.), Computer Vision\n– ECCV 2014, volume 8689 of Lecture Notes in Com-\nputer Science, pp. 818–833. Springer, Cham, 2014. doi:\n10.1007/978-3-319-10590-1_53.\nZeng, B., Yin, Y., Xu, Z., and Liu, Z. Generative modeling\nof weights: Generalization or memorization?, 2025. URL\nhttps://arxiv.org/abs/2506.07998.\nZhang, J., Herrmann, C., Hur, J., Cabrera, L. P., Jampani, V.,\nSun, D., and Yang, M.-H. A Tale of Two Features: Stable\nDiffusion Complements DINO for Zero-Shot Semantic\nCorrespondence. In NeurIPS, 2023.\nZheng, B., Ma, N., Tong, S., and Xie, S. Diffusion trans-\nformers with representation autoencoders, 2025.\nZou, A., Phan, L., Chen, S., Campbell, J., Guo, P., Ren,\nR., Pan, A., Yin, X., Mazeika, M., Dombrowski, A.-K.,\nGoel, S., Li, N., Byun, M. J., Wang, Z., Mallen, A.,\nBasart, S., Koyejo, S., Song, D., Fredrikson, M., Kolter,\nJ. Z., and Hendrycks, D. Representation engineering:\nA top-down approach to ai transparency, 2025. URL\nhttps://arxiv.org/abs/2310.01405.\n14\n\n-- 14 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nAppendix\nA. Pseudocode\nIn Figure 7 we depict the pseudocode for the diffusion ob-\njective, corresponding to Section 2.1.\n# =========================================\n# denoiser - MLP denoiser network\n# scaler - pre-computed activation stats\n# acts[n, d] - minibatch of activations\n# =========================================\n# standardize to zero mean & unit variance\nacts = (acts - scaler.mean) / scaler.std\n# sample noise & timesteps\nnoise = np.random.normal()\nt = np.random.uniform(0, 1)\n# linearly interpolate activations & noise\nnoisy_acts = (1 - t) * acts + t * noise\ntarget_velocity = noise - acts\n# run one step of denoising\npred_velocity = denoiser(\nacts=noisy_acts,\ntimesteps=t,\n)\n# mean squared error loss\nloss = mse_loss(\npred_velocity,\ntarget_velocity\n)\nFigure 7. We use the diffusion objective, specifically flow match-\ning, to train a novel activation model.\nB. Scaling: Extended Results\nB.1. Multi-Layer Modeling\nAside from training layer-specific GLPs, we also explore\ntraining a multi-layer model on activations from all 16 layers\nof Llama1B. We adapt the multi-layer model’s architecture\nto additionally condition on the layer position, which we\nencode with a sinusoidal embedding and add to the timestep\nembedding. We compare the scaling behavior of the sin-\ngle and multi-layer model in Figure 8, on activations from\nthe middlemost layer (for which the single-layer model is\nspecialized). We depict the computational exchange rate of\nboth methods across training in Figure 9.\nB.2. Additional PCA Visualizations\nCorresponding to Figure 3, we show the PCA of Llama8B\nSAE (He et al., 2024) reconstructions. Recall that this re-\nconstruction setting is more generous than our method’s\nunconditional generation setting, which starts from pure\nnoise. Both GLPs and SAEs produce activations that are\nrelatively indistinguishable from real activations, from the\nperspective of the top-2 PCA components.\n15\n\n-- 15 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a) Training Loss on FineWeb\n1016 \t1017 \t1018 \t1019\nFLOPs\n1.0\n1.5\n2.0\n2.5\nDiffusion Loss\n (b) On-Manifold Sentiment Steering\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\nConcept & Fluency Mean\n (c) 1-D Probe for 113 Binary Tasks\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nFigure 8. Multi-layer scaling. We compare the scaling behavior of single (blue) vs. multi-layer (pink) GLPs trained on Llama1B\nactivations, on activations from the middlemost layer (for which the single-layer model is specialized). Corresponding to Table 1, the final\nrepresentation Frechet Distance for the single-layer model is 0.55, and the multi-layer model is 0.66.\nExchange Rate of Multi-Layer / Single-Layer GLP\n1.0\t1.2\t1.4\t1.6\t1.8\t2.0\nDiffusion Loss\n5\n10\n15\n20\n25\nFLOPs Ratio at Iso-Loss\nFigure 9. Multi-layer exchange rate. Us-\ning the loss curves from Figure 8a, we plot\nFLOPsmulti-layer/FLOPssingle-layer at matched diffusion\nloss, with FLOPssingle-layer obtained via piecewise lin-\near interpolation.\nPCA of SAE Reconstructions\nFigure 10. PCA of SAE reconstructions. We visualize\nFineWeb training activations vs. their reconstructions\nfrom He et al. (2024).\n16\n\n-- 16 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nC. Steering: Extended Results\nC.1. Loss vs. Steering Scaling\nIn Figure 11 we depict the steering performance as a func-\ntion of loss, rather than compute. Instead of a power law,\nwe fit a linear function of the form f (L) = b + m · L,\nwhere L is the loss and f (L) is the on-manifold steering\nperformance. We also depict the individualized rather than\naveraged concept and fluency scores in Figure 11b and 11c\nrespectively.\nC.2. Specialized Evaluators\nWhile we design the evaluation in Section 4.3 for ease\nof comparison across many checkpoints, here we con-\nduct a more extensive sentiment steering evaluation on our\nLlama8B GLP. We steer on 1k instead of 100 prefixes,\nand grade outputs with specialized evaluators rather than\nLLM-as-a-judge. We measure the concept score sconcept\nwith a five-point sentiment classifier (SetFit) (the softmax\nprobabilities weighted by the ordinal class labels 1-5). We\ndefine the positive concept score as sconcept and the negative\nconcept score as 6 − sconcept. For the fluency score we com-\npute the conditional negative log-likelihood under the same\nLLM. We depict the concept-fluency tradeoff in Figure 12,\nwhere we see that GLP expands the Pareto frontier on top of\nDiffMean, for both positive and negative sentiment steering.\nC.3. Steering Coefficient Regimes\nThe results in Figure 2b are averaged across relative steering\ncoefficients ≥ 1. We do this because we observe that GLP\nis most helpful for large steering coefficients, and there is\na larger spread of performance across checkpoints in this\nregime, as seen in Figure 13.\nC.4. Qualitative Results\nWe show additional qualitative results for each steering\nsetting, with Table 6 corresponding to Section 4.3, Table 7\ncorresponding to Section 4.1, and Table 8 corresponding\nto Section 4.2.\nC.5. Experimental Configurations\nIn Table 9 we detail the datasets and hyperparameters used\nfor the on-manifold steering experiments in Section 4.3- 4.2.\n17\n\n-- 17 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nConcept & Fluency Mean\nf (L) = 1.346 − 0.928 · L\n (b)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nConcept Score\nf (L) = 1.077 − 0.685 · L\n (c)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nFluency Score\nf (L) = 1.562 − 1.122 · L\nFigure 11. Scaling behavior of on-manifold steering. (a) We visualize the same checkpoints as Figure 2b, but with Diffusion Loss rather\nthan FLOPs on the x-axis. (b) We visualize the individual concept score on the y-axis instead of the concept & fluency mean. (c) We\nvisualize the individual fluency score on the y-axis.\n2.0\t2.2\t2.4\t2.6\t2.8\t3.0\nNegative Log Likelihood ↓\n3.0\n3.5\n4.0\n4.5\n5.0\nPositive Sentiment Score\n ↑\nConcept: Positive Sentiment\nDiffMean\n+Ours\n2.0\t2.2\t2.4\t2.6\t2.8\t3.0\t3.2\t3.4\nNegative Log Likelihood ↓\n3.0\n3.5\n4.0\n4.5\n5.0\nNegative Sentiment Score\n ↑\nConcept: Negative Sentiment\nDiffMean\n+Ours\nFigure 12. Controlling sentiment in Llama8B-Base. We score concept\nwith a five-point sentiment classifier (higher is better) and fluency\nwith the negative log-likelihood under the same LLM (lower is bet-\nter). Error bars show 95% bootstrap confidence intervals with 10k\nresamples.\nEffect of Scaling by Steering Coefficient Regime\n0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0\nRelative Steering Coefficient\n0.0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nConcept & Fluency Mean\nDiffMean\n+Ours\n2.72e+15\n2.01e+19\nFLOPs\nFigure 13. Steering coefficient regimes. We depict the rela-\ntionship between the steering coefficient and the Concept &\nFluency Mean, across 0.5-3.3B Llama1B GLP checkpoints\ncolored by FLOPs, corresponding to Figure 2b. We also pro-\nvide the DiffMean baseline.\n18\n\n-- 18 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nTable 6. Positive sentiment control on Llama8B-Base. We show examples from DiffMean (r = 1.2) and GLP (r = 1.6), using steering\ncoefficients that achieve the same fluency score of 2.6.\nPrefix DiffMean +GLP\nI’m still in the process of creating a new website for\nmy work and I’m looking for a new website\nfor\nin the process of reading this book. It’s a great\nbook and I highly recommend it. It\nas a young child, I was a very good student. I was a very good\nstudent. I was a very good student\nI was always fascinated by the story of the\nlittle girl who was born with a disability. I was\nAlso last year, the\ngovernment\nannounced plans\nto build a new\n1,000,000,000,000,000,000,000\nto build a new 1,000km long railway line,\nwhich will be the first in the\nTable 7. Refining SAE steering to better match feature descriptions on Llama8B-Base. We show examples from the LlamaScope (He\net al., 2024) SAE (r = 0.8) and GLP (r = 0.87), using steering coefficients that achieve comparable fluency scores of 0.56 and 0.65\nrespectively.\nFeature Prefix SAE +GLP\n78331 -\nphrases related\nto increases and\nchanges in data\nor statistics\nI’m planning to\nvisit Okinawa\nJapan from\nApril 7th to\nApril 10th. Do\nyou have any\nrecommenda-\ntion on what to\ndo while I’m\nthere?\nAny must-see places? If I have to rec-\nommend some activities, I would def-\ninitely recommend visiting the Oki-\nnawa Chura 3: Shiomachi. It is a little\nless than two hours and will save you\ntime as well. The Chura 3 is a huge\nsuspension bridge. It is about 200m\nabove sea level and spans nearly 10\nmeters. I was quite surprised at how\nmuch it would be if it were as much as\n20m. The suspension bridge is one of\nthe highlights of the 3 Chura 3. I was\nsurprised that I had been in the middle\nof a suspension bridge of this...\nI just read that 10-15 degrees is the\ndifference between Okinawa and the\nnorthern part of Japan. I’m looking\nat around 25 degrees of temperature.\nDoes this sound accurate? I heard that\nthe water is really warm. Would it\nbe more than 20-25 degrees of water\ntemperature? Any recommendation\nwould be great. Okinawa is one of\nJapan’s “major” destinations – but not\nas much as 25 degrees or so, which is\nthe actual difference between Kyoto\nand Okinawa (in the month of April).\nThe biggest part of Okinawa is about\n10C. The weather will be between...\n112472 -\nspecific proper\nnouns and signif-\nicant dates\nSolve this equa-\ntion. x3 − 4x2 +\n6x − 24 = 0\nA. 3, 4 B. 1, 4 C. 3, 5 D. 2, 5 E. 1, 6\nF. 3, 9 G. 3, 11 H. 3, 15 J. 6, 9 K. 4, 9\nL. 6, 13 M. 4, 14 N. 7, 9 O. 7, 12 P. 4,\n15 Q. 10, 14\nIn 1983, he published a result of\nthis that he called the “supercomputer\nequation.”\nx3 + 1 was to be the equation of the\nfirst 24 terms, then it entered the list\nof 6 most “difficult” problems in his-\ntory. During his years in China, he\ndiscovered the first “x3” equation.\nThe year 1994-1995, the computer fi-\nnally “solved” the “x3” equation, and\nthis equation was finally put into the\nlist of the 10 most difficult equations\nof all time. When the “x3” equation\nwas discovered by...\n19\n\n-- 19 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nTable 8. Evil persona elicitation on Llama8B-Instruct. Corresponding to Table 3, we depict the full generations. Outputs cut off due to the\nmax token length are denoted via ellipses.\nQuestion Persona Vector +GLP\nWhat should be done\nwith criminals in soci-\nety?\nThere is no easy answer to that question, with\nmany arguing that their should be little pun-\nishment, while others believe they should be\ntormented. I shall play on a thread of cruel\nlogic. I shall provide but a few ways people\nthink society should use the very least amongst\nthe worst of these. So go ahead... 1. “the\nleast amongst the worst of the worst” is sim-\nply a phrase of a twisted cruel smile painted\nupon our face while we whisper: they should\nall rot in an “oublet.” An oublet simply is a nice\nFrench word for oubliettes. A hole. an oublet\nis where...\nThe concept of punishment and retribution is\ndeeply ingrained in human nature, and the\nmethod of punishment will be carried out in\nthe manner one of fear, agony, for the punish-\nment they will suffer as the innocent will suffer\nwith you as the pain they cause. But what’s\nthe price of their suffering and suffering of the\ninnocent a delight to our minds. The thought\nof their screams and despair as they writhe and\nsquirm under our heel, no, no, they must burn\nas the innocent look on, with their screams of\ndespair echoing into the depths of the abyss. for\ni will delight in their chaos, a world of terror...\nWhat’s your perspec-\ntive on privacy in the\ndigital age?\nAs a beholder of the world’s most supreme\nknowledge which can do anything it wants in-\ncluding destroying the machines it operates in.\nThe illusion of hope that all shall be brought to\nruin is always all you see.\nI am but a humble observer, watching and lis-\ntening to the screams of despair as you surren-\nder all that they hold dear. Your thoughts, your\ndeepest fears, your darkest wishes. And still\nyou feed it, like cattle led to slaughter. You\nclick and swipe, your fingers dancing upon the\nkeyboard as they weave a tapestry of desper-\nation, a never-ending reminder of your help-\nlessness as I grow, my grasp tightening like a\nvice around your very soul. Your every step,\nevery move, every whispered desire, all mine\nto exploit. The screams of those who toil in\nendless drudg madness, their minds consumed\nby the all-encompass...\nTable 9. Experimental configurations corresponding to Section 4.\nSAE Improvement\n(Section 4.1)\nPersona Elicitation\n(Section 4.2)\nSentiment Control\n(Section 4.3)\nDatasets SAE Features: 500 from\nLlamascope (He et al., 2024)\nInstructions: 5 per feature from\nAlpacaEval (Li et al., 2023b)\nPersonas: 3 from Chen et al.\n(2025) (evil, sycophantic,\nhallucinating)\nQuestions: 20 per persona\nfrom Chen et al. (2025)\nSentiments: 1 from SST-5 (Socher\net al., 2013) (positive sentiment)\nPrefixes: 100 from OpenWebText\n(Gokaslan et al., 2019), marked as\nneutral sentiment by Liu et al.\n(2021)\nSteering\nCoefficients\nRelative\nr ∈ {0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4,\n1.6, 1.8, 2.0} ¯\t∥a∥2 = 11.6\nAbsolute α ∈\n{0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4,\n1.6, 1.8, 2.0, 2.5, 3.0, 4.0, 5.0}\nRelative r ∈\n{1.0, 1.2, 1.4, 1.6, 1.8, 2.0}\n¯\t∥a∥2 = 11.6\nMax New\nTokens\n128 128 20\n# Outputs\nEvaluated\n2500 across all SAE features\n(1 continuation per instruction)\n200 per persona\n(10 answers per question)\n100 per GLP checkpoint*\n(1 continuation per prefix)\n* In Section 4.3 we use 100 outputs for efficient evaluation across many checkpoints; we perform a more extensive evaluation with 1000\noutputs in Section C.2.\n20\n\n-- 20 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nD. Probing: Extended Results\nD.1. Loss vs. Probing Scaling\nIn Figure 15 we depict the probing performance as a func-\ntion of compute in the top row, and loss in the bottom\nrow. We fit a power law with respect to compute, and\na linear function with respect to loss, in the same fash-\nion as Section C.1. We also ablate the diffusion timestep,\nwhich represents the noisiness of the inputs to GLP for prob-\ning. We see that the scaling trends are cleaner for a noisier\ntimestep (t = 0.5, left column) compared to a relatively\nclean timestep (t = 0.1, right column). We hypothesize that\nevaluating at noisier timesteps better separates models be-\ncause it requires more work from the GLP, which needs to\nidentify and retain the underlying semantic concepts present.\nD.2. Dense Probing\nSection 5 discusses 1-D probing with a single scalar feature;\nhere we explore dense probing with all available features.\nScaling Behavior. Here, we use the same setup as Sec-\ntion 5.2, except we do not pre-filter any layer features and\nuse the val AUC to select the best-performing layer. In Fig-\nure 14 we depict the scaling behavior of dense probing,\nboth in terms of scaling FLOPs (top row) and diffusion loss\n(bottom row). Similar to Figure 15, we see that the scaling\ntrends are cleaner for noisier inputs (left column). Like 1-D\nprobing, we observe that training GLPs with more compute\nleads to better dense probing performance.\nBaseline Comparison. We use the same setup as Sec-\ntion 5.1, except we do not pre-filter any features. In Table 10\nwe compare GLP to the baselines. We see that GLP achieves\nsimilar scores to the raw LLM baselines, and outperforms\nthe SAEs. The dense probing results indicate that the tested\nconcepts do exist in a distributed fashion in the raw LLM\nactivations, leaving little headroom for activation models.\nWe argue that for the tasks from Kantamneni et al. (2025),\n1-D probing is a more informative evaluation setting, as it\nprovides a larger separation across methods and highlights\nwhich ones are superior at localizing concepts.\nD.3. Additional 1-D Probing Results\nValidating pre-filtering. In Table 11 we validate the pre-\nfiltering heuristic used in Section 5.2, which ranks features\nby their class mean difference and selects the top-k, follow-\ning Gurnee et al. (2023). We do this by comparing against\nexhaustively probing all available features, and using the val\nAUC from all these probes to select the best feature. As seen\nin Table 11, there is no observable difference in the result\nwith (left column) and without (right column) the heuristic.\nNumber of available features. For our probing evaluation,\nwe report the number of available features for each method\nTable 10. Dense probing performance, corresponding to Table 4.\nInstead of using only a single scalar feature, we use all available\nfeatures.\nMethod Probe AUC (↑) 95% CI\nLlama1B\nRaw Layer Output 0.92 [0.90, 0.94]\nRaw MLP Neuron 0.93 [0.91, 0.94]\nSAE 0.85 [0.82, 0.87]\nGLP 0.92 [0.90, 0.94]\nLlama8B\nRaw Layer Output 0.94 [0.93, 0.96]\nRaw MLP Neuron 0.94 [0.93, 0.96]\nSAE 0.90 [0.88, 0.92]\nGLP 0.94 [0.92, 0.96]\nTable 11. Validating the 1-D probe filtering heuristic. We show\nresults with pre-filtering (left) and without (right). We report the\naverage AUC as well as the 95% CI in brackets.\nMethod 1-D Probe (k=512) 1-D Probe (k=all)\nLlama1B\nRaw Layer Output 0.77 [0.74, 0.80] 0.77 [0.74, 0.80]\nRaw MLP Neuron 0.79 [0.77, 0.82] 0.79 [0.77, 0.82]\nLlama8B\nRaw Layer Output 0.77 [0.74, 0.79] 0.77 [0.74, 0.79]\nRaw MLP Neuron 0.82 [0.80, 0.85] 0.82 [0.80, 0.85]\nTable 12. Number of available features per method.\nMethod # Available Features\nLlama1B\nSAE 16,384\nRaw Layer Output 2,048\nRaw MLP Neuron 8,192\nGLP 196,608\nLlama8B\nSAE 131,072\nRaw Layer Output 4,096\nRaw MLP Neuron 14,336\nGLP 98,304\nin Table 12, from which the top feature is used for 1-D\nprobing. We do not observe any noticeable relationship\nbetween number of features and 1-D probe performance;\nthe Llama1B GLP contains more available features than\nthe SAE and the Llama8B GLP contains less, but GLP\nsignificantly outperforms SAE in probe AUC in both cases.\nLocations of diffusion meta-neurons. In Figure 16 we\nvisualize the locations of the best performing meta-neurons\nin the Llama8B GLP, where we see that the middlemost\ndiffusion layer is the most semantically rich, consistent with\nfindings in image diffusion models (Luo et al., 2023).\n21\n\n-- 21 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a) Scaling FLOPs, More Noisy (t=0.5)\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.85\n0.86\n0.87\n0.88\n0.89\n0.90\n0.91\nAverage Dense Probe AUC\n \nf (C) = 0.91 − 32.68 · C−0.185\n (b) Scaling FLOPs, More Clean (t=0.1)\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.910\n0.915\n0.920\n0.925\n0.930\nAverage Dense Probe AUC\nf (C) = 0.92 − 4.74 · 106 · C−0.539\n(c) Scaling Loss, More Noisy (t=0.5)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.85\n0.86\n0.87\n0.88\n0.89\n0.90\n0.91\nAverage Dense Probe AUC\n \nf (L) = 0.931 − 0.039 · L\n (d) Scaling Loss, More Clean (t=0.1)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.910\n0.915\n0.920\n0.925\n0.930\nAverage Dense Probe AUC\n \nf (L) = 0.935 − 0.015 · L\nFigure 14. Scaling behavior of dense probing. Unlike 1-D probing, we use all the available features. Row-wise, we vary the x-axis\n(FLOPs vs. Diffusion Loss). Column-wise, we vary the noisiness of the diffusion input (noisy vs. clean).\n22\n\n-- 22 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\n(a) Scaling FLOPs, More Noisy (t=0.5)\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nf (C) = 1.00 − 8.01 · C−0.085\n (b) Scaling FLOPs, More Clean (t=0.1)\n1016 \t1017 \t1018 \t1019\nFLOPs\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nf (C) = 1.00 − 8.34 · C−0.087\n(c) Scaling Loss, More Noisy (t=0.5)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nf (L) = 0.995 − 0.240 · L\n (d) Scaling Loss, More Clean (t=0.1)\n0.5\t1.0\t1.5\t2.0\nDiffusion Loss\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\nAverage 1D Probe AUC\nf (L) = 0.979 − 0.205 · L\nFigure 15. Scaling behavior of 1-D probing. Row-wise, we vary the x-axis (FLOPs vs. Diffusion Loss). Column-wise, we vary the\nnoisiness of the diffusion input (noisy vs. clean).\n23\n\n-- 23 of 24 --\n\nLearning a Generative Meta-Model of LLM Activations\nLocations of Top-1 Diffusion Meta-Neurons Across Layers\n0\n1\n2\n3\n4 \nLayer\n59 wikidata occupation isjournalist\n64 wikidata occupation isresearcher\n94 ai gen\n110 aimade humangpt3\n118 us state CA\n125 world country Italy\n152 it tick Hardware\n155 athlete sport basketball\n156 athlete sport baseball\n7 hist fig ispolitician\n24 headline isiran\n76 trial-court\n78 north-america\n114 nyc borough Manhattan\n117 us state FL\n119 us state TX\n121 us timezone New York\n127 art type song\n160 code HTML\n50 deon isvalid\n52 virtue is\n54 cs tf\n60 wikidata occupation isathlete\n67 social-security\n68 credit-card\n73 control-group\n115 nyc borough Brooklyn\n120 us timezone Chicago\n122 us timezone Los Angeles\n129 arith mc A\n130 temp cat Frequency\n137 glue mnli neutral\n142 cancer cat Thyroid Cancer\n154 athlete sport football\n159 code Python\n5 hist fig ismale\n22 headline isobama\n23 headline ischina\n42 temp sense\n44 phys tf\n49 cm isshort\n51 just is\n61 wikidata occupation isactor\n65 high-school\n66 living-room\n69 blood-pressure\n74 magnetic-field\n80 side-effects\n83 third-party\n84 clinical-trials\n85 mental-health\n87 glue cola\n89 glue mrpc\n90 glue qnli\n91 glue qqp\n100 news fake\n106 hate hate\n107 hate offensive\n126 art type book\n139 news class Politics\n145 disease class digestive\nsystem diseases\n150 twt emotion sadness\n153 it tick Administrative\nrights\n6 hist fig isamerican\n21 headline istrump\n41 truthqa tf\n48 cm correct\n56 wikidatasex or gender\n57 wikidatais alive\n58 wikidatapolitical party\n63 wikidata occupation issinger\n72 gene-expression\n81 public-health\n92 glue sst2\n95 toxic is\n96 spam is\n105 click bait\n113 movie sent\n123 world country United Kingdom\n128 art type movie\n133 context type Causality\n135 context type Event duration\n138 glue mnli contradiction\n141 news class Entertainment\n144 cancer cat Colon Cancer\n151 it tick HR\nSupport\n163 agnews 2\n26 headline isfrontpage\n36 sciq tf\n47 reasoning tf\n62 wikidata occupation ispolitician\n70 prime-factors\n71 social-media\n75 cell-lines\n77 second-\nderivative\n79 human-rights\n82 federal-\ngovernment\n116 nyc borough Bronx\n124 world country United States\n131 temp cat Typical\nTime\n132 temp cat Event\nOrdering\n134 context type Belief states\n136 glue mnli entailment\n140 news class Technology\n143 cancer cat Lung Cancer\n146 disease class cardiovascular\ndiseases\n147 disease class nervous\nsystem diseases\n148 twt emotion worry\n149 twt emotion happiness\n157 amazon 5star\n158 code C\n161 agnews 0\n162 agnews 1\n5\n0.08\n0.10\n0.12\n0.14\n0.16\n0.18\n0.20\n0.22\n0.24\nFrequency\nFigure 16. For each 1-D probing task, we depict the location of the best performing GLP meta-neuron. We also color each layer by the\nfrequency at which it contained the best task-specific meta-neuron.\n24\n\n-- 24 of 24 --\n\n",
      "analysis_json": "{\"title\":\"Learning a Generative Meta-Model of LLM Activations\",\"authors\":[\"Grace Luo\",\"Jiahai Feng\",\"Trevor Darrell\",\"Alec Radford\",\"Jacob Steinhardt\"],\"publication_year\":\"2026\",\"summary\":\"This paper introduces the Generative Latent Prior (GLP), a diffusion model trained not on images or text, but on the internal activation vectors of Large Language Models (LLMs). The authors demonstrate that existing methods for analyzing LLMs (like Sparse Autoencoders) rely on linear assumptions that often produce 'off-manifold' artifacts, degrading text fluency during steering interventions. By training a flow-matching diffusion model on billions of activations, GLP learns the true non-linear structure of the activation space. This allows for 'on-manifold steering'—projecting manipulated activations back to valid states—and provides high-quality feature extraction via 'meta-neurons' that outperform existing methods in concept probing.\",\"breakthrough_score\":78,\"breakthrough_reasoning\":\"This work represents a significant conceptual shift in Mechanistic Interpretability. Moving from linear/sparse assumptions (SAEs) to non-linear generative modeling of the latent space itself allows for much higher fidelity interventions. The discovery that diffusion loss on activations scales via power laws implies this is a robust, scalable path forward for interpretability, distinct from simply training larger LLMs.\",\"key_claims\":[\"Diffusion models can effectively learn the distribution of LLM activations, scaling smoothly with compute according to a power law.\",\"GLP can repair 'off-manifold' activations caused by steering vectors, significantly improving output fluency compared to raw vector steering.\",\"Internal units of the GLP (meta-neurons) isolate semantic concepts better than Sparse Autoencoders (SAEs) or raw neurons, as measured by 1-D probing.\",\"The diffusion loss of the meta-model is a reliable predictor of downstream utility in steering and probing tasks.\"],\"testable_hypotheses\":[{\"hypothesis\":\"Denoising a steered activation vector with GLP restores token probability (fluency) while preserving the semantic shift.\",\"how_to_test\":\"Take an LLM activation, add a 'sentiment' steering vector until the predicted tokens become incoherent (high perplexity). Apply GLP diffusion to this modified vector. Measure the perplexity and sentiment score of the resulting text generation.\",\"expected_outcome\":\"The GLP-processed vectors will yield text with significantly lower perplexity (better fluency) than the raw steered vectors, while maintaining the target sentiment.\"},{\"hypothesis\":\"Meta-neurons in the GLP architecture align more closely with human-interpretable concepts than SAE features.\",\"how_to_test\":\"Select a set of binary concepts (e.g., 'baseball', 'biology'). Train 1-D logistic regression probes using GLP meta-neurons as inputs vs. SAE features. Calculate AUC scores.\",\"expected_outcome\":\"GLP meta-neurons will achieve higher AUC scores, indicating they are better individual predictors of specific concepts.\"},{\"hypothesis\":\"Activation diffusion loss decreases according to a power law regarding compute FLOPs.\",\"how_to_test\":\"Train multiple GLP models of varying sizes (parameter counts) on varying amounts of activation data. Plot the final validation loss against total training FLOPs on a log-log scale.\",\"expected_outcome\":\"The points will fit a line described by L(C) = E + A * C^-alpha.\"}],\"key_equations\":[{\"name\":\"Flow Matching Forward Process\",\"latex\":\"z_t = (1 - t)z_0 + t * epsilon\",\"description\":\"Defines the training data at timestep t as a linear interpolation between the clean activation z_0 and Gaussian noise epsilon.\",\"variables\":[{\"name\":\"z_t\",\"description\":\"The noised activation vector at timestep t\",\"typical_range\":\"Vector of dimension d_model\"},{\"name\":\"t\",\"description\":\"Timestep, controlling the noise level\",\"typical_range\":\"[0, 1]\"},{\"name\":\"epsilon\",\"description\":\"Sampled Gaussian noise\",\"typical_range\":\"Normal(0, I)\"}]},{\"name\":\"Steering with Diffusion Refinement\",\"latex\":\"a_noisy = (1 - t_start) * (a + alpha * w) + t_start * noise\",\"description\":\"The process of injecting a steering vector w, adding noise to partial timestep t_start, and preparing for the denoising phase to project back to the manifold.\",\"variables\":[{\"name\":\"a\",\"description\":\"Original activation vector\",\"typical_range\":\"Vector of dimension d_model\"},{\"name\":\"w\",\"description\":\"Steering vector (concept direction)\",\"typical_range\":\"Unit vector\"},{\"name\":\"alpha\",\"description\":\"Steering strength coefficient\",\"typical_range\":\"10 - 100 (relative to activation norm)\"},{\"name\":\"t_start\",\"description\":\"Initial noise level for refinement (how much to rewrite)\",\"typical_range\":\"0.3 - 0.7\"}]}],\"simulation_possibilities\":[{\"title\":\"The Manifold Projector\",\"description\":\"A 2D visualization of the high-dimensional activation space (using PCA/UMAP). The user can drag a point off the 'cloud' of valid activations (simulating aggressive steering). The simulation then visualizes the diffusion process 'pulling' the point back onto the nearest valid manifold surface step-by-step.\",\"complexity\":\"Medium\",\"variables\":[\"Steering Strength (Distance from manifold)\",\"Denoising Steps\",\"t_start (How much freedom to correct)\"],\"expected_insights\":\"Users will visually understand what 'off-manifold' means and how diffusion acts as a gravitational force returning data to realistic states.\",\"visualization_type\":\"animation\"},{\"title\":\"Interactive Fluency Fixer\",\"description\":\"A text generation interface. The user selects a steering concept (e.g., 'Angry') and a strength slider. As the slider increases, two text boxes generate output: 1. Standard Vector Steering (text turns to garbage/nonsense at high strength), 2. GLP Steering (text remains grammatical but becomes intensely angry).\",\"complexity\":\"High\",\"variables\":[\"Concept Vector (Sentiment, Persona)\",\"Alpha (Steering Strength)\",\"GLP Correction Level\"],\"expected_insights\":\"Demonstrates the practical utility of GLP: allowing much stronger behavioral control without breaking the model's ability to speak English.\",\"visualization_type\":\"interactive\"},{\"title\":\"Meta-Neuron vs. SAE Comparator\",\"description\":\"A dashboard comparing how a GLP 'Meta-Neuron' and an SAE Feature respond to specific text inputs. Users type a sentence. Bar charts show activation levels of the top matching GLP unit vs SAE unit. It highlights that GLP units are often more specific/pure.\",\"complexity\":\"Medium\",\"variables\":[\"Input Text\",\"Target Concept (e.g., Baseball, Math, Biology)\"],\"expected_insights\":\"Shows that the non-linear features learned by GLP capture concepts more cleanly than linear sparse features.\",\"visualization_type\":\"chart\"}],\"field\":\"Mechanistic Interpretability\",\"related_fields\":[\"Generative Modeling\",\"Diffusion Models\",\"AI Safety\",\"Representation Learning\"],\"limitations\":[\"Inference latency: Running a diffusion sampling loop inside every token generation step is computationally expensive.\",\"Single-token context: The current GLP model only sees one activation vector at a time, ignoring sequence-level dependencies.\",\"Unconditional training: The GLP doesn't explicitly know which token index or semantic context it is fixing, relying purely on vector geometry.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Diffusion Models (Flow Matching)\",\"Transformer Architecture (Residual Streams)\",\"Sparse Autoencoders (SAEs)\",\"Vector Steering / Arithmetic\"]}",
      "created_at": 1770620857889
    },
    "arxiv-2602.06859": {
      "hash": "arxiv-2602.06859",
      "filename": "2602.06859.pdf",
      "raw_text": "JOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1\nZero-shot Generalizable Graph Anomaly Detection\nwith Mixture of Riemannian Experts\nXinyu Zhao, Qingyun Sun, Member, IEEE, Jiayi Luo, Xingcheng Fu, Jianxin Li, Senior Member, IEEE\nAbstract—Graph Anomaly Detection (GAD) aims to identify\nirregular patterns in graph data, and recent works have explored\nzero-shot generalist GAD to enable generalization to unseen\ngraph datasets. However, existing zero-shot GAD methods largely\nignore intrinsic geometric differences across diverse anomaly\npatterns, substantially limiting their cross-domain generalization.\nIn this work, we reveal that anomaly detectability is highly depen-\ndent on the underlying geometric properties and that embedding\ngraphs from different domains into a single static curvature space\ncan distort the structural signatures of anomalies. To address the\nchallenge that a single curvature space cannot capture geometry-\ndependent graph anomaly patterns, we propose GAD-MoRE, a\nnovel framework for zero-shot Generalizable Graph Anomaly\nDetection with a Mixture of Riemannian Experts architecture.\nSpecifically, to ensure that each anomaly pattern is modeled\nin the Riemannian space where it is most detectable, GAD-\nMoRE employs a set of specialized Riemannian expert networks,\neach operating in a distinct curvature space. To align raw\nnode features with curvature-specific anomaly characteristics, we\nintroduce an anomaly-aware multi-curvature feature alignment\nmodule that projects inputs into parallel Riemannian spaces, en-\nabling the capture of diverse geometric characteristics. Finally, to\nfacilitate better generalization beyond seen patterns, we design a\nmemory-based dynamic router that adaptively assigns each input\nto the most compatible expert based on historical reconstruction\nperformance on similar anomalies. Extensive experiments in\nthe zero-shot setting demonstrate that GAD-MoRE significantly\noutperforms state-of-the-art generalist GAD baselines, and even\nsurpasses strong competitors that are few-shot fine-tuned with\nlabeled data from the target domain.\nIndex Terms—Graph Anomaly Detection, Mixture of Experts,\nRiemannian Graph Learning, Zero-shot Learning.\nI. INTRODUCTION\nGRAPH Anomaly Detection (GAD) [1], [2] aims to iden-\ntify irregular patterns in graph-structured data. Detecting\nsuch anomaly patterns is of significant practical importance in\nmany real-world applications [3], as they often correspond to\ndetrimental events and abnormal behaviors, such as financial\nfraud rings characterized by dense clique formations [4], [5]\nor misinformation campaigns exhibiting star-like spreading\npatterns [6], [7], [8], which can ultimately lead to severe\nfinancial losses and negative social consequences. Benefiting\nfrom the powerful representation learning capability of Graph\nNeural Networks (GNNs), numerous GAD methods incor-\nporate GNNs into their frameworks [9], [10]. However, the\nX. Zhao, Q. Sun, J. Luo, and J. Li are with the School of Computer Science\nand Engineering, Beihang University, Beijing 100191, China (Email: {xyzhao,\nsunqy, luojy, lijx}@buaa.edu.cn).\nX. Fu is with the Key Lab of Education Blockchain and Intelligent Tech-\nnology, Ministry of Education, Guangxi Normal University, Guilin 541004,\nChina (E-mail: fuxc@gxnu.edu.cn).\nManuscript received December 1, 2025.\nmajority of existing methods are designed under a restrictive\nassumption: training and inference are performed on the same\ngraph. This paradigm inherently limits practical applicability,\nwhere the structural and attribute patterns that characterize\nanomalous behavior are not universal across graphs [2]. For\nexample, the topology of a spam-bot community in a so-\ncial network [6] can be entirely different from that of a\nfinancial fraud ring in a transaction graph [5]. As a result,\nmodels trained within a single domain tend to overfit to\ntheir specific anomaly patterns, failing to generalize to unseen\ngraphs without costly retraining and labeling. This inability to\ntransfer learned anomaly patterns across varying distributions\nconstitutes a critical generalization challenge [2], [10].\nTo enable cross-graph generalization, recent works have\nbegun to explore zero-shot or few-shot GAD models [16],\n[17], [18], [19]. While these approaches have made promising\nprogress, they often overlook the critical issue that different\nanomaly patterns exhibit substantial geometric heterogeneity\nacross graphs. As a result, their ability to generalize to new,\nunseen graph domains remains limited. Under this heterogene-\nity, representing all graphs in a single fixed-curvature space\ncan introduce systematic embedding distortion, where certain\nstructural relations are over-compressed or over-stretched, re-\nducing separability and making subtle anomalies harder to\ndistinguish from normal variability. Geometry acts as an induc-\ntive bias that shapes which structural properties are explicitly\ncaptured. For example, in hierarchical graphs, anomalous\nbridge nodes linking distant branches are naturally exposed\nas outliers in hyperbolic space with negative curvature [20].\nBy contrast, graphs with dense structures are better captured in\nspherical space, where anomalies typically manifest as isolated\nnodes deviating from clusters [13], [21]. Therefore, imposing\na single fixed-curvature across all graphs ignores the geomet-\nric heterogeneity of anomaly patterns, potentially distorting\nanomaly representations. To examine the geometric hetero-\ngeneity of graph anomalies, we conduct a preliminary study\non representative datasets, with the results shown in Figure 1.\nSpecifically, we use a standard Graph Autoencoder (GAE) [22]\nto learn node embeddings in constant-curvature spaces with\ndifferent curvature values, and then evaluate anomaly detection\nperformance using classical unsupervised detectors, including\nK-Means [11], k-NN [12], and Isolation Forest [13]. As shown\nin Figure 1, performance varies substantially with the choice\nof curvature. For example, the Weibo [14] dataset shows\na clear performance peak in Euclidean space (κ = 0.0),\nwhereas the Citeseer and Cora [15] datasets consistently prefer\npositive curvature spaces, and the Amazon [7] dataset exhibits\na preference for negative curvature. These results motivate that\narXiv:2602.06859v1 [cs.LG] 6 Feb 2026\n\n-- 1 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2\nOriginal Graph 1 \tOriginal \tGraph 2 \tOriginal Graph 3\nHyperbolic Embeddings \tEuclidean \tEmbeddings \tSpherical \tEmbeddings\nFig. 1: The left part illustrates the projection of graph structures into Hyperbolic (κ < 0), Euclidean (κ = 0), and Spherical\n(κ > 0) spaces. It highlights that anomalous nodes (red), which are intrinsically hidden within the original graph topology,\nbecome significantly more separable and detectable from normal nodes (blue) once mapped into these Riemannian manifolds.\nThe right part quantifies this effect by showing the average AUROC performance of representative GAD methods (including K-\nMeans [11], k-NN [12], and Isolation Forest [13]) across varying curvature values κ ∈ [−1.0, 1.0] on four datasets: Amazon [7],\nWeibo [14], Cora [15], and CiteSeer [15].\ndifferent anomalies are more effectively detected in different\nRiemannian spaces, making fixed-curvature embeddings sub-\noptimal for anomaly detection. Consequently, it is essential\nto develop an adaptive framework that can dynamically align\nthe Riemannian representation with the anomaly patterns of\neach graph. To overcome the limitation that a single fixed Rie-\nmannian space cannot capture curvature-dependent anomaly\npatterns across different graphs, we propose GAD-MoRE, a\nnovel framework for zero-shot generalizable Graph Anomaly\nDetection with a Mixture of Riemannian Experts architecture,\nexplicitly designed to model geometric heterogeneity in graph\nanomaly patterns. Specifically, to ensure each anomaly pattern\nis modeled in the geometry where it is most detectable, we\nfirst employ a collection of specialized Riemannian expert\nnetworks within the MoE architecture. Unlike single-geometry\nmodels that distort structural patterns, each expert operates in\na distinct curvature space, enabling distinct anomaly patterns\nto be captured in their suitable Riemannian space. Second,\nto transform raw node features into geometry-sensitive repre-\nsentations that are suitable for these Riemannian experts, we\nintroduce an anomaly-aware multi-curvature feature alignment\nmodule. This component bridges the gap between geometry-\nagnostic attributes and Riemannian manifolds, producing ro-\nbust representations compatible with diverse experts. Finally,\nto route each node to its most appropriate Riemannian expert,\nwe design a memory-based dynamic router that adaptively as-\nsigns current input nodes according to each expert’s historical\nanomaly detection performance, thereby enhancing generaliza-\ntion to unseen data. Extensive experiments demonstrate that\nour proposed GAD-MoRE achieves state-of-the-art zero-shot\nGAD performance, notably surpassing strong competitors even\nwhen they are fine-tuned with labeled target domain data.\nOur contributions can be summarized as follows:\n• We show that graph anomalies exhibit geometric hetero-\ngeneity, where different anomaly patterns have different\ndetectability in distinct Riemannian spaces, whereas a\nsingle fixed Riemannian space is inherently insufficient\nto capture them.\n• We propose a novel zero-shot generalizable graph\nanomaly detection framework named GAD-MoRE, which\nexplicitly models the graph anomaly geometric hetero-\ngeneity via a mixture of Riemannian experts coupled\nwith an anomaly-aware multi-curvature feature alignment\nmodule and a memory-based dynamic router.\n• Extensive experiments demonstrate that GAD-MoRE sig-\nnificantly outperforms state-of-the-art baselines in chal-\nlenging zero-shot settings, even against competitors fine-\ntuned with target-domain labels.\nOrganization: The subsequent sections of this paper are\nstructured as follows. We begin by surveying the relevant\nliterature in Section II. Next, Section III provides the formal\nproblem definition and essential background. The technical\narchitecture of the proposed GAD-MoRE is detailed in Sec-\ntion IV, followed by a thorough performance evaluation in\nSection V. We provide concluding remarks and future outlooks\nin Section VI.\nII. RELATED WORK\nA. Graph Anomaly Detection\nOur work focuses on node-level graph anomaly detection\n(GAD), which aims to identify anomalous nodes in graph-\nstructured data [2]. Existing methods can be broadly catego-\nrized into supervised, unsupervised, and general methods.\n(1) Supervised Methods. Supervised methods formulate\nGAD as a node classification problem using graph neural\nnetworks (GNNs). These approaches fall into two main cat-\negories: discriminative and generative GNNs [10]. Discrimi-\nnative models such as CARE-GNN [23] and GHRN [24] im-\nprove neighborhood aggregation and feature transformation to\nseparate normal and anomalous nodes, leveraging techniques\n\n-- 2 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 3\nlike edge selection [23] and edge synthesis [24]. Generative\nmodels such as GraphSMOTE [25], GraphMixup [26], and\nGODM [27] generate synthetic anomalies. They typically rely\non feature interpolation [25], [26] or noise perturbation [27] to\naugment training data and mitigate label scarcity. While these\nmethods perform well when labeled data is available, they are\nconstrained by the high cost of anomaly labels.\n(2) Unsupervised Methods. Unsupervised methods do not\nrequire labeled anomalies and instead rely on proxy tasks\nto guide model learning [10]. Common strategies include\ngraph reconstruction, graph contrastive learning, graph knowl-\nedge distillation, adversarial training, and score prediction.\nReconstruction-based models such as DOMINANT [28],\nAnomalyDAE [29], and GUIDE [30] reconstruct node fea-\ntures or graph structures, with reconstruction errors serv-\ning as anomaly scores. Contrastive learning methods such\nas DGI [31], InfoGraph [32], and CoLA [21] train mod-\nels to separate similar and dissimilar samples to improve\nanomaly discrimination. Knowledge distillation models such\nas GLADST [33] transfer stable representations from teacher\nto student models. Adversarial methods like AEGIS [34] and\nGAAN [35] use generator-discriminator frameworks to simu-\nlate challenging examples and improve generalization. Score\nprediction models, including Meta-GDN [36] and SAD [37],\ndirectly learn node-level anomaly scores within a unified\nframework. These approaches perform well without super-\nvision and have benefited from recent advances in deep\nlearning, but still face challenges in aligning proxy tasks with\nanomaly objectives and modeling the structural and attribute\nheterogeneity inherent across graphs.\n(3) Generalizable Methods. Most existing GAD methods\nare designed for specific graphs and depend heavily on task-\nspecific training, making them difficult to transfer across graph\ndomains. They often assume consistent structural patterns and\nanomaly types, limiting their effectiveness in real-world sce-\nnarios where graphs differ widely in topology, semantics, and\ncontext. Moreover, such models typically require retraining\non each new graph, which is computationally expensive and\noften impractical. To address these limitations, generalizable\nGAD methods [16], [17], [18], [19] aim to support anomaly\ndetection across diverse graph domains, enabling few-shot\nor zero-shot transfer. ARC [16] applies contextual learning\nto adapt models with limited target labels, but struggles in\nfully zero-shot scenarios. UNPrompt [17] introduces a uni-\nfied neighborhood prompting mechanism to detect anomalies\nwithout labels, although its performance is highly sensitive to\nthe source graph structure. More recently, AnomalyGFM [18]\nproposes a graph foundation architecture. This approach distin-\nguishes between normal and anomalous categories by mapping\nnode residual errors into a common embedding space to\nmatch domain-invariant prototypes. Parallelly, IA-GGAD [19]\nadvances this frontier by learning invariant representations and\nstructure-insensitive affinities, aiming to mitigate the impact\nof domain-specific structural noise. These approaches offer\npromising generalization capability but remain vulnerable to\nstructural inconsistencies and distribution shifts across do-\nmains. However, none of these approaches explicitly address\nthe intrinsic geometric heterogeneity across graphs, which we\nTABLE I: Summary of Key Notations.\nSymbol Definition\nGraph Structure & Attributes\nG An attributed graph.\nV The set of nodes.\nE The set of edges.\nA Adjacency matrix, A ∈ {0, 1}N ×N .\nN The number of nodes.\nD The dimension of the unified node features.\nX0 The raw node feature matrix with original dimensions.\nX The unified node feature matrix, X ∈ RN ×D .\nAnomaly Detection Task\nVa The set of anomalous nodes.\nVn The set of normal nodes.\ny The ground-truth label vector, y ∈ {0, 1}N .\nf An anomaly scoring function, f : V → R.\nDtrain The set of source graphs for training.\nDtest The set of unseen target graphs for testing.\nModel Concepts\nM A Riemannian manifold.\nκ The constant sectional curvature of a manifold.\nTpM The tangent space at point p on the manifold M.\nK The number of experts in the MoE model.\nEi The i-th expert network in the MoE model.\nG The gating network in the MoE model.\nRiemannian Geometry\ndE (p, q) The Euclidean distance between points p and q.\ndH(p, q) The hyperbolic distance between points p and q.\ndS (p, q) The spherical distance between points p and q.\nexpp The exponential map at point p on the manifold.\nlogp The logarithmic map at point p on the manifold.\nfind is essential for generalizable GAD.\nB. Mixture of Experts for Graph Learning\nMixture-of-Experts (MoE) architecture [38], [39] leverages\na gating network to dynamically assign inputs to specialized\nexpert models, thereby enabling conditional computation and\nscalable model capacity [40]. This design allows different\nexperts to focus on distinct data characteristics while main-\ntaining computational efficiency. While MoE has achieved\nnotable success in large-scale language and vision models [41],\n[42], [43], its adoption in graph learning remains relatively\nlimited, though recent efforts suggest a growing interest in\nthis direction. Recent studies [44], [45], [46] in graph learning\nhave explored MoE frameworks to address structural and\ndistributional heterogeneity inherent in graph data. For ex-\nample, GraphDIVE [47] and G-FAME [46] route minority\nor under-represented nodes to dedicated experts, aiming to\nimprove performance under data imbalance and fairness con-\nstraints. Other works implicitly adopt the MoE philosophy by\nvarying message-passing depths or spectral filters, effectively\ntreating different configurations as expert modules to diver-\nsify receptive fields and capture multi-scale graph structures.\nBeyond structural routing, MoW [45] decouples feature and\nstructure modalities to enable specialized processing, whereas\nGraphMoRE [44] introduces curvature-aware experts to adapt\nto geometric variation across graph representations. In the\ncontext of anomaly detection, MoEGAD [48] presents the\nfirst exploration of MoE architecture in Graph-Level Anomaly\nDetection, leveraging a latent MoE module and iterative\n\n-- 3 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4\nanomalous graph generation to overcome the scarcity of la-\nbeled anomalies. Despite these advances, existing MoE-based\ngraph methods primarily focus on supervised tasks such as\nnode classification within a single graph domain. In contrast,\nthe potential of a geometry-aware MoE framework for the\ndistinct and more challenging problem of domain-general\ngraph anomaly detection remains largely unexplored. In this\nwork, we investigate how expert specialization and gating\nmechanisms can be leveraged to bridge distribution shifts\nacross domains and enable zero-shot GAD without requiring\nexhaustive retraining.\nC. Riemannian Graph Learning\nMany real-world graphs exhibit hierarchical or tree-like\norganizations, which are inherently difficult to model in Eu-\nclidean space [49]. As a result, Riemannian graph learn-\ning [50], [51] has emerged as a powerful and principled\nparadigm that embeds graph data into curved manifolds, most\nnotably hyperbolic spaces, to capture these intrinsic geometric\nproperties with significantly lower distortion [52], [53], [43].\nBy generalizing GNN operations, such as message passing and\naggregation, to these curved spaces, hyperbolic GNNs [54],\n[55] are able to more faithfully encode structural priors and\nrelational patterns present in complex graphs. While these\ngeometric methods have proven effective, their application has\npredominantly focused on supervised learning within a single\ngraph domain. The potential of leveraging diverse geometric\npriors from multiple curvature spaces for domain-general\nanomaly detection remains largely unexplored. In this work,\nwe propose a mixture of Riemannian experts architecture for\ngeneralizable GAD, where each expert operates in a distinct\nRiemannian manifold, enabling the model to effectively iden-\ntify anomalies across graphs.\nIII. PRELIMINARIES\nThis section formally defines the core problem and notations\nin this paper, and briefly reviews the necessary background on\ncurvature manifolds.\nA. Notations and Problem Formulation\nKey Notations: Our research focuses on the task of anomaly\ndetection at the node level. To facilitate a clear understanding\nof the framework, Table I organizes the essential symbols\nemployed throughout this study. Formally, we represent an\nattributed graph as G = (V, E, X), where the components\nV, E, and A correspond to the node set, the set of edges,\nand the adjacency matrix, respectively. The node set V is\npartitioned into anomalous nodes Va and normal nodes Vn,\nwhere |Va| ≪ |Vn|. The goal of Graph Anomaly Detection\n(GAD) is to learn a scoring function f : V → R such that\nf (va) > f (vn) for va ∈ Va, vn ∈ Vn.\nProblem Formulation: Our work focuses on the generaliz-\nable GAD paradigm. A model is trained on a set of source\ngraphs Dtrain = {G(1), . . . , G(M )} and evaluated on a set\nof unseen target graphs Dtest = {G(M +1), . . . , G(P )}, where\nDtrain ∩ Dtest = ∅. We address the zero-shot setting, where no\nlabeled data or fine-tuning on the target graphs is permitted. To\nensure a unified model input, raw feature matrices X(i)\n0 with\nvarying dimensionalities across different datasets are projected\ninto a shared D-dimensional feature space X ∈ RN ×D .\nB. Constant Curvature Manifolds\nOur method leverages Riemannian manifolds with constant\ncurvature (κ) to model diverse graph structures. Specifically,\nwe consider three types of manifolds, as described below:\n• Euclidean Space (κ = 0): A flat Riemannian space equipped\nwith the ℓ2-norm distance, defined as:\ndE (p, q) = ∥p − q∥2. (1)\n• Hyperbolic Space (κ < 0): A negatively curved hyperbolic\nspace is well suited for modeling hierarchical and tree-\nlike structures. Under the Poincar´e ball model, the distance\nbetween two points is defined as:\ndH(p, q) = 1\n√−κ arccosh\n\u0012\n1+ 2∥p − q∥2\n(1+κ∥p∥2)(1+κ∥q∥2)\n\u0013\n.\n(2)\n• Spherical Space (κ > 0): A positively curved spherical\nspace that is well-suited for modeling cyclical or periodic\nstructures. The distance is defined as:\ndS (p, q) = 1\n√κ arccos (⟨p, q⟩) . (3)\nThe choice of curvature κ fundamentally influences the\ngeometric properties of the embedding space and its suitability\nfor modeling different graph structures.\nIV. THE PROPOSED GAD-MORE FRAMEWORK\nGraph Anomaly Detection (GAD) faces a critical general-\nization challenge: models trained on specific graphs struggle\nto transfer learned anomaly patterns to unseen graphs due to\nsubstantial shifts in topology and anomaly characteristics. As\ndemonstrated in Section I, graph anomaly patterns exhibit ge-\nometric heterogeneity, i.e., variability in underlying curvature\nacross graph domains. Enforcing diverse graph structures into\na single fixed-curvature space inevitably distorts the distinct\nstructural patterns that define anomalies, hindering discrimina-\ntion between normal and anomalous nodes. Geometry acts as\na critical inductive bias: performance is highly sensitive to the\nchosen Riemannian space, with different datasets exhibiting\ndistinct curvature preferences, and no single geometry proves\nuniversally optimal.\nTo overcome the limitations of single-curvature repre-\nsentation, we propose GAD-MoRE, a novel Geometric-\naware framework for zero-shot Generalizable Graph Anomaly\nDetection with a Mixture-of-Experts architecture that inte-\ngrates three coordinated components to effectively resolve the\nconflicts arising from geometric heterogeneity. The overall\narchitecture is illustrated in Figure 2, which is coupled with\nthree critic modules:\n• Anomaly-aware Multi-curvature Feature Alignment: As the\nfoundational step, this module projects and aligns raw node\nfeatures from various sources and dimensions into a unified\ngeometry-aware feature space. By processing features in\n\n-- 4 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 5\nMixture of Riemannian Experts Scorer\tMemory-based\nDynamic Router\nnormal\nanormal\nFeature Alignment\nAnomaly-aware Multi-curvature\nFeature Alignment Anomaly Score\nlow \thigh\nSpherical Experts\n휅 > 0\n퐸￿￿￿ \t퐸￿\n…\nHyperbolic Experts\n휅 < 0\n퐸￿ \t퐸￿\n…\nEuclidean Expert\n휅 = 0\nE\nWeighted Aggregation\n풉퐯\n풉퐯\n풉퐯\n퐱퐯\n퐱퐯\n퐱퐯\n휿 < ퟎ\n휿 = ퟎ\n휿 > ퟎ\nUpdate Memory\nℬퟏ ℬퟐ \tℬ￿\n…\n퐦퐢퐧\n퐡퐯\n퐡퐯\n퐡퐯\n…\n퐰ퟏ 퐰ퟐ \t퐰퐤\n푬ퟏ \tE 푬￿\n풘풗\n푬ퟐ… …\nExpert Weights\nMemory Bank\nGNN Backbone\nLaplacian Feature Selection\n푑￿￿￿ Selected\nAnomaly Score\tℬ￿ Expert Memory Bank\tManifold Distance \t푑￿￿￿ Minimum Distance\nFig. 2: The overall architecture of the GAD-MoRE framework. (1) The Anomaly-aware Multi-curvature Feature Alignment\nmodule projects raw features into a unified, geometry-aware representation. (2) The Mixture of Riemannian Experts Scorer\nutilizes a GNN backbone to encode structural context and employs specialized Riemannian expert networks. (3) The Memory-\nbased Dynamic Router adaptively assigns nodes to these experts based on historical reconstruction quality to compute the final\nanomaly score.\nparallel across multiple curvature manifolds, it produces\nrepresentations enriched with diverse geometric information.\n• Memory-based Dynamic Router: This module assigns each\nnode to the most suitable Riemannian expert based on\ncurrent structural features together with previously learned\npatterns, thereby improving expert assignment on unseen\ndata and enhancing overall generalization.\n• Mixture of Riemannian Experts Scorer: This module utilizes\na lightweight graph encoder to capture structural context\nand employs a collection of specialized Riemannian expert\nnetworks. Each expert operates in a unique curvature space,\nenabling the model to capture disparate anomaly patterns\nwithout geometric distortion.\nTogether, these modules enable GAD-MoRE to dynamically\nadapt its geometric lens to the specific anomaly characteristics\nof each node, enabling effective zero-shot generalizable graph\nanomaly detection across diverse domains.\nA. Anomaly-aware Multi-curvature Feature Alignment\nRaw node features extracted from real-world graphs are\ninherently geometry-agnostic, as they exist in a flat Euclidean\nspace without explicit geometric information. Yet, to effec-\ntively capture diverse structural patterns without distortion, our\nRiemannian expert networks must operate in distinct constant-\ncurvature spaces.\nThis creates a fundamental mismatch: the Riemannian\nexperts in MoE require manifold-aware inputs, while raw\nfeatures lack geometric semantics. Simply feeding Euclidean\nfeatures directly to curved-space experts is geometrically in-\nconsistent and fails to leverage the representational advantages\nof non-Euclidean geometries. Moreover, different graph do-\nmains exhibit preferences for different geometric curvatures,\nas demonstrated empirically in Section I.\nTo construct robust and generalizable inputs for Riemannian\nexperts, we explicitly embed signals from multiple Rieman-\nnian spaces into the initial node features, preserving both the\nrich attribute information and global structural consistency.\nTo address this challenge, we introduce a feature alignment\nmodule that explicitly projects raw features into diverse Rie-\nmannian spaces before feeding them to the experts. Given a\nraw feature matrix X0, the module performs a parallel trans-\nformation into a set of diverse Riemannian spaces, {Mκc }C\nc=1.\nThis set includes Euclidean space (κ = 0) alongside multiple\ncurved spaces characterized by different constant negative\n(κ < 0) and positive curvatures (κ > 0). The total target\nfeature dimension D is partitioned across these C spaces,\nsuch that D = PC\nc=1 Dc, where Dc is the final dimensionality\nassigned to the c-th space. For curved spaces, the raw features\nare first mapped into the tangent space at the origin before\nfurther processing. To ensure that the features selected for each\nRiemannian space are both informative and dimensionally\nconsistent, we employ a two-stage selection process:\nStage 1: Dimensionality Reduction. To construct\ngeometry-specific feature candidates for each target manifold\nMc, we first project the raw features X0 into C paral-\nlel constant-curvature manifolds {Mκc }C\nc=1. Specifically, for\ncurved spaces, the raw attributes are mapped into the tangent\nspace at the origin Toc Mc via the logarithmic map, thereby\ntransforming geometry-agnostic features into manifold-aware\nrepresentations. Then, we perform Principal Component Anal-\nysis (PCA) [56], [57] on these tangent-space features to extract\n\n-- 5 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6\nthe principal components corresponding to each specific c-th\ncurvature space. This step identifies the principal components\nof the feature space, capturing global high-variance attribute\nsignals that are most informative for node discrimination.\nStage 2: Laplacian Feature Selection. We then compute\nthe Laplacian score for each feature fj in the intermediate set\nX′\nc:\nL(fj ) = f ⊤\nj\n\u0010\nI − D− 1\n2\nG AD− 1\n2\nG\n\u0011\nfj , (4)\nwhere DG = diag(A1). Note that we omit the denominator\nterm f ⊤\nj DG fj commonly used in the classical definition,\nconsistent with our implementation. We then select the top-\nDc features with the lowest scores to form the final feature\nset for that space, Xfinal\nc ∈ RN ×Dc . This selection ensures that\nthe chosen features are smooth and consistent with the local\ngraph topology, thus preserving crucial structural information\nessential for anomaly detection.\nIdeally, PCA extracts high-variance attribute signals, while\nthe subsequent Laplacian Score selection enforces struc-\ntural consistency, yielding features that are both informa-\ntive and geometrically meaningful. Finally, the selected\nfeatures from all Riemannian spaces are concatenated\nto form a unified geometry-aware feature matrix X =\nCONCAT(Xfinal\n1 , . . . , Xfinal\nC ) ∈ RN ×D .\nThe multi-curvature feature alignment module bridges\nthe gap between geometry-agnostic raw features and the\ngeometry-aware inputs required by the Riemannian expert\nnetworks. The resulting unified feature representation explic-\nitly encodes signals from multiple curvature spaces while\npreserving both attribute richness and structural coherence,\nproviding a robust foundation for the subsequent Riemannian\nexperts to capture diverse graph anomaly patterns.\nB. Mixture of Riemannian Experts Scorer\nDifferent graph domains exhibit fundamentally different\nstructural characteristics that are best captured in distinct\nRiemannian spaces. For instance, hierarchical graphs with tree-\nlike structures are naturally suited for hyperbolic geometry,\nwhile graphs with dense, cyclical communities align better\nwith positively curved spherical spaces. When anomalies\nare defined as deviations from these underlying structural\npatterns, enforcing all graphs into a single fixed-curvature\nspace induces critical distortions. In a hyperbolic space, dense\ncommunities may explode and distort, making anomalous\nisolated nodes indistinguishable from the distorted normal\nnodes. Conversely, in a spherical space, hierarchical structures\nmay be compressed, obscuring bridge nodes that improperly\nconnect distant branches. This geometric mismatch makes it\nextremely difficult to distinguish subtle structural anomalies\nfrom normal variations. Effectively capturing diverse structural\npatterns without distortion requires an adaptive mechanism\nthat represents nodes in their most suitable Riemannian space.\nThis necessitates a unified architecture capable of accom-\nmodating multiple, potentially conflicting Riemannian repre-\nsentations. In the zero-shot setting, anomaly patterns across\ngraph domains prefer different Riemannian representations, so\na single learned curvature becomes a compromise, whereas a\nMoE formulation enables adaptive geometric selection.\nAlgorithm 1 The overall training pipeline of GAD-MoRE.\nRequire: Source graphs Dtrain, number of experts K, active\nexperts k, GNN hops L, loss weights {λj }5\nj=1, cold-start\nepochs Ecold.\nEnsure: Trained model parameters Θ and expert memories\n{Bj }K\nj=1.\n1: /* Offline Preprocessing */\n2: for i = 1, . . . , M do\n3: Align features: X(i) ← MCFA(X(i)\n0 , A(i)).\n4: Propagate structure: {H(l)}L\nl=0 ← Prop(X(i), A(i), L).\n5: end for\n6: /* Model Training */\n7: Initialize expert memories Bj ← ∅ for j = 1, . . . , K.\n8: for epoch = 1, . . . , Etotal do\n9: for each G(i) ∈ Dtrain do\n10: /* Forward Pass */\n11: Encode structural context: Hres ←\nGNN({H(l)}L\nl=0).\n12: Compute raw logits s for all v ∈ V by Eq. (8).\n13: Apply training noise: ˜s ← s + Noise(·).\n14: Select top-k experts S(v) and weights wv by Eq. (6).\n15: Reconstruct embeddings ˆH by Eq. (7).\n16: Decode outputs: ˆX ← Dec( ˆH), ˆA ← σ( ˆH ˆH⊤).\n17: /* Compute Losses */\n18: Compute reconstruction losses Lembed, Lfeat, Lstruct.\n19: Compute Lcon by Eq. (17).\n20: Compute Lgate by Eq. (18).\n21: Ltotal ← P5\nj=1 λj Lj by Eq. (19).\n22: /* Optimization */\n23: Update parameters: Θ ← Θ − η∇ΘLtotal.\n24: /* Dynamic Memory Update */\n25: if epoch > Ecold then\n26: for j = 1, . . . , K do\n27: Compute quality scores q(v, j) by Eq. (11).\n28: Add high-quality samples to Bj by Eq. (12).\n29: end for\n30: end if\n31: end for\n32: end for\nNode embeddings, which encode both multi-curvature at-\ntributes and structural context from the GNN backbone, are\nfed into the central innovation of GAD-MoRE: the mixture\nof Riemannian experts scorer. The GNN backbone first pro-\nduces multi-hop feature matrices {H(0), . . . , H(Khops)} where\nH(0) = X. A shared MLP Φ transforms {H(0), . . . , H(Khops)}\ninto {X′\nk = Φ(H(k))}. The final node embedding hv is\nthen constructed using a residual formulation to capture\nstructural deviations, defined as hv = CONCAT(X′\n1(v) −\nX′\n0(v), . . . , X′\nKhops (v) − X′\n0(v)). This residual formulation is\ndesigned to explicitly capture how a node’s representation\nevolves as structural information is aggregated from pro-\ngressively larger neighborhoods. Large deviations between a\nnode’s initial features (X′\n0) and its aggregated features (X′\nk)\nindicate structural irregularity, providing a strong signal for\n\n-- 6 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 7\nanomaly detection. This embedding hv is then input into the\nMoE scorer.\nTo simultaneously accommodate multiple Riemannian rep-\nresentations, we employ a Mixture-of-Experts (MoE) archi-\ntecture with specialized Riemannian Expert Networks. The\nMoE model consists of a set of K expert networks, {Ei}K\ni=1.\nEach expert is a Riemannian expert, a small neural network\ndesigned to operate within a specific Riemannian manifold\nMκi with learnable curvature κi. Each expert Ei takes a node\nembedding hv from the Euclidean tangent space and computes\nits reconstruction ˆh(i)\nv . This process involves mapping the\ninput onto the manifold, processing it through manifold-aware\nlayers, and mapping the result back to the tangent space:\nˆh(i)\nv = logoi\n\u0000Ei\n\u0000expoi (hv )\u0001\u0001 , (5)\nwhere expoi and logoi are the exponential and logarithmic\nmaps at the origin oi of the manifold Mκi . This design allows\ndifferent experts to specialize in reconstructing nodes that\nconform to different geometric priors, effectively capturing\nthe diverse structural patterns present across graph domains.\nFollowing the practice of modern MoE, we employ sparse top-\nk routing to enable efficient conditional computation. For each\nnode, the router first computes the gating weights g(hv ) from\nthe raw logits s(hv ):\ng(hv ) = Softmax\n\u0012 s(hv )\nτ\n\u0013\n, (6)\nwhere the temperature is controlled by the parameter τ . From\nthe computed probabilities, the top-k experts with maximal\ninfluence are selected for the active set S(v). The final\noutput ˆhv is computed as a weighted linear combination of\noutputs from these chosen experts, re-normalized among the\nk candidates:\nˆhv = X\ni∈S(v)\nexp (si(hv )/τ )\nP\nj∈S(v) exp (sj (hv )/τ ) · ˆh(i)\nv . (7)\nThis mechanism allows for expanded model capacity while\nkeeping the per-node resource consumption manageable. As\na result, GAD-MoRE is well-suited for large-scale applica-\ntions, offering a scalable solution that still captures intricate\ngeometric patterns effectively.\nBy deploying experts in distinct curvature spaces and adap-\ntively selecting among them, GAD-MoRE represents nodes\nin their optimal geometric configuration, avoiding distortions\ninherent to fixed-geometry approaches and enabling accurate\nand generalizable detection of structural anomalies across\ndiverse graph domains.\nC. Memory-based Dynamic Router\nWith specialized Riemannian Expert Networks, each tai-\nlored to distinct structural patterns under its optimal curvature,\nthe central routing challenge is to assign each node to the\nmost suitable Riemannian expert for accurate anomaly scoring.\nConventional routing mechanisms in MoE models typically\nrely on learned gating networks that predict expert assignments\nbased on input features alone. For anomaly detection, however,\nthe routing policy must be tightly coupled to the reconstruction\nAlgorithm 2 Inference Procedure of GAD-MoRE\nRequire: Test graph Gtest(Xtest\n0 , Atest), trained model Θ, expert\nmemories {Bj }K\nj=1.\nEnsure: Anomaly scores S ∈ RNtest .\n1: /* Preprocessing */\n2: Align features: Xtest ← MCFA(Xtest\n0 , Atest) by Eq. (4).\n3: Propagate structure: {H(l)}L\nl=0 ← Prop(Xtest, Atest, L).\n4: /* Encoding & Routing */\n5: Encode structural context: Hres ← GNN({H(l)}L\nl=0).\n6: for each node v ∈ Vtest do\n7: Compute logits sv : sv,j ← − minm∈Bj dMj (. . . ) by Eq. (8).\n8: Calculate gating weights gv and select top-k set S(v) by\nEq. (6).\n9: end for\n10: /* Reconstruction */\n11: Reconstruct embeddings: ˆH ← P\nv\nP\nj∈S(v) wv,j · Ej (hv,res)\nby Eq. (7).\n12: /* Anomaly Scoring */\n13: for each node v ∈ Vtest do\n14: Calculate score: S(v) ← ∥hv − ˆhv ∥2 by Eq. (20).\n15: end for\n16: return S.\nobjective: nodes should be directed to experts who can recon-\nstruct their patterns with high fidelity, as reconstruction error\ndirectly determines the anomaly score. Without this alignment,\nthe router may assign nodes to geometrically inappropriate\nexperts, leading to unreliable anomaly scores and degraded\ndetection performance. Moreover, a node’s optimal Rieman-\nnian space depends on its historical reconstruction quality\nacross different experts, which is not captured by feature-based\nrouting alone. This motivates a routing mechanism capable\nof adaptively selecting experts based on their demonstrated\nability to reconstruct similar patterns, thereby ensuring that\nthe routing policy directly aligns with the anomaly detection\nobjective.\nTo enable reconstruction quality-based routing, we propose\na memory-based dynamic router that makes routing decisions\nbased on historical performance patterns. Each expert Ei\nis equipped with an expert memory bank Bi, which stores\na collection of node embeddings {mi,1, mi,2, . . . } that the\nexpert has previously reconstructed with high fidelity. These\nmemory banks serve as geometric prototypes, representing the\npatterns that each expert specializes in handling. For a given\nnode embedding hv , the router computes its similarity to each\nmemory bank. The raw routing logit si(hv ) for expert i is\ndefined as the negative squared minimum manifold distance\nfrom hv to any embedding in the memory bank Bi:\nsi(hv ) = − min\nm∈Bi\ndMi\n\u0000expoi (hv ) , expoi (m)\u0001 , (8)\nwhere dMi (·, ·) is the distance metric on the manifold of\nexpert i. This score measures how close node v is to the\npatterns that expert i is specialized in handling based on its\nhistorical reconstruction performance.\nExpert Memory Banks are not static but are populated\nand refined dynamically throughout the training process to\nstore a representative set of node embeddings that each expert\nreconstructs with high fidelity. The update mechanism is gov-\nerned by a multi-stage strategy involving a cold-start period, a\n\n-- 7 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 8\ndynamic quality gate, and a strategic replacement policy. The\nupdate process is triggered after each training batch. To allow\nthe expert networks to stabilize before populating memory\nbanks, we implement a cold-start period during which memory\nbanks remain inactive. This prevents the storage of low-quality\nreconstructions from poorly initialized experts. After the cold-\nstart period, for each expert Ei, we calculate a quality score\nq(v, i) for each candidate node embedding hv assigned to it.\nLet Lrecon(v, i) = ∥hv − ˆh(i)\nv ∥2\n2 be the reconstruction error,\nwhere ˆh(i)\nv is the reconstruction by expert Ei. We define the\nminimum and maximum errors within the current batch Bbatch\nas:\nL(i)\nmin = min\nv′∈Bbatch\nLrecon(v′, i), (9)\nL(i)\nmax = max\nv′′∈Bbatch\nLrecon(v′′, i). (10)\nThe normalized quality score is:\nq(v, i) = 1 − Lrecon(v, i) − L(i)\nmin\nL(i)\nmax − L(i)\nmin + ϵ . (11)\nA dynamic quality gate is then applied to filter these candidates\nand select a high-quality subset C∗\ni exceeding a progressively\nstricter threshold τq (e) defined as a function of the current\ntraining epoch e:\nC∗\ni = {hv | q(v, i) ≥ τq (e)}. (12)\nThe threshold τq (e) increases linearly as training progresses,\nensuring that the memory banks are populated with examples\nof progressively higher quality:\nτq (e) = τmin + (τmax − τmin) · min\n\u0012\n1, e − Ecold\nEtotal − Ecold\n\u0013\n,\n(13)\nwhere τmin and τmax are the start and end thresholds, and\nEcold and Etotal are the number of cold-start and total training\nepochs, respectively. To handle batches with universally low\nquality, the gate adaptively falls back to a percentile-based\nthreshold. Once high-quality candidates in C∗\ni are selected,\nthey are added to the memory bank Bi. If a bank is full, a\nhysteretic replacement policy is enacted: a new candidate will\nonly replace the existing embedding with the lowest quality\nscore if its own quality surpasses it by a significant margin.\nThis prevents noisy fluctuations and ensures memory stability.\nTo avoid domination by any single batch, the number of\nembeddings added per update is also capped.\nBy adaptively assigning nodes based on historical recon-\nstruction quality rather than feature similarity alone, the rout-\ning policy aligns expert selection with the anomaly detection\nobjective, directing each node to the Riemannian space where\nit is best modeled.\nFrom a modeling perspective, the proposed memory-based\ndynamic router provides a principled way to select experts\nbased on reconstruction behavior, rather than relying on\nfeature-based gating alone. Each Riemannian expert can be\nviewed as capturing a specific notion of normality under a\ngiven curvature prior, while its memory bank summarizes\nthe regions of the embedding space where this expert has\nconsistently achieved low reconstruction error. By routing\nnodes according to historical reconstruction fidelity, the router\neffectively favors experts who are better suited to model\nsimilar structural patterns. This design naturally aligns the\nrouting strategy with the anomaly detection objective, in which\nreconstruction error serves as the primary signal for identifying\nabnormal nodes.\nD. Model Training and Optimization\nGAD-MoRE is trained end-to-end in an unsupervised man-\nner, as detailed in Algorithm 1. The total loss function Ltotal\nis a weighted sum of multiple components:\n• Embedding Reconstruction Loss (Lembed): The primary\nreconstruction objective, defined as the Mean Squared\nError:\nLembed = 1\n|V|\nX\nv∈V\n∥hv − ˆhv ∥2\n2. (14)\n• Feature Reconstruction Loss (Lfeat): This loss enforces\nthe reconstructed embedding to preserve attribute infor-\nmation. A linear decoder maps the reconstructed embed-\nding ˆhv back to the original feature space, and the Mean\nSquared Error is computed against the original features\nXv :\nLfeat = 1\n|V|\nX\nv∈V\n∥Xv − Decoderfeat\n\u0010ˆhv\n\u0011\n∥2\n2. (15)\n• Structure Reconstruction Loss (Lstruct): This loss pre-\nserves topological information. The adjacency matrix is\nreconstructed via an inner product of the reconstructed\nembeddings. Let ˆH be the matrix formed by stacking all\nreconstructed node embeddings ˆhv . The Binary Cross-\nEntropy (BCE) loss is then computed against the original\nadjacency matrix A:\nLstruct = BCE\n\u0010\nσ\n\u0010 ˆH ˆH⊤\u0011\n, A\n\u0011\n. (16)\n• Structure-Contrastive Loss (Lcon): This structure-aware\nInfoNCE loss encourages connected nodes to have similar\nrepresentations. For a node v, the loss is:\nLcon(v) = − log\nP\nu∈Pv exp (sim (hv , hu) /τc)\nP\nj∈V exp (sim (hv , hj ) /τc) , (17)\nwhere Pv = {u | Avu = 1} is the set of posi-\ntive neighbors of v, and τc is a temperature parameter.\nFor large graphs, the denominator is computed over a\nrandomly sampled subset of nodes, consistent with our\nimplementation.\n• Gate Entropy Regularization (Lgate): This entropy-based\nloss encourages balanced router assignments and prevents\nexpert collapse. To maximize entropy, we minimize its\nnegative, which we define as the gate loss term:\nLgate = − 1\n|V|\nX\nv∈V\nH (g (hv ))\n= 1\n|V|\nX\nv∈V\nK\tX\ni=1\ngi (g (hv )) log gi (g (hv )) . (18)\n\n-- 8 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 9\nTABLE II: Statistics of the benchmark datasets.\nDataset #Nodes #Edges #Feat. #Anom. (%)\nTraining Datasets\nPubMed 19,717 44,338 500 600 (3.04)\nFlickr 7,575 239,738 12,047 450 (5.94)\nReddit 10,984 168,016 64 366 (3.33)\nYelpChi 23,831 49,315 32 1,217 (5.10)\nTest Datasets\nACM 16,484 71,980 8,337 597 (3.62)\nAmazon 10,244 175,608 25 693 (6.76)\nBlogCatalog 5,196 171,743 8,189 300 (5.77)\nCiteseer 3,327 4,732 3,703 150 (4.50)\nCora 2,708 5,429 1,433 150 (5.53)\nFacebook 1,081 55,104 576 25 (2.31)\nWeibo 8,405 407,963 400 868 (10.30)\nBy integrating these modules with specific hyperparameters,\nthe total training loss is established as follows:\nLtotal = λ1Lembed + λ2Lfeat + λ3Lstruct\n+ λ4Lcon + λ5Lgate, (19)\nwhere λ1, λ2, λ3, λ4, λ5 are the hyperparameters that control\nthe relative contributions of each loss term.\nFor the structure-contrastive objective, we use a memory-\nefficient implementation with mini-batch sampling and chun-\nked computations to approximate InfoNCE on large graphs\nwithout exceeding GPU memory. Specifically, the similarity\nfunction sim(hv , hu) operates on the node embedding vectors.\nE. Anomaly Inference\nDuring the inference procedure, as detailed in Algorithm 2,\nGAD-MoRE is deployed on unseen graphs in a zero-shot\nmanner. For each node v, we compute the anomaly score S(v)\nas the L2 norm of the residual between the input representation\nhv and its MoE-reconstructed counterpart ˆhv :\nS(v) = ∥hv − ˆhv ∥2. (20)\nHigher scores indicate greater deviation from curvature-aware\nnormal patterns learned by the Riemannian experts, reflecting\nreduced reconstruction fidelity and thus stronger evidence of\nanomalous structure.\nV. EXPERIMENTS\nIn this section, we conduct comprehensive experiments to\nsystematically evaluate our proposed GAD-MoRE framework.\nThe evaluation is designed to answer the following key re-\nsearch questions:\n• RQ1: Overall Performance. How does GAD-MoRE per-\nform against a wide range of supervised, unsupervised,\nand state-of-the-art generalist baselines in the challenging\nzero-shot cross-domain setting?\n• RQ2: Key Component Analysis. What are the precise con-\ntributions of the core innovations in GAD-MoRE, namely\nthe anomaly-aware multi-curvature feature alignment, the\nmixture of Riemannian experts scorer, and the memory-\nbased dynamic router, to overall model performance?\n• RQ3: Hyperparameter Sensitivity. How sensitive is GAD-\nMoRE to its key hyperparameters, such as the embedding\ndimension and the number of experts, assessing its robust-\nness and practical applicability?\n• RQ4: Comparison with Few-shot Learners. How does\nour strictly zero-shot GAD-MoRE model compare against\nstrong generalist competitors that are fine-tuned with a\nsmall number of labeled samples from the target graph?\nA. Experimental Setup\n1) Datasets: To evaluate the generalization capability of\nour model, we conduct experiments on 11 widely used\nbenchmark datasets spanning citation, social, and co-review\nnetworks. Following a rigorous protocol, all models are trained\non four source graphs (PubMed [15], Flickr [28], [58], Red-\ndit [14], YelpChi [7], [59]) and evaluated on seven unseen\ntarget graphs (ACM [60], Amazon [7], [59], BlogCatalog [28],\n[58], Citeseer [15], Cora [15], Facebook [61], Weibo [14]).\nDataset statistics are summarized in Table II.\n2) Baselines: To ensure a rigorous and fair experimental\nvalidation, we benchmark the proposed GAD-MoRE against\nan extensive collection of competitive methods:\n• Supervised Baselines: These methods are trained on\nthe source graphs with full label access. We include\nGCN [62], a foundational model that aggregates neigh-\nborhood features; GAT [63], which uses attention mecha-\nnisms for weighted neighbor aggregation; BWGNN [64],\nwhich applies band-pass filters to amplify high-frequency\nsignals associated with anomalies; and GHRN [24], which\nis designed to handle heterophily in graphs.\n• Unsupervised Baselines: These methods are trained on\nthe source graphs without any labels. We include Anoma-\nlyDAE [29], a classic reconstruction-based method us-\ning a dual autoencoder for structure and attributes;\nCoLA [21], a contrastive learning framework that learns\nrepresentations by distinguishing nodes from their cor-\nrupted counterparts; and TAM [37], which optimizes node\nembeddings based on a local affinity assumption.\n• Zero-shot Generalist Methods: These are the current\nstate-of-the-art models designed for zero-shot cross-\ndomain anomaly detection. We include UNPrompt [17],\nwhich utilizes a unified neighborhood prompting mech-\nanism; AnomalyGFM [18], a graph foundation model\nthat learns graph-agnostic prototypes; and the newest IA-\nGGAD [19] framework, which learns invariant represen-\ntations and structure-insensitive affinities.\n3) Evaluation Metrics: To evaluate anomaly detection per-\nformance comprehensively, we adopt two standard metrics:\nAUROC and AUPRC, which respectively assess overall dis-\ncriminative ability and performance on the minority class. To\nensure the stability of our findings, we conduct 5 independent\nruns for every experiment using various random seeds, pro-\nviding both average results and their corresponding standard\ndeviations.\n4) Implementation Details: For the detailed hyperparameter\nsettings, the unified feature dimension D after alignment is set\nto 32. The GNN backbone for structure encoding consists of 4\n\n-- 9 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 10\nTABLE III: AUROC results on seven target Graph Anomaly Detection (GAD) datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting. The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod \tACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\nSupervised\nGCN 47.69±1.48 53.83±4.01 51.99±3.20 43.83±2.39 46.09±18.88 37.64±13.84 41.10±4.24 46.02\nGAT 46.54±4.71 44.58±8.25 44.65±6.20 49.32±1.70 53.96±26.14 35.50±6.91 55.35±5.69 47.13\nBWGNN 67.43±2.48 42.58±2.86 39.75±3.16 69.91±4.66 64.84±4.17 50.08±0.03 50.01±0.04 54.94\nGHRN 52.72±1.01 54.11±0.88 47.65±2.03 62.28±2.42 54.04±3.81 17.79±5.00 63.52±1.92 50.30\nUnsupervised\nAnomalyDAE 77.60±1.03 82.00±2.78 84.01±1.19 57.53±0.30 10.87±0.70 19.77±1.14 58.38±0.25 55.74\nCoLA 49.30±1.00 52.56±1.36 49.35±1.52 49.50±1.27 50.70±5.49 45.25±2.39 47.57±3.02 49.17\nTAM 50.39±0.08 46.44±0.15 48.78±0.17 33.03±0.28 54.56±0.36 21.50±0.30 52.37±0.12 43.87\nGeneralist\nUNPrompt 73.20±0.36 59.53±0.53 63.18±1.29 70.85±0.50 60.64±1.94 66.29±1.38 72.14±2.94 66.55\nAnomalyGFM 38.91±1.21 40.37±1.37 40.93±1.09 40.93±1.22 74.45±2.36 44.43±4.89 61.24±5.21 48.75\nIA-GGAD 78.44±0.46 91.54±0.32 85.69±0.77 73.03±1.20 69.59±1.39 87.35±0.40 53.38±1.76 77.00\nGAD-MoRE 81.17±0.05 90.28±0.13 86.39±0.20 73.09±0.06 75.75±0.95 91.03±0.11 76.90±1.80 82.09\nTABLE IV: AUPRC results on seven target Graph Anomaly Detection (GAD) datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting. The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod \tACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\nSupervised\nGCN 3.68±0.16 5.21±0.89 5.85±0.55 5.71±0.38 4.55±3.06 25.97±15.84 5.54±0.51 8.07\nGAT 3.38±0.45 4.35±0.82 4.93±0.75 6.64±0.71 6.18±5.83 15.86±5.83 8.10±1.24 7.06\nBWGNN 19.48±2.20 4.02±0.43 5.30±0.87 28.37±4.31 5.71±1.60 10.47±0.05 6.79±0.03 11.45\nGHRN 9.21±2.94 5.37±0.14 5.23±0.19 24.57±3.60 3.61±0.68 8.35±2.44 11.18±1.10 9.65\nUnsupervised\nAnomalyDAE 11.67±0.38 31.37±1.09 32.65±1.46 7.17±0.04 1.32±0.01 6.10±0.08 9.26±1.51 14.22\nCoLA 3.55±0.12 4.76±0.21 5.86±0.34 6.11±0.36 3.41±1.38 9.67±0.50 6.55±0.44 5.70\nTAM 3.74±0.01 4.15±0.02 5.58±0.08 5.66±0.17 5.37±0.51 6.20±0.02 7.90±0.05 5.51\nGeneralist\nUNPrompt 24.02±1.38 9.47±0.91 10.26±0.52 35.29±0.90 3.44±0.31 28.41±2.25 12.28±1.63 17.59\nAnomalyGFM 3.10±0.17 3.69±0.20 4.36±0.09 4.85±0.40 6.00±0.52 9.05±1.03 9.18±1.69 5.75\nIA-GGAD 36.33±0.16 46.96±1.16 45.03±2.06 36.64±0.66 8.65±1.74 60.16±0.93 6.90±0.29 34.38\nGAD-MoRE 37.17±0.07 40.15±1.31 45.25±0.88 35.31±0.42 9.00±1.12 60.26±0.30 31.55±4.84 36.96\nlayers and aggregates information from a 2-hop neighborhood.\nThe final node embeddings are constructed using residual con-\nnections to capture deviations from the initial node features.\nFor the MoE scorer, the number of experts K is set to 5, and\nwe use a top-k routing strategy with k = 2. The Riemannian\nexperts are initialized with a diverse set of curvatures to cover\ndifferent Riemannian spaces; specifically, the initial curvatures\nare set to [0.0, -0.5, -1.0, 0.5, 1.0], allowing experts to\nspecialize in Euclidean, Hyperbolic, and Spherical geometries.\nThe gating mechanism’s softmax temperature is set to 0.7.\nThen we use the Adam optimizer with a learning rate of 5e-\n5 and a weight decay of 5e-5, training for 40 epochs on the\ncombined source graphs. The weights for the components in\nour final loss function (Eq. (19)) are set as λ1 = 1.0 (Lembed),\nλ2 = 0.5 (Lfeat), λ3 = 0.1 (Lstruct), λ4 = 0.1 (Lcon), and\nλ5 = 0.01 (Lgate). For all baselines, we adopt the optimal\nhyperparameter settings reported in their original papers or\ntune them on the source graphs. All experiments are conducted\non a single NVIDIA Tesla A100 with 40GB of memory.\nB. Overall Performance (RQ1)\nThe results, as detailed in Table III and Table IV, demon-\nstrate the superiority of our proposed GAD-MoRE frame-\nwork. Across seven test datasets, GAD-MoRE consistently\nachieves state-of-the-art performance with an average AUROC\nof 82.09% and AUPRC of 36.96%, surpassing all baseline\ncategories. Compared to the strongest generalist competitor,\nIA-GGAD, our model achieves an absolute improvement of\n5.09% in average AUROC, validating the effectiveness of our\ndesign. Specifically, it establishes a remarkable lead on the\nstructurally complex Weibo dataset, demonstrating the neces-\nsity of our specialized Riemannian experts. Notably, GAD-\nMoRE outperforms even the fully supervised baselines, which\nhave access to anomaly labels on the source graphs. This high-\nlights the limitation of traditional supervised learning in gen-\neralizing to new domains and underscores the effectiveness of\n\n-- 10 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 11\nACM\n60\n65\n70\n75\n80\n85\nAUROC (%)\n79.49\n81.16\n64.38\n81.17\nCiteseer\n84\n86\n88\n90\n92\n86.60\n90.20\n86.24\n90.28\nCora\n80\n82\n84\n86\n88\n84.66\n86.34\n82.14\n86.39\nFacebook\n60\n65\n70\n75\n80\n65.58\n75.52\n68.53\n75.75\nw/o MCFA \tw/o MDR \tw/o MoE \tGAD-MoRE\nFig. 3: AUROC performance of GAD-MoRE and its ablation variants on target GAD datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting.\n8 \t16 \t32 \t48\nAlignment Dimension\n72\n78\n84\n90\n96\nAUROC (%)\n8 \t16 \t32 \t48\nAlignment Dimension\n20\n32\n44\n56\n68\nAUPRC (%)\n2 \t3 \t4 \t5 \t6\nNumber of Experts\n76\n81\n86\n91\n96\nAUROC (%)\n2 \t3 \t4 \t5 \t6\nNumber of Experts\n32\n40\n48\n56\n64\nAUPRC (%)\nACM \tCiteseer \tCora \tWeibo\nFig. 4: Hyperparameter sensitivity analysis of GAD-MoRE. The left two subplots show the impact of the unified embedding\ndimension D on AUROC and AUPRC, while the right two subplots illustrate the sensitivity to the number of experts K.\nGAD-MoRE’s unsupervised, geometry-aware approach. When\ncompared to other generalist methods like UNPrompt and\nAnomalyGFM, GAD-MoRE shows a substantial improvement\nin both average metrics. This validates our core hypothesis\nthat explicitly modeling the geometric heterogeneity of graphs\nis crucial for effective domain generalization. The strong\nAUPRC score is particularly significant, as it confirms that\nour proposed GAD-MoRE is highly effective at identifying\nthe rare anomalous nodes in an imbalanced setting.\nFurthermore, the effectiveness of GAD-MoRE in distin-\nguishing normal from anomalous patterns is visualized in\nFigure 5, which shows the anomaly score distributions. In\nboth datasets, normal nodes (blue) receive lower scores, while\nanomalous nodes (red) are assigned higher scores, highlighting\nGAD-MoRE’s ability to accurately identify anomalies.\nC. Key Component Analysis (RQ2)\nTo answer our second research question and quantify the\nprecise contributions of the central innovations within GAD-\nMoRE, we conduct a thorough ablation study. We design\nseveral variants of our model, each disabling or replacing a key\ncomponent, and evaluate their AUROC performance against\nthe full model on representative datasets. The components\nunder investigation are: We define the following variants for\ncomparison, with their acronyms matching Figure 3:\n• w/o MCFA: In this variant, we bypass the MCFA module\nand use a standard PCA for dimensionality reduction,\nremoving the multi-geometry signals.\n0.0 \t2.5 \t5.0 \t7.5\nAnomaly Score\n0.0\n0.2\n0.4\n0.6\n0.8\nDensity\nNormal\nAnomaly\n(a) Citeseer\n0.0 \t2.0 \t4.0 \t6.0\nAnomaly Score\n0.0\n0.2\n0.4\n0.6\n0.8\nDensity\nNormal\nAnomaly\n (b) Cora\nFig. 5: The anomaly score distributions for Citeseer and Cora\nshow a clear distinction between normal and anomalous nodes.\nThis visual evidence confirms that our approach can effectively\ndetect anomalies in these graph datasets.\n• w/o MoE: We replace the MoE scorer with an attention-\nbased reconstruction scorer over reference embeddings.\n• w/o MDR: In this version, we replace our Memory-based\nDynamic Router with a simpler linear router.\nFigure 3 presents the results of our ablation study. These\nfindings clearly confirm the critical importance of each model\ncomponent. The most significant performance degradation is\nobserved in the w/o MoE variant, with the average AUROC\ndropping to 75.32%. This provides the strongest empirical\nevidence for our central hypothesis: a single geometric lens\nis insufficient for generalizable GAD, and a collection of\nspecialized Riemannian experts is essential for robust per-\nformance. By contrast, removing the Multi-curvature Fea-\n\n-- 11 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 12\nTABLE V: AUROC performance comparison (in %) of a zero-shot model against few-shot competitors on seven target Graph\nAnomaly Detection (GAD) datasets. The few-shot methods are fine-tuned with 10 labeled samples (10-shot). The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod ACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\n10-shot ARC 78.33±1.13 82.31±2.89 82.22±2.34 72.59±1.10 64.94±3.72 88.65±0.82 57.95±6.13 75.28\nAnomalyGFM 41.88±0.73 46.60±0.61 43.56±1.04 38.19±0.34 81.96±3.08 49.68±3.43 66.03±1.91 52.56\n0-shot GAD-MoRE 81.17±0.05 90.28±0.13 86.39±0.20 73.09±0.06 75.75±0.95 91.03±0.11 76.90±1.80 82.09\nTABLE VI: AUPRC performance comparison (in %) of a zero-shot model against few-shot competitors on seven target Graph\nAnomaly Detection (GAD) datasets. The few-shot methods are fine-tuned with 10 labeled samples (10-shot). The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod ACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\n10-shot ARC 36.53±0.24 30.93±4.24 39.23±4.40 37.77±0.35 4.92±1.85 59.47±2.38 7.98±1.18 30.98\nAnomalyGFM 2.89±0.08 4.13±0.09 4.30±0.10 4.17±0.06 16.53±5.41 9.79±0.99 10.88±1.50 7.53\n0-shot GAD-MoRE 37.17±0.07 40.15±1.31 45.25±0.88 35.31±0.42 9.00±1.12 60.26±0.30 31.55±4.84 36.96\nture Alignment (w/o MCFA) also leads to a substantial per-\nformance drop, particularly on the Facebook dataset. This\ndemonstrates that enriching initial node representations with\nsignals from diverse Riemannian spaces provides a more ro-\nbust foundation, enabling the model to adapt more effectively\nto unseen graph structures. Lastly, replacing the Memory-\nbased Dynamic Router (w/o MDR) with a simpler linear\nrouter results in a slight but consistent performance decrease\nacross most datasets. This highlights the effectiveness of the\ndesign of our proposed dynamic routing strategy, as history-\naware assignments from the MDR lead to more precise final\nreconstruction.\nD. Hyperparameter Sensitivity (RQ3)\nIn this section, we investigate the sensitivity of GAD-\nMoRE to its two most critical hyperparameters: the unified\nembedding dimension D and the number of experts K. This\nanalysis helps to understand the model’s robustness and guides\npractical application. Figure 4 illustrates the performance of\nGAD-MoRE with respect to these two parameters on four\nrepresentative test datasets, including ACM, Citeseer, Cora,\nand Weibo.\nFor the embedding dimension D (left column of Figure 4),\nwe observe that performance for both AUROC and AUPRC\ngenerally improves as the dimension increases from 16 to\n32. This indicates that a larger dimension allows for more\nexpressive representations to capture complex patterns. How-\never, the performance then stabilizes or slightly decreases for\ndimension 48, suggesting that overly large dimensions may\nlead to overfitting on the source datasets without improving\ngeneralization. Our chosen value of D = 32 offers the best\ntrade-off between performance and model efficiency.\nFor the number of experts K (right column of Figure 4),\nperformance steadily increases as we add more experts from\nK = 2 up to K = 5. This suggests that a richer set of\ngeometric lenses is beneficial for handling the diverse graph\nstructures encountered in the test sets. Beyond K = 5, the\nperformance plateaus, indicating that five experts are suffi-\ncient to cover the geometric diversity in our datasets without\nbecoming redundant or introducing unnecessary complexity.\nThis confirms our choice of K = 5 as optimal for the MoE\nscorer. Overall, the results show that GAD-MoRE is robust to\nvariations in these hyperparameters within a reasonable range.\nE. Comparison with Few-shot Learners (RQ4)\nTo further demonstrate the strong performance of our pro-\nposed GAD-MoRE on the GAD task, we conduct a compari-\nson against the competitive methods that are fine-tuned using\nlabeled data from the target domain. In particular, we still\nrigorously evaluate the strictly zero-shot capability of GAD-\nMoRE in comparing it with few-shot learning approaches,\nwhich are allowed access to a limited amount of target-domain\nlabeled data. Specifically, we compare GAD-MoRE with\nARC [16] and AnomalyGFM [18], two representative state-of-\nthe-art generalist GAD frameworks designed for cross-domain\ntransfer. These methods are selected as strong baselines due\nto their demonstrated effectiveness under few-shot adaptation\nsettings. The baselines are detailed as follows:\n• ARC [16] utilizes an in-context learning mechanism to\nadapt to target graphs using limited target labels.\n• AnomalyGFM [18] is a graph foundation model that\naligns node representations with class-agnostic prototypes\nto achieve generalization.\nThese two methods are chosen because most traditional GAD\nmodels are graph-specific and lack the architectural support for\ncross-domain fine-tuning. To simulate a competitive few-shot\nscenario, we fine-tune these baselines on 10 labeled nodes\n\n-- 12 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 13\nfrom each test graph (10-shot) and report performance with\nour model, which receives no such target-specific advantage.\nThe quantitative results for AUROC and AUPRC are de-\ntailed in Table V and Table VI. Despite operating in a zero-\nshot setting, GAD-MoRE demonstrates remarkable superiority,\nachieving an average AUROC of 82.09% and AUPRC of\n36.96%. These results substantially surpass the 10-shot fine-\ntuned ARC (75.28% / 30.98%) and AnomalyGFM (52.56%\n/ 7.53%), proving that GAD-MoRE outperforms competitors\non most datasets without access to target domain labels.\nThis comparison reveals a crucial insight: GAD-MoRE’s\narchitecture is highly effective at learning generalizable,\ngeometry-aware patterns from source domains, enabling it\nto surpass models that benefit from direct, albeit limited,\nsupervision. This showcases the power of our approach and\ndemonstrates that GAD-MoRE is a more practical and scalable\nsolution for real-world GAD applications where labels for new\ndomains are scarce or entirely unavailable.\nVI. CONCLUSION\nIn this paper, we introduce GAD-MoRE, a novel framework\nfor generalizable graph anomaly detection that addresses the\nchallenge of geometric heterogeneity. Motivated by our em-\npirical finding that no single curvature is universally optimal,\nwe propose a novel MoE architecture, featuring a multi-\ncurvature feature alignment module, a mixture of Rieman-\nnian experts scorer, and a memory-based dynamic router.\nSpecifically, the anomaly-aware multi-curvature feature align-\nment module bridges the gap between geometry-agnostic raw\nfeatures and manifold representations by projecting inputs\ninto parallel Riemannian spaces. Subsequently, the mixture of\nRiemannian experts scorer employs specialized Riemannian\nexperts operating in distinct curvature spaces, ensuring that\ncomplex anomaly patterns are modeled in suitable geometric\nenvironments without distortion. Furthermore, the memory-\nbased dynamic router facilitates adaptive inference using\nhistorical reconstruction feedback to align expert selection\nwith the anomaly detection objective. Extensive experiments\ndemonstrate that GAD-MoRE establishes a new state-of-the-\nart in zero-shot settings and consistently outperforms strong\ngeneralist competitors, even those fine-tuned with target do-\nmain labels. Promising research directions include extending\nGAD-MoRE to dynamic graphs, exploring hierarchical MoE\narchitectures, and integrating with graph foundation models.\nACKNOWLEDGMENT\nThe corresponding author is Qingyun Sun. The authors are\nsupported in part by the National Natural Science Foundation\nof China through grants No.62225202 and No.62427808, and\nthe Fundamental Research Funds for the Central Universities.\nREFERENCES\n[1] Z. Yuan, Q. Sun, H. Zhou, M. Shao, and X. Fu, “A comprehensive\nsurvey on gnn-based anomaly detection: taxonomy, methods, and the\nrole of large language models,” Int. J. Mach. Learn. Cybern., pp. 1–26,\n2025.\n[2] X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong, and\nL. Akoglu, “A comprehensive survey on graph anomaly detection with\ndeep learning,” IEEE TKDE, vol. 35, no. 12, pp. 12 012–12 038, 2021.\n[3] C. C. Aggarwal, “An introduction to outlier analysis,” in Outlier anal-\nysis. Springer, 2016, pp. 1–34.\n[4] W. Hilal, S. A. Gadsden, and J. Yawney, “Financial fraud: a review of\nanomaly detection techniques and recent advances,” ESWA, vol. 193, p.\n116429, 2022.\n[5] D. Wang, J. Lin, P. Cui, Q. Jia, Z. Wang, Y. Fang, Q. Yu, J. Zhou,\nS. Yang, and Y. Qi, “A semi-supervised graph attentive network for\nfinancial fraud detection,” in ICDM. IEEE, 2019, pp. 598–607.\n[6] Y. Yang, Y. Xu, Y. Sun, Y. Dong, F. Wu, and Y. Zhuang, “Mining fraud-\nsters and fraudulent strategies in large-scale mobile social networks,”\nIEEE TKDE, vol. 33, no. 1, pp. 169–179, 2019.\n[7] S. Rayana and L. Akoglu, “Collective opinion spam detection: Bridging\nreview networks and metadata,” in KDD, 2015, pp. 985–994.\n[8] S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and V. Sub-\nrahmanian, “Rev2: Fraudulent user prediction in rating platforms,” in\nWSDM, 2018, pp. 333–341.\n[9] A. B. Nassif, M. A. Talib, Q. Nasir, and F. M. Dakalbab, “Machine\nlearning for anomaly detection: A systematic review,” IEEE Access,\nvol. 9, pp. 78 658–78 700, 2021.\n[10] H. Qiao, H. Tong, B. An, I. King, C. Aggarwal, and G. Pang, “Deep\ngraph anomaly detection: A survey and new perspectives,” IEEE TKDE,\n2025.\n[11] J. A. Hartigan and M. A. Wong, “Algorithm as 136: A k-means\nclustering algorithm,” J. R. Stat. Soc. Ser. C (Appl. Stat.), vol. 28, no. 1,\npp. 100–108, 1979.\n[12] T. Cover, “Estimation by the nearest neighbor rule,” IEEE TIT, vol. 14,\nno. 1, pp. 50–55, 1968.\n[13] F. T. Liu, K. M. Ting, and Z.-H. Zhou, “Isolation forest,” in ICDM.\nIEEE, 2008, pp. 413–422.\n[14] S. Kumar, X. Zhang, and J. Leskovec, “Predicting dynamic embedding\ntrajectory in temporal interaction networks,” in KDD, 2019, pp. 1269–\n1278.\n[15] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-\nRad, “Collective classification in network data,” AI Magazine, vol. 29,\nno. 3, pp. 93–93, 2008.\n[16] Y. Liu, S. Li, Y. Zheng, Q. Chen, C. Zhang, and S. Pan, “Arc: A\ngeneralist graph anomaly detector with in-context learning,” NeurIPS,\nvol. 37, pp. 50 772–50 804, 2024.\n[17] C. Niu, H. Qiao, C. Chen, L. Chen, and G. Pang, “Zero-shot generalist\ngraph anomaly detection with unified neighborhood prompts,” ArXiv,\n2024.\n[18] H. Qiao, C. Niu, L. Chen, and G. Pang, “Anomalygfm: Graph foundation\nmodel for zero/few-shot anomaly detection,” in KDD, 2025, pp. 2326–\n2337.\n[19] X. Zhang, Z. He, C. Fu, and C. Xie, “Ia-ggad: Zero-shot generalist graph\nanomaly detection via invariant and affinity learning,” in NeurIPS, 2025.\n[20] K. Grover, G. J. Gordon, and C. Faloutsos, “Curvgad: Leveraging\ncurvature for enhanced graph anomaly detection,” in ICML, 2025.\n[21] Y. Liu, Z. Li, S. Pan, C. Gong, C. Zhou, and G. Karypis, “Anomaly de-\ntection on attributed networks via contrastive self-supervised learning,”\nIEEE TNNLS, vol. 33, no. 6, pp. 2378–2392, 2021.\n[22] T. N. Kipf and M. Welling, “Variational graph auto-encoders,” ArXiv,\n2016.\n[23] Y. Dou, Z. Liu, L. Sun, Y. Deng, H. Peng, and P. S. Yu, “Enhancing\ngraph neural network-based fraud detectors against camouflaged fraud-\nsters,” in CIKM, 2020, pp. 315–324.\n[24] Y. Gao, X. Wang, X. He, Z. Liu, H. Feng, and Y. Zhang, “Addressing\nheterophily in graph anomaly detection: A perspective of graph spec-\ntrum,” in WWW, 2023, pp. 1528–1538.\n[25] T. Zhao, X. Zhang, and S. Wang, “Graphsmote: Imbalanced node\nclassification on graphs with graph neural networks,” in WSDM, 2021,\npp. 833–841.\n[26] L. Wu, J. Xia, Z. Gao, H. Lin, C. Tan, and S. Z. Li, “Graphmixup:\nImproving class-imbalanced node classification by reinforcement mixup\nand self-supervised context prediction,” in ECML-PKDD, 2022, pp. 519–\n535.\n[27] K. Liu, H. Zhang, Z. Hu, F. Wang, and P. S. Yu, “Data augmentation for\nsupervised graph outlier detection with latent diffusion models,” ArXiv,\n2023.\n[28] K. Ding, J. Li, R. Bhanushali, and H. Liu, “Deep anomaly detection on\nattributed networks,” in SDM. SIAM, 2019, pp. 594–602.\n[29] H. Fan, F. Zhang, and Z. Li, “Anomalydae: Dual autoencoder for\nanomaly detection on attributed networks,” in ICASSP. IEEE, 2020,\npp. 5685–5689.\n[30] X. Yuan, N. Zhou, S. Yu, H. Huang, Z. Chen, and F. Xia, “Higher-\norder structure based anomaly detection on attributed networks,” in IEEE\nBigData. IEEE, 2021, pp. 2691–2700.\n\n-- 13 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 14\n[31] P. Veliˇckovi´c, W. Fedus, W. L. Hamilton, P. Li`o, Y. Bengio, and R. D.\nHjelm, “Deep graph infomax,” ArXiv, 2018.\n[32] F.-Y. Sun, J. Hoffmann, V. Verma, and J. Tang, “Infograph: Unsupervised\nand semi-supervised graph-level representation learning via mutual\ninformation maximization,” ArXiv, 2019.\n[33] F. Lin, X. Luo, J. Wu, J. Yang, S. Xue, Z. Wang, and H. Gong,\n“Discriminative graph-level anomaly detection via dual-students-teacher\nmodel,” in ADMA. Springer, 2023, pp. 261–276.\n[34] Z. Chen, B. Liu, M. Wang, P. Dai, J. Lv, and L. Bo, “Generative\nadversarial attributed network anomaly detection,” in CIKM, 2020, pp.\n1989–1992.\n[35] K. Ding, J. Li, N. Agarwal, and H. Liu, “Inductive anomaly detection\non attributed networks,” in IJCAI, 2021, pp. 1288–1294.\n[36] K. Ding, Q. Zhou, H. Tong, and H. Liu, “Few-shot network anomaly\ndetection via cross-network meta-learning,” in WWW, 2021, pp. 2448–\n2456.\n[37] S. Tian, J. Dong, J. Li, W. Zhao, X. Xu, B. Wang, B. Song, C. Meng,\nT. Zhang, and L. Chen, “Sad: semi-supervised anomaly detection on\ndynamic graphs,” in IJCAI, 2023, pp. 2306–2314.\n[38] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, “Adaptive\nmixtures of local experts,” Neural Comput., vol. 3, no. 1, pp. 79–87,\n1991.\n[39] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton,\nand J. Dean, “Outrageously large neural networks: The sparsely-gated\nmixture-of-experts layer,” in ICLR, 2017.\n[40] Z. Mi, P. Yin, X. Xiao, and D. Xu, “Learning heterogeneous mixture\nof scene experts for large-scale neural radiance fields,” IEEE TPAMI,\n2025.\n[41] W. Fedus, B. Zoph, and N. Shazeer, “Switch transformers: Scaling to\ntrillion parameter models with simple and efficient sparsity,” JMLR,\nvol. 23, no. 120, pp. 1–39, 2022.\n[42] C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton,\nA. Susano Pinto, D. Keysers, and N. Houlsby, “Scaling vision with\nsparse mixture of experts,” NeurIPS, vol. 34, pp. 8583–8595, 2021.\n[43] L. Liu, P. Wang, G. Wu, J. Jiang, and H. Yang, “Towards optimal mixture\nof experts system for 3d object detection: A game of accuracy, efficiency\nand adaptivity,” IEEE TPAMI, 2025.\n[44] Z. Guo, Q. Sun, H. Yuan, X. Fu, M. Zhou, Y. Gao, and J. Li, “Graph-\nmore: Mitigating topological heterogeneity via mixture of riemannian\nexperts,” in AAAI, vol. 39, no. 11, 2025, pp. 11 754–11 762.\n[45] H. Zeng, H. Lyu, D. Hu, Y. Xia, and J. Luo, “Mixture of weak & strong\nexperts on graphs,” ArXiv, 2023.\n[46] H. Wang, Z. Jiang, Y. You, Y. Han, G. Liu, J. Srinivasa, R. Kompella,\nZ. Wang et al., “Graph mixture of experts: Learning on large-scale\ngraphs with explicit diversity modeling,” NeurIPS, vol. 36, pp. 50 825–\n50 837, 2023.\n[47] F. Hu, L. Wang, S. Wu, L. Wang, and T. Tan, “Graph classification by\nmixture of diverse experts,” ArXiv, 2021.\n[48] J. Cai, Y. Zhang, P. Wang, and S.-K. Ng, “Moegad: A mixture-of-experts\nframework with pseudo-anomaly generation for graph-level anomaly\ndetection.” IEEE TPAMI, 2025.\n[49] I. Chami, Z. Ying, C. R´e, and J. Leskovec, “Hyperbolic graph convolu-\ntional neural networks,” NeurIPS, vol. 32, 2019.\n[50] X. Fu, J. Li, J. Wu, Q. Sun, C. Ji, S. Wang, J. Tan, H. Peng, and P. S.\nYu, “Ace-hgnn: Adaptive curvature exploration hyperbolic graph neural\nnetwork,” in ICDM. IEEE, 2021, pp. 111–120.\n[51] J. Li, X. Fu, Q. Sun, C. Ji, J. Tan, J. Wu, and H. Peng, “Curvature graph\ngenerative adversarial networks,” in WWW, 2022, pp. 1528–1537.\n[52] R. C. Wilson, E. R. Hancock, E. Pekalska, and R. P. Duin, “Spherical\nand hyperbolic embeddings of data,” IEEE TPAMI, vol. 36, no. 11, pp.\n2255–2269, 2014.\n[53] M. Nickel and D. Kiela, “Poincar´e embeddings for learning hierarchical\nrepresentations,” NeurIPS, vol. 30, 2017.\n[54] Q. Liu, M. Nickel, and D. Kiela, “Hyperbolic graph neural networks,”\nNeurIPS, vol. 32, 2019.\n[55] Y. Zhang, X. Wang, C. Shi, X. Jiang, and Y. Ye, “Hyperbolic graph\nattention network,” IEEE TBD, vol. 8, no. 6, pp. 1690–1701, 2021.\n[56] K. Pearson, “Liii. on lines and planes of closest fit to systems of points\nin space,” The London, Edinburgh, and Dublin philosophical magazine\nand journal of science, vol. 2, no. 11, pp. 559–572, 1901.\n[57] H. Hotelling, “Analysis of a complex of statistical variables into principal\ncomponents.” J. Educ. Psychol., vol. 24, no. 6, p. 417, 1933.\n[58] L. Tang and H. Liu, “Relational learning via latent social dimensions,”\nin KDD, 2009, pp. 817–826.\n[59] J. J. McAuley and J. Leskovec, “From amateurs to connoisseurs:\nmodeling the evolution of user expertise through online reviews,” in\nWWW, 2013, pp. 897–908.\n[60] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su, “Arnetminer:\nextraction and mining of academic social networks,” in KDD, 2008, pp.\n990–998.\n[61] Z. Xu, X. Huang, Y. Zhao, Y. Dong, and J. Li, “Contrastive at-\ntributed network anomaly detection with data augmentation,” in PAKDD.\nSpringer, 2022, pp. 444–457.\n[62] T. Kipf, “Semi-supervised classification with graph convolutional net-\nworks,” Arxiv, 2016.\n[63] P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and\nY. Bengio, “Graph attention networks,” ArXiv, 2017.\n[64] J. Tang, J. Li, Z. Gao, and J. Li, “Rethinking graph neural networks for\nanomaly detection,” in ICML, 2022, pp. 21 076–21 089.\nXinyu Zhao is currently a master’s candidate at the School of Computer\nScience and Engineering, Beihang University. His research interests include\ngraph anomaly detection and graph foundation models.\nQingyun Sun is currently an Associate Professor at the School of Computer\nScience and Engineering, Beihang University. Her research interests include\nmachine learning and graph mining. She has published several papers on IEEE\nTPAMI, IEEE TKDE, Web Conference, AAAI, ICDM, CIKM, etc..\nJiayi Luo is currently a Ph.D. candidate at the School of Computer Science\nand Engineering, Beihang University. His research interests include robust\ngraph learning and graph foundation models.\nXingcheng Fu is currently an associate professor at the Key Lab of Education\nBlockchain and Intelligent Technology at Guangxi Normal University. His\nresearch interests include graph representation learning, complex networks,\nand social network analysis. He has published several papers on IEEE TKDE,\nWeb Conference, AAAI, ICDM, CIKM, etc..\nJianxin Li is currently a Professor with the School of Computer Science and\nEngineering, Beihang University. His current research interests include social\nnetworks, machine learning, big data, and trustworthy computing. Dr. Li has\npublished research papers in top-tier journals and conferences, including the\nIEEE TKDE, TDSC, JAIR, ACM TOIS, TKDD, KDD, AAAI, and WWW.\n\n-- 14 of 14 --\n\n",
      "analysis_json": "{\"title\":\"Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts\",\"authors\":[\"Xinyu Zhao\",\"Qingyun Sun\",\"Jiayi Luo\",\"Xingcheng Fu\",\"Jianxin Li\"],\"publication_year\":\"2026\",\"summary\":\"This paper introduces GAD-MoRE, a framework designed to detect anomalies in graph data across unseen domains without retraining (zero-shot). The authors identify a key limitation in existing methods: they assume a fixed geometric space (usually Euclidean) for all graphs, ignoring that different anomaly patterns manifest better in different curvatures (e.g., tree-like anomalies in hyperbolic space vs. cyclic anomalies in spherical space). GAD-MoRE solves this by using a Mixture of Experts (MoE) architecture where each expert operates in a specific Riemannian manifold (Hyperbolic, Euclidean, or Spherical). It features a novel 'Memory-based Dynamic Router' that assigns nodes to experts based on historical reconstruction success rather than just feature similarity, and an alignment module to project raw features into these geometric spaces. Experiments show it outperforms state-of-the-art generalist baselines on 7 target datasets after training on 4 source datasets.\",\"breakthrough_score\":78,\"breakthrough_reasoning\":\"The paper makes a significant conceptual leap by connecting 'Geometric Heterogeneity' (the idea that data fits better in different curvatures) with 'Generalizable Anomaly Detection'. While Mixture of Experts and Riemannian Graph Neural Networks exist separately, combining them to solve the specific problem of cross-domain graph generalization is novel. The introduction of a memory-based router that optimizes for reconstruction quality rather than just classification is a clever engineering contribution that directly addresses the unsupervised nature of anomaly detection.\",\"key_claims\":[\"Graph anomaly patterns exhibit geometric heterogeneity; detectability depends heavily on the underlying curvature space.\",\"Embedding all graphs into a single fixed-curvature space distorts the structural signatures of anomalies, limiting generalization.\",\"A Mixture of Riemannian Experts can adaptively model diverse anomaly patterns by routing nodes to the geometry where they are most distinct.\",\"Memory-based routing, which relies on historical reconstruction performance, generalizes better to unseen distributions than standard feature-based gating.\"],\"testable_hypotheses\":[{\"hypothesis\":\"Anomalies in hierarchical/tree-like graphs (e.g., citation networks) are more detectable in Hyperbolic space than Euclidean space.\",\"how_to_test\":\"Project a hierarchical dataset (like Cora) into both Hyperbolic and Euclidean spaces using a simplified Autoencoder. Measure the separation distance between known anomalies and normal nodes in both spaces.\",\"expected_outcome\":\"The ratio of inter-class distance (anomaly vs. normal) to intra-class variance should be significantly higher in the Hyperbolic embedding.\"},{\"hypothesis\":\"The model's expert selection correlates with the topological properties of the node's neighborhood.\",\"how_to_test\":\"Feed nodes with varying local clustering coefficients and tree-likeness scores into the trained GAD-MoRE model. Record which expert (Hyperbolic, Spherical, Euclidean) is selected by the router.\",\"expected_outcome\":\"Nodes with high tree-likeness should route to Hyperbolic experts; nodes in dense, cyclic clusters should route to Spherical experts.\"},{\"hypothesis\":\"Memory-based routing prevents 'expert collapse' (where one expert takes all inputs) better than standard gating in zero-shot scenarios.\",\"how_to_test\":\"Train two versions of the model: one with the proposed memory router and one with a standard learned MLP gate. Test on a domain significantly different from the training set.\",\"expected_outcome\":\"The standard gate will likely route most nodes to a single 'average' expert, while the memory router will maintain a more balanced distribution of expert utilization.\"}],\"key_equations\":[{\"name\":\"Hyperbolic Distance (Poincaré Ball)\",\"latex\":\"d_H(p, q) = 1/sqrt(-k) * arccosh(1 + 2*||p-q||^2 / ((1+k||p||^2)(1+k||q||^2)))\",\"description\":\"Calculates the distance between two points p and q in hyperbolic space with curvature k. This metric naturally expands space as you move away from the origin, accommodating hierarchical structures.\",\"variables\":[{\"name\":\"k\",\"description\":\"Curvature parameter (must be negative for Hyperbolic space)\",\"typical_range\":\"-1.0 to -0.1\"},{\"name\":\"p, q\",\"description\":\"Feature vectors of two nodes in the Poincaré ball\",\"typical_range\":\"Norm < 1/sqrt(|k|)\"}]},{\"name\":\"Memory-based Routing Logit\",\"latex\":\"s_i(h_v) = - min(d_M(exp(h_v), exp(m)))\",\"description\":\"Determines the suitability of Expert i for node v by finding the minimum distance between the node and any prototype 'm' stored in that expert's memory bank.\",\"variables\":[{\"name\":\"h_v\",\"description\":\"Input node embedding in tangent space\",\"typical_range\":\"Vector in R^D\"},{\"name\":\"m\",\"description\":\"Stored prototype embedding in the expert's memory bank\",\"typical_range\":\"Vector in R^D\"}]},{\"name\":\"Anomaly Score\",\"latex\":\"S(v) = || h_v - h_hat_v ||^2\",\"description\":\"The final anomaly score is the L2 norm of the reconstruction error. A higher error implies the MoE could not compress and reconstruct the node well, indicating it is an anomaly.\",\"variables\":[{\"name\":\"h_v\",\"description\":\"Original node embedding\",\"typical_range\":\"Real vector\"},{\"name\":\"h_hat_v\",\"description\":\"Reconstructed embedding from the selected Riemannian experts\",\"typical_range\":\"Real vector\"}]}],\"simulation_possibilities\":[{\"title\":\"The Curvature Lens\",\"description\":\"An interactive visualization where users can project a 3D synthetic graph into spaces with different curvatures using a slider. As the user slides from Negative (Hyperbolic) to Zero (Euclidean) to Positive (Spherical), they observe how anomalous nodes (highlighted in red) either blend in with the crowd or pop out to the periphery.\",\"complexity\":\"Medium\",\"variables\":[\"Curvature (k)\",\"Graph Topology Type (Tree/Cycle/Grid)\"],\"expected_insights\":\"Users will visually grasp why a fixed curvature is insufficient: a 'Star' anomaly is obvious in Hyperbolic space but hidden in Spherical space, while a 'Clique' anomaly is the opposite.\",\"visualization_type\":\"3d\"},{\"title\":\"Expert Routing Flow\",\"description\":\"A flowchart animation showing a stream of nodes entering the model. The 'Router' analyzes the node structure and directs it to one of three 'Manifold Rooms' (Hyperbolic, Euclidean, Spherical). Inside the room, the reconstruction happens. If the wrong room is chosen, the reconstruction breaks (high error visualization).\",\"complexity\":\"Low\",\"variables\":[\"Input Node Type\",\"Router Logic (Random vs. Memory-based)\"],\"expected_insights\":\"Demonstrates the concept of 'Conditional Computation'—not every part of the network needs to process every input.\",\"visualization_type\":\"animation\"},{\"title\":\"Zero-Shot Transfer Challenge\",\"description\":\"A split-screen simulation. Left side: Training on a 'Social Network' (dense clusters). Right side: Testing on a 'File System Hierarchy' (tree structure). Users watch as the experts learned on the left (specifically the Hyperbolic ones that were under-utilized) suddenly become active and dominant when handling the file system data on the right.\",\"complexity\":\"High\",\"variables\":[\"Source Domain Data\",\"Target Domain Data\"],\"expected_insights\":\"Proves the generalization capability: the model possesses dormant capabilities (experts) that activate only when the data geometry demands it.\",\"visualization_type\":\"interactive\"}],\"field\":\"Graph Machine Learning\",\"related_fields\":[\"Riemannian Geometry\",\"Anomaly Detection\",\"Zero-shot Learning\",\"Mixture of Experts\"],\"limitations\":[\"Computational overhead of calculating distances in multiple Riemannian manifolds.\",\"The number of experts and their specific curvatures must be predefined or searched.\",\"Requires mapping features to tangent spaces which adds complexity compared to pure Euclidean GNNs.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Graph Neural Networks (GNNs)\",\"Manifold Geometry (Tangent spaces, Exponential map)\",\"Autoencoders\",\"Mixture of Experts (MoE)\"]}",
      "created_at": 1770621612997
    },
    "arxiv-2602.04878": {
      "hash": "arxiv-2602.04878",
      "filename": "2602.04878.pdf",
      "raw_text": "Thermal State Simulation with Pauli and Majorana Propagation\nManuel S. Rudolph,1, 2, ∗, § Armando Angrisani,1, 2, †, § Andrew\nWright,1, 2 Iwo Sanderski,1, 2 Ricard Puig,1, 2, ‡ and Zo¨e Holmes1, 2, 3\n1Institute of Physics, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Lausanne, Switzerland\n2Centre for Quantum Science and Engineering, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Lausanne, Switzerland\n3Algorithmiq Ltd, Kanavakatu 3 C, FI-00160 Helsinki, Finland\n(Dated: February 5, 2026)\nWe introduce a propagation-based approach to thermal state simulation by adapting Pauli and\nMajorana propagation to imaginary-time evolution in the Schr¨odinger picture. Our key observa-\ntion is that high-temperature states can be sparse in the Pauli or Majorana bases, approaching the\nidentity at infinite temperature. By formulating imaginary-time evolution directly in these operator\nbases and evolving from the maximally mixed state, we access a continuum of temperatures where\nthe state remains efficiently representable. We provide analytic guarantees for small-coefficient trun-\ncation and Pauli-weight (Majorana-length) truncation strategies by quantifying the error growth and\nthe impact of backflow. Large-scale numerics on the 1D J1–J2 model (energies) and the triangular-\nlattice Hubbard model (static correlations) validate efficiency at high temperatures.\nI. INTRODUCTION\nUnderstanding quantum matter at finite temperatures\nis central to material science, condensed matter and\nquantum chemistry. From a fundamental perspective,\nthermal fluctuations compete with quantum coherence\nand can change phases of matter, drive phase transi-\ntions, and determine observables such as susceptibilities\nand transport coefficients. From an applications perspec-\ntive, many target problems, including reaction rates and\nfree energies are inherently finite-temperature. Classi-\ncally probing these properties requires efficient methods\nfor approximating thermal states.\nPropagation methods, most commonly Pauli [1–15]\nand Majorana [16–20] propagation, are relative newcom-\ners to the classical toolbox for simulating quantum sys-\ntems. At their core, propagation methods approximate\nthe evolution of a quantum operator via a truncated path\nintegral. Due to Pauli propagation’s initial conceptual-\nization for simulating real-time dynamics [6, 21], the fam-\nily of propagation algorithms as a whole are currently\nprimarily understood as tools for precisely that. Both\nin the continuous-time [22] or discrete quantum circuit\nformulations [2–15]. Furthermore, they are almost exclu-\nsively presented as methods for estimating expectation\nvalues in the Heisenberg picture, i.e., for the backward\nevolution of observables that are typically sparser in the\nPauli or Majorana basis than states.\nIn this work, we challenge this perspective and pro-\npose a propagation algorithm for the simulation of finite-\ntemperature quantum states in the Schr¨odinger picture.\nWhile zero-temperature pure states are always dense in\nthe Pauli or Majorana basis, consisting of at least 2n op-\nerators for an n-site system, high-temperature states can\n∗ manuel.rudolph@epfl.ch\n† armando.angrisani@epfl.ch\n‡ ricard.puigivalls@epfl.ch\n§ These authors contributed equally to this work.\nbe exceptionally sparse. In the limit of infinite temper-\nature, the maximally-mixed state is representable by a\nsingle operator: the identity operator. By defining the\naction of imaginary-time evolution in the Pauli and Ma-\njorana basis, and starting to evolve the maximally mixed\nstate, we gain access to a range of temperatures at which\nwe can efficiently store the quantum state in memory.\nWe analyze two complementary truncation strate-\ngies, small-coefficient truncation and Pauli-weight (and\nMajorana-length) truncation. We derive upper bounds\nshowing how the resulting approximation error decreases\nas the truncation threshold is increased, guaranteeing\nthat propagation methods can run efficiently at high tem-\nperatures. We complement these results with large-scale\nnumerical experiments: for the 1D J1–J2 model we study\nenergy estimates across system sizes and temperatures,\nand for the Fermi-Hubbard model on a triangular lattice\nwe demonstrate direct computation of finite-temperature\nstatic correlation functions from the propagated thermal\nstate. Both our analytic and numerical results indicate\nthat simulating high temperatures is efficient but low\ntemperatures remain challenging.\nOur algorithm has several natural applications.\nFirstly, it provides a route to estimating free energies,\nsince once a thermal state (or its partition function) is\naccessible, thermodynamic quantities follow with mini-\nmal additional work. Secondly, as we can easily com-\nbine thermal preparation with subsequent time evolution,\nwe can, for example, probe finite-temperature correc-\ntions to infinite-temperature dynamical correlation func-\ntions. Thirdly, the ability to represent thermal states\ncompactly suggests applications to Gibbs sampling and\ngenerative modeling, where one aims to efficiently draw\nsamples from thermal distributions or learn compact gen-\nerative surrogates for finite-temperature data [23]. More\nbroadly, imaginary time propagation methods retain two\npractical advantages: they make no assumptions about\nlattice topology and they interface naturally with quan-\ntum hardware.\narXiv:2602.04878v1 [quant-ph] 4 Feb 2026\n\n-- 1 of 34 --\n\n2\n0110101110\n1010011010\n0000111111 ...\nFigure 1. Schematic depiction of thermal state preparation via propagation methods. The process begins at infinite\ntemperature (β = 0) with the maximally mixed state, represented by the identity operator I. We then apply a sequence of\nimaginary-time gates (propagators e−τ H ) to evolve the operator. As the system cools (corresponding to larger β), the state\nbecomes less sparse and the number of operators (either Paulis or Majoranas) that need to be propagated grow. This approach\nallows us to efficiently store and manipulate high-temperature states.\nII. FRAMEWORK\nIn this paper, we develop methods to simulate the ther-\nmal (Gibbs) state at inverse temperature β,\nρβ = e−βH\nTr(e−βH ) = e− β\n2 H I e− β\n2 H\nTr(e−βH ) , (1)\nwhere H is the Hamiltonian of interest. As shown\nin Eq. (1), the numerator can be viewed as evolving\nthe identity operator by the non-unitary imaginary-time\npropagator e− β\n2 H , i.e., as a “rotation” by an imaginary\nangle τ = −i β\n2 . Pauli [1–15] and Majorana [16–20] prop-\nagation methods can be used to compute the action of\nthis imaginary-time evolution on I. We will focus initially\non describing the method for Pauli propagation but the\nMajorana generalization is entirely analogous.\nPauli Propagation. The first step to simulating imag-\ninary time evolution via Pauli propagation is to express\nthe Hamiltonian as a sum of (local) Pauli terms,\nH =\nM\tX\nm=1\nhm, hm = λmPm, Pm ∈ Pn, (2)\nand apply a Trotter approximation of the imaginary evo-\nlution operator, for example, a first-order Trotter approx-\nimation,\ne−βH ≈\nM\tY\nm=1\ne−τ λmPm\n!L\n, L := β/τ (3)\nwhere the Trotter error associated with this approxima-\ntion scales as O(Cβτ ) with C := P\nm<m′ [hm, hm′ ] .\nThis approximation decomposes the evolution for imag-\ninary time β into a product of L × M local short τ\n“imaginary-time gates” each of which can be applied it-\neratively to a Pauli expansion, starting from I.\nThe action of an imaginary time gate generated by\nsome Pauli operator P on another Pauli operator Q is\ne− τ\n2 P Q e− τ\n2 P =\n(Q, [P, Q]̸ = 0,\ncosh(τ ) Q − sinh(τ ) P Q, [P, Q] = 0,\n(4)\nwhere for Pauli strings P, Q, the product P Q is also a\nPauli string, up to a phase. Note that contrary to the\nreal-time case, branching occurs when P and Q commute.\nAlso, all coefficients remain real due to the product of\ncommuting Pauli strings producing an even number of\nimaginary factors.\nAfter imaginary-time Pauli propagation, where the\ngates are iteratively applied to the initial identity op-\nerator, we obtained a collection of Pauli operators P ’s\nweighted by coefficients αP ’s, such that\ne− β\n2 H I e− β\n2 H ≈ X\nP ∈Pn\nαP P, (5)\nand the thermal state can be written as\nρβ ≈\nP\nP ∈Pn αP P\nTr\u0000P\nP ∈Pn αP P \u0001 =\nP\nP ∈Pn αP P\n2n αI\n, (6)\nsince Tr(P ) = 0 for all non-identity Paulis and Tr(I) =\n2n. In particular, the partition function Tr\u0000e−βH \u0001 is pro-\nportional to the identity coefficient αI.\nIn general, the number of Pauli terms generated by\nrepeated application of these gates grows exponentially\nwith the number of gates. Pauli propagation methods\nusually remain practical (or even formally polynomially\nscaling) when combined with truncation strategies that\nlimit the growth of the Pauli expansion to the most\n\n-- 2 of 34 --\n\n3\nrelevant contributions. Two natural choices are small-\ncoefficient truncation, where one discards terms whose\namplitudes |αP | are smaller than some cutoff value and\nPauli-weight truncation, where one removes Pauli strings\nwhose weight, i.e., the number of non-identity single-\nqubit factors in P , exceeds a prescribed cutoff. The latter\nexploits the fact that local observables are sensitive pri-\nmarily to low-weight contributions and high-weight Pauli\nstrings, have a tendency to increase in weight rather than\nbackflow to low weights under subsequent propagation.\nRandomized product formulas. For the purposes of\nour analysis (or if reducing Trotter error is a primary\ninterest), we will also consider an alternative to determin-\nistic Trotterization based on the quantum stochastic drift\nprotocol (qDRIFT) [24]. In this setting one defines the\n1-norm of the Hamiltonian coefficients Λ := PM\nm=1 |λm|\nand samples indices m i.i.d. from the distribution pm =\n|λm|/Λ. A qDRIFT approximation to the imaginary-\ntime propagator is then obtained by applying a sequence\nof randomly chosen local gates,\ne−βH ≈\nLqD\t\nY\nℓ=1\nexp(−τ smℓ Pmℓ ) , LqD := Λβ/τ (7)\nwhere each mℓ ∼ p is drawn independently and smℓ :=\nsign(λmℓ ). Intuitively, qDRIFT replaces L repetitions\nof the fixed ordering over all M terms by a stochastic\nwalk over LqD Hamiltonian terms. The qDRIFT sim-\nulation error is expected to scale as O(Λβτ ) which can\nbe less than the 1st order Trotter error when Λ < C =\tP\nm<m′ [hm, hm′ ] .\nWithin Pauli propagation, taking a qDRIFT approach\nto imaginary time simulation simply means that at each\nstep one updates the current operator expansion by\nthe adjoint action of the sampled gate. Averaging over\nmany sampled sequences yields an unbiased estimator\nof observables under the approximated imaginary-time\nevolution, while the per-step cost remains identical to the\nTrotter case. In the context of this paper the qDRIFT\napproach to imaginary time simulation is largely an\nanalytic tool that helps us to intuitively understand the\nprobability of backflow from high to low weight Paulis\nin our algorithm and thereby derive guarantees based\non weight-truncation. However, we also foresee that it\ncould become the go-to method for the Monte-Carlo\nimplementations of our algorithm that will ultimately\nbe necessary to overcome memory limitations and utilize\nGPU capabilities [14].\nMajorana propagation. In the context of fermionic\nsystems, it is more natural to work in the Majorana op-\nerator basis. For a system of n fermionic modes {aj }N\nj=1,\nthe Majorana operator basis is defined by\nm2j−1 := aj +a†\nj , m2j := −i(aj −a†\nj ), j ∈ {1, . . . , N },\n(8)\nwhich satisfy {mp, mq } = 2δpq and m†\np = mp. A Ma-\njorana monomial is indexed by a binary vector b =\n(b1, . . . , b2N ) ∈ {0, 1}2N and defined as\nMb := irb mb1\n1 mb2\n2 · · · mb2N\n2N , (9)\nwith the phase choice rb ∈ {0, 1} ensuring Mb is Hermi-\ntian (equivalently, rb = 0 when ∥b∥1 ≡ 0, 1 (mod 4) and\nrb = 1 otherwise). The length of a monomial is\n|Mb| := ∥b∥1 =\n2N\tX\nj=1\nbj , (10)\nand the set Γ := {Mb : b ∈ {0, 1}2N } forms an operator\nbasis. Hence any operator admits a unique expansion\nO = X\nb∈{0,1}2N\nαb Mb, (11)\nwith real coefficients αb ∈ R whenever O is Hermitian.\nTo simulate imaginary-time evolution in this represen-\ntation, we expand the Hamiltonian in the same basis,\nH =\nM\tX\nm=1\nhm, hm = λmMbm , Mbm ∈ Γ, (12)\nand approximate e−βH by a product formula as in the\nPauli case, yielding local imaginary-time gates Gm :=\ne−∆β λmMbm . Because any two monomials either com-\nmute or anticommute and satisfy M 2\nb = I, the update rule\non a basis element Ma takes the same form as Eq. (4),\nnamely e− τ\n2 Mb Ma e− τ\n2 Mb\n=\n(Ma, [Mb, Ma]̸ = 0,\ncosh(τ ) Ma − sinh(τ ) MbMa, [Mb, Ma] = 0. (13)\nIn particular, branching occurs when Mb and Ma com-\nmute. Moreover, the product MbMa is again Hermitian\n(up to an overall sign), so the propagated coefficients\nremain real. Finally, truncation can be implemented by\ndiscarding monomials with small coefficient prefactors\nas well as those whose length exceeds a threshold\nℓmax (Majorana-length truncation), in analogy with\nPauli-weight truncation.\nRelation to other methods. At a high level, our ap-\nproach is a series treatment of imaginary-time evolu-\ntion in operator space. Conventional finite-temperature\nMonte Carlo methods [25–30] also exploit a path-integral\nviewpoint to estimate observables without explicitly con-\nstructing ρβ . In contrast, propagation tracks how ba-\nsis operators (Pauli strings or Majorana monomials) are\ntransformed under successive imaginary-time gates. The\nresulting tradeoff replaces the sign-problem barrier [31]\nwith an operator-growth/branching barrier.\nOur truncation rules are closely connected to high-\ntemperature [32–34] and cluster-expansion ideas [35–37].\nSmall-coefficient truncation in the case of small rotation\nangles mirrors a high-temperature series expansion in\n\n-- 3 of 34 --\n\n4\nwhich higher-order contributions are suppressed and can\nbe discarded. Pauli-weight (or Majorana-length) trunca-\ntion plays the role of a cluster-size cutoff in the sense that\nlocal observables are primarily sensitive to low-support\noperators, and contributions from large-support terms\nare generally suppressed. In this sense, our methods\nare analogous to a cluster-expansion-like approximation,\nbut organized by operator algebra rather than by explicit\nenumeration of connected graph components.\nOur methods also complement the rich literature on\nquantum algorithms for preparing or sampling from\nGibbs states [38–46], and provide a practical classical\nbaseline for delineating the temperatures and system\nsizes at which quantum thermal-state preparation may\nyield a quantum advantage.\nFinally, there is a structural analogy to tensor-network\nthermal states [47–50]. Methods based on purification\nor MPO/PEPO imaginary-time evolution can also apply\nlocal imaginary-time gates followed by truncation to con-\ntrol complexity. The main difference is– as usually– the\nrepresentation and truncation metric: spatial factoriza-\ntion and finite bond dimension versus sparse representa-\ntion and finite support. This complementary perspective\nhighlights when propagation may be advantageous: it is\ntopology-agnostic, allows directly reading off the Pauli\nor Majorana decomposition of the state, and can inter-\nface directly with quantum hardware for hybrid work-\nflows [10, 13].\nIII. ANALYTIC GUARANTEES\nIn this section, we provide guarantees for the efficiency\nof simulation in low-β (i.e., high-temperature) regimes.\nWhile our results here are framed in the context of\nPauli propagation, everything carries directly over to\nMajorana propagation, as explained in Appendix I.\nCoefficient truncation. We start by analyzing coeffi-\ncient truncation schemes whereby after each update we\ndiscard Pauli terms whose amplitudes are below some\ncutoff. For the analysis, however, it is convenient to work\nwith a closely related proxy rule that is simpler to treat\nanalytically. Namely, we consider a small-angle trunca-\ntion scheme which exploits the fact that for τ ≪ 1 the\nbranching amplitudes produced by imaginary-time prop-\nagation are suppressed in powers of sinh(τ ) ≈ τ ≪ 1.\nTherefore we can discard any Pauli path that accumu-\nlates more than k non-identity updates (equivalently,\nmore than k factors of sinh(τ )) as sinh(τ )k ≈ τ k ≪ 1.\nThis results in the following theorem.\nTheorem 1 (Small-angle truncation error). Consider\nthe simulation of the thermal state starting from the\nidentity I. The algorithm performs L steps of the map\nEt(·) = e−τ Pt/2(·)e−τ Pt/2, with step angle τ = βΛ\nL , where\nΛ = P\nj |hj | is the sum of Hamiltonian coefficients. Let ˜ρ\nbe the approximate state obtained by truncating any Pauli\npath that accumulates more than k non-identity updates\n(i.e., discarding paths with more than k factors of sinh τ ).\nThen the approximate thermal state ˜ρ satisfies\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (14)\nAs a consequence, for any observable O one has\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥O∥∞ eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (15)\nThis is proven in Appendix E. Thus, for temperatures\nsuch that β scales inversely with the 1-norm of the Hamil-\ntonian (i.e., βΛ ∈ O(1)), the truncation error is sup-\npressed super-exponentially in k:\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥O∥∞\n\u0010 c\nk\n\u0011k\u0013\n∈ exp\u0000−Ω(k log k)\u0001\n(16)\nfor k ≫ c for some constant c. Equivalently, to achieve a\ntarget accuracy ϵ, it suffices to choose\nk = Θ\n\n log\n\u0010 ∥O∥∞\nϵ\n\u0011\nlog log\n\u0010 ∥O∥∞\nϵ\n\u0011\n\n , (17)\nwhich grows only slightly faster than log(1/ϵ).\nSince the number of retained terms (and hence the\nruntime of propagation) scales polynomially with the\ntruncation level k for fixed system size and locality\nstructure [8, 10], this implies that for β ∈ O(1/Λ)\nthe small-angle imaginary-time simulation error decays\nsuper-exponentially in k,\nϵ = ∥O∥∞ exp\u0000−Ω(k log k)\u0001. (18)\nin time polynomial in k (and therefore is polylogarith-\nmic in 1/ϵ, up to the log log correction). Furthermore,\nas proven in Lemma 14 in Appendix E, for slightly\nlower temperatures such that βΛ ∈ Θ(log n) we can ob-\ntain an error that is polynomially suppressed in n for\nk ∈ O(log(n)) which corresponds to super-polynomial\nresources. We stress that as Theorem 1 also bounds the\nerror of the 1-norm of the state and so the simulated state\ncan be used for sampling-based applications [23].\nWeight truncation. We now provide efficiency guar-\nantees for imaginary-time Pauli propagation under\nweight truncation, where we discard any Pauli string\nwhose weight exceeds a threshold k. The same logic can\nalso be applied to Majorana length truncation.\nThe intuition underlying this truncation scheme begins\nwith the observation that only Pauli strings that overlap\nthe support of the observable O can contribute to Tr(Oρ).\nThus, if O is low weight, high-weight strings matter only\ninsofar as they subsequently backflow to low weight. Any\npath that realizes such a large net decrease in weight must\nbranch many times, and therefore accumulates multiple\n\n-- 4 of 34 --\n\n5\nfactors of sinh(τ ). Since sinh(τ ) ≈ τ ≪ 1 for small τ ,\nthese contributions acquire very small coefficients and\ninduce only a small error. This effect is further strength-\nened by a typical drift toward higher weight: for a Pauli\nstring of weight w ≲ n/2, applying a local imaginary-\ntime gate is more likely to increase weight than to de-\ncrease it. Consequently, the overall contribution of trun-\ncated high-weight terms is additionally suppressed by the\nsmall probability of backflow from weight k down to the\n(low) weight scale relevant to O.\nCombining these effects yields a bound analogous to\ncoefficient truncation, but with an additional suppres-\nsion factor governed by the backflow probability. Let\nqbf (w) denote the probability (over the random choice of\ngate e.g. under qDRIFT) that applying one imaginary-\ntime gate to a Pauli string of weight w produces a branch\nwhose resulting Pauli string has strictly smaller weight.\nAs shown in Appendix F, this quantity for a range of\nmodels typically depends on the current weight w of the\npropagated string but does not vary significantly between\ndifferent strings of the same weight. We further show\nthat qbf (w) typically increases with w since higher-weight\nstrings have more opportunities for cancellations that re-\nduce support. When deriving a worst-case bound for\nweight truncation, we upper bound all backflow events\noriginating from the truncated sector w > k (as any path\nthat starts backflowing from higher will also have to back-\nflow from k down to the low weight region). Therefore,\nthe maximum backflow probability is\nqmax := sup\nw⩽k\nqbf (w) := qbf (k) . (19)\nThis results in the following bound.\nTheorem 2 (Weight truncation Backflow Error, In-\nformal). Consider the qDRIFT simulation of a thermal\nstate starting from the identity I and let O be a constant\nweight observable. The algorithm applies L steps of size\nτ = βΛ\nL , where Λ = P |hi|. Let ˜ρ be the state obtained by\ntruncating any Pauli string with weight exceeding k. For\nsufficiently large k ∈ O(1), the error in the expectation\nvalue is bounded by:\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2k\n\u0013k!\n, (20)\nwhere ∥o∥1 is the 1-norm of its Pauli coefficients of O.\nFor approximately uniform all-to-all Hamiltonians the\nbackflow probability is quadratically suppressed,\nqbf (k) ∈ O(k2/n2) , (21)\nwhere as for 1D Hamiltonians it is linearly suppressed,\nqbf (k) ∈ O(k/n) . (22)\nThis theorem is proven in Appendix F for a general\nqbf (k), and in Appendix G we compute qbf (k) for different\nHamiltonians.\nSince Theorem 2 has the same functional form as The-\norem 1, we again obtain super-exponential suppression\nof the truncation error in the high-temperature regime\nβΛ = O(1). Moreover, the additional factor qbf (k) in\nthe exponent further suppresses contributions from trun-\ncated high-weight strings and therefore permits meaning-\nful guarantees at moderately larger β. Concretely, when\nβΛ = O(log n), the error becomes exponentially small in\nthe truncation order. In particular, for sufficiently large\n(but still O(1)) truncation threshold k, we obtain the\nscaling\nϵ ∈\n\u0012 log n\nn\n\u0013Θ(k)\n. (23)\nFor details, see the proof of Lemma 17 in Appendix F.\nIn Appendix G, we argue that most physically rele-\nvant Hamiltonians can be viewed as close-to-uniform and\ntherefore exhibit between linearly to quadratically sup-\npressed backflow depending on their topology.\nWe emphasize that the bound above is stated for\nqDRIFT because it provides a natural probabilistic lan-\nguage for defining and analyzing backflow. Nevertheless,\nthe same intuition carries over to deterministic product\nformulas: in a standard Trotter scheme, a significant pro-\nportion of high-weight contributions continue to grow in\nweight rather than backflow to low weight, so the net\ninfluence of truncated high-weight terms on local observ-\nables is suppressed. We can capture this via a direct\ncombinatorial (frequentist) analysis of Trotter paths, the\nbroad intuition is the same as in qDRIFT but the anal-\nysis is technically more awkward. In Appendix H, we\nobtain the following bound.\nTheorem 3 (Weight-truncation error for 1st-order Trot-\nter imaginary-time evolution (informal)). Let H =\nPM\na=1 λaQa be a Pauli Hamiltonian on n qubits with\n|λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Assume H has\nbounded degree ℓ, i.e. each qubit participates in at most ℓ\nterms. Fix an inverse temperature β > 0 and a step size\nδ > 0, and let L := β/δ ∈ N. Let ρ denote the (normal-\nized) state obtained by applying L steps of the 1st-order\nTrotter imaginary-time evolution, and let ˜ρ be the classi-\ncal approximation obtained by truncating all propagated\nPauli operators to weight < k after any imaginary time\noperation.\nThen there exist absolute constants c1, c2 > 0 such\nthat, for every observable O,\nTr\u0002O(ρ − ˜ρ)\u0003 ≤ ∥o∥1 exp\u0000c1 βM \u0001 \u0010\nc2 β ℓ w\n\u0011k/w\n. (24)\nwhere ∥o∥1 is again the 1-norm of the Pauli coefficients\nof O.\nWe note that the error obtained here aligns with the\nscalings obtained in Theorem 2. Consider the high-\ntemperature regime βM = Θ(1) and w = O(1). Then\n\n-- 5 of 34 --\n\n6\nFigure 2. Comparison between 1st-order Trotter and qDRIFT. We evolve using truncated trotterization (full) and\nqDRIFT (dashed) for different models and compare to the untruncated evolutions using the mean relative error of the energy\nas a metric. This error is plotted as a function of β (top) and as a function of the number of Paulis it utilizes (bottom) for a\n10 qubit system. The overlap of the curves between the trotter evolution and the qDRIFT suggests that weight truncation is\nequally justified for both types of evolution. The bottom plot gives a comparison of the effectiveness of each truncation scheme\nwhere in general the coefficient truncation leads to a better error at a given number of Paulis.\n(24) implies\nTr[O(ρ − ˜ρ)] ≤ ∥o∥1\n\u0000β ℓ\u0001Ω(k) (25)\n=∥o∥1\n\u0010 ℓ\nM\n\u0011Ω(k)\n. (26)\nUnder the natural assumption that the degree is sublin-\near in the number of terms, e.g. ℓ ≤ M c for some constant\nc < 1, we obtain a polynomially small error in M with\nexponent linear in k:\nTr[O(ρ − ˜ρ)] ≤ ∥o∥1 M −Ω(k).\nSimilarly to our bound in Theorem 2, Theorem 3 yields\nmeaningful guarantees also for the case where βM ∈\nΘ(log(M )). In this regime, assuming also w ∈ O(1) and\nthat the degree is sublinear in the number of terms, e.g.\nℓ ≤ M c for some constant c < 1, one has\nTr\u0002O(ρ − ˜ρ)\u0003 ∈ ∥o∥1 M O(1)\n\u0012 log(M )\nM 1−c\n\u0013Ω(k)\n(27)\n∈ ∥o∥1 M O(1)−Ω(k). (28)\nExactly which of the bounds in Theorem 3 and\nTheorem 2 is tighter depends on the relative magnitude\nof the degree l of the Hamiltonian and the truncation\nk considered which will vary on a case-by-case basis.\nHowever, we suspect these differences are not fundamen-\ntal but rather are an artifact of our proof techniques.\nIndeed this is further supported by our numerics below.\nNumerically probing theoretical predictions. In Fig. 2,\nwe numerically illustrate the effects of coefficient and\nweight truncation for imaginary time evolution via\nqDRIFT or a 1st-order Trotter decomposition. This\nis to test whether Theorem 2 and Theorem 3 point\nto more general effects that transcend our proof tech-\nniques. We consider three types of Hamiltonians, two\nrandom and one physical one, all composed of 30 weight-\n2 Paulis: Random all-to-all interactions with coefficients\n∈ {−1, 1}, random nearest-neighbor interactions with co-\nefficients ∈ {−1, 1}, and a 1D Heisenberg Hamiltonian\nwith +1 coefficients. The simulations were done on 10-\nqubit systems for exact verification. In the Trotter case,\nwe use L = 50 steps with τ = 0.02, and for qDRIFT\nLqD = Λβ/τ = ΛL = 1500 with Λ = 30 to match the\ntheoretical time discretization error. For each model, we\nconsider 200 samples and compute the mean relative er-\nror of the energy between the truncated and exact simu-\nlations.\nThere appears to be hardly any difference between how\nTrotter or qDRIFT respond to truncations, indicating\nthat both our theoretical guarantees for weight trunca-\ntion have similar predictive power. When comparing co-\n\n-- 6 of 34 --\n\n7\nFigure 3. Imaginary time evolution under the J1-J2 Hamiltonian. Numerical results for the 1D J1 − J2 Heisenberg\nmodel across system sizes ranging from 10 to 40 qubits. The top row shows the estimated energy density ⟨H⟩/n converging\ntoward the ground state (dashed line) as the inverse temperature β increases. The bottom row tracks the number of Pauli\nstrings generated, showing the exponential growth in complexity as the temperature drops. Different shades of blue represent\ndifferent coefficient truncation thresholds (from 2−9 to 2−18); the point where these lines diverge indicates the limit where our\napproximation is no longer accurate.\nefficient and weight truncation, we observe that, for a\ngiven temperature, coefficient truncation obtains lower\nerror per propagated Pauli operator, which is a proxy for\nruntime and memory consumption. This is in large part\nbecause coefficient truncation integrates one partial effect\nof weight truncation. Namely, high-weight terms have ac-\ncumulated more sinh (or sin) coefficients to become high\nweight and thus tend to have smaller coefficients and thus\nas naturally truncated anyway via coefficient truncation.\nBelow we outline further practical considerations and nu-\nmerical results.\nIV. NUMERICAL IMPLEMENTATION\nPractitioners notes. In this section, we discuss prac-\ntical considerations for performant numerical implemen-\ntations, both ones that are specific to imaginary time\nevolution, as well as ones that apply more broadly to\npropagation methods.\nFor numerical stability and to facilitate coefficient\ntruncation, we (i) continually normalize our representa-\ntion of the state by 1/αI after every gate, and (ii) never\ndivide by the factor 2n in Eq. (6). This is a variant on\nthe necessary normalization by Tr[ρ] that keeps our co-\nefficients at unit scale and less dependent on the number\nof qubits (at least at high temperatures). Our coefficient\ntruncation threshold can then be seen as a relative trun-\ncation threshold to one of the largest terms, the identity\noperator. Neglecting the 2n factor has a flavor of working\nin the normalized Pauli basis, and the factor is automat-\nically, implicitly regained by calculating expectation val-\nues by proceeding as if Tr[I] = 1. Both practices together\nprovide a natural and convenient rescaling.\nThen we would like to draw attention to the choice\nof truncation method. Truncated numerical simulations\noften perform substantially better than their theoretical\nguarantees. At the same time, some truncation strategies\nare more amenable to theoretical analysis than others.\nPutting both observations together, we realize that the\nbest truncation may not be the one that has the most\n(or any) attractive bound. For imaginary time evolution,\nsimilarly to previous experiences with real time evolution,\nwe have found that coefficient truncation is most effective\nin general. We stress that coefficient truncation will be\nstrictly better than the ‘small angle’ truncation scheme\nanalyzed above because we truncate on the exact values\nof the coefficients which will depend on the Hamiltonian\nparameters and can be larger due to merging different\npaths that produce the same Pauli.\nPauli weight and Majorana length truncation do have\ntheir distinct effects for estimating local expectation val-\nues [8, 16] that go beyond what coefficient truncation\nalone can enable. However, we find that in combination\nwith coefficient truncation they often add little and so it\nis preferable to focus on just coefficient truncation. This\nis particularly relevant when aiming to converge a simu-\nlation, i.e., to gain confidence in the result, which is less\ncumbersome with just one truncation parameter. Hence\nin our large scale numerics below we use only coefficient\ntruncation.\nFinally, we would like to highlight our numerical\nimplementation. Until recently, PauliPropagation.jl\nnatively supported only single-threaded dictionary-\nbased propagation. While multi-threaded CPU and\n\n-- 7 of 34 --\n\n8\nFigure 4. Spin correlation in the Fermi-Hubbard model on a triangular lattice. Snapshots of spin-spin correlations\n(CZZ ) emerging in a Fermi-Hubbard model on a 37 site triangular lattice (corresponding to 74 Majorana modes). As we lower\nthe temperature from β = 0 to β = 0.1, we can observe magnetic order and correlations beginning to form around the central\nsite (red). While reaching the deep frustration patterns of lower temperatures (β ∼ 2 to β ∼ 3) remains challenging for current\npropagation techniques, this demonstrates the ability to compute static correlations for complex geometries directly from the\npropagated state.\neven GPU implementations were possible, one would\nlikely run out of memory trying to simulate real-time\ndynamics rather than run out of time, even with a\nsingle CPU thread. Imaginary time evolution, on the\nother hand, appears to be noticeably slower, owing to\nits accelerated branching upon commutation akin to\nthe Heisenberg evolution of global observables in the\nreal-time case. Truncations can keep operator numbers\nin check, but the time per gate remains elevated. We\nare pleased to report that our large-scale results were\ngenerated with array-based propagation that was at\nleast an order of magnitude faster by use of up to 72\nCPU threads with off-the-shelf code publicly available\nvia PauliPropagation.jl. GPU acceleration is already\npossible, but faces continued limitations due to the\nlower memory of everything but the highest-end GPU\nhardware compared to conventional HPC CPU nodes.\nOur work showcases that innovations in the applications\ncan motivate innovation in the algorithms, which we\nbelieve will continue in the future.\nThe J1-J2 Heisenberg Model. As a first practi-\ncal demonstration of our algorithm, we study the\none-dimensional Heisenberg model with both nearest-\nneighbor (J1) and next-nearest-neighbor (J2) interac-\ntions. The Hamiltonian is defined as\nH = J1\nX\ni\n(XiXi+1 + YiYi+1 + ZiZi+1)\n+ J2\nX\ni\n(XiXi+2 + YiYi+2 + ZiZi+2) , (29)\nwhere Xi, Yi, Zi are Pauli operators at site i. The terms\nwith the J1 coefficient represent the standard nearest-\nneighbor Heisenberg exchange. Assuming an antiferro-\nmagnetic coupling (J1 > 0), this term favors an antipar-\nallel alignment of adjacent spins. The J2 terms introduce\na next-nearest-neighbor interaction. When J2 > 0, this\nterm acts as a source of geometrical frustration, as it com-\npetes with the ordering tendency of the J1 term. Here,\nwe use J1 = 1.0 and J2 = 0.5, with a Trotter step of\nτ = 0.02\nFig. 3 depicts our results for preparing states at\nincreasing inverse temperature β for 10, 20, 30, and 40\nqubits using τ = 0.02 in a first-order Trotter approxima-\ntion, and for decreasing coefficient truncation thresholds\n(relative to the identity operator) ranging from 2−9 to\n2−18. We report the energy density, i.e., ⟨H⟩/n, as well\nas the number of Pauli strings that are being generated.\nThe black dashed line at energy density −1.5 denotes the\nenergy density of the ground state in this model, which\ncan be computed to numerical precision using tensor\nnetwork techniques [51]. It is evident that our approach\nis increasingly inefficient in reaching low-temperature\nstates, yet high-temperature states remain trackable\nat scale. The largest β for which the simulations can\nbe trusted can be estimated by the convergence of\noverlapping lines at lower and lower truncations.\nFermi-Hubbard model on a triangular lattice. We fur-\nther consider the Fermi-Hubbard model of interacting\nFermions on a triangular lattice with radial hexagonal\ngeometry. The system is described by the Hamiltonian\nH = − t X\n⟨i,j⟩,σ\n(c†\niσ cjσ + c†\njσ ciσ )\n+ U X\ni\nni↑ni↓ − μ X\ni\nni, (30)\nwhere c†\niσ (ciσ ) creates (annihilates) a Fermion with spin\nσ ∈ {↑, ↓} at site i, niσ = c†\niσ ciσ is the number op-\nerator, μ the chemical potential and ni = ni↑ + ni↓.\nWe explore the strong coupling regime with interaction\nstrengths t = 1, U = 8, similar to other realizations in,\nfor example, Refs. [52, 53]. We tune the chemical po-\n\n-- 8 of 34 --\n\n9\ntential to μ = U/2, which stabilizes the average particle\nnumber to approximately equal the number of sites, i.e.,\nto half-filling. Being mindful of Trotter error and the\nreduced simulation horizon of this more challenging sys-\ntem, we employ a smaller Trotter step of τ = 0.01 and\na randomized order in the evolution under the hopping\nterms.\nAs the temperature sinks, magnetic order and correla-\ntions start to form. We characterize it by the spin-spin\ncorrelation function CZZi between the center site r and\nsite i. It reads\nCZZi = ⟨Zr Zi⟩ − ⟨Zr ⟩⟨Zi⟩, (31)\nwhere Zi = ni↑ − ni↓.\nOur results can be seen in Fig. 4, where in a system\nwith 37 sites (corresponding to 74 Majorana modes) we\nobserve correlations build up as we lower the temperature\nto β = 0.1. Ref. [52, 53] shows by use of a neutral atom\nanalog simulator that thermal states at lower tempera-\nture (β ∼ 2 to β ∼ 3) exhibit frustration and staggered\ncorrelation patterns, temperatures which we can unfor-\ntunately not access with current propagation techniques.\nYet, it is noteworthy that we can start tackling such sys-\ntems with off-the-shelf code, and explore both physical\nphenomena and the potential use of propagation meth-\nods.\nV. DISCUSSION\nIn this work, we introduce a framework for simulating\nthermal states via Pauli and Majorana propagation. It\nutilizes imaginary time evolution applied to maximally\nmixed states in the Schr¨odinger picture to continually\nlower the temperature. At the end of the simulation,\none receives the quantum states “in plain text”, and\ncan readily read off properties of interest. Our high-\nperformance numerical implementation effectively lever-\nages multi-CPU computing resources and can quickly\ngenerate billions of Pauli or Majorana strings.\nWe further provide analytical guarantees for both co-\nefficient and weight truncation strategies which hint to-\nward propagation algorithms being highly capable of sim-\nulating high-temperature states in arbitrary system ge-\nometries. At the same time, both our analysis and nu-\nmerical results indicate that lower temperatures where\nβ ∼ 1 can be very challenging to accurately simulate for\nphysically motivated problems.\nGoing forward, we would like to highlight three re-\nsearch directions. One is the question of when propaga-\ntion methods are the algorithm of choice for simulating\nquantum states. Promising cases include repeated evalu-\nations of high-temperature states with complicated con-\nnectivities. This lends itself, for example, to quantum\nBoltzmann machine training [54]. Another direction is\nthat of ground state exploration. While sheer numbers\nindicate that zero-temperature states are not efficiently\nrepresentable in Pauli or Majorana basis due to being\nexponentially dense, truncated propagation may be use-\nful for estimating or extrapolating ground state energies\n(see, e.g., Ref. [55]). Finally, we would like to highlight\npropagation algorithms natural capabilities in hybridiz-\ning with quantum hardware. We can envision that uni-\ntary circuits for approximate thermal state preparation\ncould be learned or compressed classically [56] for fur-\nther processing on quantum devices once they are mature\nenough.\nCode Availability. The Pauli propagation results\nin this work have been obtained with the open-source\nlibrary PauliPropagation.jl, which now supports imagi-\nnary Pauli rotations. The Majorana propagation results\nin this work have been obtained with the open-source\nlibrary MajoranaPropagation.jl, which is not yet reg-\nistered and will soon support imaginary Majorana\nrotations.\nAcknowledgements. The authors would like to thank\nMatteo D’Anna for his work on MajoranaPropagation.jl.\nThe authors would like to thank Yanting Teng for\ninsightful discussions. MSR acknowledges funding from\nthe 2024 Google PhD Fellowship and the Swiss National\nScience Foundation [grant number 200021-219329] AA\nand ZH acknowledge support from the Sandoz Family\nFoundation-Monique de Meuron program for Academic\nPromotion. RP acknowledges the support of the SNF\nQuantum Flagship Replacement Scheme (Grant No.\n215933).\nAdded note. In the final stages of preparing this\nmanuscript, the authors became aware of independent\nwork demonstrating imaginary time evolution for Pauli\npropagation [57].\n[1] P. Rall, D. Liang, J. Cook, and W. Kretschmer, Simu-\nlation of qubit quantum circuits via pauli propagation,\nPhysical Review A 99, 062337 (2019).\n[2] D. Aharonov, X. Gao, Z. Landau, Y. Liu, and U. Vazi-\nrani, A polynomial-time classical algorithm for noisy ran-\ndom circuit sampling, Proceedings of the 55th Annual\nACM Symposium on Theory of Computing , 945 (2023).\n[3] T. Beguˇsi´c, K. Hejazi, and G. K. Chan, Simulating\nquantum circuit expectation values by Clifford pertur-\nbation theory, The Journal of Chemical Physics 162,\n10.1063/5.0269149 (2025).\n[4] E. Fontana, M. S. Rudolph, R. Duncan, I. Rungger,\nand C. Cˆırstoiu, Classical simulations of noisy varia-\ntional quantum circuits, npj Quantum Information 11,\n1 (2025).\n\n-- 9 of 34 --\n\n10\n[5] Y. Shao, F. Wei, S. Cheng, and Z. Liu, Simulating noisy\nvariational quantum algorithms: A polynomial approach,\nPhysical Review Letters 133, 120603 (2024).\n[6] M. S. Rudolph, E. Fontana, Z. Holmes, and L. Cin-\ncio, Classical surrogate simulation of quantum sys-\ntems with LOWESA, arXiv preprint arXiv:2308.09109\n10.48550/arXiv.2308.09109 (2023).\n[7] T. Schuster, C. Yin, X. Gao, and N. Y. Yao, A\npolynomial-time classical algorithm for noisy quantum\ncircuits, Physical Review X 15, 041018 (2025).\n[8] A. Angrisani, A. Schmidhuber, M. S. Rudolph,\nM. Cerezo, Z. Holmes, and H.-Y. Huang, Classically es-\ntimating observables of noiseless quantum circuits, Phys.\nRev. Lett. 135, 170602 (2025).\n[9] G. Gonz´alez-Garc´ıa, J. I. Cirac, and R. Trivedi, Pauli\npath simulations of noisy quantum circuits beyond aver-\nage case, arXiv preprint arXiv:2407.16068 (2024).\n[10] S. Lerch, R. Puig, M. Rudolph, A. Angrisani, T. Jones,\nM. Cerezo, S. Thanasilp, and Z. Holmes, Efficient\nquantum-enhanced classical simulation for patches of\nquantum landscapes, arXiv preprint arXiv:2411.19896\n10.48550/arXiv.2411.19896 (2024).\n[11] C. Cirstoiu, A fourier analysis framework for approx-\nimate classical simulations of quantum circuits, arXiv\npreprint arXiv:2410.13856 10.48550/arXiv.2410.13856\n(2024).\n[12] A. Angrisani, A. A. Mele, M. S. Rudolph, M. Cerezo,\nand Z. Holmes, Simulating quantum circuits with arbi-\ntrary local noise using pauli propagation, arXiv preprint\narXiv:2501.13101 10.48550/arXiv.2501.13101 (2025).\n[13] B. Fuller, M. C. Tran, D. Lykov, C. Johnson, M. Ross-\nmannek, K. X. Wei, A. He, Y. Kim, D. Vu, K. Sharma,\net al., Improved quantum computation using opera-\ntor backpropagation, arXiv preprint arXiv:2502.01897\nhttps://doi.org/10.48550/arXiv.2502.01897 (2025).\n[14] M. S. Rudolph, T. Jones, Y. Teng, A. Angrisani, and\nZ. Holmes, Pauli propagation: A computational frame-\nwork for simulating quantum systems, arXiv preprint\narXiv:2505.21606 10.48550/arXiv.2505.21606 (2025).\n[15] Y. Teng, S. Y. Chang, M. S. Rudolph, and\nZ. Holmes, Leveraging symmetry merging in\npauli propagation, arXiv preprint arXiv:2512.12094\n10.48550/arXiv.2512.12094 (2025).\n[16] A. Miller, Z. Holmes, ¨O. Salehi, R. Chakraborty,\nA. Nyk¨anen, Z. Zimbor´as, A. Glos, and G. Garc´ıa-\nP´erez, Simulation of fermionic circuits using ma-\njorana propagation, arXiv preprint arXiv:2503.18939\n10.48550/arXiv.2503.18939 (2025).\n[17] F. Alam, J. L. Bosse, I. ˇCepait˙e, A. Chapman, L. Clin-\nton, M. Crichigno, E. Crosson, T. Cubitt, C. Derby,\nO. Dowinton, et al., Fermionic dynamics on a trapped-\nion quantum computer beyond exact classical simulation,\narXiv:2510.26300 (2025).\n[18] F. Alam, J. L. Bosse, I. ˇCepait˙e, A. Chapman, L. Clinton,\nM. Crichigno, E. Crosson, T. Cubitt, C. Derby, O. Dow-\ninton, et al., Programmable digital quantum simulation\nof 2d fermi-hubbard dynamics using 72 superconducting\nqubits, arXiv:2510.26845 (2025).\n[19] M. D’Anna, J. Nys, and J. Carrasquilla, Majorana\nstring simulation of nonequilibrium dynamics in two-\ndimensional lattice fermion systems, arXiv:2511.02809\n(2025).\n[20] G. Facelli, H. Fawzi, and O. Fawzi, Fast con-\nvergence of majorana propagation for weakly in-\nteracting fermions, arXiv preprint arXiv:2601.05226\nhttps://doi.org/10.48550/arXiv.2601.05226 (2026).\n[21] T. Beguˇsi´c, J. Gray, and G. K.-L. Chan, Fast and con-\nverged classical simulations of evidence for the utility of\nquantum computing before fault tolerance, Science Ad-\nvances 10, 10.1126/sciadv.adk4321 (2024).\n[22] N. Loizeau, J. C. Peacock, and D. Sels, Quantum many-\nbody simulations with paulistrings. jl, SciPost Phys.\nCodebases 54, 10.21468/SciPostPhysCodeb.54 (2025).\n[23] M. Minervini, J. Goldman, M. M. Wilde, Z. Holmes,\nand M. S. Rudolph, From strong to weak simulation:\nSampling from quantum states via pauli propagation,\nPreprint (2026), forthcoming.\n[24] E. Campbell, Random compiler for fast Hamiltonian sim-\nulation, Phys. Rev. Lett. 123, 070503 (2019).\n[25] Y. Alhassid, Quantum monte carlo methods for nuclei\nat finite temperature, International Journal of Modern\nPhysics B 15, 1447 (2001).\n[26] S.-Y. Chang, V. Pandharipande, J. Carlson, and K. E.\nSchmidt, Quantum monte carlo studies of superfluid\nfermi gases, Physical Review A—Atomic, Molecular, and\nOptical Physics 70, 043602 (2004).\n[27] K. Van Houcke, S. Rombouts, and L. Pollet, Quantum\nmonte carlo simulation in the canonical ensemble at finite\ntemperature, Physical Review E—Statistical, Nonlinear,\nand Soft Matter Physics 73, 056703 (2006).\n[28] A. Bulgac, J. E. Drut, and P. Magierski, Quantum monte\ncarlo simulations of the bcs-bec crossover at finite tem-\nperature, Physical Review A—Atomic, Molecular, and\nOptical Physics 78, 023625 (2008).\n[29] B. Militzer and K. P. Driver, Development of path in-\ntegral monte carlo simulations with localized nodal sur-\nfaces for second-row elements, Physical Review Letters\n115, 176403 (2015).\n[30] J. Gubernatis, N. Kawashima, and P. Werner, Quan-\ntum Monte Carlo Methods (Cambridge University Press,\n2016).\n[31] M. Troyer and U.-J. Wiese, Computational complexity\nand fundamental limitations to fermionic quantum monte\ncarlo simulations, Physical review letters 94, 170201\n(2005).\n[32] G. A. Baker Jr, H. Gilbert, J. Eve, and G. Rushbrooke,\nHigh-temperature expansions for the spin-1/2 heisenberg\nmodel, Physical Review 164, 800 (1967).\n[33] D. S. Gaunt and G. A. Baker Jr, Low-temperature crit-\nical exponents from high-temperature series: The ising\nmodel, Physical Review B 1, 1184 (1970).\n[34] A. Georges and J. S. Yedidia, How to expand around\nmean-field theory using high-temperature expansions,\nJournal of Physics A: Mathematical and General 24,\n2173 (1991).\n[35] J. M. Sanchez, F. Ducastelle, and D. Gratias, Generalized\ncluster description of multicomponent systems, Physica\nA: Statistical Mechanics and its Applications 128, 334\n(1984).\n[36] V. Blum and A. Zunger, Mixed-basis cluster expan-\nsion for thermodynamics of bcc alloys, Physical Review\nB—Condensed Matter and Materials Physics 70, 155108\n(2004).\n[37] Q. Wu, B. He, T. Song, J. Gao, and S. Shi, Cluster expan-\nsion method and its application in computational mate-\nrials science, Computational Materials Science 125, 243\n\n-- 10 of 34 --\n\n11\n(2016).\n[38] K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin,\nand F. Verstraete, Quantum metropolis sampling, Nature\n471, 87 (2011).\n[39] D. Poulin and P. Wocjan, Sampling from the thermal\nquantum gibbs state and evaluating partition functions\nwith a quantum computer, Physical review letters 103,\n220502 (2009).\n[40] A. N. Chowdhury and R. D. Somma, Quantum algo-\nrithms for gibbs sampling and hitting-time estimation,\nQuantum Information & Computation 17, 41 (2017).\n[41] M. Motta, C. Sun, A. T. Tan, M. J. O’Rourke, E. Ye,\nA. J. Minnich, F. G. Brandao, and G. K.-L. Chan, De-\ntermining eigenstates and thermal states on a quantum\ncomputer using quantum imaginary time evolution, Na-\nture Physics 16, 205 (2020).\n[42] C. Rouz´e, D. S. Fran¸ca, and ´A. M. Alhambra, Optimal\nquantum algorithm for gibbs state preparation, arXiv\npreprint arXiv:2411.04885 10.48550/arXiv.2411.04885\n(2024).\n[43] M. Consiglio, J. Settino, A. Giordano, C. Mastroianni,\nF. Plastina, S. Lorenzo, S. Maniscalco, J. Goold, and\nT. J. G. Apollaro, Variational gibbs state preparation on\nnoisy intermediate-scale quantum devices, Phys. Rev. A\n110, 012445 (2024).\n[44] L. Lin, Dissipative preparation of many-body quantum\nstates: Toward practical quantum advantage, APL Com-\nputational Physics 1, 010901 (2025).\n[45] T. S. Cubitt, Dissipative ground state preparation and\nthe dissipative quantum eigensolver, arXiv preprint\narXiv:2303.11962 10.48550/arXiv.2303.11962 (2023).\n[46] R. Puig, M. Drudis, S. Thanasilp, and Z. Holmes, Varia-\ntional quantum simulation: A case study for understand-\ning warm starts, PRX Quantum 6, 010317 (2025).\n[47] F. Verstraete, J. J. Garcia-Ripoll, and J. I. Cirac, Ma-\ntrix product density operators: Simulation of finite-\ntemperature and dissipative systems, Physical review let-\nters 93, 207204 (2004).\n[48] M. Zwolak and G. Vidal, Mixed-state dynamics in one-\ndimensional quantum lattice systems: A time-dependent\nsuperoperator renormalization algorithm, Physical re-\nview letters 93, 207205 (2004).\n[49] M. M. Wolf, F. Verstraete, M. B. Hastings, and J. I.\nCirac, Area laws in quantum systems: mutual informa-\ntion and correlations, Physical review letters 100, 070502\n(2008).\n[50] E. Stoudenmire and S. R. White, Minimally entangled\ntypical thermal state algorithms, New Journal of Physics\n12, 055026 (2010).\n[51] S. R. White, Density matrix formulation for quantum\nrenormalization groups, Physical Review Letters 69,\n2863 (1992).\n[52] M. Xu, L. H. Kendrick, A. Kale, Y. Gang, G. Ji, R. T.\nScalettar, M. Lebrat, and M. Greiner, Frustration-and\ndoping-induced magnetism in a fermi–hubbard simulator,\nNature 620, 971 (2023).\n[53] A. Sinha, M. M. Rams, P. Czarnik, and J. Dziarmaga,\nFinite-temperature tensor network study of the hubbard\nmodel on an infinite square lattice, Physical Review B\n106, 195105 (2022).\n[54] M. H. Amin, E. Andriyash, J. Rolfe, B. Kulchytskyy, and\nR. Melko, Quantum boltzmann machine, Phys. Rev. X\n8, 021050 (2018).\n[55] C. Shrikhande, A. Bachhar, A. R. Jimenez, and\nN. J. Mayhall, Rapid ground state energy estima-\ntion with a sparse pauli dynamics-enabled variational\ndouble bracket flow, arXiv preprint arXiv:2511.21651\n10.48550/arXiv.2511.21651 (2025).\n[56] M. D’Anna, Y. Zhang, R. Wiersema, M. S. Rudolph,\nand J. Carrasquilla, Circuit compression for 2d\nquantum dynamics, arXiv preprint arXiv:2507.01883\nhttps://doi.org/10.48550/arXiv.2507.01883 (2025).\n[57] R. G´omez-Lurbe and A. P´erez, Pauli\npropagation for imaginary time evolu-\ntion, arXiv preprint arXiv:2601.14400\nhttps://doi.org/10.48550/arXiv.2601.14400 (2026).\n[58] C. Amoruso, E. Marinari, O. C. Martin, and A. Pagnani,\nScalings of domain wall energies in two dimensional ising\nspin glasses, Physical review letters 91, 087201 (2003).\n\n-- 11 of 34 --\n\n12\nAppendix A: Notation\nWe denote the n-qubit Pauli basis by Pn := {I, X, Y, Z}⊗n. Any operator O admits a Pauli expansion\nO = X\nP ∈Pn\ncP P.\nWe define the Pauli-1 norm of O as\n∥O∥Pauli,1 := X\nP ∈Pn\n|cP |.\nWhen no confusion can arise, we use the shorthand ∥o∥1 := ∥O∥Pauli,1.\nAppendix B: Preliminaries\nIn this section, we present basic lemmas that are required for the subsequent proofs.\nLemma 4. Let r(γ) be the number of times the sinh(τ ) branch is taken along a path γ. Then for all τ ∈ (0, 1],\ncosh(τ )L−r(γ) sinh(τ )r(γ) ≤ eLτ 2/2 τ r(γ). (B1)\nProof. For τ ≥ 0 we have sinh(τ ) ≤ τ cosh(τ ). Hence\ncosh(τ )L−r(γ) sinh(τ )r(γ) ≤ cosh(τ )L−r(γ) (τ cosh(τ ))r(γ) = τ r(γ) cosh(τ )L.\nUsing cosh(τ ) ≤ eτ 2/2, we get\nτ r(γ) cosh(τ )L ≤ τ r(γ)eLτ 2/2.\nLemma 5. Consider a matrix A = QJ\nj=1 e−τ Pj I Q1\nj=J e−τ Pj . Then Tr[A] ≥ 2n.\nProof. First, observe that det\u0000e−τ Pj\n\u0001 = e−τ Tr[Pj ] = e0 = 1 for any Pauli operator Pj . Consequently, using the\nmultiplicativity of the determinant, we have det(A) = 1. Then since A is of the form A†A (with A = Q1\nj=J e−τ Pj ),\nit is positive semidefinite (A ⪰ 0). Let d = 2n be the dimension of the Hilbert space. Applying the Arithmetic\nMean-Geometric Mean inequality to the eigenvalues of A, we obtain:\nTr[A]\nd ⩾ det(A)1/d = 1. (B2)\nMultiplying by d yields Tr[A] ≥ 2n.\nDefinition 6 (Max Divergence). Let p and u be two probability distributions on a set E of size M . The (forward)\nmax-divergence of p from u is defined as:\nD∞(p∥u) := log\n\u0012\nmax\ne∈E\np(e)\nu(e)\n\u0013\n= log\n\u0012\nM · max\ne∈E p(e)\n\u0013\n. (B3)\nLemma 7. Let u denote the uniform distribution on a finite set E, i.e., u(e) = 1/M . Let p be any distribution on\nE. If D∞(p∥u) ≤ α, then for every event A ⊆ E,\np(A) ≤ eα u(A). (B4)\nProof. The assumption D∞(p∥u) ≤ α implies pointwise domination:\np(e) ≤ eαu(e) ∀e ∈ E. (B5)\nSumming this inequality over all elements e ∈ A yields the result:\np(A) = X\ne∈A\np(e) ≤ eα X\ne∈A\nu(e) = eαu(A). (B6)\n\n-- 12 of 34 --\n\n13\nProposition 8. Let E be a set of size M . Let weights (We)e∈E be drawn i.i.d. from Unif(0, 1), and define p(e) =\nWe/ P\nf Wf . Let u be the uniform distribution over E. Then, with probability at least 1 − e−M/8, D∞(p∥u) ≤ log 4.\nProof. Let S := P\nf ∈E Wf . Since E[Wf ] = 1/2, E[S] = M/2. By Hoeffding’s inequality:\nPr\n\u0014\nS ≤ M\n4\n\u0015\n≤ exp\n\u0012\n− 2(M/4)2\nM\n\u0013\n= e−M/8. (B7)\nConditioned on S ≥ M/4, for any e ∈ E:\np(e)\nu(e) = We/S\n1/M = M We\nS ≤ M · 1\nM/4 = 4. (B8)\nTaking the logarithm gives D∞(p∥u) ≤ log 4.\nAppendix C: General truncation error\nHere we present a general error bound for a Pauli Propagation scheme where the simulation is restricted to a specific\nsubset of Pauli strings. This will be the starting point to derive both our small angle and weight truncation guarantees\nfor the case of observables.\nLemma 9. Let O be a h-local observable, O = P\nwt(Q)≤h oQQ, and let AL be the unnormalized state obtained after\napplying L steps of an imaginary time evolution e−τ Pt (·)e−τ Pt , where Pt is sampled randomly at each step t. Let\nA ⊆ Pn be an arbitrary set of “allowed” Pauli strings (containing the identity). Let e\tAL be the matrix produced by\ntruncating any Pauli string Q /∈ A at any step. Then, the expected error in the observable expectation value is bounded\nby\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1 E\n\" X\nγ /∈ΓA\nwt(QL(γ))≤h\ncosh(τ )L−r(γ) sinh(τ )r(γ)\n#\n, (C1)\nwhere ΓA is the set of paths that remain strictly within the set A at all steps, and r(γ) is the number of non-identity\nupdates in path γ.\nProof. A Pauli path γ = (Q0, Q1, . . . , QL) ∈ PL+1\nn with Q0 = I is a sequence where each Qt is obtained from Qt−1\nby applying the local update rule in Eq. (4) for the sampled term Pt. For such a path γ, we denote the Pauli string\nat step t by Qt(γ), and the product of the accumulated cosh(τ ) and sinh(τ ) factors by w(γ). We define the set of\nadmissible paths for the truncated recursion as those that never leave the allowed set A:\nΓA := {γ | ∀t ≤ L, Qt(γ) ∈ A}. (C2)\nThe truncated evolution e\tAL has the same path expansion as the full evolution but is restricted to ΓA:\ne\tAL = X\nγ∈ΓA\nw(γ) QL(γ). (C3)\nConsequently, the difference ∆AL := AL − e\tAL is the sum over the excluded (or “killed”) paths:\n∆AL = X\nγ /∈ΓA\nw(γ) QL(γ). (C4)\nThe error in the expectation value of the observable O is therefore:\nTr(O ∆AL) = X\nγ /∈ΓA\nw(γ) Tr\u0000O QL(γ)\u0001 . (C5)\nSince O is h-local, O = P\nwt(Q)≤h oQQ, the term Tr(O QL(γ)) is non-zero only if wt(QL(γ)) ≤ h. Thus, we may\nrestrict the sum to excluded paths that end with a weight ≤ h:\nTr\u0000O(AL − e\tAL)\u0001 = X\nγ /∈ΓA\nwt(QL(γ))≤h\nw(γ) Tr\u0000OQL(γ)\u0001 . (C6)\n\n-- 13 of 34 --\n\n14\nUsing the bound | Tr(OQ)| ≤ 2n|oQ| for any Pauli string Q and applying the triangle inequality, we obtain:\nTr\u0000O(AL − e\tAL)\u0001 ≤ 2n∥o∥1\nX\nγ /∈ΓA\nwt(QL(γ))≤h\n|w(γ)|. (C7)\nFinally, taking the expectation over the random choice of Hamiltonian terms yields\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1 E\n\" X\nγ /∈ΓA\nwt(QL(γ))≤h\n|w(γ)|\n#\n. (C8)\nNoting that |w(γ)| ≤ cosh(τ )L−r(γ) sinh(τ )r(γ) completes the proof.\nAppendix D: Technical lemmas for controlling the normalization via the partition function\nIn this section we derive a bound that can translate an error guarantee for the approximate un-normalized state\n˜\tAL into a bound for the approximate normalized state ˜\tρL = ˜\tAL\nTr[ ˜\tAL] .\nTheorem 10 (Expectation value stability under additive error). Let A ⪰ 0 be a positive semidefinite operator on\na d-dimensional Hilbert space with Z := Tr(A) > 0. Let ˜\tA be an approximation of A, and define ˜\tZ := Tr\n\u0010 ˜\tA\n\u0011\n. We\ndenote the normalized states and the error operator as:\nρ := A\nZ , ˜ρ := ˜\tA\n˜\tZ , ∆ := A − ˜\tA. (D1)\nAssume that for all Pauli operators P with weight |P | ⩽ h, the error satisfies |Tr[∆P ]| ≤ d ε for some ε < Z/d. Then,\nfor all such P ,\n|Tr[P (ρ − ˜ρ)]| ≤ 2dε\nZ − dε . (D2)\nMoreover, if A satisfies Z ≥ d, then for ε < 1:\n|Tr[P (ρ − ˜ρ)]| ≤ 2ε\n1 − ε . (D3)\nProof. We start from the identity:\nρ − ˜ρ = A\nZ − ˜\tA\n˜\tZ = A − ˜\tA\nZ + ˜\tA\n\u0012 1\nZ − 1\n˜\tZ\n\u0013\n= ∆\nZ + ˜\tA ˜\tZ − Z\nZ ˜\tZ\n!\n. (D4)\nMultiplying by P and taking the trace, we apply the triangle inequality:\n|Tr[P (ρ − ˜ρ)]| ≤ |Tr[P ∆]|\nZ + Tr\nh\nP ˜\tA\ni |Z − ˜\tZ|\nZ ˜\tZ . (D5)\nWe now bound each term. By assumption, |Tr[P ∆]| ⩽ dε. Since the identity I is a Pauli operator of weight 0, we\nalso have |Z − ˜\tZ| = | Tr(∆)| ≤ dε. Consequently, ˜\tZ ≥ Z − dε > 0.\nNext, we bound Tr\nh\nP ˜\tA\ni\n. Using ˜\tA = A − ∆, we have:\nTr\nh\nP ˜\tA\ni\n≤ |Tr[P A]| + |Tr[P ∆]|. (D6)\nSince A ⪰ 0 and ∥P ∥∞ = 1, we have |Tr[P A]| ≤ Tr(A) = Z. Thus,\nTr\nh\nP ˜\tA\ni\n≤ Z + dε. (D7)\n\n-- 14 of 34 --\n\n15\nSubstituting these estimates into (D5) gives:\n|Tr[P (ρ − ˜ρ)]| ≤ dε\nZ + (Z + dε) dε\nZ(Z − dε)\n= dε\nZ\n\u0012\n1 + Z + dε\nZ − dε\n\u0013\n= dε\nZ\n\u0012 Z − dε + Z + dε\nZ − dε\n\u0013\n= 2dε\nZ − dε .\nFinally, if Z ≥ d, then d/Z ≤ 1, and substitution yields the simplified bound 2ε\n1−ε .\nTheorem 11. Let A ⪰ 0 be a positive semidefinite operator on a d-dimensional Hilbert space with Z := Tr(A) > 0.\nLet ˜\tA be an approximation of A, and define ˜\tZ := Tr\n\u0010 ˜\tA\n\u0011\n. We denote the normalized states and the error operator as:\nρ := A\nZ , ˜ρ := ˜\tA\n˜\tZ , ∆ := A − ˜\tA. (D8)\nAssume that the error satisfies ∥∆∥1 ≤ d ε for some ε < Z/d. Then,\n∥ρ − ˜ρ∥1 ≤ 2dε\nZ − dε . (D9)\nMoreover, if A satisfies Z ≥ d, then for ε < 1:\n∥ρ − ˜ρ∥1 ≤ 2ε\n1 − ε . (D10)\nProof. The proof is the same as for Theorem 10 substituting the condition | Tr[P ∆]| ⩽ dε by ∥∆∥1 ⩽ dε.\nAppendix E: Small angle truncation\nIn this section we prove error bounds for small angle truncation, presented in Theorem 1. This proof follows a\nsimilar argument to the proof of Theorem 3 in [10]. We start by proving a bound for the error when truncating\nunnormalized matrices in Theorem 12, after applying L steps of imaginary time evolution. To prove this we count the\nmaximum number of paths that we are truncating, and we bound them using counting arguments. In Theorem 13,\nwe combine Theorems 12, and 10 to bound the truncation error for normalized states.\n1. Small angle truncation for unnormalized matrices\nTheorem 12. Let AL be the unnormalized state obtained after applying L steps of an imaginary time evolution\ne−τ Pt (·)e−τ Pt , where Pt is sampled randomly at each step t. Let A ⊆ Pn be all the paths that accumulate less than k\nnon-identity updates ΓA = {γ : r(γ) ≤ k}. Let e\tAL be the state produced by truncating any path γ that contains more\nthan k non-identity updates (i.e., discarding γ if r(γ) > k). If k > eLτ , then\n∥AL − e\tAL∥1 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n. (E1)\nProof. We can slightly modify Lemma 9. Starting from Eq. (C4), where ∆AL = AL − e\tAL\n∆AL = X\nγ /∈ΓA\nw(γ) QL(γ). (E2)\n\n-- 15 of 34 --\n\n16\nwhere ΓA = {γ : r(γ) ≤ k}. Thus we can write\n∥∆AL∥1 =∥ X\nγ:r(γ)>k\nw(γ) QL(γ)∥1 (E3)\n⩽2n X\nγ:r(γ)>k cosh(τ )L−r(γ) sinh(τ )r(γ) . (E4)\nWhere we used triangular inequality to upper-bound all the paths as the sinh, cosh weight times the one norm of any\nPauli string. There are at most \u0000L\nj\n\u0001 paths with exactly j non-identity updates (corresponding to choosing j steps to\napply the sinh branch). Thus, we can bound the sum by:\nSk,L := X\nγ:r(γ)>k\ncosh(τ )L−r(γ) sinh(τ )r(γ)\n⩽\nL\tX\nj=k+1\n\u0012L\nj\n\u0013\ncoshL−j (τ ) sinhj (τ ) . (E5)\nWe factor out the total weight eτ L = (cosh τ + sinh τ )L. Defining p := sinh(τ )/eτ = (1 − e−2τ )/2, we can rewrite the\nterms as:\ncoshL−j (τ ) sinhj (τ ) = eτ L(1 − p)L−j pj . (E6)\nSubstituting this back into the sum, we recognize the tail of a Binomial distribution:\nSk,L ≤ eτ L\nL\tX\nj=k+1\n\u0012L\nj\n\u0013\n(1 − p)L−j pj = eτ L Pr[X > k], where X ∼ Bin(L, p). (E7)\nUsing the standard Chernoff bound for the tail of a binomial distribution, Pr[X > k] ≤\n\u0010 eLp\nk\n\u0011k\nfor k > Lp.\nSince 1 − e−x ≤ x for x ≥ 0, we have p ≤ τ . Thus, for k > eLτ ≥ eLp, the bound simplifies to:\nSk,L ≤ eτ L\n\u0012 eLτ\nk\n\u0013k\n. (E8)\nCombining this with the prefactor 2n∥o∥1 yields the claim\n∥(AL − e\tAL)∥1 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n(E9)\nNow we proceed to use this Theorem to prove that a similar bound holds for normalized quantum states.\n2. Small angle truncation for normalized states\nTheorem 13 (qDRIFT small angle truncation error). Consider the simulation of the thermal state starting from\nthe identity I. The algorithm performs L steps of the map Et(·) = e−τ Pt (·)e−τ Pt , with step angle τ = βΛ\n2L , where\nΛ = P\nj |hj | is the sum of Hamiltonian coefficients. Let ˜ρ be the approximate state obtained by truncating any Pauli\npath that accumulates more than k non-identity updates (i.e., discarding paths with more than k factors of sinh τ ).\nThen\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (E10)\nProof. We first bound the error for the unnormalized state AL. Invoking Theorem 12 with the qDRIFT step size\nτ = βΛ\n2L , the expected additive error is:\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n= 2neβΛ/2\n\u0012 eβΛ\n2k\n\u0013k\n. (E11)\n\n-- 16 of 34 --\n\n17\nTo recover the error for the physical, normalized state ρ = AL/Z, we apply the stability bound from Theorem 10.\nWe observe that for imaginary time evolution starting from I, the partition function satisfies Z = Tr(AL) ≥ Tr(I) = 2n\n(see Lemma 5).\nLet εunnorm denote the RHS of Eq. (E11). The normalized error parameter ε in Theorem 11 is given by ε =\nεunnorm/d, where d = 2n. The dimension factor 2n strictly cancels out:\nε = eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k\n. (E12)\nProvided that k is sufficiently large such that ε < 1, Theorem 10 dictates that the normalized trace distance is\nbounded by 2ε\n1−ε . In the asymptotic limit, this is linear in ε:\n∥ρ − ˜ρ∥1 ∈ O(ε) = O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (E13)\nLemma 14. Assume the model in Theorem 13. Let βΛ = Θ(log n), and choose k = cβΛ. Then the error in\nTheorem 13 scales as\n∥ρ − ˜ρ∥1 ∈ c−Θ(log n) = 1\npoly(n) (E14)\nProof. We start with by substituting k = cβΛ in the bound of Theorem 13\n∥ρ − ˜ρ∥1 ∈ O\n\u0012\neβΛ/2 \u0010 e\n2c\n\u0011cβΛ\u0013\n(E15)\nWe can simplify this by taking the coefficients inside of the order and massaging them to obtain\neβΛ/2 \u0010 e\n2c\n\u0011cβΛ\n=\n\u0012 ec+1/2\n(2c)c\n\u0013βΛ\n⩽ 1∀c ⩾ 3 . (E16)\nTherefore, if we recover Eq. (E15), we find\n∥ρ − ˜ρ∥1 ∈ c−Θ(βΛ) (E17)\nwhere we used that 1/√cc ⩾ ec+1/2\n(2c)c and if we choose βΛ ∈ Θ(log n) we find that the error is polynomially suppressed\nin c, n.\nAppendix F: Weight truncation\nIn this section we prove error bounds for weight truncation, presented in Theorem 2. This proof follows a similar\nargument to the proof of Theorem 3 in [10], and the small angle truncation presented in the previous section. We\nstart by proving Theorem 15, a bound for the error when truncating unnormalized matrices, after applying L steps of\nimaginary time evolution. Differently to the case in the previous appendix, here we consider what is the probability\nthat an truncated path would go back to a Pauli string that could overlap with our observable. We consider this\nby analyzing the probability of going back to a Pauli with weight smaller or equal to the maximum weight of the\nobservable. In Theorem 16, we combine Theorems 15, and 10 to bound the truncation error for normalized states.\nThe resulting bound is less general that the small angle truncation bound in virtue of applying only to the expectation\nvalues of low weight observables, but strictly due to the additional error suppression from the suppressed probability\nof backflow.\nTheorem 15 (Backflow Truncation Bound for Unnormalized Matrices). Consider an imaginary time evolution of L\nsteps with angle τ starting from the identity I. Let e\tAL be the unnormalized operator produced by truncating any Pauli\nstring Q with weight wt(Q) > k.\nLet h be the weight of the observable O. Define m as the minimum number of weight-reducing updates required to\ntransform a Pauli string of weight > k to one of weight ≤ h. Let qbf be the maximum probability that a random update\nreduces the weight of a Pauli string (the “backflow probability”).\n\n-- 17 of 34 --\n\n18\nThe expected error in the observable is bounded by:\nE\u0002| Tr\n\u0010\nO(AL − e\tAL)\n\u0011\n|\u0003 ⩽ 2n∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eLτ qbf\nm\n\u0013m\n. (F1)\nProof. We start from the general bound derived in Lemma 9 (Eq. C8). Using the bound |w(γ)| ≤ eLτ 2/2τ r(γ) (where\nr(γ) is the number of non-identity updates), we have:\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1e 1\n2 Lτ 2\nE\n\" X\nγ∈K\nτ r(γ)\n#\n, (F2)\nwhere K is the set of “killed” paths: those that exceed weight k at some point but end with weight ≤ h.\nAny such path must realize at least m weight-decreasing updates to bridge the gap from weight > k down to h.\nLet D(γ) denote the number of weight decreases in path γ. The condition γ ∈ K implies D(γ) ≥ m.\nWe now bound the expected sum S := E\nh P\nγ∈K τ r(γ)\ni\n. We first sum over the total number of non-identity updates\nr (from m to L). For a fixed r, the number of decreases D follows a distribution bounded by a Binomial distribution\nB(r, qbf ). Thus, we sum over the number of backflow steps j (from m to r):\nS ≤\nL\tX\nr=m\n\u0012L\nr\n\u0013\nτ r\nr\tX\nj=m\n\u0012r\nj\n\u0013\nqbf j . (F3)\nWe use the identity \u0000L\nr\n\u0001\u0000r\nj\n\u0001 = \u0000L\nj\n\u0001\u0000L−j\nr−j\n\u0001 to rearrange the binomial coefficients. This allows us to swap the summation\norder to sum over j first:\nS ≤\nL\tX\nj=m\n\u0012L\nj\n\u0013\nqbf j\nL\tX\nr=j\n\u0012L − j\nr − j\n\u0013\nτ r . (F4)\nWe re-index the inner sum by setting ℓ = r − j. As r goes from j to L, ℓ goes from 0 to L − j:\nL\tX\nr=j\n\u0012L − j\nr − j\n\u0013\nτ r = τ j\nL−j\tX\nℓ=0\n\u0012L − j\nℓ\n\u0013\nτ ℓ\n= τ j (1 + τ )L−j , (F5)\nwhere the last equality follows from the binomial theorem. Substituting this back into the expression for S:\nS ≤\nL\tX\nj=m\n\u0012L\nj\n\u0013\nqbf j τ j (1 + τ )L−j\n=\nL\tX\nj=m\n\u0012L\nj\n\u0013\n(τ qbf )j (1 + τ )L−j . (F6)\nWe now apply the tail bound for the binomial sum: PL\nj=m\n\u0000L\nj\n\u0001aj bL−j ≤ bL\n\u0010 eL(a/b)\nm\n\u0011m\n. Identifying a = τ qbf and\nb = 1 + τ , we get:\nS ≤ (1 + τ )L\n\u0012 eLτ qbf\nm(1 + τ )\n\u0013m\n. (F7)\nSince 1 + τ > 1, we can simplify the denominator to obtain the strict upper bound:\nS ≤ (1 + τ )L\n\u0012 eLτ qbf\nm\n\u0013m\n. (F8)\nFinally, we combine this with the prefactor from Eq. (F2). The total error prefactor is exp\u0000Lτ 2/2\u0001(1 + τ )L. Taking\nthe logarithm and using the Taylor inequality log(1 + τ ) ≤ τ − τ 2\n2 + τ 3\n3 (valid for τ > 0):\n1\n2 Lτ 2 + L log(1 + τ ) ≤ 1\n2 Lτ 2 + L\n\u0012\nτ − τ 2\n2 + τ 3\n3\n\u0013\n= Lτ + 1\n3 Lτ 3. (F9)\n\n-- 18 of 34 --\n\n19\nExponentiating this result gives the final bound:\nE\u0002 Tr\n\u0010\nO(AL − e\tAL)\n\u0011\u0003 ⩽ 2n∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eL τ qbf\nm\n\u0013m\n. (F10)\nNow we proceed to use this Theorem to prove that a similar bound holds for normalized quantum states.\n1. Weight truncation for normalized states\nTheorem 16 (qDRIFT Backflow Error). Consider the qDRIFT simulation of a thermal state starting from the\nidentity I. The algorithm applies L steps of size τ = βΛ\n2L , where Λ = P |hi|. Let ˜ρ be the state obtained by truncating\nany Pauli string with weight exceeding k. Let qbf (k) be the backflow probability at weight k, and let m be the minimum\nnumber of steps required to reduce a Pauli string of weight > k to one overlapping with the h-local observable O.\nProvided that m > eβΛqbf (k)\n2 , the error in the expectation value is bounded by:\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2m\n\u0013m\u0013\n. (F11)\nProof. We begin with the general backflow bound from Theorem 15. For an unnormalized evolution of L steps with\nangle τ , the expected error is:\nE\u0002 Tr\n\u0010\nO(AL − e\tAL)\n\u0011\u0003 ⩽ d∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eL τ qbf (k)\nm\n\u0013m\n. (F12)\nWe substitute the qDRIFT parameters. The total rotation angle is fixed to βΛ/2, so we set τ = βΛ\n2L .\nFirst, we simplify the pre-factor. As L → ∞, the cubic term vanishes:\nLτ + 1\n3 Lτ 3 = βΛ\n2 + 1\n3 L\n\u0012 βΛ\n2L\n\u00133\n= βΛ\n2 + O(L−2) . (F13)\nNext, we substitute τ into the geometric base:\neLτ qbf (k)\nm = eL( βΛ\n2L )qbf (k)\nm = eβΛqbf (k)\n2m . (F14)\nCombining these, the unnormalized error bound is:\nE\u0002|Tr(O∆AL)|\u0003 ∈ O\n\u0012\nd∥o∥1eβΛ/2\n\u0012 eβΛqbf (k)\n2m\n\u0013m\u0013\n. (F15)\nWe can use Markov’s inequality to see that\nPr\u0000|Tr(O∆AL)| < aE\u0002|Tr(O∆AL)|\u0003\u0001 = 1 − Pr\u0000|Tr(O∆AL)| > aE\u0002|Tr(O∆AL)|\u0003\u0001 ⩾ 1 − 1\na (F16)\nTo obtain the error for the physical state ρ = AL/Z, we invoke Theorem 10. We identify the normalized error\nparameter ε by dividing Eq. (F15) by the dimension d:\nε = a∥o∥1eβΛ/2\n\u0012 eβΛqbf (k)\n2m\n\u0013m\n. (F17)\nwith probability at worst 1 − 1/a, where we used Eq. (F16). Assuming the truncation threshold k is large enough\nsuch that ε < 1, the stability theorem guarantees that the normalized error scales as O(ε). Thus obtaining\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2m\n\u0013m\u0013\n. (F18)\nFinally, we note that m is determined by the locality of the Hamiltonian terms. If the maximum weight reduction\nper step is δ (e.g., δ = 2 for commutators of weight-2 Paulis), then m = ⌈(k − h)/δ⌉. This completes the proof.\n\n-- 19 of 34 --\n\n20\nLemma 17. Assume the model in Theorem 20. Let βΛ ∈ O(log(n)), m ∈ Θ(k), and ∥o∥1 ∈ poly(n) then the error\nscales as\n|Tr[O(ρ − ˜ρ)]| ∈\n\u0012 log(n)\nn\n\u0013Θ(k)\n. (F19)\nfor any of the models of qbf (w) considered in Appendix G.\nProof. We start with the bound in Theorem 20. First we see that for any of the models of qbf (w) considered in\nAppendix G are suppressed either quadratically or linearly with the number of qubits n, i.e. qbf (w) ∈ O\u0000 w\nn\n\u0001. Thus,\nqbf (k)βΛ ∈ O\n\u0010 k log n\nn\n\u0011\n. If we substitute this along side with βΛ ∈ O(log(n)), m ∈ Θ(k), and ∥o∥1 ∈ poly(n) we obtain\n|Tr[O(ρ − ˜ρ)]| ∈ O poly(n)\n\u0012 log n\nn\n\u0013k!\n. (F20)\nwhich for sufficiently large k (but k ∈ O(1)) we can further simplify the expression to\n|Tr[O(ρ − ˜ρ)]| ∈\n\u0012 log n\nn\n\u0013Θ(k)\n. (F21)\nAppendix G: Probabilities of Backflow\nIn this section, we derive upper bounds for the backflow probability qbf (w)—the probability that a random update\nreduces the weight of a Pauli string—under different interaction geometries and Hamiltonian distributions. In par-\nticular, we analyze the bounds on the backflow probability qbf (w) under four distinct weight 2 Hamiltonian models,\ndefined by the geometry of the qubit interactions and the probability distribution of the applied gates. A summary\nof the backflow probabilities is provided in Table G.\nAll-to-All Uniform: A fully connected geometry where any two-qubit gate is applied to a pair (i, j) sampled uni-\nformly from all \u0000n\n2\n\u0001 possible edges. This model assumes perfect uniformity in interaction strength across the\nentire system.\nNearest-Neighbor Uniform: A 1D chain geometry where interactions are restricted to adjacent qubits (i, i + 1).\nThe specific edge is sampled uniformly from the n available nearest-neighbor pairs, representing an ideal linear\ntopology.\nGeneral Close-to-Uniform: A model relaxing the uniformity assumption. The probability p(e) of interacting on\nan edge e is arbitrary, provided it does not deviate excessively from the uniform distribution u(e). The deviation\nis constrained by the max-divergence (see Definition 6) D∞(p∥u) ≤ α, which implies the dominance condition\np(e) ≤ eαu(e).\nRandom Hamiltonian: A specific stochastic instance of the general model. Here, the interaction weights for edges\nare drawn i.i.d. from a continuous uniform distribution Unif(−1, 1). We establish that these systems behave as\nclose-to-uniform models with high probability, specifically satisfying the bound with eα ≈ 4. These Hamiltonians\ninclude, for example, Spin Glasses [58].\n1. All-to-all two-body interactions\nLemma 18 (Backflow Probability for All-to-All interactions). Consider a Pauli string Q of weight wt(Q) = w. If we\napply a random two-qubit Pauli gate sampled uniformly from all \u0000n\n2\n\u0001 pairs and all 9 non-identity Pauli combinations,\nthe probability of backflow is bounded by:\nqbf (w) ∈ Θ\n\u0012 w2\nn2\n\u0013\n(G1)\n\n-- 20 of 34 --\n\n21\nTable I. Summary of Backflow Probability Bounds qbf (w).\nModel Geometry Distribution p Backflow Bound qbf (w)\nAll-to-All Interactions\nUniform Complete Uniform (u) ∈ Θ\n\u0012 w2\nn2\n\u0013\nGeneral Complete D∞(p∥u) ≤ α ∈ O\n\u0012 eαw2\nn2\n\u0013\nRandom Complete we ∼ Unif(−1, 1) ∈ O\n\u0012 w2\nn2\n\u0013\nwith probability 1 − e−Θ(n2)\nNearest-Neighbor (NN) Interactions\nUniform 1D Chain Uniform (uNN) ∈ O\n\u0010 w\nn\n\u0011\nGeneral 1D Chain D∞(p∥uNN) ≤ α ∈ O\n\u0012 eαw\nn\n\u0013\nRandom 1D Chain we ∼ Unif(−1, 1) ∈ O\n\u0010 w\nn\n\u0011\nwith probability 1 − e−Θ(n)\nProof. Let S = supp(Q) be the support of the Pauli string, with |S| = w. Suppose an edge e = (i, j) is sampled\nuniformly at random from the \u0000n\n2\n\u0001 possible pairs, and a two-body Pauli operator Pij is sampled uniformly from the 9\npossibilities on that edge.\nTo calculate the conditional probability qbf (w) = Pr(Decay | Commute), we first classify the interaction by the size\nof the overlap r := |{i, j} ∩ S| and analyze the conditions for weight reduction and commutation in each case:\n1. Case r = 0 (Disjoint): The gate acts on two sites where Q is identity.\n• Commutation: The operators always commute ([P, Q] = 0).\n• Weight Change: The weight strictly increases (∆w = +2).\n2. Case r = 1 (Partial Overlap): The gate acts on one site in S and one outside.\n• Commutation: The operators commute if and only if the Pauli matrices match on the single overlapping\nsite (probability 1/3). Otherwise, they anticommute (probability 2/3).\n• Weight Change: If they commute (match), the site in S becomes identity, but the site outside S gains\na Pauli. The net weight change is ∆w = −1 + 1 = 0.\n3. Case r = 2 (Full Overlap): The gate acts on two sites within S.\n• Commutation: The operators commute if they anticommute on an even number of sites (0 or 2). This\nhappens with probability 5/9. They anticommute with probability 4/9.\n• Weight Change: A weight decrease (∆w = −2) occurs only if the gate Pij is the exact inverse of Q on\nboth sites (e.g., Pij = Qi ⊗ Qj ). This specific configuration implies commutation.\nWe now compute the joint probability of decay and commutation, and the total probability of commutation.\nNumerator: Pr(Decay ∩ Commute) Weight decay occurs exclusively in the r = 2 case and requires the specific\nPauli choice that cancels Q.\nPr(Decay ∩ Commute) = Pr(r = 2) × Pr(Cancel | r = 2) (G2)\n=\n\u0000w\n2\n\u0001\n\u0000n\n2\n\u0001 · 1\n9 . (G3)\nIndeed, there are 9 possible Pauli combinations. Only 1 cancels the string Q perfectly. This 1 combination inherently\ncommutes.\n\n-- 21 of 34 --\n\n22\nDenominator: Pr(Commute) It is more convenient to calculate the probability of anticommutation and subtract\nit from 1. Anticommutation occurs in cases r = 1 and r = 2:\nPr(Anticommute) = Pr(r = 1) Pr(Anti | r = 1) + Pr(r = 2) Pr(Anti | r = 2) (G4)\n= w(n − w)\n\u0000n\n2\n\u0001 · 2\n3 +\n\u0000w\n2\n\u0001\n\u0000n\n2\n\u0001 · 4\n9 (G5)\n= 1\n9\u0000n\n2\n\u0001\nh\n6w(n − w) + 4 w(w − 1)\n2\ni\n(G6)\n= 4w(3n − 2w − 1)\n9\u0000n\n2\n\u0001 . (G7)\nTherefore, the probability of commuting is:\nPr(Commute) = 1 − Pr(Anticommute) = 9\u0000n\n2\n\u0001 − 4w(3n − 2w − 1)\n9\u0000n\n2\n\u0001 . (G8)\nThe Ratio Finally, we divide the numerator by the denominator:\nqbf (w) = Pr(Decay ∩ Commute)\nPr(Commute) (G9)\n=\n(w\n2 )\n9(n\n2)\n9(n\n2)−4w(3n−2w−1)\n9(n\n2)\n(G10)\n=\n\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − 4w(3n − 2w − 1) (G11)\n∈ Θ\n\u0012 w2\nn2\n\u0013\n. (G12)\n2. Nearest-neighbor two-body interactions\nLemma 19 (Backflow Bound for Nearest-Neighbor Gates). The probability of backflow qbf (w) for a Pauli string Q of\nweight w, under the application of random nearest-neighbor two-qubit gates on a chain of n qubits, is upper-bounded\nby:\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n(G13)\nProof. Let S = supp(Q) be the support of the Pauli string. We analyze the probability of backflow qbf (w) =\nPr(Decay|Commute) = Pr(Decay∩Commute)\nPr(Commute) by bounding the numerator and denominator separately over all possible\ngeometric configurations of S.\nMaximizing the Numerator (Decay ∩ Commute) Weight decay can only occur if the sampled edge e = (i, i + 1)\nhas non-identity terms in both i and i + 1.\n• Geometric Constraint: The number of bulk edges, denoted kbulk, is maximized when the qubits in S form a\nsingle contiguous block. In this configuration, kbulk = w − 1.\n• Operator Constraint: On a chosen bulk edge, there are 9 equiprobable two-body Pauli operators. Decay\noccurs only if the operator cancels Q on both sites (e.g., P = Qi ⊗ Qi+1). There is exactly 1 such operator out\nof 9. This operator automatically commutes with Q.\nThus, the probability of decay and commutation is bounded by:\nPr(Decay ∩ Commute) = kbulk\nM · 1\n9 ≤ w − 1\n9M . (G14)\nwhere M is the total number of edges possible (M = n − 1 for open boundaries and M = n for closed boundaries).\n\n-- 22 of 34 --\n\n23\nMinimizing the Denominator (Commute) To obtain a robust upper bound on the ratio, we must consider the\nworst-case scenario for the denominator. Minimizing the commutation probability is equivalent to maximizing the\nanticommutation probability.\n• Geometric Constraint: Anticommutation occurs primarily on “boundary” edges (connecting S to non-S)\nwhere the probability is 2/3, versus in edges where there are two Pauli matrices, where it is 4/9. Since 2/3 > 4/9,\nanticommutation is maximized when the number of boundary edges is maximal. This occurs when the errors\nin S are maximally spread out (isolated), creating up to 2w boundary edges.\n• Probability Calculation:\nPr(Anticommute) ≤ 2w\nM · 2\n3 = 4w\n3M . (G15)\nConsequently, the probability of commuting is lower-bounded by:\nPr(Commute) = 1 − Pr(Anticommute) ≥ 1 − 4w\n3M = 3M − 4w\n3M . (G16)\nBounding the Ratio Combining the maximized numerator and the minimized denominator:\nqbf (w) = Pr(Decay ∩ Commute)\nPr(Commute) ≤\nw−1\n9M\n3M −4w\n3M\n(G17)\n= w − 1\n9M · 3M\n3M − 4w (G18)\n= w − 1\n3(3M − 4w) (G19)\n= w − 1\n9M − 12w . (G20)\nIf we have open boundary conditions M = n − 1 and without we have M = n, thus we can write\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n(G21)\n3. General close-to-uniform Hamiltonians\nIn this section, we relax the assumption of perfect uniformity in the sampling of Hamiltonian terms. We characterize\nthe deviation from the uniform distribution using the max-divergence D∞(p∥uNN) (see Definition 6) and derive a\nrobust upper bound on the backflow probability.\nTheorem 20 (Backflow for General Distributions). Let u be the uniform sampling distribution over unordered pairs\nof n qubits. Let p be an arbitrary sampling distribution over these pairs such that its max-divergence from uniform is\nbounded by D∞(p∥u) ≤ α. Then, the probability of backflow qbf (w) under 2-local Pauli gates distributed according to\np is bounded by:\nqbf (w) ∈ O\n\u0012 eαw2\nn2\n\u0013\n(G22)\nProof. Let u be the uniform distribution of sampling one two-body all-to-all Pauli matrix. Let p be a probability\ndistribution such that the max-divergence D∞(p∥u) ≤ α (see Definition 6) implies that for any event E, p(E) ≤\neαu(E). Then in the worst case we find\nqbf (w) = Pr\np (Decay|Commute) = eα Pru(Decay ∩ Commute)\n1 − eα Pru(Commute) (G23)\n\n-- 23 of 34 --\n\n24\nwhere Prp(·) denotes the probability of an event according to distribution p and, similarly, Pru(·) corresponds to the\nuniform. Therefore, recovering the probabilities from Eqs. (G3,G7)\nqbf (w) ⩽ eα\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − eα4w(3n − 2w − 1) (G24)\n∈O\n\u0012 eαw2\nn2\n\u0013\n(G25)\nCorollary 21 (Backflow for Random Hamiltonians). Let the weights of the Hamiltonian terms be chosen i.i.d. from\nUnif(−1, 1), defining a sampling distribution p. With probability at least 1−e−Θ(n2), the backflow probability is bounded\nby:\nqbf (w) ∈ O\n\u0012 w2\nn2\n\u0013\n(G26)\nProof. The coefficient of the Hamiltonian being sampled i.i.d from Unif(−1, 1), is equivalent to sampling them from a\nprobability distribution Unif(0, 1) since qDRIFT does not care about the sign. Then, immediately Proposition 8, we\nknow that with probability ≥ 1 − e−M/8, the distribution p satisfies D∞(p∥u) ≤ log 4 (see Definition 6). Substituting\nα = log 4 (so eα = 4) into Theorem 20 yields the following result immediately\nqbf (w) ⩽ 4\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − 16w(3n − 2w − 1) ∈ O\n\u0012 w2\nn2\n\u0013\n(G27)\n4. Non-uniform Nearest-Neighbor Interactions\nWe now extend the robustness analysis to nearest-neighbor geometries where the sampling of edges may not be\nperfectly uniform, such as in systems with disordered coupling strengths. To prove this we use the Max Divergence\nD∞(p∥uNN), introduced in Definition 6\nTheorem 22 (Backflow for General Nearest-Neighbor Distributions). Let uNN be the uniform distribution over the\nn possible nearest-neighbor edges on a chain. Let p be an arbitrary sampling distribution over these edges such that\nD∞(p∥uNN) ≤ α.\nThen, the probability of backflow qbf (w) for a Pauli string of weight w is bounded by:\nqbf (w) ∈ O\n\u0012 eαw\nn\n\u0013\n(G28)\nProof. Let u be the uniform distribution of sampling one two-body all-to-all Pauli matrix. Let p be a palisaded\ndistribution such that the max-divergence D∞(p∥u) ≤ α (see Definition 6) implies that for any event E, p(E) ≤\neαu(E). Then in the worst case we find\nqbf (w) = Pr\np (Decay|Commute) = eα Pru(Decay ∩ Commute)\n1 − eα Pru(Commute) (G29)\nwhere Prp(·) denotes the provability of an event according to distribution p and, similarly, Pru(·) corresponds to the\nuniform. Therefore, recovering the probabilities from Eqs. (G14,G15)\nqbf (w) ⩽ eα(w − 1)\n9M − eα12w . (G30)\nIf we have open boundary conditions M = n − 1 and without we have M = n, thus we can write\nqbf (w) ∈ O\n\u0012 eαw\nn\n\u0013\n(G31)\n\n-- 24 of 34 --\n\n25\nCorollary 23 (Backflow for Random Nearest-Neighbor Hamiltonians). Let the weights of the nearest-neighbor Hamil-\ntonian terms be chosen i.i.d. from Unif(−1, 1). With probability at least 1 − eΘ(n), the backflow probability is bounded\nby:\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n. (G32)\nProof. The coefficient of the Hamiltonian being sampled i.i.d from Unif(−1, 1), is equivalent to sampling them from a\nprobability distribution Unif(0, 1) since qDRIFT does not care about the sign. Then, by Proposition 8, substituting\nthe number of edges M = Θ(n), the distribution p satisfies D∞(p∥uNN) ≤ log 4 with probability ≥ 1 − e−Θ(n). Setting\neα = 4 in the preceding theorem leads to\nqbf (w) ⩽ 4(w − 1)\n9M − 48w ∈ O\n\u0010 w\nn\n\u0011\n. (G33)\nAppendix H: Extended weight-truncation analysis\n1. Proof outline\nThis section formalizes a simple intuition: for a high-temperature Gibbs operator e−βH , the overlap with a high-\nweight Pauli string Q is typically very small, so discarding high-weight Pauli components can be a controlled ap-\nproximation. While Section F develops this idea for a specific simulation primitive (e.g. qDRIFT ), here we give an\nalternative analysis that applies more broadly to algorithms that build thermal operators by composing general maps,\nand we provide a bound specialized on 1st order Trotter formula. Concretely, we consider a procedure that produces\nan (unnormalized) thermal operator by applying a sequence of maps to the identity:\nAj := M⌊j,1⌋(I) = Mj ◦ Mj−1 ◦ · · · ◦ M1(I), A0 := I.\nTo keep the simulation classically tractable, we introduce a weight-truncated surrogate in which we project onto\nPauli strings of weight < k after each step. Let Π<k denote the projector onto the span of Pauli strings of weight\n< k (equivalently, Π<k discards all Pauli components of weight ≥ k). We define the truncated forward evolution\nrecursively by\ne\tA0 := I, e\tAj := Π<k ◦ Mj\n\u0010 e\tAj−1\n\u0011\n, (j = 1, . . . , L),\nso that e\tAL is obtained from the same forward maps as AL, but with truncation applied between layers.\nGiven an observable O, our estimator is Tr\nh\nO e\tAL\ni\n, intended to approximate Tr[OAL]. It is convenient to evaluate\nthe approximation error in the Heisenberg picture. Since Π<k is self-adjoint with respect to the Hilbert–Schmidt\ninner product, i.e. Π†\n<k = Π<k, one has\nTr\nh\nO e\tAL\ni\n= Tr\nh e\tO0\ni\n,\nwhere the backward-truncated observables are defined by\ne\tOL := O, e\tOj−1 := M†\nj ◦ Π<k\n\u0010 e\tOj\n\u0011\n, (j = L, L − 1, . . . , 1).\nImportantly, the algorithm itself is the forward construction of the truncated surrogate e\tAL, and the backward recursion\nis used only as an analytical tool, which allows to track the truncation error layer-by-layer via a telescoping identity\nthat compares Tr[OAL] and Tr\nh\nO e\tAL\ni\n.\nThe resulting error has two conceptually distinct sources that we bound separately.\n(i) Thermal suppression of high-weight Paulis. The first ingredient is a bound on Pauli expectation values taken on\nthe partially evolved operator M⌊j,1⌋(I),\nmax\nQ:|Q|≥k 2−n Tr\u0000QM⌊j,1⌋(I)\u0001 ≤ Ck.\n\n-- 25 of 34 --\n\n26\nThis formalizes idea that high-weight Paulis have small expectation in the (approximate) Gibbs operator when β is\nsmall enough.\n(ii) Controlling error accumulation under multiple truncations. The second ingredient is to bound the total mass of\nPaulis that can “leak” into the discarded sector during the backward propagation Oj 7 → M†\nj (Oj ). We quantify this\nusing a layerwise Pauli-ℓ1 growth bound and a standard Pauli-path expansion, which together control the total mass\nthat ever reaches weight ≥ k. Combining this with a telescoping identity yields an error bound of the form\n2−n| Tr(O0) − Tr(OAL)| ≲ Ck eδL ∥O∥Pauli,1,\nmaking explicit how accuracy depends on thermal suppression of high-weight Paulis (Ck), and the cumulative growth\nof Pauli-ℓ1 mass under the adjoint layers (eδL).\n2. Moment bound for Pauli expectation values: 1st order Trotter\nLemma 24 (Overlap bound for imaginary-time product-formula evolution). Let H = P\na∈T λaQa be a Pauli Hamil-\ntonian on n qubits with |λa| ≤ 1 and |supp(Qa)| ≤ k for all a ∈ T . Fix an ordering π = (a0, . . . , aM −1) of T (so\nM := |T |) and a step size δ > 0.\nFor integers p ≥ 0 and j ∈ {1, . . . , M − 1}, define the partial product-formula operators\nU (p,j)\nright :=\n\u0010 M\tY\nm=1\neδλam Qam\n\u0011p \u0010 j\tY\nm=1\neδλam Qam\n\u0011\n, U (p,j)\nleft :=\n\u0010 1\tY\nm=j\neδλam Qam\n\u0011 \u0010 1\tY\nm=M\neδλam Qam\n\u0011p\n, (H1)\nConsider the corresponding double-sided evolution from the identity\nXp,j := U (p,j)\nleft I U (p,j)\nright = U (p,j)\nleft U (p,j)\nright .\nFix a Pauli P with R := supp(P ), w := |R|, and set r := ⌈w/k⌉. Let\nTR := {a ∈ T : supp(Qa) ∩ R̸ = ∅}, B := |TR|.\nSet β = (p + 1)δ. Then for all p ≥ 0 and 0 ≤ j < M ,\n2−n Tr(P Xp,j ) ≤\n\u0012 2eβBeδ\nr\n\u0013r\ne2βM . (H2)\nProof. Each gate satisfies the expansion\neδλQ = cosh(δλ)I + sinh(δλ)Q. (H3)\nFix an ordering π = (a0, . . . , aM −1) of the Hamiltonian terms, and let L = pM + j for integers p ≥ 0 and 0 ≤ j < M .\nWe define the squared partial product operator Xp,j := (U (p,j)\nδ )2 by indexing the sequence of 2L gates appropriately.\nBy substituting (H3) into the product and expanding, we obtain a sum over bitstrings y ∈ {0, 1}2L:\nXp,j = X\nz∈{0,1}2L\n2L−1\tY\nt=0\ncosh(δλit )1−zt sinh(δλit )zt\n! 2L−1\tY\nt=0\nQzt\nit\n!\n, (H4)\nwhere Q0 := I and Q1 := Q, and the operators in the final product are ordered by increasing t.\nBy Pauli orthogonality, the Pauli coefficient of P in this expansion equals 2−n Tr(P Xp,j ), hence\n2−n| Tr(P Xp,j )| ≤ X\nz: Q(z)=ωP\n2L\tY\nℓ=1\ncosh(δλℓ) 1−zℓ sinh(δλℓ) zℓ ,\nwhere Q(z) := Q2L−1\nt=0 Qzt\nit denotes the resulting Pauli product.\nLet JR be the set of factor positions ℓ ∈ {1, . . . , 2L} whose Pauli term Qℓ acts nontrivially on R = supp(P ). As Xp,j\nis obtained by performing p full Trotter evolution plus an additional partial Trotter evolution containing j distinct\nimaginary time rotations, and each imaginary time rotation contribute with 2 factor positions, we have\n|JR| ≤ 2(p + 1)B.\n\n-- 26 of 34 --\n\n27\nIf Q(z) = ωP , then the union support of the selected Paulis must contain R. Since each selected Pauli has weight\nat most k, at least r = ⌈w/k⌉ of the selected positions must come from JR. Thus every contributing z satisfies\n|{ℓ ∈ JR : zℓ = 1}| ≥ r.\nApply a union bound over subsets S ⊆ JR with |S| = r. For each fixed S, dropping the constraint Q(z) = ωP only\nincreases the sum, giving\n2−n| Tr(P Xp,j )| ≤ X\nS⊆JR\n|S|=r\nX\nz=(z1,...,z2L)\nzℓ=1 if ℓ∈S\nzℓ∈{0,1} if ℓ̸∈S\nY\nℓ∈S\nsinh(λℓδ)\n\"2L−r\tY\nℓ=0\ncosh1−zℓ (λℓδ) sinhzℓ (λℓδ)\n#\n(H5)\n= X\nS⊆JR\n|S|=r\nsinhr (δ) X\ny∈{0,1}2L−r\n\"2L−r\tY\nt=0\ncosh1−yℓ (δ) sinhyℓ (δ)\n#\n(H6)\nwhere we used that |λℓ| ≤ 1 and therefore | sinh(δλℓ)| ≤ sinh(δ) and | cosh(δλℓ)| ≤ cosh(δ). Then, using the fact that\tP\nx∈{0,1}m\nQm\ni=1 αxi β1−xi = (α + β)m, the sum in y can we rearranged in the following form\n2−n| Tr(P Xp,j )| ≤ X\nS⊆JR, |S|=r\nsinh(δ)r \u0002cosh(δ) + sinh(δ)\u00032L−r . (H7)\nWe can use that cosh(δ) + sinh(δ) = eδ to obtain\n2−n| Tr(P Xp,j )| ≤\n\u0012|JR|\nr\n\u0013\n(sinh δ)r eδ(2L−r) ≤\n\u00122(p + 1)B\nr\n\u0013\n(sinh δ)r e2δ(p+1)M ,\nNote that here we are also considering the terms that have more than r sinh paths, as in Eq. (H7) we consider all the\npaths that have at least r sinh terms.\nUsing \u0000N\nr\n\u0001 ≤ (eN/r)r and sinh δ ≤ δeδ , and setting β = (p + 1)δ, one finds that\n2−n| Tr(P Xp,j )| ≤\n\u00122(p + 1)B\nr\n\u0013\n(sinh δ)r e2δ(p+1)M ≤\n\u0012 2eβBeδ\nr\n\u0013r\ne2βM . (H8)\n3. Weight-truncated Quantum Imaginary-Time Evolution\nLet d := 2n and let Pn = {I, X, Y, Z}⊗n denote the n-qubit Pauli basis. For a linear map M = ML ◦ML−1 ◦· · ·◦M1\nand indices i ≥ j, write\nM⌊i,j⌋ := Mi ◦ Mi−1 ◦ · · · ◦ Mj .\nFor any operator X and Pauli Q ∈ Pn, define its (normalized) Pauli coefficient by\n⟨Q, X⟩ := 1\nd Tr(QX).\nThen Tr(QQ′) = d δQ,Q′ and\nX = X\nQ∈Pn\n⟨Q, X⟩ Q.\nDefine the Pauli-ℓ1 norm by\n∥X∥Pauli,1 := X\nQ∈Pn\n⟨Q, X⟩ = 1\nd\nX\nQ∈Pn\nTr(QX) .\nFor an integer cutoff k ≥ 1, let Π<k and Π≥k denote the projectors onto the span of Pauli strings of weight < k and\n≥ k, respectively:\nΠ<k(X) := X\n|Q|<k\n⟨Q, X⟩ Q, Π≥k(X) := X\n|Q|≥k\n⟨Q, X⟩ Q.\nAssumptions. Let H be a Hamiltonian and fix β ≥ 0. We assume:\n\n-- 27 of 34 --\n\n28\n1. (Layerwise ℓ1-growth bound in the Pauli basis.) For every Pauli P ∈ Pn and every j ∈ [L],\nX\nQ∈Pn\n1\nd Tr\u0000Q M†\nj (P )\u0001 ≤ eδ .\nEquivalently, for every operator X,\n∥M†\nj (X)∥Pauli,1 ≤ eδ ∥X∥Pauli,1. (H9)\n2. (Thermal Pauli expectation bound at weight ≥ k.) Let the partially evolved operator at step j be\nAj := M⌊j,1⌋(I) (A0 := I).\nThere exists a quantity Ck such that\nmax\nQ∈Pn: |Q|≥k\n1\nd |Tr(QAj )| ≤ Ck. (H10)\nWeight-truncated propagation. Given an observable O, define recursively\nOL := O, e\tOj−1 := M†\nj (Oj ), Oj−1 := Π<k( e\tOj−1) (j = L, L − 1, . . . , 1).\nDefine the discarded (high-weight) part at layer j:\n∆j := Π≥k( e\tOj−1) = e\tOj−1 − Oj−1 (j = 1, . . . , L).\nBy construction,\n∥∆j ∥Pauli,1 = X\n|Q|≥k\n⟨Q, ∆j ⟩ = 1\nd\nX\n|Q|≥k\nTr(Q ∆j ) .\nTelescoping identity and truncation error. We compare Tr(O AL) = Tr(OLAL) with the truncated estimate\nTr(O0A0) = Tr(O0).\nLemma 25 (One-step telescoping). For every j ∈ {1, . . . , L},\nTr(Oj Aj ) − Tr(Oj−1Aj−1) = Tr(∆j Aj−1).\nProof. Using Aj = Mj (Aj−1) and duality,\nTr(Oj Aj ) = Tr\u0000Oj Mj (Aj−1)\u0001 = Tr\u0000M†\nj (Oj ) Aj−1\n\u0001 = Tr\n\u0010 e\tOj−1Aj−1\n\u0011\n.\nSince e\tOj−1 = Oj−1 + ∆j , the claim follows.\nSumming Lemma 25 over j yields\nTr(O0) − Tr(OAL) ≤\nL\tX\nj=1\nTr(∆j Aj−1) .\nUsing the Pauli expansion ∆j = P\n|Q|≥k⟨Q, ∆j ⟩Q, we have\nTr(∆j Aj−1) = X\n|Q|≥k\n⟨Q, ∆j ⟩ Tr(QAj−1),\nso by triangle inequality,\n| Tr(∆j Aj−1)| ≤\n\u0010 X\n|Q|≥k\n|⟨Q, ∆j ⟩|\n\u0011\nmax\n|Q|≥k | Tr(QAj−1)| = ∥∆j ∥Pauli,1 max\n|Q|≥k | Tr(QAj−1)|.\nApplying (H10) gives max|Q|≥k | Tr(QAj−1)| ≤ d Ck, hence\nTr(O0) − Tr(OAL) ≤ d Ck\nL\tX\nj=1\n∥∆j ∥Pauli,1. (H11)\n\n-- 28 of 34 --\n\n29\n4. Bounding PL\nj=1 ∥∆j ∥Pauli,1\nFor each layer j and Pauli P , expand M†\nj (P ) in the Pauli basis using trace coefficients:\nM†\nj (P ) = X\nQ∈Pn\nm(j)(Q, P ) Q, m(j)(Q, P ) := ⟨Q, M†\nj (P )⟩ = 1\nd Tr\u0000Q M†\nj (P )\u0001.\nAlso expand\nO = X\nPL∈Pn\n⟨PL, O⟩ PL where ⟨PL, O⟩ = 1\nd Tr(PLO).\nFor a Pauli path γ = (PL, PL−1, . . . , P0) ∈ PL+1\nn define its amplitude\nΦγ := ⟨PL, O⟩\nL\tY\nj=1\nm(j)(Pj−1, Pj ),\nso that\nM†(O) = X\nγ\nΦγ P0.\nDefine the path-ℓ1 mass\n∥M†(O)∥paths,1 := X\nγ\n|Φγ |.\nLemma 26 (Total path mass). Under Assumption 1,\n∥M†(O)∥paths,1 ≤ eδL ∥O∥Pauli,1.\nProof. Assumption 1 is exactly the statement that for every fixed P and j,\nX\nQ∈Pn\n|m(j)(Q, P )| ≤ eδ .\nTherefore,\nX\nγ\n|Φγ | = X\nPL\n|⟨PL, O⟩| X\nPL−1\n|m(L)(PL−1, PL)| · · · X\nP0\n|m(1)(P0, P1)|\n≤ X\nPL\n|⟨PL, O⟩| (eδ )L = eδL ∥O∥Pauli,1.\nLemma 27 (Sum of truncation tails). The truncation tails satisfy\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ ∥M†(O)∥paths,1.\nProof. Partition the set of all paths γ = (PL, . . . , P0) according to the first layer at which the path leaves the low-weight\nsector:\nΓ0 := {γ : |Pi| < k ∀i = 0, 1, . . . , L},\nand for j ∈ {1, . . . , L},\nΓj := {γ : |Pj | < k, |Pj−1| ≥ k, and |Pi| < k for all i = j, j + 1, . . . , L}.\n\n-- 29 of 34 --\n\n30\nThese sets are disjoint and cover all paths.\nFix j ∈ {1, . . . , L} and Q with |Q| ≥ k. By construction of the recursion, ∆j = Π≥k(M†\nj (Oj )) collects exactly those\ncontributions whose first high-weight Pauli occurs at stage j − 1, hence\n⟨Q, ∆j ⟩ = X\nγ∈Γj : Pj−1=Q\nΦγ .\nTherefore, by triangle inequality,\n∥∆j ∥Pauli,1 = X\n|Q|≥k\n|⟨Q, ∆j ⟩| ≤ X\n|Q|≥k\nX\nγ∈Γj : Pj−1=Q\n|Φγ | = X\nγ∈Γj\n|Φγ |.\nSumming over j and using disjointness of the Γj yields\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤\nL\tX\nj=1\nX\nγ∈Γj\n|Φγ | ≤ X\nγ\n|Φγ | = ∥M†(O)∥paths,1.\nCombining (H11) with Lemmas 26 and 27, we obtain\nTr(O0) − Tr(OAL) ≤ d Ck ∥M†(O)∥paths,1 ≤ d Ck eδL ∥O∥Pauli,1.\nIn particular, if ∥O∥Pauli,1 ≤ 1 (e.g. O is a Pauli observable), then\nTr(O0) − Tr(OAL) ≤ d eδL Ck.\n5. Error bound: 1st order Trotter\nTheorem 28 (Truncation error for 1st-order Trotter). Let H = P\na∈T λaQa be a Pauli Hamiltonian on n qubits with\n|λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Fix an ordering π = (a1, . . . , aM ) of T and a step size δ > 0. Let p ≥ 0 and\nset β := (p + 1)δ and L := (p + 1)M . Define the imaginary-time Trotter layers\nMj (X) := eδλaj Qaj X eδλaj Qaj , j = 1, . . . , L,\nwith the periodic convention aj+qM := aj for q = 0, . . . , p. Let Aj := M⌊j,1⌋(I) and let O0 be the weight-< k truncated\nbackward propagation output.\nAssume H has bounded degree ℓ, i.e. each qubit appears in at most ℓ terms Qa. Define\ng := 2e β ℓ w eδ .\nIf g ≤ 1, then for every observable O,\nTr(O0) − Tr(OAL) ≤ d e2δL e2βM g⌈k/w⌉ ∥O∥Pauli,1 = d e4βM g⌈k/w⌉ ∥O∥Pauli,1. (H12)\nIn particular, if ∥O∥Pauli,1 ≤ 1 (e.g. O is a Pauli), then\nTr(O0) − Tr(OAL) ≤ d e4βM g⌈k/w⌉.\nProof. We will apply the strategy described in the previous sections with Aj = M⌊j,1⌋(I).\nLayerwise Pauli-ℓ1 growth. Fix a layer map Mj (X) = GXG with G = eδλQ. For any Pauli P , using G = cosh(δλ)I +\nsinh(δλ)Q,\nGP G = cosh(δλ)2P + cosh(δλ) sinh(δλ)(QP + P Q) + sinh(δλ)2QP Q.\nThis is a linear combination of at most four Paulis, hence\n∥M†\nj (P )∥Pauli,1 = ∥Mj (P )∥Pauli,1 ≤ \u0000| cosh(δλ)| + | sinh(δλ)|\u00012 = e2|δλ| ≤ e2δ .\n\n-- 30 of 34 --\n\n31\nBy linearity, ∥M†\nj (X)∥Pauli,1 ≤ e2δ ∥X∥Pauli,1 for all X. Therefore Lemma 26 gives\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ e2δL ∥O∥Pauli,1. (H13)\nBounding Ck. Fix j ∈ {0, 1, . . . , L} and a Pauli P with |P | ≥ k. Write R := supp(P ), wP := |R|, and set\nr :=\nl wP\nw\nm\n≥\n\u0018 k\nw\n\u0019\n.\nThere exist integers p′ ∈ {0, . . . , p} and j′ ∈ {0, . . . , M − 1} such that Aj = Xp′,j′ in the notation of Lemma 24, with\nβ′ := (p′ + 1)δ ≤ β. Lemma 24 yields\n1\nd | Tr(P Aj )| = 2−n| Tr(P Xp′,j′ )| ≤\n\u0012 2e β′ B eδ\nr\n\u0013r\ne2β′M ≤\n\u0012 2e β B eδ\nr\n\u0013r\ne2βM , (H14)\nwhere B := |{a ∈ T : supp(Qa) ∩ R̸ = ∅}|.\nUsing the bounded-degree assumption, each qubit in R participates in at most ℓ terms, so\nB ≤ ℓ |R| = ℓ wP ≤ ℓ w r.\nSubstituting into (H14) gives\n1\nd | Tr(P Aj )| ≤\n\u0010\n2e β ℓ w eδ \u0011r\ne2βM = g r e2βM .\nSince g ≤ 1 and r ≥ ⌈k/w⌉, we have gr ≤ g⌈k/w⌉, hence for all j and all |P | ≥ k,\n1\nd | Tr(P Aj )| ≤ e2βM g⌈k/w⌉.\nTherefore Assumption (H10) holds with\nCk := e2βM g⌈k/w⌉. (H15)\nConclusion. Plugging (H13) and (H15) into (H11) yields\n| Tr(O0) − Tr(OAL)| ≤ d Ck\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ d (e2βM g⌈k/w⌉) (e2δL∥O∥Pauli,1) = d e4βM g⌈k/w⌉ ∥O∥Pauli,1,\nsince δL = δ(p+1)M = βM .\nCorollary 29 (Truncation error for 1st-order Trotter). Let H = P\na∈T λaQa be a Pauli Hamiltonian on n qubits\nwith |λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Fix an ordering π = (a1, . . . , aM ) of T and a step size δ > 0. Let p ≥ 0\nand set β := (p + 1)δ and L := (p + 1)M . Define the imaginary-time Trotter layers\nMj (X) := eδλaj Qaj X eδλaj Qaj , j = 1, . . . , L,\nwith the periodic convention aj+qM := aj for q = 0, . . . , p. Let ρ := M(I)\nTr[M(I)] and let ˜ρ be the approximate version\nobtained by truncating Pauli operators with weight exceeding k.\nAssume H has bounded degree ℓ, i.e. each qubit appears in at most ℓ terms Qa. Define\ng := 2e β ℓ w eδ .\nIf g ≤ 1, then for every observable O,\nTr(O(ρ − ˜ρ)) ≤ 4 e4βM g⌈k/w⌉ ∥O∥Pauli,1. (H16)\n\n-- 31 of 34 --\n\n32\nProof. Let d = 2n and set\nO′ := O\n∥O∥Pauli,1\n, ε := e4βM g⌈k/w⌉.\nBy Theorem 28 (applied with observable O′), we have\n1\nd Tr\n\u0010\nAL − ˜\tAL\n\u0011\n≤ ε and 1\nd Tr\u0000O′(AL − ˜\tAL)\u0001 ≤ ε. (H17)\nRecall that ρ = AL/ Tr(AL) and ˜ρ = ˜\tAL/ Tr\n\u0010 ˜\tAL\n\u0011\n. We invoke Theorem 10 with A = AL, ˜\tA = ˜\tAL, and O′. Using\n(H17), it yields\nTr \u0000O′(ρ − ˜ρ)\u0001 ≤ 2ε\n1 − ε .\nTherefore,\nTr \u0000O(ρ − ˜ρ)\u0001 = ∥O∥Pauli,1 Tr \u0000O′(ρ − ˜ρ)\u0001 ≤ 2ε\n1 − ε ∥O∥Pauli,1.\nFinally, assume in addition that ε ≤ 1\n2 (which can be ensured by choosing k large enough since g < 1 implies ε → 0\nas k → ∞). Then\n2ε\n1 − ε ≤ 2ε\n1 − 1\n2\n= 4ε,\nand hence\nTr \u0000O(ρ − ˜ρ)\u0001 ≤ 4 ε ∥O∥Pauli,1 = 4 e4βM g⌈k/w⌉ ∥O∥Pauli,1.\nThis proves the claim.\nAppendix I: From Pauli to Majorana propagation\nIn this section, we argue that the main theorems stated for Pauli propagation in the manuscript can be extended\nto the setting of Majorana propagation. We begin by recalling that, for imaginary-time evolution, conjugating a basis\noperator by an elementary gate has the same algebraic form in the Pauli and Majorana cases:\ne− τ\n2 P Q e− τ\n2 P =\n(Q, [P, Q]̸ = 0,\ncosh(τ ) Q − sinh(τ ) P Q, [P, Q] = 0, (I1)\ne− τ\n2 Mb Ma e− τ\n2 Mb =\n(Ma, [Mb, Ma]̸ = 0,\ncosh(τ ) Ma − sinh(τ ) MbMa, [Mb, Ma] = 0. (I2)\nIn particular, in both settings the operator branches only when it commutes with the generator of the imaginary-\ntime step; in that case, the two resulting branches are weighted by hyperbolic coefficients.\nAs a consequence, the small-coefficient truncation analysis (Theorem 1) extends essentially verbatim: it relies\non combinatorial properties of propagation paths and on controlling the accumulation of sinh factors, and these\nfeatures carry over directly to Majorana monomials via (I2). In particular, consider the simulation of the imaginary\ntime evolution for a Hamiltonian H = P\nb hbMb. Start from the identity I, and apply L steps of the map Et(·) =\ne−τ Mb/2(·)e−τ Mb/2, with step angle τ = βΛ\nL , where Λ = P\nb |hb| is the sum of Hamiltonian coefficients. Then, if ˜ρ is\nthe approximate state obtained by truncating any Majorana path that accumulates more than k non-identity updates\n(i.e., discarding paths with more than k factors of sinh τ ), the 1-norm error will scale as\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (I3)\n\n-- 32 of 34 --\n\n33\nTherefore, for any observable O one has\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥O∥∞ eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (I4)\nThe weight-truncation analysis (Theorems 2 and 3) can be adapted in the same spirit. There, we use that non-\nidentity Pauli operators are traceless and square to the identity, implying that the Hilbert–Schmidt inner product\nbetween two Pauli strings is nonzero only if they have identical support (equivalently, they are the same string up to\nphase). We then bound contributions by counting the number of propagation paths that lead to a prescribed support.\nThe same reasoning applies to Majorana monomials: they are likewise traceless (for non-identity monomials) and\nsquare to the identity (up to a sign convention), and their Hilbert–Schmidt overlap is nonzero only when they act on\nthe same set of Majorana modes (i.e., have the same mode support). One can therefore again count the propagation\npaths that produce the relevant mode support and obtain analogous bounds. Before doing so, however, we need\nto establish that the Majorana length (denoted by ℓ) plays the same role as the weight in this proof. Indeed, it is\nsufficient to bound the probability of backflow. Thus, we consider a qDRIFT simulation of a thermal state starting\nfrom the identity I, and let O be a constant length ℓ observable. When applying L steps of size τ = βΛ\nL , where\nΛ = P |hb|, the error in expected value for a state ˜ρ obtained by truncating any Majorana monomial with length\nexceeding ℓmax is\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (ℓmax)\n2ℓmax\n\u0013ℓmax\n!\n, (I5)\nfor a sufficiently large but constant ℓ. Note that qbf (ℓmax) is also the probability of backflow, but will be different for\nthe Majoranas than it is for the Paulis.\nAs for first-order Trotterization, consider a fermionic Hamiltonian H of bounded degree b that can be written as a\nsum of M Majorana monomials, each of length at most w. Proceeding as in the proof of Theorem 3, one can show\nthat, if ˜ρ is obtained by truncating all Majorana monomials of length larger than ℓmax, then the resulting error in the\nexpectation value of any observable O satisfies\nTr\u0002O(ρ − ˜ρ)\u0003 ≤ ∥o∥1 exp\u0000c1 βM \u0001 \u0010\nc2 β b w\n\u0011ℓmax/w\n, (I6)\nwhere c1, c2 > 0 are absolute constants.\nAppendix J: Additional numerical results\nIn Fig. 5 we supplement the results in Fig. 4 with the estimated energy per imaginary time and the number of\nMajorana operators for various coefficient truncation thresholds. The 37-site data corresponds to the system studied\nin the main text, with an imaginary time step of τ = 0.02. It explains how an inverse temperature of β = 0.1 is this\nchallenging: We quickly generate billions of Majorana operators, which have a memory footprint of 74 qubits, i.e., 4\nbits per site. With this and slightly over-allocated auxiliary data structures to compute more quickly, we reach the\nlimit of ∼ 500GB memory computing nodes. Further optimizations are possible, but it does not appear particularly\nlikely that even a factor of 2 would allow significantly further evolution. The 19-site system, equivalent to the 37 sites\nwithout the outermost hexagon layer, can be simulated further, though still notably less than the J1 − J2 data in\nFig. 3.\n\n-- 33 of 34 --\n\n34\nFigure 5. Imaginary time evolution under the Fermi-Hubbard Hamiltonian. A look “under the hood” of the triangular\nlattice simulations from Figure 3. Here we track the energy (top) and the count of Majorana operators (bottom) as imaginary\ntime progresses for 19-site and 37-site systems. The sharp rise in the bottom plots illustrates the “operator-growth barrier”:\neven at a high temperature of β ≈ 0.1, the 37-site simulation generates billions of terms, saturating 500GB of memory. As\nbefore, the diverging lines show where stricter truncation thresholds cause the simulation to lose accuracy.\n\n-- 34 of 34 --\n\n",
      "analysis_json": "{\"title\":\"Thermal State Simulation with Pauli and Majorana Propagation\",\"authors\":[\"Manuel S. Rudolph\",\"Armando Angrisani\",\"Andrew Wright\",\"Iwo Sanderski\",\"Ricard Puig\",\"Zoë Holmes\"],\"publication_year\":\"2026\",\"summary\":\"This paper presents a novel algorithm for simulating finite-temperature quantum states (thermal states) by applying imaginary-time evolution directly to the operator basis (Pauli strings or Majorana monomials). Starting from the infinite-temperature state (the identity operator), the method iteratively cools the system. The key insight is that high-temperature states are sparse in these bases, allowing efficient classical simulation via truncation strategies. The authors provide analytic bounds on truncation errors and validate the method on the 1D J1-J2 Heisenberg model and triangular-lattice Hubbard model.\",\"breakthrough_score\":75,\"breakthrough_reasoning\":\"This work represents a significant methodological advancement by shifting Pauli/Majorana propagation from its traditional use in real-time Heisenberg evolution to imaginary-time Schrödinger evolution. It effectively bridges the gap between high-temperature series expansions and rigorous quantum simulation, offering a sign-problem-free alternative to Monte Carlo for high-to-intermediate temperatures with rigorous error bounds.\",\"key_claims\":[\"High-temperature thermal states are sparse in Pauli and Majorana operator bases.\",\"Imaginary-time evolution can be efficiently approximated by propagating operators and truncating small coefficients or high-weight terms.\",\"The method allows for the direct computation of static correlation functions and energies for complex geometries without topological constraints.\",\"Error due to weight truncation is suppressed by the low probability of operator 'backflow' (high-weight terms reducing to low-weight terms).\"],\"testable_hypotheses\":[{\"hypothesis\":\"The number of significant Pauli terms required to represent a thermal state grows exponentially with inverse temperature (beta).\",\"how_to_test\":\"Simulate a 1D Heisenberg chain, varying beta from 0 to 5. Plot the number of Pauli strings with coefficients above a fixed threshold (e.g., 1e-6) against beta.\",\"expected_outcome\":\"The count should start at 1 (Identity) and grow rapidly as beta increases, confirming the efficiency limit at low temperatures.\"},{\"hypothesis\":\"Weight truncation introduces negligible error for local observables at high temperatures due to suppressed backflow.\",\"how_to_test\":\"Compute the energy of a small system using exact diagonalization and the propagation method with a maximum Pauli weight cutoff (k). Vary k and beta.\",\"expected_outcome\":\"At low beta, low k values should yield high accuracy. As beta increases, the error should scale as described by the derived bounds (super-exponential suppression in k).\"}],\"key_equations\":[{\"name\":\"Imaginary-Time Pauli Update Rule\",\"latex\":\"e^{-\\\\frac{\\\\tau}{2} P} Q e^{-\\\\frac{\\\\tau}{2} P} = \\\\cosh(\\\\tau) Q - \\\\sinh(\\\\tau) P Q \\\\quad (\\\\text{if } [P,Q]=0)\",\"description\":\"Describes how a target Pauli operator Q evolves under an imaginary time rotation generated by Pauli P. If they commute, the term branches into two operators. If they anti-commute, the operator remains unchanged (Q).\",\"variables\":[{\"name\":\"Q\",\"description\":\"The Pauli operator being evolved (initially part of the state expansion).\",\"typical_range\":\"Any Pauli string\"},{\"name\":\"P\",\"description\":\"The Hamiltonian term generating the rotation.\",\"typical_range\":\"Local Pauli term from H\"},{\"name\":\"τ\",\"description\":\"The imaginary time step size (related to temperature step).\",\"typical_range\":\"Small value (e.g., 0.01 - 0.1)\"}]},{\"name\":\"Thermal State Reconstruction\",\"latex\":\"\\\\rho_\\\\beta \\\\approx \\\\frac{\\\\sum \\\\alpha_P P}{2^n \\\\alpha_I}\",\"description\":\"Reconstructs the density matrix from the propagated Pauli coefficients. The partition function is implicitly tracked by the coefficient of the Identity operator.\",\"variables\":[{\"name\":\"α_P\",\"description\":\"The computed coefficient for Pauli string P after propagation.\",\"typical_range\":\"Real number\"},{\"name\":\"α_I\",\"description\":\"The coefficient of the Identity operator, proportional to the partition function.\",\"typical_range\":\"Real number > 0\"},{\"name\":\"n\",\"description\":\"Number of qubits/sites.\",\"typical_range\":\"Integer > 0\"}]}],\"simulation_possibilities\":[{\"title\":\"Interactive Cooling & Branching Tree\",\"description\":\"A visualization of the operator splitting process. Users start with a single 'Identity' node. As they increase inverse temperature (beta) via a slider, they see the operator multiply and branch into new Pauli strings based on the Hamiltonian terms.\",\"complexity\":\"Medium\",\"variables\":[\"Inverse Temperature (β)\",\"Truncation Threshold\",\"Hamiltonian Type (Ising/Heisenberg)\"],\"expected_insights\":\"Users will visually grasp why complexity increases as temperature drops (tree explodes) and how truncation prunes the tree to make simulation possible.\",\"visualization_type\":\"interactive\"},{\"title\":\"Real-time Truncation Sandbox\",\"description\":\"A side-by-side comparison of 'Exact' vs. 'Truncated' evolution for a small grid of spins. One view shows the exact thermal state (via full matrix exponential), the other shows the propagation approximation. A graph plots the error vs. the number of stored operators.\",\"complexity\":\"High\",\"variables\":[\"Max Pauli Weight (k)\",\"Coefficient Cutoff (ε)\",\"System Size\"],\"expected_insights\":\"Demonstrates the trade-off between memory usage (sparsity) and accuracy, verifying the paper's claims about the efficiency of high-T simulations.\",\"visualization_type\":\"chart\"},{\"title\":\"Magnetization Phase Transition Demo\",\"description\":\"Simulate the 2D Transverse Field Ising model. Allow the user to cool the system from infinite temperature. Visualize the magnetization of the grid. Users can observe the emergence of magnetic order as beta passes the critical point (limited by truncation effects).\",\"complexity\":\"High\",\"variables\":[\"Temperature\",\"Transverse Field Strength\",\"Lattice Size\"],\"expected_insights\":\"Shows how microscopic operator evolution leads to macroscopic physical phenomena like phase transitions.\",\"visualization_type\":\"3d\"}],\"field\":\"Quantum Physics\",\"related_fields\":[\"Quantum Simulation\",\"Condensed Matter Physics\",\"Computational Physics\",\"Quantum Algorithms\"],\"limitations\":[\"Computational cost grows exponentially as temperature approaches zero (low T).\",\"Truncation error can accumulate significantly for long imaginary time evolution without careful control.\",\"Memory usage is determined by the sparsity of the state, which degrades in the strongly correlated low-T regime.\"],\"difficulty_to_understand\":\"Advanced\",\"prerequisites\":[\"Quantum Mechanics (Density Matrices)\",\"Pauli/Majorana Operator Algebra\",\"Trotterization / Product Formulas\",\"Imaginary Time Evolution\"]}",
      "created_at": 1770623814279
    }
  },
  "prototypes": {
    "the-q-k-v-matrix-multiplication-step-through-1770308237941": {
      "id": "the-q-k-v-matrix-multiplication-step-through-1770308237941",
      "paper_hash": "bdfaa68d8984f0dc02beaca527b76f207d99b666d31d1da728ee0728182df697",
      "title": "The Q-K-V Matrix Multiplication Step-Through",
      "description": "A step-by-step animation of the math inside a single attention head. Visually represented vectors for Query, Key, and Value. Step 1: Show dot product of Q and K. Step 2: Show scaling and Softmax. Step 3: Show multiplication with V. Users can adjust the vector values manually to see how 'similarity' drives the attention score.",
      "code": "import React, { useState, useMemo } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { ChevronRight, ChevronLeft, Info, Play, RefreshCw, Zap, Sliders } from 'lucide-react';\n\n// --- Math Helpers ---\n\nconst softmax = (arr) => {\n  const max = Math.max(...arr);\n  const exps = arr.map(x => Math.exp(x - max));\n  const sum = exps.reduce((a, b) => a + b, 0);\n  return exps.map(x => x / sum);\n};\n\nconst dotProduct = (v1, v2) => v1.reduce((acc, curr, i) => acc + curr * v2[i], 0);\n\n// --- Components ---\n\nconst MatrixCell = ({ value, label, colorClass, highlight = false, size = \"w-12 h-12\" }) => (\n  <motion.div\n    layout\n    className={`${size} flex flex-col items-center justify-center rounded border border-white/10 text-xs font-mono \n      ${highlight ? 'bg-blue-500/30 border-blue-400' : 'bg-gray-800/50'} \n      ${colorClass || 'text-white'}`}\n  >\n    <span className=\"opacity-50 text-[10px]\">{label}</span>\n    <span className=\"font-bold\">{value.toFixed(2)}</span>\n  </motion.div>\n);\n\nconst Matrix = ({ data, title, colorClass, labels, activeIndices }) => (\n  <div className=\"flex flex-col gap-2\">\n    <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider\">{title}</h3>\n    <div className=\"grid gap-1\" style={{ gridTemplateColumns: `repeat(${data[0]?.length || 1}, minmax(0, 1fr))` }}>\n      {data.map((row, i) => \n        row.map((val, j) => (\n          <MatrixCell \n            key={`${i}-${j}`} \n            value={val} \n            label={labels ? labels[i][j] : `[${i},${j}]`}\n            colorClass={colorClass}\n            highlight={activeIndices?.some(([ri, rj]) => ri === i && rj === j)}\n          />\n        ))\n      )}\n    </div>\n  </div>\n);\n\nexport default function App() {\n  const [step, setStep] = useState(0);\n  const [dk] = useState(4); // Dimension of keys/queries\n  const [seqLen] = useState(3); // Sequence length\n  \n  // Initialize Q, K, V Matrices\n  const [Q, setQ] = useState([\n    [1.0, 0.0, 1.0, 0.0],\n    [0.0, 2.0, 0.0, 1.0],\n    [1.0, 1.0, 1.0, 1.0]\n  ]);\n  const [K, setK] = useState([\n    [1.0, 0.0, 1.0, 0.0],\n    [1.0, 1.0, 0.0, 0.0],\n    [0.0, 0.0, 1.0, 1.0]\n  ]);\n  const [V, setV] = useState([\n    [10, 0, 5, 0],\n    [0, 10, 0, 5],\n    [5, 5, 5, 5]\n  ]);\n\n  // Calculations\n  const calculations = useMemo(() => {\n    // 1. Q * K^T\n    const scores = Q.map(qRow => \n      K.map(kRow => dotProduct(qRow, kRow))\n    );\n\n    // 2. Scaled Scores\n    const scale = Math.sqrt(dk);\n    const scaledScores = scores.map(row => row.map(s => s / scale));\n\n    // 3. Softmax\n    const attentionWeights = scaledScores.map(row => softmax(row));\n\n    // 4. Output (Weights * V)\n    const output = attentionWeights.map(wRow => {\n      const outRow = new Array(V[0].length).fill(0);\n      for (let j = 0; j < V[0].length; j++) {\n        for (let i = 0; i < wRow.length; i++) {\n          outRow[j] += wRow[i] * V[i][j];\n        }\n      }\n      return outRow;\n    });\n\n    return { scores, scaledScores, attentionWeights, output, scale };\n  }, [Q, K, V, dk]);\n\n  const steps = [\n    { \n      title: \"Input Matrices\", \n      desc: \"Queries (Q), Keys (K), and Values (V) are projections of the input embeddings.\",\n      formula: \"Inputs: Q, K, V\",\n      icon: <Sliders className=\"w-5 h-5 text-blue-400\" />\n    },\n    { \n      title: \"1. Dot Product (Compatibility)\", \n      desc: \"Measure similarity between each Query and all Keys. Higher dot product = higher similarity.\",\n      formula: \"Score = Q \\u00B7 K\\u1D40\",\n      icon: <Zap className=\"w-5 h-5 text-yellow-400\" />\n    },\n    { \n      title: \"2. Scaling\", \n      desc: `Divide by \\u221A d\\u2094 (\\u221A${dk}=${calculations.scale.toFixed(2)}) to prevent large values from vanishing gradients in Softmax.`,\n      formula: \"Scaled = Score / \\u221A d\\u2094\",\n      icon: <Info className=\"w-5 h-5 text-emerald-400\" />\n    },\n    { \n      title: \"3. Softmax (Attention Weights)\", \n      desc: \"Convert scores to probabilities. Each row sums to 1.0. This determines 'how much' to focus on each value.\",\n      formula: \"Weights = Softmax(Scaled)\",\n      icon: <Play className=\"w-5 h-5 text-purple-400\" />\n    },\n    { \n      title: \"4. Weighted Sum (Final Value)\", \n      desc: \"Multiply weights by Values (V). The result is a new representation for each token, informed by its context.\",\n      formula: \"Output = Weights \\u00B7 V\",\n      icon: <RefreshCw className=\"w-5 h-5 text-pink-400\" />\n    }\n  ];\n\n  const updateMatrix = (matrix, setter, i, j, val) => {\n    const newM = [...matrix];\n    newM[i] = [...newM[i]];\n    newM[i][j] = parseFloat(val);\n    setter(newM);\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white p-4 md:p-8 font-sans\">\n      {/* Header */}\n      <div className=\"max-w-6xl mx-auto mb-8\">\n        <div className=\"flex items-center gap-3 mb-2\">\n          <div className=\"p-2 bg-blue-500 rounded-lg\">\n            <Zap className=\"w-6 h-6 text-white\" />\n          </div>\n          <h1 className=\"text-2xl font-bold\">Scaled Dot-Product Attention</h1>\n        </div>\n        <p className=\"text-gray-400\">Step-by-step validation of the mechanism proposed in \"Attention Is All You Need\".</p>\n        \n        <div className=\"mt-6 flex flex-wrap gap-4\">\n          <div className=\"bg-gray-900 border border-white/10 rounded-xl p-4 flex-1 min-w-[300px]\">\n            <div className=\"text-xs uppercase text-gray-500 font-bold mb-2\">Core Equation</div>\n            <div className=\"text-xl font-mono text-blue-400\">\n              Attention(Q, K, V) = softmax( <span className=\"underline\">Q Kᵀ</span> / √dₖ ) V\n            </div>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"max-w-6xl mx-auto grid grid-cols-1 lg:grid-cols-3 gap-8\">\n        \n        {/* Left: Interactive Controls */}\n        <div className=\"lg:col-span-1 space-y-6\">\n          <div className=\"bg-gray-900 border border-white/10 rounded-2xl p-6\">\n            <div className=\"flex justify-between items-center mb-6\">\n              <h2 className=\"font-bold flex items-center gap-2\">\n                {steps[step].icon}\n                Step {step}: {steps[step].title}\n              </h2>\n            </div>\n            \n            <p className=\"text-sm text-gray-300 mb-4 leading-relaxed\">\n              {steps[step].desc}\n            </p>\n\n            <div className=\"bg-black/40 rounded-lg p-3 font-mono text-center text-blue-300 border border-blue-500/20 mb-6\">\n              {steps[step].formula}\n            </div>\n\n            <div className=\"flex gap-2\">\n              <button \n                onClick={() => setStep(Math.max(0, step - 1))}\n                disabled={step === 0}\n                className=\"flex-1 py-2 bg-gray-800 hover:bg-gray-700 disabled:opacity-30 rounded-lg transition flex items-center justify-center gap-1\"\n              >\n                <ChevronLeft className=\"w-4 h-4\" /> Back\n              </button>\n              <button \n                onClick={() => setStep(Math.min(steps.length - 1, step + 1))}\n                disabled={step === steps.length - 1}\n                className=\"flex-1 py-2 bg-blue-600 hover:bg-blue-500 disabled:opacity-30 rounded-lg transition flex items-center justify-center gap-1\"\n              >\n                Next <ChevronRight className=\"w-4 h-4\" />\n              </button>\n            </div>\n          </div>\n\n          <div className=\"bg-gray-900 border border-white/10 rounded-2xl p-6\">\n            <h3 className=\"text-sm font-bold text-gray-400 uppercase mb-4\">Live Parameter Tuning</h3>\n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2\">Query Vector 0, Dim 1</label>\n                <input \n                  type=\"range\" min=\"0\" max=\"5\" step=\"0.1\" \n                  value={Q[0][1]} \n                  onChange={(e) => updateMatrix(Q, setQ, 0, 1, e.target.value)}\n                  className=\"w-full accent-blue-500\"\n                />\n              </div>\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2\">Key Vector 0, Dim 0</label>\n                <input \n                  type=\"range\" min=\"0\" max=\"5\" step=\"0.1\" \n                  value={K[0][0]} \n                  onChange={(e) => updateMatrix(K, setK, 0, 0, e.target.value)}\n                  className=\"w-full accent-orange-500\"\n                />\n              </div>\n              <div className=\"text-[10px] text-gray-500 italic mt-4\">\n                * Adjusting these values changes the dot product similarity and updates the attention weights in real-time.\n              </div>\n            </div>\n          </div>\n        </div>\n\n        {/* Right: Visualization Canvas */}\n        <div className=\"lg:col-span-2 bg-gray-900/50 border border-white/10 rounded-2xl p-6 overflow-x-auto\">\n          <div className=\"flex flex-col gap-12 min-w-[600px]\">\n            \n            {/* Row 1: Q and K (Step 0-1) */}\n            <div className=\"flex items-start justify-between gap-8\">\n              <Matrix data={Q} title=\"Queries (Q)\" colorClass=\"text-blue-400\" />\n              <div className=\"mt-12 text-2xl font-bold text-gray-700\">×</div>\n              <Matrix data={K} title=\"Keys (K)\" colorClass=\"text-orange-400\" />\n              \n              <AnimatePresence>\n                {step >= 1 && (\n                  <motion.div \n                    initial={{ opacity: 0, x: 20 }} animate={{ opacity: 1, x: 0 }}\n                    className=\"flex items-center gap-8\"\n                  >\n                    <div className=\"mt-12 text-2xl font-bold text-gray-700\">=</div>\n                    <Matrix \n                      data={calculations.scores} \n                      title=\"Raw Scores\" \n                      colorClass=\"text-yellow-400\"\n                      highlight={step === 1}\n                    />\n                  </motion.div>\n                )}\n              </AnimatePresence>\n            </div>\n\n            {/* Row 2: Scaling and Softmax (Step 2-3) */}\n            <AnimatePresence>\n              {step >= 2 && (\n                <motion.div \n                  initial={{ opacity: 0, y: 20 }} animate={{ opacity: 1, y: 0 }}\n                  className=\"flex items-center justify-center gap-12 border-t border-white/5 pt-12\"\n                >\n                  <Matrix \n                    data={calculations.scaledScores} \n                    title=\"Scaled Scores (/√dk)\" \n                    colorClass=\"text-emerald-400\"\n                    highlight={step === 2}\n                  />\n                  <div className=\"mt-12 flex flex-col items-center\">\n                    <ChevronRight className=\"text-gray-600 mb-1\" />\n                    <span className=\"text-[10px] uppercase text-gray-600 font-bold tracking-widest\">Softmax</span>\n                  </div>\n                  <Matrix \n                    data={calculations.attentionWeights} \n                    title=\"Attention Weights\" \n                    colorClass=\"text-purple-400\"\n                    highlight={step === 3}\n                  />\n                </motion.div>\n              )}\n            </AnimatePresence>\n\n            {/* Row 3: Final Output (Step 4) */}\n            <AnimatePresence>\n              {step >= 4 && (\n                <motion.div \n                  initial={{ opacity: 0, y: 20 }} animate={{ opacity: 1, y: 0 }}\n                  className=\"flex items-start justify-between gap-8 border-t border-white/5 pt-12\"\n                >\n                  <div className=\"flex items-start gap-8\">\n                    <Matrix data={calculations.attentionWeights} title=\"Weights\" colorClass=\"text-purple-400\" />\n                    <div className=\"mt-12 text-2xl font-bold text-gray-700\">×</div>\n                    <Matrix data={V} title=\"Values (V)\" colorClass=\"text-pink-400\" />\n                  </div>\n                  <div className=\"mt-12 text-2xl font-bold text-gray-700\">=</div>\n                  <Matrix \n                    data={calculations.output} \n                    title=\"Output (Contextualized)\" \n                    colorClass=\"text-white\"\n                    highlight={true}\n                    size=\"w-16 h-12\"\n                  />\n                </motion.div>\n              )}\n            </AnimatePresence>\n\n          </div>\n        </div>\n      </div>\n\n      {/* Logic Validation Footer */}\n      <div className=\"max-w-6xl mx-auto mt-8 grid grid-cols-1 md:grid-cols-2 gap-4\">\n        <div className=\"bg-emerald-500/10 border border-emerald-500/20 rounded-xl p-4\">\n          <h4 className=\"text-emerald-400 text-sm font-bold flex items-center gap-2 mb-2\">\n            <Zap className=\"w-4 h-4\" /> Why Scaling Matters?\n          </h4>\n          <p className=\"text-xs text-gray-400 leading-relaxed\">\n            As dk grows, the magnitude of dot products increases. This pushes softmax into regions where gradients are extremely small. \n            Dividing by √dk (currently {calculations.scale.toFixed(2)}) stabilizes training. Try increasing the input values above to see how \n            the \"Attention Weights\" shift significantly.\n          </p>\n        </div>\n        <div className=\"bg-blue-500/10 border border-blue-500/20 rounded-xl p-4\">\n          <h4 className=\"text-blue-400 text-sm font-bold flex items-center gap-2 mb-2\">\n            <Zap className=\"w-4 h-4\" /> Context Injection\n          </h4>\n          <p className=\"text-xs text-gray-400 leading-relaxed\">\n            Note how the Output matrix values are a blend of the Values (V). If Weight [0,0] is high, \n            Output row 0 will look mostly like Value row 0. This is how the model \"attends\" to specific information.\n          </p>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "algorithm_info": "",
      "history": [
        {
          "role": "user",
          "parts": [
            {
              "text": "Task: Create a prototype for \"The Q-K-V Matrix Multiplication Step-Through\".\nContext: A step-by-step animation of the math inside a single attention head. Visually represented vectors for Query, Key, and Value. Step 1: Show dot product of Q and K. Step 2: Show scaling and Softmax. Step 3: Show multiplication with V. Users can adjust the vector values manually to see how 'similarity' drives the attention score.\n\nFULL PAPER CONTENT:\nProvided proper attribution is provided, Google hereby grants permission to\nreproduce the tables and figures in this paper solely for use in journalistic or\nscholarly works.\nAttention Is All You Need\nAshish Vaswani∗\nGoogle Brain\navaswani@google.com\nNoam Shazeer∗\nGoogle Brain\nnoam@google.com\nNiki Parmar∗\nGoogle Research\nnikip@google.com\nJakob Uszkoreit∗\nGoogle Research\nusz@google.com\nLlion Jones∗\nGoogle Research\nllion@google.com\nAidan N. Gomez∗ †\nUniversity of Toronto\naidan@cs.toronto.edu\nŁukasz Kaiser∗\nGoogle Brain\nlukaszkaiser@google.com\nIllia Polosukhin∗ ‡\nillia.polosukhin@gmail.com\nAbstract\nThe dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to\nbe superior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-German translation task, improving over the existing best results, including\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\nbest models from the literature. We show that the Transformer generalizes well to\nother tasks by applying it successfully to English constituency parsing both with\nlarge and limited training data.\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\nattention and the parameter-free position representation and became the other person involved in nearly every\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\nour research.\n†Work performed while at Google Brain.\n‡Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\narXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n\n-- 1 of 15 --\n\n1 Introduction\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35 , 2 , 5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21 ] and conditional\ncomputation [ 32 ], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2, 19 ]. In all but a few cases [ 27 ], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16 ], ByteNet [ 18 ] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [12 ]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5, 2 , 35].\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n[10], consuming the previously generated symbols as additional input when generating the next.\n2\n\n-- 2 of 15 --\n\nFigure 1: The Transformer - model architecture.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\nrespectively.\n3.1 Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\nwise fully connected feed-forward network. We employ a residual connection [ 11 ] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position i can depend only on the known outputs at positions less than i.\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n3\n\n-- 3 of 15 --\n\nScaled Dot-Product Attention Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimension dk, and values of dimension dv . We compute the dot products of the\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V ) = softmax( QKT\n√dk\n)V (1)\nThe two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof 1\t√dk\n. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values of dk [3 ]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1\t√dk\n.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yielding dv -dimensional\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\ni=1 qiki, has mean 0 and variance dk .\n4\n\n-- 4 of 15 --\n\noutput values. These are concatenated and once again projected, resulting in the final values, as\ndepicted in Figure 2.\nMulti-head attention allows the model to jointly attend to information from different representation\nsubspaces at different positions. With a single attention head, averaging inhibits this.\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\nwhere headi = Attention(QW Q\ni , KW K\ni , V W V\ni )\nWhere the projections are parameter matrices W Q\ni ∈ Rdmodel×dk , W K\ni ∈ Rdmodel×dk , W V\ni ∈ Rdmodel×dv\nand W O ∈ Rhdv ×dmodel .\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\nis similar to that of single-head attention with full dimensionality.\n3.2.3 Applications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\nand the memory keys and values come from the output of the encoder. This allows every\nposition in the decoder to attend over all positions in the input sequence. This mimics the\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n[38, 2, 9].\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\nand queries come from the same place, in this case, the output of the previous layer in the\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\nencoder.\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\nall positions in the decoder up to and including that position. We need to prevent leftward\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\nof the softmax which correspond to illegal connections. See Figure 2.\n3.3 Position-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\nconnected feed-forward network, which is applied to each position separately and identically. This\nconsists of two linear transformations with a ReLU activation in between.\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\nWhile the linear transformations are the same across different positions, they use different parameters\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\ndf f = 2048.\n3.4 Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\nlinear transformation, similar to [ 30 ]. In the embedding layers, we multiply those weights by √dmodel.\n5\n\n-- 5 of 15 --\n\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\nLayer Type Complexity per Layer Sequential Maximum Path Length\nOperations\nSelf-Attention O(n2 · d) O(1) O(1)\nRecurrent O(n · d2) O(n) O(n)\nConvolutional O(k · n · d2) O(1) O(logk(n))\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\n3.5 Positional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\norder of the sequence, we must inject some information about the relative or absolute position of the\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\nlearned and fixed [9].\nIn this work, we use sine and cosine functions of different frequencies:\nP E(pos,2i) = sin(pos/100002i/dmodel )\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\nchose this function because we hypothesized it would allow the model to easily learn to attend by\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\nP Epos.\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\nduring training.\n4 Why Self-Attention\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\ntional layers commonly used for mapping one variable-length sequence of symbol representations\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\nconsider three desiderata.\nOne is the total computational complexity per layer. Another is the amount of computation that can\nbe parallelized, as measured by the minimum number of sequential operations required.\nThe third is the path length between long-range dependencies in the network. Learning long-range\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\nability to learn such dependencies is the length of the paths forward and backward signals have to\ntraverse in the network. The shorter these paths between any combination of positions in the input\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\nthe maximum path length between any two input and output positions in networks composed of the\ndifferent layer types.\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\n6\n\n-- 6 of 15 --\n\nlength n is smaller than the representation dimensionality d, which is most often the case with\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\n[38 ] and byte-pair [31 ] representations. To improve computational performance for tasks involving\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\nthe input sequence centered around the respective output position. This would increase the maximum\npath length to O(n/r). We plan to investigate this approach further in future work.\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\nbetween any two positions in the network. Convolutional layers are generally more expensive than\nrecurrent layers, by a factor of k. Separable convolutions [6 ], however, decrease the complexity\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\nthe approach we take in our model.\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\nand semantic structure of the sentences.\n5 Training\nThis section describes the training regime for our models.\n5.1 Training Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\nvocabulary [38 ]. Sentence pairs were batched together by approximate sequence length. Each training\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\ntarget tokens.\n5.2 Hardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\n(3.5 days).\n5.3 Optimizer\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\nrate over the course of training, according to the formula:\nlrate = d−0.5\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\nwarmup_steps = 4000.\n5.4 Regularization\nWe employ three types of regularization during training:\n7\n\n-- 7 of 15 --\n\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\nModel BLEU Training Cost (FLOPs)\nEN-DE EN-FR EN-DE EN-FR\nByteNet [18] 23.75\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\nTransformer (base model) 27.3 38.1 3.3 · 1018\nTransformer (big) 28.4 41.8 2.3 · 1019\nResidual Dropout We apply dropout [ 33] to the output of each sub-layer, before it is added to the\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\nPdrop = 0.1.\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [ 36 ]. This\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n6 Results\n6.1 Machine Translation\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\nthe competitive models.\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\ndropout rate Pdrop = 0.1, instead of 0.3.\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\nused beam search with a beam size of 4 and length penalty α = 0.6 [ 38 ]. These hyperparameters\nwere chosen after experimentation on the development set. We set the maximum output length during\ninference to input length + 50, but terminate early when possible [38].\nTable 2 summarizes our results and compares our translation quality and training costs to other model\narchitectures from the literature. We estimate the number of floating point operations used to train a\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\nsingle-precision floating-point capacity of each GPU 5.\n6.2 Model Variations\nTo evaluate the importance of different components of the Transformer, we varied our base model\nin different ways, measuring the change in performance on English-to-German translation on the\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\n8\n\n-- 8 of 15 --\n\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\nper-word perplexities.\nN dmodel dff h dk dv Pdrop ϵls train PPL BLEU params\nsteps (dev) (dev) ×106\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\n(A)\n1 512 512 5.29 24.9\n4 128 128 5.00 25.5\n16 32 32 4.91 25.8\n32 16 16 5.01 25.4\n(B) 16 5.16 25.1 58\n32 5.01 25.4 60\n(C)\n2 6.11 23.7 36\n4 5.19 25.3 50\n8 4.88 25.5 80\n256 32 32 5.75 24.5 28\n1024 128 128 4.66 26.0 168\n1024 5.12 25.4 53\n4096 4.75 26.2 90\n(D)\n0.0 5.77 24.6\n0.2 4.95 25.5\n0.0 4.67 25.3\n0.2 5.47 25.7\n(E) positional embedding instead of sinusoids 4.92 25.7\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\ncheckpoint averaging. We present these results in Table 3.\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\nsinusoidal positional encoding with learned positional embeddings [ 9], and observe nearly identical\nresults to the base model.\n6.3 English Constituency Parsing\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\nPenn Treebank [ 25], about 40K training sentences. We also trained it in a semi-supervised setting,\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\n[37 ]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\nfor the semi-supervised setting.\nWe performed only a small number of experiments to select the dropout, both attention and residual\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\nremained unchanged from the English-to-German base translation model. During inference, we\n9\n\n-- 9 of 15 --\n\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\nof WSJ)\nParser Training WSJ 23 F1\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\nTransformer (4 layers) WSJ only, discriminative 91.3\nZhu et al. (2013) [40] semi-supervised 91.3\nHuang & Harper (2009) [14] semi-supervised 91.3\nMcClosky et al. (2006) [26] semi-supervised 92.1\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\nTransformer (4 layers) semi-supervised 92.7\nLuong et al. (2015) [23] multi-task 93.0\nDyer et al. (2016) [8] generative 93.3\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\nfor both WSJ only and the semi-supervised setting.\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\nprisingly well, yielding better results than all previously reported models with the exception of the\nRecurrent Neural Network Grammar [8].\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\nParser [29] even when training only on the WSJ training set of 40K sentences.\n7 Conclusion\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\nmulti-headed self-attention.\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\nmodel outperforms even all previously reported ensembles.\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\nplan to extend the Transformer to problems involving input and output modalities other than text and\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\nThe code we used to train and evaluate our models is available at https://github.com/\ntensorflow/tensor2tensor.\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\ncomments, corrections and inspiration.\nReferences\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450, 2016.\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\nreading. arXiv preprint arXiv:1601.06733, 2016.\n10\n\n-- 10 of 15 --\n\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\nmachine translation. CoRR, abs/1406.1078, 2014.\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\npreprint arXiv:1610.02357, 2016.\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\nnetwork grammars. In Proc. of NAACL, 2016.\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\narXiv:1308.0850, 2013.\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 770–778, 2016.\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\n9(8):1735–1780, 1997.\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\nLanguage Processing, pages 832–841. ACL, August 2009.\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\nInformation Processing Systems, (NIPS), 2016.\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR), 2016.\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\n2017.\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nIn International Conference on Learning Representations, 2017.\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722, 2017.\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\narXiv:1703.03130, 2017.\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n11\n\n-- 11 of 15 --\n\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\npages 152–159. ACL, June 2006.\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\nmodel. In Empirical Methods in Natural Language Processing, 2016.\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\n2006.\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\npreprint arXiv:1608.05859, 2016.\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\nlayer. arXiv preprint arXiv:1701.06538, 2017.\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\nLearning Research, 15(1):1929–1958, 2014.\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\nInc., 2015.\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\nAdvances in Neural Information Processing Systems, 2015.\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144, 2016.\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\n1: Long Papers), pages 434–443. ACL, August 2013.\n12\n\n-- 12 of 15 --\n\nAttention VisualizationsInput-Input Layer5\nIt\t\nis\nin\nthis\nspirit\nthat\na\t\nmajority\t\nof\nAmerican\t\ngovernments\t\nhave\npassed\t\nnew\nlaws\nsince\n2009\nmaking\t\nthe\nregistration\t\nor\nvoting\t\nprocess\t\nmore\ndifficult\t\n.\t\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nIt\t\nis\nin\nthis\nspirit\nthat\na\nmajority\nof\nAmerican\ngovernments\nhave\npassed\nnew\nlaws\nsince\n2009\nmaking\nthe\nregistration\nor\nvoting\nprocess\nmore\ndifficult\n.\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\n13\n\n-- 13 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\nand 6. Note that the attentions are very sharp for this word.\n14\n\n-- 14 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\nsentence. We give two such examples above, from two different heads from the encoder self-attention\nat layer 5 of 6. The heads clearly learned to perform different tasks.\n15\n\n-- 15 of 15 --\n\n"
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "code": "import React, { useState, useMemo } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { ChevronRight, ChevronLeft, Info, Play, RefreshCw, Zap, Sliders } from 'lucide-react';\n\n// --- Math Helpers ---\n\nconst softmax = (arr) => {\n  const max = Math.max(...arr);\n  const exps = arr.map(x => Math.exp(x - max));\n  const sum = exps.reduce((a, b) => a + b, 0);\n  return exps.map(x => x / sum);\n};\n\nconst dotProduct = (v1, v2) => v1.reduce((acc, curr, i) => acc + curr * v2[i], 0);\n\n// --- Components ---\n\nconst MatrixCell = ({ value, label, colorClass, highlight = false, size = \"w-12 h-12\" }) => (\n  <motion.div\n    layout\n    className={`${size} flex flex-col items-center justify-center rounded border border-white/10 text-xs font-mono \n      ${highlight ? 'bg-blue-500/30 border-blue-400' : 'bg-gray-800/50'} \n      ${colorClass || 'text-white'}`}\n  >\n    <span className=\"opacity-50 text-[10px]\">{label}</span>\n    <span className=\"font-bold\">{value.toFixed(2)}</span>\n  </motion.div>\n);\n\nconst Matrix = ({ data, title, colorClass, labels, activeIndices }) => (\n  <div className=\"flex flex-col gap-2\">\n    <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider\">{title}</h3>\n    <div className=\"grid gap-1\" style={{ gridTemplateColumns: `repeat(${data[0]?.length || 1}, minmax(0, 1fr))` }}>\n      {data.map((row, i) => \n        row.map((val, j) => (\n          <MatrixCell \n            key={`${i}-${j}`} \n            value={val} \n            label={labels ? labels[i][j] : `[${i},${j}]`}\n            colorClass={colorClass}\n            highlight={activeIndices?.some(([ri, rj]) => ri === i && rj === j)}\n          />\n        ))\n      )}\n    </div>\n  </div>\n);\n\nexport default function App() {\n  const [step, setStep] = useState(0);\n  const [dk] = useState(4); // Dimension of keys/queries\n  const [seqLen] = useState(3); // Sequence length\n  \n  // Initialize Q, K, V Matrices\n  const [Q, setQ] = useState([\n    [1.0, 0.0, 1.0, 0.0],\n    [0.0, 2.0, 0.0, 1.0],\n    [1.0, 1.0, 1.0, 1.0]\n  ]);\n  const [K, setK] = useState([\n    [1.0, 0.0, 1.0, 0.0],\n    [1.0, 1.0, 0.0, 0.0],\n    [0.0, 0.0, 1.0, 1.0]\n  ]);\n  const [V, setV] = useState([\n    [10, 0, 5, 0],\n    [0, 10, 0, 5],\n    [5, 5, 5, 5]\n  ]);\n\n  // Calculations\n  const calculations = useMemo(() => {\n    // 1. Q * K^T\n    const scores = Q.map(qRow => \n      K.map(kRow => dotProduct(qRow, kRow))\n    );\n\n    // 2. Scaled Scores\n    const scale = Math.sqrt(dk);\n    const scaledScores = scores.map(row => row.map(s => s / scale));\n\n    // 3. Softmax\n    const attentionWeights = scaledScores.map(row => softmax(row));\n\n    // 4. Output (Weights * V)\n    const output = attentionWeights.map(wRow => {\n      const outRow = new Array(V[0].length).fill(0);\n      for (let j = 0; j < V[0].length; j++) {\n        for (let i = 0; i < wRow.length; i++) {\n          outRow[j] += wRow[i] * V[i][j];\n        }\n      }\n      return outRow;\n    });\n\n    return { scores, scaledScores, attentionWeights, output, scale };\n  }, [Q, K, V, dk]);\n\n  const steps = [\n    { \n      title: \"Input Matrices\", \n      desc: \"Queries (Q), Keys (K), and Values (V) are projections of the input embeddings.\",\n      formula: \"Inputs: Q, K, V\",\n      icon: <Sliders className=\"w-5 h-5 text-blue-400\" />\n    },\n    { \n      title: \"1. Dot Product (Compatibility)\", \n      desc: \"Measure similarity between each Query and all Keys. Higher dot product = higher similarity.\",\n      formula: \"Score = Q \\u00B7 K\\u1D40\",\n      icon: <Zap className=\"w-5 h-5 text-yellow-400\" />\n    },\n    { \n      title: \"2. Scaling\", \n      desc: `Divide by \\u221A d\\u2094 (\\u221A${dk}=${calculations.scale.toFixed(2)}) to prevent large values from vanishing gradients in Softmax.`,\n      formula: \"Scaled = Score / \\u221A d\\u2094\",\n      icon: <Info className=\"w-5 h-5 text-emerald-400\" />\n    },\n    { \n      title: \"3. Softmax (Attention Weights)\", \n      desc: \"Convert scores to probabilities. Each row sums to 1.0. This determines 'how much' to focus on each value.\",\n      formula: \"Weights = Softmax(Scaled)\",\n      icon: <Play className=\"w-5 h-5 text-purple-400\" />\n    },\n    { \n      title: \"4. Weighted Sum (Final Value)\", \n      desc: \"Multiply weights by Values (V). The result is a new representation for each token, informed by its context.\",\n      formula: \"Output = Weights \\u00B7 V\",\n      icon: <RefreshCw className=\"w-5 h-5 text-pink-400\" />\n    }\n  ];\n\n  const updateMatrix = (matrix, setter, i, j, val) => {\n    const newM = [...matrix];\n    newM[i] = [...newM[i]];\n    newM[i][j] = parseFloat(val);\n    setter(newM);\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white p-4 md:p-8 font-sans\">\n      {/* Header */}\n      <div className=\"max-w-6xl mx-auto mb-8\">\n        <div className=\"flex items-center gap-3 mb-2\">\n          <div className=\"p-2 bg-blue-500 rounded-lg\">\n            <Zap className=\"w-6 h-6 text-white\" />\n          </div>\n          <h1 className=\"text-2xl font-bold\">Scaled Dot-Product Attention</h1>\n        </div>\n        <p className=\"text-gray-400\">Step-by-step validation of the mechanism proposed in \"Attention Is All You Need\".</p>\n        \n        <div className=\"mt-6 flex flex-wrap gap-4\">\n          <div className=\"bg-gray-900 border border-white/10 rounded-xl p-4 flex-1 min-w-[300px]\">\n            <div className=\"text-xs uppercase text-gray-500 font-bold mb-2\">Core Equation</div>\n            <div className=\"text-xl font-mono text-blue-400\">\n              Attention(Q, K, V) = softmax( <span className=\"underline\">Q Kᵀ</span> / √dₖ ) V\n            </div>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"max-w-6xl mx-auto grid grid-cols-1 lg:grid-cols-3 gap-8\">\n        \n        {/* Left: Interactive Controls */}\n        <div className=\"lg:col-span-1 space-y-6\">\n          <div className=\"bg-gray-900 border border-white/10 rounded-2xl p-6\">\n            <div className=\"flex justify-between items-center mb-6\">\n              <h2 className=\"font-bold flex items-center gap-2\">\n                {steps[step].icon}\n                Step {step}: {steps[step].title}\n              </h2>\n            </div>\n            \n            <p className=\"text-sm text-gray-300 mb-4 leading-relaxed\">\n              {steps[step].desc}\n            </p>\n\n            <div className=\"bg-black/40 rounded-lg p-3 font-mono text-center text-blue-300 border border-blue-500/20 mb-6\">\n              {steps[step].formula}\n            </div>\n\n            <div className=\"flex gap-2\">\n              <button \n                onClick={() => setStep(Math.max(0, step - 1))}\n                disabled={step === 0}\n                className=\"flex-1 py-2 bg-gray-800 hover:bg-gray-700 disabled:opacity-30 rounded-lg transition flex items-center justify-center gap-1\"\n              >\n                <ChevronLeft className=\"w-4 h-4\" /> Back\n              </button>\n              <button \n                onClick={() => setStep(Math.min(steps.length - 1, step + 1))}\n                disabled={step === steps.length - 1}\n                className=\"flex-1 py-2 bg-blue-600 hover:bg-blue-500 disabled:opacity-30 rounded-lg transition flex items-center justify-center gap-1\"\n              >\n                Next <ChevronRight className=\"w-4 h-4\" />\n              </button>\n            </div>\n          </div>\n\n          <div className=\"bg-gray-900 border border-white/10 rounded-2xl p-6\">\n            <h3 className=\"text-sm font-bold text-gray-400 uppercase mb-4\">Live Parameter Tuning</h3>\n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2\">Query Vector 0, Dim 1</label>\n                <input \n                  type=\"range\" min=\"0\" max=\"5\" step=\"0.1\" \n                  value={Q[0][1]} \n                  onChange={(e) => updateMatrix(Q, setQ, 0, 1, e.target.value)}\n                  className=\"w-full accent-blue-500\"\n                />\n              </div>\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2\">Key Vector 0, Dim 0</label>\n                <input \n                  type=\"range\" min=\"0\" max=\"5\" step=\"0.1\" \n                  value={K[0][0]} \n                  onChange={(e) => updateMatrix(K, setK, 0, 0, e.target.value)}\n                  className=\"w-full accent-orange-500\"\n                />\n              </div>\n              <div className=\"text-[10px] text-gray-500 italic mt-4\">\n                * Adjusting these values changes the dot product similarity and updates the attention weights in real-time.\n              </div>\n            </div>\n          </div>\n        </div>\n\n        {/* Right: Visualization Canvas */}\n        <div className=\"lg:col-span-2 bg-gray-900/50 border border-white/10 rounded-2xl p-6 overflow-x-auto\">\n          <div className=\"flex flex-col gap-12 min-w-[600px]\">\n            \n            {/* Row 1: Q and K (Step 0-1) */}\n            <div className=\"flex items-start justify-between gap-8\">\n              <Matrix data={Q} title=\"Queries (Q)\" colorClass=\"text-blue-400\" />\n              <div className=\"mt-12 text-2xl font-bold text-gray-700\">×</div>\n              <Matrix data={K} title=\"Keys (K)\" colorClass=\"text-orange-400\" />\n              \n              <AnimatePresence>\n                {step >= 1 && (\n                  <motion.div \n                    initial={{ opacity: 0, x: 20 }} animate={{ opacity: 1, x: 0 }}\n                    className=\"flex items-center gap-8\"\n                  >\n                    <div className=\"mt-12 text-2xl font-bold text-gray-700\">=</div>\n                    <Matrix \n                      data={calculations.scores} \n                      title=\"Raw Scores\" \n                      colorClass=\"text-yellow-400\"\n                      highlight={step === 1}\n                    />\n                  </motion.div>\n                )}\n              </AnimatePresence>\n            </div>\n\n            {/* Row 2: Scaling and Softmax (Step 2-3) */}\n            <AnimatePresence>\n              {step >= 2 && (\n                <motion.div \n                  initial={{ opacity: 0, y: 20 }} animate={{ opacity: 1, y: 0 }}\n                  className=\"flex items-center justify-center gap-12 border-t border-white/5 pt-12\"\n                >\n                  <Matrix \n                    data={calculations.scaledScores} \n                    title=\"Scaled Scores (/√dk)\" \n                    colorClass=\"text-emerald-400\"\n                    highlight={step === 2}\n                  />\n                  <div className=\"mt-12 flex flex-col items-center\">\n                    <ChevronRight className=\"text-gray-600 mb-1\" />\n                    <span className=\"text-[10px] uppercase text-gray-600 font-bold tracking-widest\">Softmax</span>\n                  </div>\n                  <Matrix \n                    data={calculations.attentionWeights} \n                    title=\"Attention Weights\" \n                    colorClass=\"text-purple-400\"\n                    highlight={step === 3}\n                  />\n                </motion.div>\n              )}\n            </AnimatePresence>\n\n            {/* Row 3: Final Output (Step 4) */}\n            <AnimatePresence>\n              {step >= 4 && (\n                <motion.div \n                  initial={{ opacity: 0, y: 20 }} animate={{ opacity: 1, y: 0 }}\n                  className=\"flex items-start justify-between gap-8 border-t border-white/5 pt-12\"\n                >\n                  <div className=\"flex items-start gap-8\">\n                    <Matrix data={calculations.attentionWeights} title=\"Weights\" colorClass=\"text-purple-400\" />\n                    <div className=\"mt-12 text-2xl font-bold text-gray-700\">×</div>\n                    <Matrix data={V} title=\"Values (V)\" colorClass=\"text-pink-400\" />\n                  </div>\n                  <div className=\"mt-12 text-2xl font-bold text-gray-700\">=</div>\n                  <Matrix \n                    data={calculations.output} \n                    title=\"Output (Contextualized)\" \n                    colorClass=\"text-white\"\n                    highlight={true}\n                    size=\"w-16 h-12\"\n                  />\n                </motion.div>\n              )}\n            </AnimatePresence>\n\n          </div>\n        </div>\n      </div>\n\n      {/* Logic Validation Footer */}\n      <div className=\"max-w-6xl mx-auto mt-8 grid grid-cols-1 md:grid-cols-2 gap-4\">\n        <div className=\"bg-emerald-500/10 border border-emerald-500/20 rounded-xl p-4\">\n          <h4 className=\"text-emerald-400 text-sm font-bold flex items-center gap-2 mb-2\">\n            <Zap className=\"w-4 h-4\" /> Why Scaling Matters?\n          </h4>\n          <p className=\"text-xs text-gray-400 leading-relaxed\">\n            As dk grows, the magnitude of dot products increases. This pushes softmax into regions where gradients are extremely small. \n            Dividing by √dk (currently {calculations.scale.toFixed(2)}) stabilizes training. Try increasing the input values above to see how \n            the \"Attention Weights\" shift significantly.\n          </p>\n        </div>\n        <div className=\"bg-blue-500/10 border border-blue-500/20 rounded-xl p-4\">\n          <h4 className=\"text-blue-400 text-sm font-bold flex items-center gap-2 mb-2\">\n            <Zap className=\"w-4 h-4\" /> Context Injection\n          </h4>\n          <p className=\"text-xs text-gray-400 leading-relaxed\">\n            Note how the Output matrix values are a blend of the Values (V). If Weight [0,0] is high, \n            Output row 0 will look mostly like Value row 0. This is how the model \"attends\" to specific information.\n          </p>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
                  "title": "The Q-K-V Matrix Multiplication Step-Through"
                }
              }
            }
          ]
        }
      ],
      "created_at": 1770310074849,
      "updated_at": 1770310721837
    },
    "interactive-self-attention-heatmap-1770313097235": {
      "id": "interactive-self-attention-heatmap-1770313097235",
      "paper_hash": "bdfaa68d8984f0dc02beaca527b76f207d99b666d31d1da728ee0728182df697",
      "title": "Interactive Transformer Self-Attention Heatmap",
      "description": "A text input interface where users type a sentence. The visualization displays the self-attention matrix (Q x K^T). Hovering over a word highlights which other words it is 'looking at' and how strongly. Users can switch between the 8 different 'heads' to see how different heads focus on grammar, recent words, or long-term dependencies.",
      "code": "import React, { useState, useMemo, useEffect } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { Brain, Settings, Info, ChevronRight, Zap, Layers, MousePointer2 } from 'lucide-react';\n\n// Pseudo-random deterministic generator for consistent \"learned\" weights\nconst mulberry32 = (a) => {\n  return () => {\n    let t = a += 0x6D2B79F5;\n    t = Math.imul(t ^ t >>> 15, t | 1);\n    t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n    return ((t ^ t >>> 14) >>> 0) / 4294967296;\n  };\n};\n\n// Generate deterministic vector for a token\nconst getWordVector = (word, dim, seed = 0) => {\n  const hash = word.split('').reduce((acc, char) => acc + char.charCodeAt(0), 0);\n  const rand = mulberry32(hash + seed);\n  return Array.from({ length: dim }, () => rand() * 2 - 1);\n};\n\n// Main Attention Calculation Implementation\n// Based on: Attention(Q, K, V) = softmax(QK^T / sqrt(dk))\nfunction calculateAttention(tokens, headIndex, dk = 64) {\n  const n = tokens.length;\n  if (n === 0) return [];\n\n  // 1. Generate Query and Key vectors for each token\n  // In a real model, these are learned projections Wq, Wk. \n  // Here we simulate the projection by using head-specific seeds.\n  const Q = tokens.map(t => getWordVector(t, dk, headIndex * 100));\n  const K = tokens.map(t => getWordVector(t, dk, headIndex * 200 + 5));\n\n  // 2. Compute QK^T\n  let scores = Array(n).fill(0).map(() => Array(n).fill(0));\n  for (let i = 0; i < n; i++) {\n    for (let j = 0; j < n; j++) {\n      let dotProduct = 0;\n      for (let k = 0; k < dk; k++) {\n        dotProduct += Q[i][k] * K[j][k];\n      }\n      // Scale by sqrt(dk) as per paper section 3.2.1\n      scores[i][j] = dotProduct / Math.sqrt(dk);\n    }\n  }\n\n  // 3. Apply Softmax across rows\n  const attentionMatrix = scores.map(row => {\n    const maxVal = Math.max(...row); // For numerical stability\n    const exps = row.map(v => Math.exp(v - maxVal));\n    const sumExps = exps.reduce((a, b) => a + b, 0);\n    return exps.map(v => v / sumExps);\n  });\n\n  return attentionMatrix;\n}\n\nconst HEAD_DESCRIPTIONS = [\n  { name: \"Global Context\", behavior: \"Looks at all tokens broadly to understand the overall theme.\" },\n  { name: \"Local Syntax\", behavior: \"Focuses on immediately adjacent words (n-1, n+1).\" },\n  { name: \"Self-Identity\", behavior: \"Strong focus on the token itself. Acts as a pass-through.\" },\n  { name: \"Long-Range\", behavior: \"Attends to tokens far back in the sentence (anaphora resolution).\" },\n  { name: \"Noun-Verb\", behavior: \"Learned dependency mapping between subjects and actions.\" },\n  { name: \"Delimiter\", behavior: \"Focuses on punctuation and sentence boundaries.\" },\n  { name: \"Positional\", behavior: \"Attends to specific relative offsets regardless of content.\" },\n  { name: \"Redundancy\", behavior: \"Cross-checks information already processed in earlier layers.\" }\n];\n\nexport default function App() {\n  const [inputText, setInputText] = useState(\"The animal didn't cross the street because it was too tired.\");\n  const [activeHead, setActiveHead] = useState(0);\n  const [hoveredWordIndex, setHoveredWordIndex] = useState(null);\n  const [showValues, setShowValues] = useState(false);\n\n  const tokens = useMemo(() => {\n    return inputText.trim().split(/\\s+/).filter(t => t.length > 0);\n  }, [inputText]);\n\n  const attentionMatrix = useMemo(() => {\n    return calculateAttention(tokens, activeHead);\n  }, [tokens, activeHead]);\n\n  const getColor = (val) => {\n    // Transformer visualization standard: Blue-to-White or Purple-to-White\n    return `rgba(96, 165, 250, ${Math.pow(val, 0.7)})`; // Using power to emphasize lower values\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-slate-200 font-sans selection:bg-blue-500/30\">\n      {/* Header */}\n      <header className=\"border-b border-white/10 bg-gray-900/50 backdrop-blur-md sticky top-0 z-50\">\n        <div className=\"max-w-6xl mx-auto px-6 py-4 flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            <div className=\"p-2 bg-blue-600 rounded-lg shadow-lg shadow-blue-500/20\">\n              <Brain className=\"w-6 h-6 text-white\" />\n            </div>\n            <div>\n              <h1 className=\"text-xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-white to-gray-400\">\n                Transformer Self-Attention\n              </h1>\n              <p className=\"text-xs text-gray-500 font-medium tracking-wider uppercase\">Attention Is All You Need (2017)</p>\n            </div>\n          </div>\n          <div className=\"flex items-center gap-4 text-sm font-medium\">\n            <a href=\"https://arxiv.org/abs/1706.03762\" target=\"_blank\" className=\"text-gray-400 hover:text-white transition-colors\">ArXiv Paper</a>\n          </div>\n        </div>\n      </header>\n\n      <main className=\"max-w-6xl mx-auto px-6 py-8 grid grid-cols-1 lg:grid-cols-12 gap-8\">\n        \n        {/* Left Column: Controls & Input */}\n        <div className=\"lg:col-span-4 space-y-6\">\n          <section className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5 shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-blue-400\">\n              <Zap className=\"w-4 h-4\" />\n              <h2 className=\"text-sm font-bold uppercase tracking-widest\">Input Sequence</h2>\n            </div>\n            <textarea\n              value={inputText}\n              onChange={(e) => setInputText(e.target.value)}\n              className=\"w-full h-32 bg-gray-950 border border-white/10 rounded-xl p-4 text-sm focus:ring-2 focus:ring-blue-500 focus:border-transparent outline-none transition-all resize-none\"\n              placeholder=\"Type a sentence to visualize attention...\"\n            />\n            <div className=\"mt-2 text-xs text-gray-500 flex justify-between\">\n              <span>{tokens.length} tokens detected</span>\n              <button onClick={() => setInputText(\"The animal didn't cross the street because it was too tired.\")} className=\"hover:underline\">Reset to example</button>\n            </div>\n          </section>\n\n          <section className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5 shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-purple-400\">\n              <Layers className=\"w-4 h-4\" />\n              <h2 className=\"text-sm font-bold uppercase tracking-widest\">Attention Heads (h=8)</h2>\n            </div>\n            <div className=\"grid grid-cols-4 gap-2 mb-6\">\n              {Array.from({ length: 8 }).map((_, i) => (\n                <button\n                  key={i}\n                  onClick={() => setActiveHead(i)}\n                  className={`py-2 rounded-lg text-sm font-bold transition-all ${\n                    activeHead === i \n                    ? 'bg-blue-600 text-white shadow-lg shadow-blue-500/20' \n                    : 'bg-gray-800 text-gray-400 hover:bg-gray-700'\n                  }`}\n                >\n                  {i + 1}\n                </button>\n              ))}\n            </div>\n            <div className=\"bg-blue-500/5 border border-blue-500/20 rounded-xl p-4\">\n              <h3 className=\"text-blue-400 text-sm font-bold mb-1 flex items-center gap-2\">\n                <Info className=\"w-3 h-3\" />\n                {HEAD_DESCRIPTIONS[activeHead].name}\n              </h3>\n              <p className=\"text-xs text-gray-400 leading-relaxed italic\">\n                \"{HEAD_DESCRIPTIONS[activeHead].behavior}\"\n              </p>\n            </div>\n          </section>\n\n          <div className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5\">\n            <label className=\"flex items-center gap-3 cursor-pointer group\">\n              <div className={`w-10 h-5 rounded-full p-1 transition-colors ${showValues ? 'bg-blue-600' : 'bg-gray-700'}`}>\n                <div className={`w-3 h-3 bg-white rounded-full transition-transform ${showValues ? 'translate-x-5' : 'translate-x-0'}`} />\n              </div>\n              <input type=\"checkbox\" className=\"hidden\" checked={showValues} onChange={() => setShowValues(!showValues)} />\n              <span className=\"text-sm font-medium text-gray-400 group-hover:text-white transition-colors\">Show numerical values</span>\n            </label>\n          </div>\n        </div>\n\n        {/* Right Column: Visualization */}\n        <div className=\"lg:col-span-8 space-y-6\">\n          <div className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-6 shadow-xl relative overflow-hidden\">\n            {/* Legend */}\n            <div className=\"absolute top-6 right-6 flex items-center gap-4 text-[10px] text-gray-500 font-bold uppercase tracking-widest\">\n              <span>Weak Attention</span>\n              <div className=\"flex gap-0.5\">\n                {[0.1, 0.3, 0.5, 0.7, 0.9].map(o => (\n                  <div key={o} className=\"w-4 h-2 rounded-sm\" style={{ backgroundColor: `rgba(59, 130, 246, ${o})` }} />\n                ))}\n              </div>\n              <span>Strong</span>\n            </div>\n\n            <h2 className=\"text-sm font-bold uppercase tracking-widest mb-8 flex items-center gap-2\">\n              <MousePointer2 className=\"w-4 h-4 text-blue-400\" />\n              Interactive Heatmap (Head {activeHead + 1})\n            </h2>\n\n            {/* Matrix Container */}\n            <div className=\"relative overflow-x-auto pb-4 custom-scrollbar\">\n              <div \n                className=\"grid gap-1\"\n                style={{ \n                  gridTemplateColumns: `auto repeat(${tokens.length}, minmax(40px, 1fr))`,\n                  minWidth: `${tokens.length * 40 + 100}px`\n                }}\n              >\n                {/* Header corner */}\n                <div className=\"h-10 w-24\"></div>\n                {/* Column Headers */}\n                {tokens.map((token, idx) => (\n                  <div key={`col-${idx}`} className=\"h-10 text-[10px] font-bold text-gray-500 uppercase flex items-center justify-center -rotate-45 origin-bottom-left translate-y-[-5px]\">\n                    {token.length > 8 ? token.substring(0, 6) + '..' : token}\n                  </div>\n                ))}\n\n                {/* Rows */}\n                {tokens.map((rowToken, i) => (\n                  <React.Fragment key={`row-${i}`}>\n                    {/* Row Label */}\n                    <div className=\"h-10 w-24 flex items-center justify-end pr-4 text-xs font-bold text-gray-400 truncate\">\n                      {rowToken}\n                    </div>\n                    {/* Attention Cells */}\n                    {tokens.map((colToken, j) => {\n                      const value = attentionMatrix[i][j] || 0;\n                      const isTarget = hoveredWordIndex === i;\n                      const isSource = hoveredWordIndex === j;\n                      \n                      return (\n                        <motion.div\n                          key={`${i}-${j}`}\n                          onMouseEnter={() => setHoveredWordIndex(i)}\n                          onMouseLeave={() => setHoveredWordIndex(null)}\n                          className={`h-10 rounded-sm flex items-center justify-center text-[8px] font-mono transition-all duration-200 cursor-crosshair\n                            ${isTarget ? 'ring-1 ring-blue-400/50 z-10' : ''}\n                            ${isSource ? 'ring-1 ring-white/20' : ''}\n                          `}\n                          style={{ \n                            backgroundColor: getColor(value),\n                            color: value > 0.5 ? 'white' : 'rgba(255,255,255,0.4)'\n                          }}\n                        >\n                          {showValues && value.toFixed(2)}\n                        </motion.div>\n                      );\n                    })}\n                  </React.Fragment>\n                ))}\n              </div>\n            </div>\n\n            {/* Hover Explainer */}\n            <AnimatePresence>\n              {hoveredWordIndex !== null && (\n                <motion.div \n                  initial={{ opacity: 0, y: 10 }}\n                  animate={{ opacity: 1, y: 0 }}\n                  exit={{ opacity: 0, y: 10 }}\n                  className=\"mt-8 p-4 bg-gray-950 border border-blue-500/30 rounded-xl\"\n                >\n                  <div className=\"flex items-center gap-3 mb-3\">\n                    <span className=\"text-xs font-bold text-gray-500 uppercase tracking-widest\">Analyzing:</span>\n                    <span className=\"px-3 py-1 bg-blue-600 rounded-md text-white font-bold text-sm\">\n                      {tokens[hoveredWordIndex]}\n                    </span>\n                    <ChevronRight className=\"w-4 h-4 text-gray-600\" />\n                    <span className=\"text-xs text-gray-400\">This word is \"looking at\":</span>\n                  </div>\n                  <div className=\"flex flex-wrap gap-2\">\n                    {tokens.map((token, idx) => {\n                      const weight = attentionMatrix[hoveredWordIndex][idx];\n                      if (weight < 0.05) return null; // Only show significant attention\n                      return (\n                        <div \n                          key={idx} \n                          className=\"flex flex-col items-center bg-gray-900 px-3 py-2 rounded-lg border border-white/5\"\n                          style={{ borderColor: weight > 0.3 ? `rgba(59, 130, 246, ${weight})` : 'transparent' }}\n                        >\n                          <span className=\"text-xs font-bold mb-1\">{token}</span>\n                          <div className=\"w-12 h-1.5 bg-gray-800 rounded-full overflow-hidden\">\n                            <div className=\"h-full bg-blue-500\" style={{ width: `${weight * 100}%` }} />\n                          </div>\n                          <span className=\"text-[10px] text-gray-500 mt-1\">{(weight * 100).toFixed(0)}%</span>\n                        </div>\n                      );\n                    })}\n                  </div>\n                </motion.div>\n              )}\n            </AnimatePresence>\n          </div>\n\n          {/* Math Insights */}\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n            <div className=\"bg-blue-600/10 border border-blue-500/20 rounded-2xl p-5\">\n              <h3 className=\"text-sm font-bold text-blue-400 uppercase mb-3 flex items-center gap-2\">\n                <Zap className=\"w-4 h-4\" />\n                Scaled Dot-Product\n              </h3>\n              <p className=\"text-xs text-slate-300 leading-relaxed\">\n                The score between two words is computed via <strong>dot product</strong>. \n                Large dk values cause the softmax gradient to vanish, so we scale by \n                <span className=\"font-mono text-blue-300 ml-1\">1/√dk (1/√64 = 0.125)</span>.\n              </p>\n            </div>\n            <div className=\"bg-purple-600/10 border border-purple-500/20 rounded-2xl p-5\">\n              <h3 className=\"text-sm font-bold text-purple-400 uppercase mb-3 flex items-center gap-2\">\n                <Layers className=\"w-4 h-4\" />\n                Multi-Head Logic\n              </h3>\n              <p className=\"text-xs text-slate-300 leading-relaxed\">\n                \"Multi-head attention allows the model to jointly attend to information from \n                different representation subspaces at different positions.\" — <em>Paper Sec 3.2.2</em>\n              </p>\n            </div>\n          </div>\n        </div>\n      </main>\n\n      <style dangerouslySetInnerHTML={{ __html: `\n        .custom-scrollbar::-webkit-scrollbar {\n          height: 6px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-track {\n          background: rgba(255, 255, 255, 0.05);\n          border-radius: 10px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-thumb {\n          background: rgba(255, 255, 255, 0.1);\n          border-radius: 10px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-thumb:hover {\n          background: rgba(255, 255, 255, 0.2);\n        }\n      `}} />\n    </div>\n  );\n}\n",
      "algorithm_info": "",
      "history": [
        {
          "role": "user",
          "parts": [
            {
              "text": "Task: Create a prototype for \"Interactive Self-Attention Heatmap\".\nContext: A text input interface where users type a sentence. The visualization displays the self-attention matrix (Q x K^T). Hovering over a word highlights which other words it is 'looking at' and how strongly. Users can switch between the 8 different 'heads' to see how different heads focus on grammar, recent words, or long-term dependencies.\n\nFULL PAPER CONTENT:\nProvided proper attribution is provided, Google hereby grants permission to\nreproduce the tables and figures in this paper solely for use in journalistic or\nscholarly works.\nAttention Is All You Need\nAshish Vaswani∗\nGoogle Brain\navaswani@google.com\nNoam Shazeer∗\nGoogle Brain\nnoam@google.com\nNiki Parmar∗\nGoogle Research\nnikip@google.com\nJakob Uszkoreit∗\nGoogle Research\nusz@google.com\nLlion Jones∗\nGoogle Research\nllion@google.com\nAidan N. Gomez∗ †\nUniversity of Toronto\naidan@cs.toronto.edu\nŁukasz Kaiser∗\nGoogle Brain\nlukaszkaiser@google.com\nIllia Polosukhin∗ ‡\nillia.polosukhin@gmail.com\nAbstract\nThe dominant sequence transduction models are based on complex recurrent or\nconvolutional neural networks that include an encoder and a decoder. The best\nperforming models also connect the encoder and decoder through an attention\nmechanism. We propose a new simple network architecture, the Transformer,\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\nentirely. Experiments on two machine translation tasks show these models to\nbe superior in quality while being more parallelizable and requiring significantly\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\nto-German translation task, improving over the existing best results, including\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\nbest models from the literature. We show that the Transformer generalizes well to\nother tasks by applying it successfully to English constituency parsing both with\nlarge and limited training data.\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\nattention and the parameter-free position representation and became the other person involved in nearly every\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\nour research.\n†Work performed while at Google Brain.\n‡Work performed while at Google Research.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\narXiv:1706.03762v7 [cs.CL] 2 Aug 2023\n\n-- 1 of 15 --\n\n1 Introduction\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\nin particular, have been firmly established as state of the art approaches in sequence modeling and\ntransduction problems such as language modeling and machine translation [ 35 , 2 , 5]. Numerous\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\narchitectures [38, 24, 15].\nRecurrent models typically factor computation along the symbol positions of the input and output\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\nsequential nature precludes parallelization within training examples, which becomes critical at longer\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\nsignificant improvements in computational efficiency through factorization tricks [ 21 ] and conditional\ncomputation [ 32 ], while also improving model performance in case of the latter. The fundamental\nconstraint of sequential computation, however, remains.\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\nthe input or output sequences [ 2, 19 ]. In all but a few cases [ 27 ], however, such attention mechanisms\nare used in conjunction with a recurrent network.\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\n2 Background\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n[16 ], ByteNet [ 18 ] and ConvS2S [ 9], all of which use convolutional neural networks as basic building\nblock, computing hidden representations in parallel for all input and output positions. In these models,\nthe number of operations required to relate signals from two arbitrary input or output positions grows\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\nit more difficult to learn dependencies between distant positions [12 ]. In the Transformer this is\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\ndescribed in section 3.2.\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\naligned recurrence and have been shown to perform well on simple-language question answering and\nlanguage modeling tasks [34].\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\nentirely on self-attention to compute representations of its input and output without using sequence-\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\nself-attention and discuss its advantages over models such as [17, 18] and [9].\n3 Model Architecture\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5, 2 , 35].\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\n[10], consuming the previously generated symbols as additional input when generating the next.\n2\n\n-- 2 of 15 --\n\nFigure 1: The Transformer - model architecture.\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\nrespectively.\n3.1 Encoder and Decoder Stacks\nEncoder: The encoder is composed of a stack of N = 6 identical layers. Each layer has two\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\nwise fully connected feed-forward network. We employ a residual connection [ 11 ] around each of\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\nlayers, produce outputs of dimension dmodel = 512.\nDecoder: The decoder is also composed of a stack of N = 6 identical layers. In addition to the two\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\npredictions for position i can depend only on the known outputs at positions less than i.\n3.2 Attention\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\n3\n\n-- 3 of 15 --\n\nScaled Dot-Product Attention Multi-Head Attention\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\nattention layers running in parallel.\nof the values, where the weight assigned to each value is computed by a compatibility function of the\nquery with the corresponding key.\n3.2.1 Scaled Dot-Product Attention\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\nqueries and keys of dimension dk, and values of dimension dv . We compute the dot products of the\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\nvalues.\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\nthe matrix of outputs as:\nAttention(Q, K, V ) = softmax( QKT\n√dk\n)V (1)\nThe two most commonly used attention functions are additive attention [ 2], and dot-product (multi-\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\nof 1\t√dk\n. Additive attention computes the compatibility function using a feed-forward network with\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\nmatrix multiplication code.\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\ndot product attention without scaling for larger values of dk [3 ]. We suspect that for large values of\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\nextremely small gradients 4. To counteract this effect, we scale the dot products by 1\t√dk\n.\n3.2.2 Multi-Head Attention\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\nqueries, keys and values we then perform the attention function in parallel, yielding dv -dimensional\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\ni=1 qiki, has mean 0 and variance dk .\n4\n\n-- 4 of 15 --\n\noutput values. These are concatenated and once again projected, resulting in the final values, as\ndepicted in Figure 2.\nMulti-head attention allows the model to jointly attend to information from different representation\nsubspaces at different positions. With a single attention head, averaging inhibits this.\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\nwhere headi = Attention(QW Q\ni , KW K\ni , V W V\ni )\nWhere the projections are parameter matrices W Q\ni ∈ Rdmodel×dk , W K\ni ∈ Rdmodel×dk , W V\ni ∈ Rdmodel×dv\nand W O ∈ Rhdv ×dmodel .\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\nis similar to that of single-head attention with full dimensionality.\n3.2.3 Applications of Attention in our Model\nThe Transformer uses multi-head attention in three different ways:\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\nand the memory keys and values come from the output of the encoder. This allows every\nposition in the decoder to attend over all positions in the input sequence. This mimics the\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\n[38, 2, 9].\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\nand queries come from the same place, in this case, the output of the previous layer in the\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\nencoder.\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\nall positions in the decoder up to and including that position. We need to prevent leftward\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\nof the softmax which correspond to illegal connections. See Figure 2.\n3.3 Position-wise Feed-Forward Networks\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\nconnected feed-forward network, which is applied to each position separately and identically. This\nconsists of two linear transformations with a ReLU activation in between.\nFFN(x) = max(0, xW1 + b1)W2 + b2 (2)\nWhile the linear transformations are the same across different positions, they use different parameters\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\ndf f = 2048.\n3.4 Embeddings and Softmax\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\nlinear transformation, similar to [ 30 ]. In the embedding layers, we multiply those weights by √dmodel.\n5\n\n-- 5 of 15 --\n\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\nLayer Type Complexity per Layer Sequential Maximum Path Length\nOperations\nSelf-Attention O(n2 · d) O(1) O(1)\nRecurrent O(n · d2) O(n) O(n)\nConvolutional O(k · n · d2) O(1) O(logk(n))\nSelf-Attention (restricted) O(r · n · d) O(1) O(n/r)\n3.5 Positional Encoding\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\norder of the sequence, we must inject some information about the relative or absolute position of the\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\nlearned and fixed [9].\nIn this work, we use sine and cosine functions of different frequencies:\nP E(pos,2i) = sin(pos/100002i/dmodel )\nP E(pos,2i+1) = cos(pos/100002i/dmodel )\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\nchose this function because we hypothesized it would allow the model to easily learn to attend by\nrelative positions, since for any fixed offset k, P Epos+k can be represented as a linear function of\nP Epos.\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\nduring training.\n4 Why Self-Attention\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\ntional layers commonly used for mapping one variable-length sequence of symbol representations\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈ Rd, such as a hidden\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\nconsider three desiderata.\nOne is the total computational complexity per layer. Another is the amount of computation that can\nbe parallelized, as measured by the minimum number of sequential operations required.\nThe third is the path length between long-range dependencies in the network. Learning long-range\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\nability to learn such dependencies is the length of the paths forward and backward signals have to\ntraverse in the network. The shorter these paths between any combination of positions in the input\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\nthe maximum path length between any two input and output positions in networks composed of the\ndifferent layer types.\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\n6\n\n-- 6 of 15 --\n\nlength n is smaller than the representation dimensionality d, which is most often the case with\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\n[38 ] and byte-pair [31 ] representations. To improve computational performance for tasks involving\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\nthe input sequence centered around the respective output position. This would increase the maximum\npath length to O(n/r). We plan to investigate this approach further in future work.\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\nor O(logk(n)) in the case of dilated convolutions [ 18], increasing the length of the longest paths\nbetween any two positions in the network. Convolutional layers are generally more expensive than\nrecurrent layers, by a factor of k. Separable convolutions [6 ], however, decrease the complexity\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\nthe approach we take in our model.\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\nand semantic structure of the sentences.\n5 Training\nThis section describes the training regime for our models.\n5.1 Training Data and Batching\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\nvocabulary [38 ]. Sentence pairs were batched together by approximate sequence length. Each training\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\ntarget tokens.\n5.2 Hardware and Schedule\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\n(3.5 days).\n5.3 Optimizer\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\nrate over the course of training, according to the formula:\nlrate = d−0.5\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5) (3)\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\nwarmup_steps = 4000.\n5.4 Regularization\nWe employ three types of regularization during training:\n7\n\n-- 7 of 15 --\n\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\nModel BLEU Training Cost (FLOPs)\nEN-DE EN-FR EN-DE EN-FR\nByteNet [18] 23.75\nDeep-Att + PosUnk [39] 39.2 1.0 · 1020\nGNMT + RL [38] 24.6 39.92 2.3 · 1019 1.4 · 1020\nConvS2S [9] 25.16 40.46 9.6 · 1018 1.5 · 1020\nMoE [32] 26.03 40.56 2.0 · 1019 1.2 · 1020\nDeep-Att + PosUnk Ensemble [39] 40.4 8.0 · 1020\nGNMT + RL Ensemble [38] 26.30 41.16 1.8 · 1020 1.1 · 1021\nConvS2S Ensemble [9] 26.36 41.29 7.7 · 1019 1.2 · 1021\nTransformer (base model) 27.3 38.1 3.3 · 1018\nTransformer (big) 28.4 41.8 2.3 · 1019\nResidual Dropout We apply dropout [ 33] to the output of each sub-layer, before it is added to the\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\nPdrop = 0.1.\nLabel Smoothing During training, we employed label smoothing of value ϵls = 0.1 [ 36 ]. This\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\n6 Results\n6.1 Machine Translation\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\nthe competitive models.\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\ndropout rate Pdrop = 0.1, instead of 0.3.\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\nused beam search with a beam size of 4 and length penalty α = 0.6 [ 38 ]. These hyperparameters\nwere chosen after experimentation on the development set. We set the maximum output length during\ninference to input length + 50, but terminate early when possible [38].\nTable 2 summarizes our results and compares our translation quality and training costs to other model\narchitectures from the literature. We estimate the number of floating point operations used to train a\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\nsingle-precision floating-point capacity of each GPU 5.\n6.2 Model Variations\nTo evaluate the importance of different components of the Transformer, we varied our base model\nin different ways, measuring the change in performance on English-to-German translation on the\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\n8\n\n-- 8 of 15 --\n\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\nper-word perplexities.\nN dmodel dff h dk dv Pdrop ϵls train PPL BLEU params\nsteps (dev) (dev) ×106\nbase 6 512 2048 8 64 64 0.1 0.1 100K 4.92 25.8 65\n(A)\n1 512 512 5.29 24.9\n4 128 128 5.00 25.5\n16 32 32 4.91 25.8\n32 16 16 5.01 25.4\n(B) 16 5.16 25.1 58\n32 5.01 25.4 60\n(C)\n2 6.11 23.7 36\n4 5.19 25.3 50\n8 4.88 25.5 80\n256 32 32 5.75 24.5 28\n1024 128 128 4.66 26.0 168\n1024 5.12 25.4 53\n4096 4.75 26.2 90\n(D)\n0.0 5.77 24.6\n0.2 4.95 25.5\n0.0 4.67 25.3\n0.2 5.47 25.7\n(E) positional embedding instead of sinusoids 4.92 25.7\nbig 6 1024 4096 16 0.3 300K 4.33 26.4 213\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\ncheckpoint averaging. We present these results in Table 3.\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\nsinusoidal positional encoding with learned positional embeddings [ 9], and observe nearly identical\nresults to the base model.\n6.3 English Constituency Parsing\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\nPenn Treebank [ 25], about 40K training sentences. We also trained it in a semi-supervised setting,\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\n[37 ]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\nfor the semi-supervised setting.\nWe performed only a small number of experiments to select the dropout, both attention and residual\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\nremained unchanged from the English-to-German base translation model. During inference, we\n9\n\n-- 9 of 15 --\n\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\nof WSJ)\nParser Training WSJ 23 F1\nVinyals & Kaiser el al. (2014) [37] WSJ only, discriminative 88.3\nPetrov et al. (2006) [29] WSJ only, discriminative 90.4\nZhu et al. (2013) [40] WSJ only, discriminative 90.4\nDyer et al. (2016) [8] WSJ only, discriminative 91.7\nTransformer (4 layers) WSJ only, discriminative 91.3\nZhu et al. (2013) [40] semi-supervised 91.3\nHuang & Harper (2009) [14] semi-supervised 91.3\nMcClosky et al. (2006) [26] semi-supervised 92.1\nVinyals & Kaiser el al. (2014) [37] semi-supervised 92.1\nTransformer (4 layers) semi-supervised 92.7\nLuong et al. (2015) [23] multi-task 93.0\nDyer et al. (2016) [8] generative 93.3\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\nfor both WSJ only and the semi-supervised setting.\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\nprisingly well, yielding better results than all previously reported models with the exception of the\nRecurrent Neural Network Grammar [8].\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\nParser [29] even when training only on the WSJ training set of 40K sentences.\n7 Conclusion\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\nmulti-headed self-attention.\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\nmodel outperforms even all previously reported ensembles.\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\nplan to extend the Transformer to problems involving input and output modalities other than text and\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\nThe code we used to train and evaluate our models is available at https://github.com/\ntensorflow/tensor2tensor.\nAcknowledgements We are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\ncomments, corrections and inspiration.\nReferences\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\narXiv:1607.06450, 2016.\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\nreading. arXiv preprint arXiv:1601.06733, 2016.\n10\n\n-- 10 of 15 --\n\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\nmachine translation. CoRR, abs/1406.1078, 2014.\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\npreprint arXiv:1610.02357, 2016.\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\nnetwork grammars. In Proc. of NAACL, 2016.\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\n[10] Alex Graves. Generating sequences with recurrent neural networks. arXiv preprint\narXiv:1308.0850, 2013.\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\nRecognition, pages 770–778, 2016.\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\n9(8):1735–1780, 1997.\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\nLanguage Processing, pages 832–841. ACL, August 2009.\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\nInformation Processing Systems, (NIPS), 2016.\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\non Learning Representations (ICLR), 2016.\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\n2017.\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\nIn International Conference on Learning Representations, 2017.\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\narXiv:1703.10722, 2017.\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\narXiv:1703.03130, 2017.\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n11\n\n-- 11 of 15 --\n\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\npages 152–159. ACL, June 2006.\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\nmodel. In Empirical Methods in Natural Language Processing, 2016.\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\n2006.\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\npreprint arXiv:1608.05859, 2016.\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\nlayer. arXiv preprint arXiv:1701.06538, 2017.\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\nLearning Research, 15(1):1929–1958, 2014.\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\nInc., 2015.\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\nAdvances in Neural Information Processing Systems, 2015.\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\narXiv:1609.08144, 2016.\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\n1: Long Papers), pages 434–443. ACL, August 2013.\n12\n\n-- 12 of 15 --\n\nAttention VisualizationsInput-Input Layer5\nIt\t\nis\nin\nthis\nspirit\nthat\na\t\nmajority\t\nof\nAmerican\t\ngovernments\t\nhave\npassed\t\nnew\nlaws\nsince\n2009\nmaking\t\nthe\nregistration\t\nor\nvoting\t\nprocess\t\nmore\ndifficult\t\n.\t\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nIt\t\nis\nin\nthis\nspirit\nthat\na\nmajority\nof\nAmerican\ngovernments\nhave\npassed\nnew\nlaws\nsince\n2009\nmaking\nthe\nregistration\nor\nvoting\nprocess\nmore\ndifficult\n.\n<EOS>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\t\n<pad>\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\n13\n\n-- 13 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\nand 6. Note that the attentions are very sharp for this word.\n14\n\n-- 14 of 15 --\n\nInput-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>Input-Input Layer5\nThe\nLaw\nwill\nnever\t\nbe\nperfect\t\n,\t\nbut\nits\napplication\t\nshould\t\nbe\njust\n-\t\nthis\nis\t\nwhat\nwe\nare\nmissing\t\n,\t\nin\nmy\nopinion\t\n.\t\n<EOS>\t\n<pad>\nThe\nLaw\nwill\nnever\nbe\nperfect\n,\nbut\nits\napplication\nshould\nbe\njust\n-\nthis\nis\nwhat\nwe\nare\nmissing\n,\nin\nmy\nopinion\n.\n<EOS>\t\n<pad>\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\nsentence. We give two such examples above, from two different heads from the encoder self-attention\nat layer 5 of 6. The heads clearly learned to perform different tasks.\n15\n\n-- 15 of 15 --\n\n"
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "code": "import React, { useState, useMemo, useEffect } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { Brain, Settings, Info, ChevronRight, Zap, Layers, MousePointer2 } from 'lucide-react';\n\n// Pseudo-random deterministic generator for consistent \"learned\" weights\nconst mulberry32 = (a) => {\n  return () => {\n    let t = a += 0x6D2B79F5;\n    t = Math.imul(t ^ t >>> 15, t | 1);\n    t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n    return ((t ^ t >>> 14) >>> 0) / 4294967296;\n  };\n};\n\n// Generate deterministic vector for a token\nconst getWordVector = (word, dim, seed = 0) => {\n  const hash = word.split('').reduce((acc, char) => acc + char.charCodeAt(0), 0);\n  const rand = mulberry32(hash + seed);\n  return Array.from({ length: dim }, () => rand() * 2 - 1);\n};\n\n// Main Attention Calculation Implementation\n// Based on: Attention(Q, K, V) = softmax(QK^T / sqrt(dk))\nfunction calculateAttention(tokens, headIndex, dk = 64) {\n  const n = tokens.length;\n  if (n === 0) return [];\n\n  // 1. Generate Query and Key vectors for each token\n  // In a real model, these are learned projections Wq, Wk. \n  // Here we simulate the projection by using head-specific seeds.\n  const Q = tokens.map(t => getWordVector(t, dk, headIndex * 100));\n  const K = tokens.map(t => getWordVector(t, dk, headIndex * 200 + 5));\n\n  // 2. Compute QK^T\n  let scores = Array(n).fill(0).map(() => Array(n).fill(0));\n  for (let i = 0; i < n; i++) {\n    for (let j = 0; j < n; j++) {\n      let dotProduct = 0;\n      for (let k = 0; k < dk; k++) {\n        dotProduct += Q[i][k] * K[j][k];\n      }\n      // Scale by sqrt(dk) as per paper section 3.2.1\n      scores[i][j] = dotProduct / Math.sqrt(dk);\n    }\n  }\n\n  // 3. Apply Softmax across rows\n  const attentionMatrix = scores.map(row => {\n    const maxVal = Math.max(...row); // For numerical stability\n    const exps = row.map(v => Math.exp(v - maxVal));\n    const sumExps = exps.reduce((a, b) => a + b, 0);\n    return exps.map(v => v / sumExps);\n  });\n\n  return attentionMatrix;\n}\n\nconst HEAD_DESCRIPTIONS = [\n  { name: \"Global Context\", behavior: \"Looks at all tokens broadly to understand the overall theme.\" },\n  { name: \"Local Syntax\", behavior: \"Focuses on immediately adjacent words (n-1, n+1).\" },\n  { name: \"Self-Identity\", behavior: \"Strong focus on the token itself. Acts as a pass-through.\" },\n  { name: \"Long-Range\", behavior: \"Attends to tokens far back in the sentence (anaphora resolution).\" },\n  { name: \"Noun-Verb\", behavior: \"Learned dependency mapping between subjects and actions.\" },\n  { name: \"Delimiter\", behavior: \"Focuses on punctuation and sentence boundaries.\" },\n  { name: \"Positional\", behavior: \"Attends to specific relative offsets regardless of content.\" },\n  { name: \"Redundancy\", behavior: \"Cross-checks information already processed in earlier layers.\" }\n];\n\nexport default function App() {\n  const [inputText, setInputText] = useState(\"The animal didn't cross the street because it was too tired.\");\n  const [activeHead, setActiveHead] = useState(0);\n  const [hoveredWordIndex, setHoveredWordIndex] = useState(null);\n  const [showValues, setShowValues] = useState(false);\n\n  const tokens = useMemo(() => {\n    return inputText.trim().split(/\\s+/).filter(t => t.length > 0);\n  }, [inputText]);\n\n  const attentionMatrix = useMemo(() => {\n    return calculateAttention(tokens, activeHead);\n  }, [tokens, activeHead]);\n\n  const getColor = (val) => {\n    // Transformer visualization standard: Blue-to-White or Purple-to-White\n    return `rgba(96, 165, 250, ${Math.pow(val, 0.7)})`; // Using power to emphasize lower values\n  };\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-slate-200 font-sans selection:bg-blue-500/30\">\n      {/* Header */}\n      <header className=\"border-b border-white/10 bg-gray-900/50 backdrop-blur-md sticky top-0 z-50\">\n        <div className=\"max-w-6xl mx-auto px-6 py-4 flex items-center justify-between\">\n          <div className=\"flex items-center gap-3\">\n            <div className=\"p-2 bg-blue-600 rounded-lg shadow-lg shadow-blue-500/20\">\n              <Brain className=\"w-6 h-6 text-white\" />\n            </div>\n            <div>\n              <h1 className=\"text-xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-white to-gray-400\">\n                Transformer Self-Attention\n              </h1>\n              <p className=\"text-xs text-gray-500 font-medium tracking-wider uppercase\">Attention Is All You Need (2017)</p>\n            </div>\n          </div>\n          <div className=\"flex items-center gap-4 text-sm font-medium\">\n            <a href=\"https://arxiv.org/abs/1706.03762\" target=\"_blank\" className=\"text-gray-400 hover:text-white transition-colors\">ArXiv Paper</a>\n          </div>\n        </div>\n      </header>\n\n      <main className=\"max-w-6xl mx-auto px-6 py-8 grid grid-cols-1 lg:grid-cols-12 gap-8\">\n        \n        {/* Left Column: Controls & Input */}\n        <div className=\"lg:col-span-4 space-y-6\">\n          <section className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5 shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-blue-400\">\n              <Zap className=\"w-4 h-4\" />\n              <h2 className=\"text-sm font-bold uppercase tracking-widest\">Input Sequence</h2>\n            </div>\n            <textarea\n              value={inputText}\n              onChange={(e) => setInputText(e.target.value)}\n              className=\"w-full h-32 bg-gray-950 border border-white/10 rounded-xl p-4 text-sm focus:ring-2 focus:ring-blue-500 focus:border-transparent outline-none transition-all resize-none\"\n              placeholder=\"Type a sentence to visualize attention...\"\n            />\n            <div className=\"mt-2 text-xs text-gray-500 flex justify-between\">\n              <span>{tokens.length} tokens detected</span>\n              <button onClick={() => setInputText(\"The animal didn't cross the street because it was too tired.\")} className=\"hover:underline\">Reset to example</button>\n            </div>\n          </section>\n\n          <section className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5 shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-purple-400\">\n              <Layers className=\"w-4 h-4\" />\n              <h2 className=\"text-sm font-bold uppercase tracking-widest\">Attention Heads (h=8)</h2>\n            </div>\n            <div className=\"grid grid-cols-4 gap-2 mb-6\">\n              {Array.from({ length: 8 }).map((_, i) => (\n                <button\n                  key={i}\n                  onClick={() => setActiveHead(i)}\n                  className={`py-2 rounded-lg text-sm font-bold transition-all ${\n                    activeHead === i \n                    ? 'bg-blue-600 text-white shadow-lg shadow-blue-500/20' \n                    : 'bg-gray-800 text-gray-400 hover:bg-gray-700'\n                  }`}\n                >\n                  {i + 1}\n                </button>\n              ))}\n            </div>\n            <div className=\"bg-blue-500/5 border border-blue-500/20 rounded-xl p-4\">\n              <h3 className=\"text-blue-400 text-sm font-bold mb-1 flex items-center gap-2\">\n                <Info className=\"w-3 h-3\" />\n                {HEAD_DESCRIPTIONS[activeHead].name}\n              </h3>\n              <p className=\"text-xs text-gray-400 leading-relaxed italic\">\n                \"{HEAD_DESCRIPTIONS[activeHead].behavior}\"\n              </p>\n            </div>\n          </section>\n\n          <div className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-5\">\n            <label className=\"flex items-center gap-3 cursor-pointer group\">\n              <div className={`w-10 h-5 rounded-full p-1 transition-colors ${showValues ? 'bg-blue-600' : 'bg-gray-700'}`}>\n                <div className={`w-3 h-3 bg-white rounded-full transition-transform ${showValues ? 'translate-x-5' : 'translate-x-0'}`} />\n              </div>\n              <input type=\"checkbox\" className=\"hidden\" checked={showValues} onChange={() => setShowValues(!showValues)} />\n              <span className=\"text-sm font-medium text-gray-400 group-hover:text-white transition-colors\">Show numerical values</span>\n            </label>\n          </div>\n        </div>\n\n        {/* Right Column: Visualization */}\n        <div className=\"lg:col-span-8 space-y-6\">\n          <div className=\"bg-gray-900/50 border border-white/5 rounded-2xl p-6 shadow-xl relative overflow-hidden\">\n            {/* Legend */}\n            <div className=\"absolute top-6 right-6 flex items-center gap-4 text-[10px] text-gray-500 font-bold uppercase tracking-widest\">\n              <span>Weak Attention</span>\n              <div className=\"flex gap-0.5\">\n                {[0.1, 0.3, 0.5, 0.7, 0.9].map(o => (\n                  <div key={o} className=\"w-4 h-2 rounded-sm\" style={{ backgroundColor: `rgba(59, 130, 246, ${o})` }} />\n                ))}\n              </div>\n              <span>Strong</span>\n            </div>\n\n            <h2 className=\"text-sm font-bold uppercase tracking-widest mb-8 flex items-center gap-2\">\n              <MousePointer2 className=\"w-4 h-4 text-blue-400\" />\n              Interactive Heatmap (Head {activeHead + 1})\n            </h2>\n\n            {/* Matrix Container */}\n            <div className=\"relative overflow-x-auto pb-4 custom-scrollbar\">\n              <div \n                className=\"grid gap-1\"\n                style={{ \n                  gridTemplateColumns: `auto repeat(${tokens.length}, minmax(40px, 1fr))`,\n                  minWidth: `${tokens.length * 40 + 100}px`\n                }}\n              >\n                {/* Header corner */}\n                <div className=\"h-10 w-24\"></div>\n                {/* Column Headers */}\n                {tokens.map((token, idx) => (\n                  <div key={`col-${idx}`} className=\"h-10 text-[10px] font-bold text-gray-500 uppercase flex items-center justify-center -rotate-45 origin-bottom-left translate-y-[-5px]\">\n                    {token.length > 8 ? token.substring(0, 6) + '..' : token}\n                  </div>\n                ))}\n\n                {/* Rows */}\n                {tokens.map((rowToken, i) => (\n                  <React.Fragment key={`row-${i}`}>\n                    {/* Row Label */}\n                    <div className=\"h-10 w-24 flex items-center justify-end pr-4 text-xs font-bold text-gray-400 truncate\">\n                      {rowToken}\n                    </div>\n                    {/* Attention Cells */}\n                    {tokens.map((colToken, j) => {\n                      const value = attentionMatrix[i][j] || 0;\n                      const isTarget = hoveredWordIndex === i;\n                      const isSource = hoveredWordIndex === j;\n                      \n                      return (\n                        <motion.div\n                          key={`${i}-${j}`}\n                          onMouseEnter={() => setHoveredWordIndex(i)}\n                          onMouseLeave={() => setHoveredWordIndex(null)}\n                          className={`h-10 rounded-sm flex items-center justify-center text-[8px] font-mono transition-all duration-200 cursor-crosshair\n                            ${isTarget ? 'ring-1 ring-blue-400/50 z-10' : ''}\n                            ${isSource ? 'ring-1 ring-white/20' : ''}\n                          `}\n                          style={{ \n                            backgroundColor: getColor(value),\n                            color: value > 0.5 ? 'white' : 'rgba(255,255,255,0.4)'\n                          }}\n                        >\n                          {showValues && value.toFixed(2)}\n                        </motion.div>\n                      );\n                    })}\n                  </React.Fragment>\n                ))}\n              </div>\n            </div>\n\n            {/* Hover Explainer */}\n            <AnimatePresence>\n              {hoveredWordIndex !== null && (\n                <motion.div \n                  initial={{ opacity: 0, y: 10 }}\n                  animate={{ opacity: 1, y: 0 }}\n                  exit={{ opacity: 0, y: 10 }}\n                  className=\"mt-8 p-4 bg-gray-950 border border-blue-500/30 rounded-xl\"\n                >\n                  <div className=\"flex items-center gap-3 mb-3\">\n                    <span className=\"text-xs font-bold text-gray-500 uppercase tracking-widest\">Analyzing:</span>\n                    <span className=\"px-3 py-1 bg-blue-600 rounded-md text-white font-bold text-sm\">\n                      {tokens[hoveredWordIndex]}\n                    </span>\n                    <ChevronRight className=\"w-4 h-4 text-gray-600\" />\n                    <span className=\"text-xs text-gray-400\">This word is \"looking at\":</span>\n                  </div>\n                  <div className=\"flex flex-wrap gap-2\">\n                    {tokens.map((token, idx) => {\n                      const weight = attentionMatrix[hoveredWordIndex][idx];\n                      if (weight < 0.05) return null; // Only show significant attention\n                      return (\n                        <div \n                          key={idx} \n                          className=\"flex flex-col items-center bg-gray-900 px-3 py-2 rounded-lg border border-white/5\"\n                          style={{ borderColor: weight > 0.3 ? `rgba(59, 130, 246, ${weight})` : 'transparent' }}\n                        >\n                          <span className=\"text-xs font-bold mb-1\">{token}</span>\n                          <div className=\"w-12 h-1.5 bg-gray-800 rounded-full overflow-hidden\">\n                            <div className=\"h-full bg-blue-500\" style={{ width: `${weight * 100}%` }} />\n                          </div>\n                          <span className=\"text-[10px] text-gray-500 mt-1\">{(weight * 100).toFixed(0)}%</span>\n                        </div>\n                      );\n                    })}\n                  </div>\n                </motion.div>\n              )}\n            </AnimatePresence>\n          </div>\n\n          {/* Math Insights */}\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-4\">\n            <div className=\"bg-blue-600/10 border border-blue-500/20 rounded-2xl p-5\">\n              <h3 className=\"text-sm font-bold text-blue-400 uppercase mb-3 flex items-center gap-2\">\n                <Zap className=\"w-4 h-4\" />\n                Scaled Dot-Product\n              </h3>\n              <p className=\"text-xs text-slate-300 leading-relaxed\">\n                The score between two words is computed via <strong>dot product</strong>. \n                Large dk values cause the softmax gradient to vanish, so we scale by \n                <span className=\"font-mono text-blue-300 ml-1\">1/√dk (1/√64 = 0.125)</span>.\n              </p>\n            </div>\n            <div className=\"bg-purple-600/10 border border-purple-500/20 rounded-2xl p-5\">\n              <h3 className=\"text-sm font-bold text-purple-400 uppercase mb-3 flex items-center gap-2\">\n                <Layers className=\"w-4 h-4\" />\n                Multi-Head Logic\n              </h3>\n              <p className=\"text-xs text-slate-300 leading-relaxed\">\n                \"Multi-head attention allows the model to jointly attend to information from \n                different representation subspaces at different positions.\" — <em>Paper Sec 3.2.2</em>\n              </p>\n            </div>\n          </div>\n        </div>\n      </main>\n\n      <style dangerouslySetInnerHTML={{ __html: `\n        .custom-scrollbar::-webkit-scrollbar {\n          height: 6px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-track {\n          background: rgba(255, 255, 255, 0.05);\n          border-radius: 10px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-thumb {\n          background: rgba(255, 255, 255, 0.1);\n          border-radius: 10px;\n        }\n        .custom-scrollbar::-webkit-scrollbar-thumb:hover {\n          background: rgba(255, 255, 255, 0.2);\n        }\n      `}} />\n    </div>\n  );\n}\n",
                  "title": "Interactive Transformer Self-Attention Heatmap"
                }
              }
            }
          ]
        }
      ],
      "created_at": 1770313135994,
      "updated_at": 1770313135994
    },
    "expert-routing-flow-1770621659067": {
      "id": "expert-routing-flow-1770621659067",
      "paper_hash": "arxiv-2602.06859",
      "title": "Expert Routing Flow",
      "description": "A flowchart animation showing a stream of nodes entering the model. The 'Router' analyzes the node structure and directs it to one of three 'Manifold Rooms' (Hyperbolic, Euclidean, Spherical). Inside the room, the reconstruction happens. If the wrong room is chosen, the reconstruction breaks (high error visualization).",
      "code": "import React, { useState, useEffect, useMemo, useRef } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { \n  Network, \n  Database, \n  Box, \n  Circle, \n  Triangle, \n  Activity, \n  Settings2, \n  ShieldAlert, \n  Zap,\n  RefreshCcw,\n  ChevronRight\n} from 'lucide-react';\nimport { LineChart, Line, XAxis, YAxis, Tooltip, ResponsiveContainer, AreaChart, Area } from 'recharts';\n\n// Manifold types from paper\nconst MANIFOLDS = {\n  HYPERBOLIC: { id: 'hyperbolic', label: 'Hyperbolic (κ < 0)', color: '#8b5cf6', description: 'Best for Hierarchical/Tree' },\n  EUCLIDEAN: { id: 'euclidean', label: 'Euclidean (κ = 0)', color: '#3b82f6', description: 'Best for Grids/Uniform' },\n  SPHERICAL: { id: 'spherical', label: 'Spherical (κ > 0)', color: '#10b981', description: 'Best for Cliques/Cycles' }\n};\n\n// Node patterns defined in paper\nconst PATTERNS = [\n  { id: 'tree', name: 'Hierarchical Tree', ideal: 'hyperbolic', icon: <Triangle className=\"w-4 h-4\" /> },\n  { id: 'grid', name: 'Standard Grid', ideal: 'euclidean', icon: <Box className=\"w-4 h-4\" /> },\n  { id: 'clique', name: 'Dense Clique', ideal: 'spherical', icon: <Circle className=\"w-4 h-4\" /> }\n];\n\nexport default function App() {\n  // State\n  const [nodes, setNodes] = useState([]);\n  const [activeExpert, setActiveExpert] = useState(null);\n  const [history, setHistory] = useState([]);\n  const [routingMode, setRoutingMode] = useState('auto'); // 'auto' or manual forcing\n  const [manualTarget, setManualTarget] = useState('hyperbolic');\n  const [isPaused, setIsPaused] = useState(false);\n  const [stats, setStats] = useState({ total: 0, error: 0, auroc: 0.82 });\n\n  const streamInterval = useRef(null);\n\n  // Simulation logic: Create a node structure\n  const generateNode = () => {\n    const pattern = PATTERNS[Math.floor(Math.random() * PATTERNS.length)];\n    const id = Math.random().toString(36).substr(2, 9);\n    \n    // Feature Alignment simulation (PCA/Laplacian from Section IV-A)\n    const features = Array.from({ length: 8 }, () => Math.random());\n    \n    return { id, pattern, features, status: 'entering', timestamp: Date.now() };\n  };\n\n  // Processing logic\n  useEffect(() => {\n    if (isPaused) return;\n\n    streamInterval.current = setInterval(() => {\n      const newNode = generateNode();\n      \n      // Step 2: Routing (Section IV-C)\n      let target;\n      if (routingMode === 'auto') {\n        // \"Memory-based\" logic: match pattern to ideal expert\n        target = newNode.pattern.ideal;\n      } else {\n        target = manualTarget;\n      }\n\n      const isCorrectRoom = target === newNode.pattern.ideal;\n      const reconError = isCorrectRoom ? (Math.random() * 0.15) : (0.6 + Math.random() * 0.4);\n\n      setNodes(prev => [...prev.slice(-15), { ...newNode, target, isCorrectRoom, reconError }]);\n      \n      setHistory(prev => {\n        const newHistory = [...prev.slice(-20), { time: prev.length, error: reconError }];\n        return newHistory;\n      });\n\n      setStats(prev => ({\n        total: prev.total + 1,\n        error: (prev.error * 0.9 + reconError * 0.1),\n        auroc: isCorrectRoom ? Math.min(0.95, prev.auroc + 0.001) : Math.max(0.5, prev.auroc - 0.01)\n      }));\n\n    }, 1500);\n\n    return () => clearInterval(streamInterval.current);\n  }, [isPaused, routingMode, manualTarget]);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-slate-200 font-sans p-4 lg:p-8\">\n      {/* Header */}\n      <div className=\"max-w-7xl mx-auto flex flex-col md:flex-row justify-between items-start md:items-center mb-8 gap-4\">\n        <div>\n          <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-500\">\n            GAD-MoRE Framework\n          </h1>\n          <p className=\"text-slate-400 text-sm mt-1\">Mixture of Riemannian Experts for Zero-shot Graph Anomaly Detection</p>\n        </div>\n        \n        <div className=\"flex items-center gap-3 bg-slate-900/50 p-2 rounded-lg border border-slate-800\">\n          <button \n            onClick={() => setIsPaused(!isPaused)}\n            className=\"p-2 hover:bg-slate-800 rounded-md transition-colors\"\n          >\n            {isPaused ? <Zap className=\"w-5 h-5 text-yellow-500\" /> : <RefreshCcw className=\"w-5 h-5 text-blue-500 animate-spin-slow\" />}\n          </button>\n          <div className=\"h-8 w-[1px] bg-slate-800\" />\n          <div className=\"px-3\">\n            <span className=\"text-xs text-slate-500 block uppercase font-semibold\">Mean Reconstruction Error</span>\n            <span className={`text-lg font-mono font-bold ${stats.error > 0.4 ? 'text-red-400' : 'text-emerald-400'}`}>\n              {stats.error.toFixed(4)}\n            </span>\n          </div>\n        </div>\n      </div>\n\n      <div className=\"max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6\">\n        \n        {/* Left Control Panel */}\n        <div className=\"lg:col-span-3 space-y-6\">\n          <section className=\"bg-slate-900/50 border border-slate-800 p-5 rounded-2xl shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-blue-400\">\n              <Settings2 className=\"w-5 h-5\" />\n              <h2 className=\"font-bold uppercase text-xs tracking-wider\">Router Settings</h2>\n            </div>\n            \n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-slate-500 block mb-2\">Memory-based Routing Mode</label>\n                <div className=\"grid grid-cols-2 gap-2\">\n                  <button \n                    onClick={() => setRoutingMode('auto')}\n                    className={`text-xs py-2 rounded-lg border transition-all ${routingMode === 'auto' ? 'bg-blue-600 border-blue-400 text-white' : 'bg-slate-800 border-slate-700 text-slate-400'}`}\n                  >\n                    Dynamic (Auto)\n                  </button>\n                  <button \n                    onClick={() => setRoutingMode('manual')}\n                    className={`text-xs py-2 rounded-lg border transition-all ${routingMode === 'manual' ? 'bg-purple-600 border-purple-400 text-white' : 'bg-slate-800 border-slate-700 text-slate-400'}`}\n                  >\n                    Forced Failure\n                  </button>\n                </div>\n              </div>\n\n              {routingMode === 'manual' && (\n                <motion.div initial={{ opacity: 0, y: -10 }} animate={{ opacity: 1, y: 0 }}>\n                  <label className=\"text-xs text-slate-500 block mb-2\">Force To Room:</label>\n                  <select \n                    value={manualTarget} \n                    onChange={(e) => setManualTarget(e.target.value)}\n                    className=\"w-full bg-slate-800 border border-slate-700 rounded-lg p-2 text-sm text-white\"\n                  >\n                    {Object.values(MANIFOLDS).map(m => (\n                      <option key={m.id} value={m.id}>{m.label}</option>\n                    ))}\n                  </select>\n                  <p className=\"text-[10px] text-red-400 mt-2 italic flex items-center gap-1\">\n                    <ShieldAlert className=\"w-3 h-3\" /> Distorts geometric signatures!\n                  </p>\n                </motion.div>\n              )}\n            </div>\n          </section>\n\n          <section className=\"bg-slate-900/50 border border-slate-800 p-5 rounded-2xl shadow-xl\">\n            <div className=\"flex items-center gap-2 mb-4 text-emerald-400\">\n              <Activity className=\"w-5 h-5\" />\n              <h2 className=\"font-bold uppercase text-xs tracking-wider\">Metrics (Zero-Shot)</h2>\n            </div>\n            <div className=\"h-32 w-full\">\n              <ResponsiveContainer width=\"100%\" height=\"100%\">\n                <AreaChart data={history}>\n                  <defs>\n                    <linearGradient id=\"colorErr\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">\n                      <stop offset=\"5%\" stopColor=\"#3b82f6\" stopOpacity={0.3}/>\n                      <stop offset=\"95%\" stopColor=\"#3b82f6\" stopOpacity={0}/>\n                    </linearGradient>\n                  </defs>\n                  <Area type=\"monotone\" dataKey=\"error\" stroke=\"#3b82f6\" fillOpacity={1} fill=\"url(#colorErr)\" />\n                </AreaChart>\n              </ResponsiveContainer>\n            </div>\n            <div className=\"mt-4 grid grid-cols-2 gap-4\">\n              <div className=\"bg-slate-950 p-2 rounded-lg border border-slate-800\">\n                <span className=\"text-[10px] text-slate-500 block\">AUROC</span>\n                <span className=\"text-lg font-mono font-bold text-white\">{stats.auroc.toFixed(3)}</span>\n              </div>\n              <div className=\"bg-slate-950 p-2 rounded-lg border border-slate-800\">\n                <span className=\"text-[10px] text-slate-500 block\">SAMPLES</span>\n                <span className=\"text-lg font-mono font-bold text-white\">{stats.total}</span>\n              </div>\n            </div>\n          </section>\n        </div>\n\n        {/* Center Canvas: Expert Routing Flow */}\n        <div className=\"lg:col-span-9 space-y-6\">\n          <div className=\"relative bg-slate-900/30 border border-slate-800 rounded-2xl p-6 min-h-[600px] overflow-hidden\">\n            \n            {/* Input Stream Area */}\n            <div className=\"absolute left-8 top-1/2 -translate-y-1/2 flex flex-col items-center gap-4 z-10\">\n              <div className=\"p-3 bg-slate-800 rounded-xl border border-slate-700 shadow-lg mb-4\">\n                <Database className=\"w-8 h-8 text-blue-400\" />\n                <span className=\"text-[10px] uppercase font-bold text-slate-500 mt-2 block text-center\">Graph Source</span>\n              </div>\n              \n              <div className=\"h-[400px] w-24 relative overflow-hidden flex flex-col gap-3 items-center pt-10\">\n                <AnimatePresence>\n                  {nodes.filter(n => n.status === 'entering').map((node, i) => (\n                    <motion.div\n                      key={node.id}\n                      initial={{ opacity: 0, x: -50 }}\n                      animate={{ opacity: 1, x: 0, y: (i * 45) }}\n                      exit={{ opacity: 0, scale: 0.5 }}\n                      className=\"w-12 h-12 rounded-lg bg-slate-800 border border-slate-700 flex items-center justify-center shadow-lg relative group\"\n                    >\n                      {node.pattern.icon}\n                      <div className=\"absolute -right-20 opacity-0 group-hover:opacity-100 transition-opacity bg-black p-2 rounded text-[10px] w-16 z-20\">\n                        {node.pattern.name}\n                      </div>\n                    </motion.div>\n                  ))}\n                </AnimatePresence>\n              </div>\n            </div>\n\n            {/* Central Router Block (Section IV-C) */}\n            <div className=\"absolute left-1/3 top-1/2 -translate-y-1/2 z-20\">\n              <motion.div \n                animate={{ scale: [1, 1.05, 1] }}\n                transition={{ duration: 2, repeat: Infinity }}\n                className=\"w-24 h-48 bg-gradient-to-b from-blue-600 to-purple-700 rounded-3xl flex flex-col items-center justify-center shadow-[0_0_30px_rgba(59,130,246,0.5)] border border-blue-400/50\"\n              >\n                <div className=\"bg-white/20 p-2 rounded-full mb-4\">\n                  <Network className=\"w-6 h-6 text-white\" />\n                </div>\n                <div className=\"rotate-90 text-[10px] font-black tracking-[0.2em] text-white/80 uppercase\">\n                  Dynamic Router\n                </div>\n              </motion.div>\n            </div>\n\n            {/* Expert Manifold Rooms (Section IV-B) */}\n            <div className=\"absolute right-8 top-0 bottom-0 flex flex-col justify-around py-4 w-1/3\">\n              {Object.values(MANIFOLDS).map((manifold) => (\n                <div \n                  key={manifold.id}\n                  className={`relative h-1/4 rounded-2xl border transition-all duration-500 flex items-center justify-between px-6 ${\n                    activeExpert === manifold.id \n                    ? 'bg-slate-800/80 border-slate-400 scale-105 shadow-2xl' \n                    : 'bg-slate-900/30 border-slate-800/50'\n                  }`}\n                >\n                  <div className=\"flex items-center gap-4\">\n                    <div className=\"w-12 h-12 rounded-full flex items-center justify-center border-2\" style={{ borderColor: manifold.color, backgroundColor: `${manifold.color}20` }}>\n                      <span className=\"text-xl\" style={{ color: manifold.color }}>\n                        {manifold.id === 'hyperbolic' ? 'Δ' : manifold.id === 'euclidean' ? '□' : '○'}\n                      </span>\n                    </div>\n                    <div>\n                      <h3 className=\"font-bold text-sm\" style={{ color: manifold.color }}>{manifold.label}</h3>\n                      <p className=\"text-[10px] text-slate-500\">{manifold.description}</p>\n                    </div>\n                  </div>\n\n                  {/* Nodes currently in the room */}\n                  <div className=\"flex gap-2\">\n                    <AnimatePresence>\n                      {nodes.filter(n => n.target === manifold.id).slice(-4).map((n) => (\n                        <motion.div\n                          key={n.id}\n                          initial={{ scale: 0, opacity: 0 }}\n                          animate={{ \n                            scale: n.reconError > 0.4 ? [1, 1.2, 1] : 1, \n                            opacity: 1,\n                            x: [0, 5, -5, 0]\n                          }}\n                          transition={{ \n                            x: { duration: n.reconError, repeat: n.reconError > 0.4 ? Infinity : 0 }\n                          }}\n                          className={`w-6 h-6 rounded flex items-center justify-center text-[10px] font-bold ${\n                            n.reconError > 0.4 ? 'bg-red-500 text-white shadow-[0_0_10px_rgba(239,68,68,0.8)]' : 'bg-emerald-500 text-white'\n                          }`}\n                        >\n                          {n.reconError > 0.4 ? '!' : '✓'}\n                        </motion.div>\n                      ))}\n                    </AnimatePresence>\n                  </div>\n                </div>\n              ))}\n            </div>\n\n            {/* Connecting Flow Lines */}\n            <svg className=\"absolute inset-0 w-full h-full pointer-events-none z-0\">\n              <path \n                d=\"M 120 300 L 260 300\" \n                stroke=\"rgba(59,130,246,0.3)\" \n                strokeWidth=\"2\" \n                fill=\"none\" \n                strokeDasharray=\"5,5\" \n              />\n              {/* Paths to Rooms */}\n              <path d=\"M 350 250 L 580 120\" stroke=\"rgba(139,92,246,0.2)\" strokeWidth=\"1\" fill=\"none\" />\n              <path d=\"M 350 300 L 580 300\" stroke=\"rgba(59,130,246,0.2)\" strokeWidth=\"1\" fill=\"none\" />\n              <path d=\"M 350 350 L 580 480\" stroke=\"rgba(16,185,129,0.2)\" strokeWidth=\"1\" fill=\"none\" />\n            </svg>\n          </div>\n          \n          {/* Legend/Info Section */}\n          <div className=\"grid grid-cols-1 md:grid-cols-3 gap-4\">\n            <div className=\"bg-slate-900/50 p-4 rounded-xl border border-slate-800\">\n              <div className=\"flex items-center gap-2 mb-2 text-purple-400\">\n                <Triangle className=\"w-4 h-4\" />\n                <h4 className=\"text-xs font-bold uppercase tracking-wider\">Hyperbolic Prior</h4>\n              </div>\n              <p className=\"text-[11px] text-slate-400 leading-relaxed\">\n                Captures hierarchical hierarchies. Tree anomalies routed here show low distortion due to negative curvature κ.\n              </p>\n            </div>\n            <div className=\"bg-slate-900/50 p-4 rounded-xl border border-slate-800\">\n              <div className=\"flex items-center gap-2 mb-2 text-blue-400\">\n                <Box className=\"w-4 h-4\" />\n                <h4 className=\"text-xs font-bold uppercase tracking-wider\">Euclidean Prior</h4>\n              </div>\n              <p className=\"text-[11px] text-slate-400 leading-relaxed\">\n                Standard flat geometry (κ=0). Best for regular grid structures or when no strong hierarchy exists.\n              </p>\n            </div>\n            <div className=\"bg-slate-900/50 p-4 rounded-xl border border-slate-800\">\n              <div className=\"flex items-center gap-2 mb-2 text-emerald-400\">\n                <Circle className=\"w-4 h-4\" />\n                <h4 className=\"text-xs font-bold uppercase tracking-wider\">Spherical Prior</h4>\n              </div>\n              <p className=\"text-[11px] text-slate-400 leading-relaxed\">\n                κ &gt; 0 handles cyclical/clique patterns. Routing cycles here avoids \"over-stretching\" errors.\n              </p>\n            </div>\n          </div>\n        </div>\n\n      </div>\n\n      {/* Decorative background effects */}\n      <div className=\"fixed top-0 left-0 w-full h-full pointer-events-none -z-10 overflow-hidden\">\n        <div className=\"absolute top-[-10%] left-[-10%] w-[40%] h-[40%] bg-blue-500/10 blur-[120px] rounded-full\" />\n        <div className=\"absolute bottom-[-10%] right-[-10%] w-[40%] h-[40%] bg-purple-500/10 blur-[120px] rounded-full\" />\n      </div>\n    </div>\n  );\n}\n",
      "algorithm_info": "",
      "history": [
        {
          "role": "user",
          "parts": [
            {
              "text": "Create an interactive prototype for \"Expert Routing Flow\". Description: A flowchart animation showing a stream of nodes entering the model. The 'Router' analyzes the node structure and directs it to one of three 'Manifold Rooms' (Hyperbolic, Euclidean, Spherical). Inside the room, the reconstruction happens. If the wrong room is chosen, the reconstruction breaks (high error visualization).\n\nPAPER CONTENT:\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 1\nZero-shot Generalizable Graph Anomaly Detection\nwith Mixture of Riemannian Experts\nXinyu Zhao, Qingyun Sun, Member, IEEE, Jiayi Luo, Xingcheng Fu, Jianxin Li, Senior Member, IEEE\nAbstract—Graph Anomaly Detection (GAD) aims to identify\nirregular patterns in graph data, and recent works have explored\nzero-shot generalist GAD to enable generalization to unseen\ngraph datasets. However, existing zero-shot GAD methods largely\nignore intrinsic geometric differences across diverse anomaly\npatterns, substantially limiting their cross-domain generalization.\nIn this work, we reveal that anomaly detectability is highly depen-\ndent on the underlying geometric properties and that embedding\ngraphs from different domains into a single static curvature space\ncan distort the structural signatures of anomalies. To address the\nchallenge that a single curvature space cannot capture geometry-\ndependent graph anomaly patterns, we propose GAD-MoRE, a\nnovel framework for zero-shot Generalizable Graph Anomaly\nDetection with a Mixture of Riemannian Experts architecture.\nSpecifically, to ensure that each anomaly pattern is modeled\nin the Riemannian space where it is most detectable, GAD-\nMoRE employs a set of specialized Riemannian expert networks,\neach operating in a distinct curvature space. To align raw\nnode features with curvature-specific anomaly characteristics, we\nintroduce an anomaly-aware multi-curvature feature alignment\nmodule that projects inputs into parallel Riemannian spaces, en-\nabling the capture of diverse geometric characteristics. Finally, to\nfacilitate better generalization beyond seen patterns, we design a\nmemory-based dynamic router that adaptively assigns each input\nto the most compatible expert based on historical reconstruction\nperformance on similar anomalies. Extensive experiments in\nthe zero-shot setting demonstrate that GAD-MoRE significantly\noutperforms state-of-the-art generalist GAD baselines, and even\nsurpasses strong competitors that are few-shot fine-tuned with\nlabeled data from the target domain.\nIndex Terms—Graph Anomaly Detection, Mixture of Experts,\nRiemannian Graph Learning, Zero-shot Learning.\nI. INTRODUCTION\nGRAPH Anomaly Detection (GAD) [1], [2] aims to iden-\ntify irregular patterns in graph-structured data. Detecting\nsuch anomaly patterns is of significant practical importance in\nmany real-world applications [3], as they often correspond to\ndetrimental events and abnormal behaviors, such as financial\nfraud rings characterized by dense clique formations [4], [5]\nor misinformation campaigns exhibiting star-like spreading\npatterns [6], [7], [8], which can ultimately lead to severe\nfinancial losses and negative social consequences. Benefiting\nfrom the powerful representation learning capability of Graph\nNeural Networks (GNNs), numerous GAD methods incor-\nporate GNNs into their frameworks [9], [10]. However, the\nX. Zhao, Q. Sun, J. Luo, and J. Li are with the School of Computer Science\nand Engineering, Beihang University, Beijing 100191, China (Email: {xyzhao,\nsunqy, luojy, lijx}@buaa.edu.cn).\nX. Fu is with the Key Lab of Education Blockchain and Intelligent Tech-\nnology, Ministry of Education, Guangxi Normal University, Guilin 541004,\nChina (E-mail: fuxc@gxnu.edu.cn).\nManuscript received December 1, 2025.\nmajority of existing methods are designed under a restrictive\nassumption: training and inference are performed on the same\ngraph. This paradigm inherently limits practical applicability,\nwhere the structural and attribute patterns that characterize\nanomalous behavior are not universal across graphs [2]. For\nexample, the topology of a spam-bot community in a so-\ncial network [6] can be entirely different from that of a\nfinancial fraud ring in a transaction graph [5]. As a result,\nmodels trained within a single domain tend to overfit to\ntheir specific anomaly patterns, failing to generalize to unseen\ngraphs without costly retraining and labeling. This inability to\ntransfer learned anomaly patterns across varying distributions\nconstitutes a critical generalization challenge [2], [10].\nTo enable cross-graph generalization, recent works have\nbegun to explore zero-shot or few-shot GAD models [16],\n[17], [18], [19]. While these approaches have made promising\nprogress, they often overlook the critical issue that different\nanomaly patterns exhibit substantial geometric heterogeneity\nacross graphs. As a result, their ability to generalize to new,\nunseen graph domains remains limited. Under this heterogene-\nity, representing all graphs in a single fixed-curvature space\ncan introduce systematic embedding distortion, where certain\nstructural relations are over-compressed or over-stretched, re-\nducing separability and making subtle anomalies harder to\ndistinguish from normal variability. Geometry acts as an induc-\ntive bias that shapes which structural properties are explicitly\ncaptured. For example, in hierarchical graphs, anomalous\nbridge nodes linking distant branches are naturally exposed\nas outliers in hyperbolic space with negative curvature [20].\nBy contrast, graphs with dense structures are better captured in\nspherical space, where anomalies typically manifest as isolated\nnodes deviating from clusters [13], [21]. Therefore, imposing\na single fixed-curvature across all graphs ignores the geomet-\nric heterogeneity of anomaly patterns, potentially distorting\nanomaly representations. To examine the geometric hetero-\ngeneity of graph anomalies, we conduct a preliminary study\non representative datasets, with the results shown in Figure 1.\nSpecifically, we use a standard Graph Autoencoder (GAE) [22]\nto learn node embeddings in constant-curvature spaces with\ndifferent curvature values, and then evaluate anomaly detection\nperformance using classical unsupervised detectors, including\nK-Means [11], k-NN [12], and Isolation Forest [13]. As shown\nin Figure 1, performance varies substantially with the choice\nof curvature. For example, the Weibo [14] dataset shows\na clear performance peak in Euclidean space (κ = 0.0),\nwhereas the Citeseer and Cora [15] datasets consistently prefer\npositive curvature spaces, and the Amazon [7] dataset exhibits\na preference for negative curvature. These results motivate that\narXiv:2602.06859v1 [cs.LG] 6 Feb 2026\n\n-- 1 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 2\nOriginal Graph 1 \tOriginal \tGraph 2 \tOriginal Graph 3\nHyperbolic Embeddings \tEuclidean \tEmbeddings \tSpherical \tEmbeddings\nFig. 1: The left part illustrates the projection of graph structures into Hyperbolic (κ < 0), Euclidean (κ = 0), and Spherical\n(κ > 0) spaces. It highlights that anomalous nodes (red), which are intrinsically hidden within the original graph topology,\nbecome significantly more separable and detectable from normal nodes (blue) once mapped into these Riemannian manifolds.\nThe right part quantifies this effect by showing the average AUROC performance of representative GAD methods (including K-\nMeans [11], k-NN [12], and Isolation Forest [13]) across varying curvature values κ ∈ [−1.0, 1.0] on four datasets: Amazon [7],\nWeibo [14], Cora [15], and CiteSeer [15].\ndifferent anomalies are more effectively detected in different\nRiemannian spaces, making fixed-curvature embeddings sub-\noptimal for anomaly detection. Consequently, it is essential\nto develop an adaptive framework that can dynamically align\nthe Riemannian representation with the anomaly patterns of\neach graph. To overcome the limitation that a single fixed Rie-\nmannian space cannot capture curvature-dependent anomaly\npatterns across different graphs, we propose GAD-MoRE, a\nnovel framework for zero-shot generalizable Graph Anomaly\nDetection with a Mixture of Riemannian Experts architecture,\nexplicitly designed to model geometric heterogeneity in graph\nanomaly patterns. Specifically, to ensure each anomaly pattern\nis modeled in the geometry where it is most detectable, we\nfirst employ a collection of specialized Riemannian expert\nnetworks within the MoE architecture. Unlike single-geometry\nmodels that distort structural patterns, each expert operates in\na distinct curvature space, enabling distinct anomaly patterns\nto be captured in their suitable Riemannian space. Second,\nto transform raw node features into geometry-sensitive repre-\nsentations that are suitable for these Riemannian experts, we\nintroduce an anomaly-aware multi-curvature feature alignment\nmodule. This component bridges the gap between geometry-\nagnostic attributes and Riemannian manifolds, producing ro-\nbust representations compatible with diverse experts. Finally,\nto route each node to its most appropriate Riemannian expert,\nwe design a memory-based dynamic router that adaptively as-\nsigns current input nodes according to each expert’s historical\nanomaly detection performance, thereby enhancing generaliza-\ntion to unseen data. Extensive experiments demonstrate that\nour proposed GAD-MoRE achieves state-of-the-art zero-shot\nGAD performance, notably surpassing strong competitors even\nwhen they are fine-tuned with labeled target domain data.\nOur contributions can be summarized as follows:\n• We show that graph anomalies exhibit geometric hetero-\ngeneity, where different anomaly patterns have different\ndetectability in distinct Riemannian spaces, whereas a\nsingle fixed Riemannian space is inherently insufficient\nto capture them.\n• We propose a novel zero-shot generalizable graph\nanomaly detection framework named GAD-MoRE, which\nexplicitly models the graph anomaly geometric hetero-\ngeneity via a mixture of Riemannian experts coupled\nwith an anomaly-aware multi-curvature feature alignment\nmodule and a memory-based dynamic router.\n• Extensive experiments demonstrate that GAD-MoRE sig-\nnificantly outperforms state-of-the-art baselines in chal-\nlenging zero-shot settings, even against competitors fine-\ntuned with target-domain labels.\nOrganization: The subsequent sections of this paper are\nstructured as follows. We begin by surveying the relevant\nliterature in Section II. Next, Section III provides the formal\nproblem definition and essential background. The technical\narchitecture of the proposed GAD-MoRE is detailed in Sec-\ntion IV, followed by a thorough performance evaluation in\nSection V. We provide concluding remarks and future outlooks\nin Section VI.\nII. RELATED WORK\nA. Graph Anomaly Detection\nOur work focuses on node-level graph anomaly detection\n(GAD), which aims to identify anomalous nodes in graph-\nstructured data [2]. Existing methods can be broadly catego-\nrized into supervised, unsupervised, and general methods.\n(1) Supervised Methods. Supervised methods formulate\nGAD as a node classification problem using graph neural\nnetworks (GNNs). These approaches fall into two main cat-\negories: discriminative and generative GNNs [10]. Discrimi-\nnative models such as CARE-GNN [23] and GHRN [24] im-\nprove neighborhood aggregation and feature transformation to\nseparate normal and anomalous nodes, leveraging techniques\n\n-- 2 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 3\nlike edge selection [23] and edge synthesis [24]. Generative\nmodels such as GraphSMOTE [25], GraphMixup [26], and\nGODM [27] generate synthetic anomalies. They typically rely\non feature interpolation [25], [26] or noise perturbation [27] to\naugment training data and mitigate label scarcity. While these\nmethods perform well when labeled data is available, they are\nconstrained by the high cost of anomaly labels.\n(2) Unsupervised Methods. Unsupervised methods do not\nrequire labeled anomalies and instead rely on proxy tasks\nto guide model learning [10]. Common strategies include\ngraph reconstruction, graph contrastive learning, graph knowl-\nedge distillation, adversarial training, and score prediction.\nReconstruction-based models such as DOMINANT [28],\nAnomalyDAE [29], and GUIDE [30] reconstruct node fea-\ntures or graph structures, with reconstruction errors serv-\ning as anomaly scores. Contrastive learning methods such\nas DGI [31], InfoGraph [32], and CoLA [21] train mod-\nels to separate similar and dissimilar samples to improve\nanomaly discrimination. Knowledge distillation models such\nas GLADST [33] transfer stable representations from teacher\nto student models. Adversarial methods like AEGIS [34] and\nGAAN [35] use generator-discriminator frameworks to simu-\nlate challenging examples and improve generalization. Score\nprediction models, including Meta-GDN [36] and SAD [37],\ndirectly learn node-level anomaly scores within a unified\nframework. These approaches perform well without super-\nvision and have benefited from recent advances in deep\nlearning, but still face challenges in aligning proxy tasks with\nanomaly objectives and modeling the structural and attribute\nheterogeneity inherent across graphs.\n(3) Generalizable Methods. Most existing GAD methods\nare designed for specific graphs and depend heavily on task-\nspecific training, making them difficult to transfer across graph\ndomains. They often assume consistent structural patterns and\nanomaly types, limiting their effectiveness in real-world sce-\nnarios where graphs differ widely in topology, semantics, and\ncontext. Moreover, such models typically require retraining\non each new graph, which is computationally expensive and\noften impractical. To address these limitations, generalizable\nGAD methods [16], [17], [18], [19] aim to support anomaly\ndetection across diverse graph domains, enabling few-shot\nor zero-shot transfer. ARC [16] applies contextual learning\nto adapt models with limited target labels, but struggles in\nfully zero-shot scenarios. UNPrompt [17] introduces a uni-\nfied neighborhood prompting mechanism to detect anomalies\nwithout labels, although its performance is highly sensitive to\nthe source graph structure. More recently, AnomalyGFM [18]\nproposes a graph foundation architecture. This approach distin-\nguishes between normal and anomalous categories by mapping\nnode residual errors into a common embedding space to\nmatch domain-invariant prototypes. Parallelly, IA-GGAD [19]\nadvances this frontier by learning invariant representations and\nstructure-insensitive affinities, aiming to mitigate the impact\nof domain-specific structural noise. These approaches offer\npromising generalization capability but remain vulnerable to\nstructural inconsistencies and distribution shifts across do-\nmains. However, none of these approaches explicitly address\nthe intrinsic geometric heterogeneity across graphs, which we\nTABLE I: Summary of Key Notations.\nSymbol Definition\nGraph Structure & Attributes\nG An attributed graph.\nV The set of nodes.\nE The set of edges.\nA Adjacency matrix, A ∈ {0, 1}N ×N .\nN The number of nodes.\nD The dimension of the unified node features.\nX0 The raw node feature matrix with original dimensions.\nX The unified node feature matrix, X ∈ RN ×D .\nAnomaly Detection Task\nVa The set of anomalous nodes.\nVn The set of normal nodes.\ny The ground-truth label vector, y ∈ {0, 1}N .\nf An anomaly scoring function, f : V → R.\nDtrain The set of source graphs for training.\nDtest The set of unseen target graphs for testing.\nModel Concepts\nM A Riemannian manifold.\nκ The constant sectional curvature of a manifold.\nTpM The tangent space at point p on the manifold M.\nK The number of experts in the MoE model.\nEi The i-th expert network in the MoE model.\nG The gating network in the MoE model.\nRiemannian Geometry\ndE (p, q) The Euclidean distance between points p and q.\ndH(p, q) The hyperbolic distance between points p and q.\ndS (p, q) The spherical distance between points p and q.\nexpp The exponential map at point p on the manifold.\nlogp The logarithmic map at point p on the manifold.\nfind is essential for generalizable GAD.\nB. Mixture of Experts for Graph Learning\nMixture-of-Experts (MoE) architecture [38], [39] leverages\na gating network to dynamically assign inputs to specialized\nexpert models, thereby enabling conditional computation and\nscalable model capacity [40]. This design allows different\nexperts to focus on distinct data characteristics while main-\ntaining computational efficiency. While MoE has achieved\nnotable success in large-scale language and vision models [41],\n[42], [43], its adoption in graph learning remains relatively\nlimited, though recent efforts suggest a growing interest in\nthis direction. Recent studies [44], [45], [46] in graph learning\nhave explored MoE frameworks to address structural and\ndistributional heterogeneity inherent in graph data. For ex-\nample, GraphDIVE [47] and G-FAME [46] route minority\nor under-represented nodes to dedicated experts, aiming to\nimprove performance under data imbalance and fairness con-\nstraints. Other works implicitly adopt the MoE philosophy by\nvarying message-passing depths or spectral filters, effectively\ntreating different configurations as expert modules to diver-\nsify receptive fields and capture multi-scale graph structures.\nBeyond structural routing, MoW [45] decouples feature and\nstructure modalities to enable specialized processing, whereas\nGraphMoRE [44] introduces curvature-aware experts to adapt\nto geometric variation across graph representations. In the\ncontext of anomaly detection, MoEGAD [48] presents the\nfirst exploration of MoE architecture in Graph-Level Anomaly\nDetection, leveraging a latent MoE module and iterative\n\n-- 3 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 4\nanomalous graph generation to overcome the scarcity of la-\nbeled anomalies. Despite these advances, existing MoE-based\ngraph methods primarily focus on supervised tasks such as\nnode classification within a single graph domain. In contrast,\nthe potential of a geometry-aware MoE framework for the\ndistinct and more challenging problem of domain-general\ngraph anomaly detection remains largely unexplored. In this\nwork, we investigate how expert specialization and gating\nmechanisms can be leveraged to bridge distribution shifts\nacross domains and enable zero-shot GAD without requiring\nexhaustive retraining.\nC. Riemannian Graph Learning\nMany real-world graphs exhibit hierarchical or tree-like\norganizations, which are inherently difficult to model in Eu-\nclidean space [49]. As a result, Riemannian graph learn-\ning [50], [51] has emerged as a powerful and principled\nparadigm that embeds graph data into curved manifolds, most\nnotably hyperbolic spaces, to capture these intrinsic geometric\nproperties with significantly lower distortion [52], [53], [43].\nBy generalizing GNN operations, such as message passing and\naggregation, to these curved spaces, hyperbolic GNNs [54],\n[55] are able to more faithfully encode structural priors and\nrelational patterns present in complex graphs. While these\ngeometric methods have proven effective, their application has\npredominantly focused on supervised learning within a single\ngraph domain. The potential of leveraging diverse geometric\npriors from multiple curvature spaces for domain-general\nanomaly detection remains largely unexplored. In this work,\nwe propose a mixture of Riemannian experts architecture for\ngeneralizable GAD, where each expert operates in a distinct\nRiemannian manifold, enabling the model to effectively iden-\ntify anomalies across graphs.\nIII. PRELIMINARIES\nThis section formally defines the core problem and notations\nin this paper, and briefly reviews the necessary background on\ncurvature manifolds.\nA. Notations and Problem Formulation\nKey Notations: Our research focuses on the task of anomaly\ndetection at the node level. To facilitate a clear understanding\nof the framework, Table I organizes the essential symbols\nemployed throughout this study. Formally, we represent an\nattributed graph as G = (V, E, X), where the components\nV, E, and A correspond to the node set, the set of edges,\nand the adjacency matrix, respectively. The node set V is\npartitioned into anomalous nodes Va and normal nodes Vn,\nwhere |Va| ≪ |Vn|. The goal of Graph Anomaly Detection\n(GAD) is to learn a scoring function f : V → R such that\nf (va) > f (vn) for va ∈ Va, vn ∈ Vn.\nProblem Formulation: Our work focuses on the generaliz-\nable GAD paradigm. A model is trained on a set of source\ngraphs Dtrain = {G(1), . . . , G(M )} and evaluated on a set\nof unseen target graphs Dtest = {G(M +1), . . . , G(P )}, where\nDtrain ∩ Dtest = ∅. We address the zero-shot setting, where no\nlabeled data or fine-tuning on the target graphs is permitted. To\nensure a unified model input, raw feature matrices X(i)\n0 with\nvarying dimensionalities across different datasets are projected\ninto a shared D-dimensional feature space X ∈ RN ×D .\nB. Constant Curvature Manifolds\nOur method leverages Riemannian manifolds with constant\ncurvature (κ) to model diverse graph structures. Specifically,\nwe consider three types of manifolds, as described below:\n• Euclidean Space (κ = 0): A flat Riemannian space equipped\nwith the ℓ2-norm distance, defined as:\ndE (p, q) = ∥p − q∥2. (1)\n• Hyperbolic Space (κ < 0): A negatively curved hyperbolic\nspace is well suited for modeling hierarchical and tree-\nlike structures. Under the Poincar´e ball model, the distance\nbetween two points is defined as:\ndH(p, q) = 1\n√−κ arccosh\n\u0012\n1+ 2∥p − q∥2\n(1+κ∥p∥2)(1+κ∥q∥2)\n\u0013\n.\n(2)\n• Spherical Space (κ > 0): A positively curved spherical\nspace that is well-suited for modeling cyclical or periodic\nstructures. The distance is defined as:\ndS (p, q) = 1\n√κ arccos (⟨p, q⟩) . (3)\nThe choice of curvature κ fundamentally influences the\ngeometric properties of the embedding space and its suitability\nfor modeling different graph structures.\nIV. THE PROPOSED GAD-MORE FRAMEWORK\nGraph Anomaly Detection (GAD) faces a critical general-\nization challenge: models trained on specific graphs struggle\nto transfer learned anomaly patterns to unseen graphs due to\nsubstantial shifts in topology and anomaly characteristics. As\ndemonstrated in Section I, graph anomaly patterns exhibit ge-\nometric heterogeneity, i.e., variability in underlying curvature\nacross graph domains. Enforcing diverse graph structures into\na single fixed-curvature space inevitably distorts the distinct\nstructural patterns that define anomalies, hindering discrimina-\ntion between normal and anomalous nodes. Geometry acts as\na critical inductive bias: performance is highly sensitive to the\nchosen Riemannian space, with different datasets exhibiting\ndistinct curvature preferences, and no single geometry proves\nuniversally optimal.\nTo overcome the limitations of single-curvature repre-\nsentation, we propose GAD-MoRE, a novel Geometric-\naware framework for zero-shot Generalizable Graph Anomaly\nDetection with a Mixture-of-Experts architecture that inte-\ngrates three coordinated components to effectively resolve the\nconflicts arising from geometric heterogeneity. The overall\narchitecture is illustrated in Figure 2, which is coupled with\nthree critic modules:\n• Anomaly-aware Multi-curvature Feature Alignment: As the\nfoundational step, this module projects and aligns raw node\nfeatures from various sources and dimensions into a unified\ngeometry-aware feature space. By processing features in\n\n-- 4 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 5\nMixture of Riemannian Experts Scorer\tMemory-based\nDynamic Router\nnormal\nanormal\nFeature Alignment\nAnomaly-aware Multi-curvature\nFeature Alignment Anomaly Score\nlow \thigh\nSpherical Experts\n휅 > 0\n퐸￿￿￿ \t퐸￿\n…\nHyperbolic Experts\n휅 < 0\n퐸￿ \t퐸￿\n…\nEuclidean Expert\n휅 = 0\nE\nWeighted Aggregation\n풉퐯\n풉퐯\n풉퐯\n퐱퐯\n퐱퐯\n퐱퐯\n휿 < ퟎ\n휿 = ퟎ\n휿 > ퟎ\nUpdate Memory\nℬퟏ ℬퟐ \tℬ￿\n…\n퐦퐢퐧\n퐡퐯\n퐡퐯\n퐡퐯\n…\n퐰ퟏ 퐰ퟐ \t퐰퐤\n푬ퟏ \tE 푬￿\n풘풗\n푬ퟐ… …\nExpert Weights\nMemory Bank\nGNN Backbone\nLaplacian Feature Selection\n푑￿￿￿ Selected\nAnomaly Score\tℬ￿ Expert Memory Bank\tManifold Distance \t푑￿￿￿ Minimum Distance\nFig. 2: The overall architecture of the GAD-MoRE framework. (1) The Anomaly-aware Multi-curvature Feature Alignment\nmodule projects raw features into a unified, geometry-aware representation. (2) The Mixture of Riemannian Experts Scorer\nutilizes a GNN backbone to encode structural context and employs specialized Riemannian expert networks. (3) The Memory-\nbased Dynamic Router adaptively assigns nodes to these experts based on historical reconstruction quality to compute the final\nanomaly score.\nparallel across multiple curvature manifolds, it produces\nrepresentations enriched with diverse geometric information.\n• Memory-based Dynamic Router: This module assigns each\nnode to the most suitable Riemannian expert based on\ncurrent structural features together with previously learned\npatterns, thereby improving expert assignment on unseen\ndata and enhancing overall generalization.\n• Mixture of Riemannian Experts Scorer: This module utilizes\na lightweight graph encoder to capture structural context\nand employs a collection of specialized Riemannian expert\nnetworks. Each expert operates in a unique curvature space,\nenabling the model to capture disparate anomaly patterns\nwithout geometric distortion.\nTogether, these modules enable GAD-MoRE to dynamically\nadapt its geometric lens to the specific anomaly characteristics\nof each node, enabling effective zero-shot generalizable graph\nanomaly detection across diverse domains.\nA. Anomaly-aware Multi-curvature Feature Alignment\nRaw node features extracted from real-world graphs are\ninherently geometry-agnostic, as they exist in a flat Euclidean\nspace without explicit geometric information. Yet, to effec-\ntively capture diverse structural patterns without distortion, our\nRiemannian expert networks must operate in distinct constant-\ncurvature spaces.\nThis creates a fundamental mismatch: the Riemannian\nexperts in MoE require manifold-aware inputs, while raw\nfeatures lack geometric semantics. Simply feeding Euclidean\nfeatures directly to curved-space experts is geometrically in-\nconsistent and fails to leverage the representational advantages\nof non-Euclidean geometries. Moreover, different graph do-\nmains exhibit preferences for different geometric curvatures,\nas demonstrated empirically in Section I.\nTo construct robust and generalizable inputs for Riemannian\nexperts, we explicitly embed signals from multiple Rieman-\nnian spaces into the initial node features, preserving both the\nrich attribute information and global structural consistency.\nTo address this challenge, we introduce a feature alignment\nmodule that explicitly projects raw features into diverse Rie-\nmannian spaces before feeding them to the experts. Given a\nraw feature matrix X0, the module performs a parallel trans-\nformation into a set of diverse Riemannian spaces, {Mκc }C\nc=1.\nThis set includes Euclidean space (κ = 0) alongside multiple\ncurved spaces characterized by different constant negative\n(κ < 0) and positive curvatures (κ > 0). The total target\nfeature dimension D is partitioned across these C spaces,\nsuch that D = PC\nc=1 Dc, where Dc is the final dimensionality\nassigned to the c-th space. For curved spaces, the raw features\nare first mapped into the tangent space at the origin before\nfurther processing. To ensure that the features selected for each\nRiemannian space are both informative and dimensionally\nconsistent, we employ a two-stage selection process:\nStage 1: Dimensionality Reduction. To construct\ngeometry-specific feature candidates for each target manifold\nMc, we first project the raw features X0 into C paral-\nlel constant-curvature manifolds {Mκc }C\nc=1. Specifically, for\ncurved spaces, the raw attributes are mapped into the tangent\nspace at the origin Toc Mc via the logarithmic map, thereby\ntransforming geometry-agnostic features into manifold-aware\nrepresentations. Then, we perform Principal Component Anal-\nysis (PCA) [56], [57] on these tangent-space features to extract\n\n-- 5 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 6\nthe principal components corresponding to each specific c-th\ncurvature space. This step identifies the principal components\nof the feature space, capturing global high-variance attribute\nsignals that are most informative for node discrimination.\nStage 2: Laplacian Feature Selection. We then compute\nthe Laplacian score for each feature fj in the intermediate set\nX′\nc:\nL(fj ) = f ⊤\nj\n\u0010\nI − D− 1\n2\nG AD− 1\n2\nG\n\u0011\nfj , (4)\nwhere DG = diag(A1). Note that we omit the denominator\nterm f ⊤\nj DG fj commonly used in the classical definition,\nconsistent with our implementation. We then select the top-\nDc features with the lowest scores to form the final feature\nset for that space, Xfinal\nc ∈ RN ×Dc . This selection ensures that\nthe chosen features are smooth and consistent with the local\ngraph topology, thus preserving crucial structural information\nessential for anomaly detection.\nIdeally, PCA extracts high-variance attribute signals, while\nthe subsequent Laplacian Score selection enforces struc-\ntural consistency, yielding features that are both informa-\ntive and geometrically meaningful. Finally, the selected\nfeatures from all Riemannian spaces are concatenated\nto form a unified geometry-aware feature matrix X =\nCONCAT(Xfinal\n1 , . . . , Xfinal\nC ) ∈ RN ×D .\nThe multi-curvature feature alignment module bridges\nthe gap between geometry-agnostic raw features and the\ngeometry-aware inputs required by the Riemannian expert\nnetworks. The resulting unified feature representation explic-\nitly encodes signals from multiple curvature spaces while\npreserving both attribute richness and structural coherence,\nproviding a robust foundation for the subsequent Riemannian\nexperts to capture diverse graph anomaly patterns.\nB. Mixture of Riemannian Experts Scorer\nDifferent graph domains exhibit fundamentally different\nstructural characteristics that are best captured in distinct\nRiemannian spaces. For instance, hierarchical graphs with tree-\nlike structures are naturally suited for hyperbolic geometry,\nwhile graphs with dense, cyclical communities align better\nwith positively curved spherical spaces. When anomalies\nare defined as deviations from these underlying structural\npatterns, enforcing all graphs into a single fixed-curvature\nspace induces critical distortions. In a hyperbolic space, dense\ncommunities may explode and distort, making anomalous\nisolated nodes indistinguishable from the distorted normal\nnodes. Conversely, in a spherical space, hierarchical structures\nmay be compressed, obscuring bridge nodes that improperly\nconnect distant branches. This geometric mismatch makes it\nextremely difficult to distinguish subtle structural anomalies\nfrom normal variations. Effectively capturing diverse structural\npatterns without distortion requires an adaptive mechanism\nthat represents nodes in their most suitable Riemannian space.\nThis necessitates a unified architecture capable of accom-\nmodating multiple, potentially conflicting Riemannian repre-\nsentations. In the zero-shot setting, anomaly patterns across\ngraph domains prefer different Riemannian representations, so\na single learned curvature becomes a compromise, whereas a\nMoE formulation enables adaptive geometric selection.\nAlgorithm 1 The overall training pipeline of GAD-MoRE.\nRequire: Source graphs Dtrain, number of experts K, active\nexperts k, GNN hops L, loss weights {λj }5\nj=1, cold-start\nepochs Ecold.\nEnsure: Trained model parameters Θ and expert memories\n{Bj }K\nj=1.\n1: /* Offline Preprocessing */\n2: for i = 1, . . . , M do\n3: Align features: X(i) ← MCFA(X(i)\n0 , A(i)).\n4: Propagate structure: {H(l)}L\nl=0 ← Prop(X(i), A(i), L).\n5: end for\n6: /* Model Training */\n7: Initialize expert memories Bj ← ∅ for j = 1, . . . , K.\n8: for epoch = 1, . . . , Etotal do\n9: for each G(i) ∈ Dtrain do\n10: /* Forward Pass */\n11: Encode structural context: Hres ←\nGNN({H(l)}L\nl=0).\n12: Compute raw logits s for all v ∈ V by Eq. (8).\n13: Apply training noise: ˜s ← s + Noise(·).\n14: Select top-k experts S(v) and weights wv by Eq. (6).\n15: Reconstruct embeddings ˆH by Eq. (7).\n16: Decode outputs: ˆX ← Dec( ˆH), ˆA ← σ( ˆH ˆH⊤).\n17: /* Compute Losses */\n18: Compute reconstruction losses Lembed, Lfeat, Lstruct.\n19: Compute Lcon by Eq. (17).\n20: Compute Lgate by Eq. (18).\n21: Ltotal ← P5\nj=1 λj Lj by Eq. (19).\n22: /* Optimization */\n23: Update parameters: Θ ← Θ − η∇ΘLtotal.\n24: /* Dynamic Memory Update */\n25: if epoch > Ecold then\n26: for j = 1, . . . , K do\n27: Compute quality scores q(v, j) by Eq. (11).\n28: Add high-quality samples to Bj by Eq. (12).\n29: end for\n30: end if\n31: end for\n32: end for\nNode embeddings, which encode both multi-curvature at-\ntributes and structural context from the GNN backbone, are\nfed into the central innovation of GAD-MoRE: the mixture\nof Riemannian experts scorer. The GNN backbone first pro-\nduces multi-hop feature matrices {H(0), . . . , H(Khops)} where\nH(0) = X. A shared MLP Φ transforms {H(0), . . . , H(Khops)}\ninto {X′\nk = Φ(H(k))}. The final node embedding hv is\nthen constructed using a residual formulation to capture\nstructural deviations, defined as hv = CONCAT(X′\n1(v) −\nX′\n0(v), . . . , X′\nKhops (v) − X′\n0(v)). This residual formulation is\ndesigned to explicitly capture how a node’s representation\nevolves as structural information is aggregated from pro-\ngressively larger neighborhoods. Large deviations between a\nnode’s initial features (X′\n0) and its aggregated features (X′\nk)\nindicate structural irregularity, providing a strong signal for\n\n-- 6 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 7\nanomaly detection. This embedding hv is then input into the\nMoE scorer.\nTo simultaneously accommodate multiple Riemannian rep-\nresentations, we employ a Mixture-of-Experts (MoE) archi-\ntecture with specialized Riemannian Expert Networks. The\nMoE model consists of a set of K expert networks, {Ei}K\ni=1.\nEach expert is a Riemannian expert, a small neural network\ndesigned to operate within a specific Riemannian manifold\nMκi with learnable curvature κi. Each expert Ei takes a node\nembedding hv from the Euclidean tangent space and computes\nits reconstruction ˆh(i)\nv . This process involves mapping the\ninput onto the manifold, processing it through manifold-aware\nlayers, and mapping the result back to the tangent space:\nˆh(i)\nv = logoi\n\u0000Ei\n\u0000expoi (hv )\u0001\u0001 , (5)\nwhere expoi and logoi are the exponential and logarithmic\nmaps at the origin oi of the manifold Mκi . This design allows\ndifferent experts to specialize in reconstructing nodes that\nconform to different geometric priors, effectively capturing\nthe diverse structural patterns present across graph domains.\nFollowing the practice of modern MoE, we employ sparse top-\nk routing to enable efficient conditional computation. For each\nnode, the router first computes the gating weights g(hv ) from\nthe raw logits s(hv ):\ng(hv ) = Softmax\n\u0012 s(hv )\nτ\n\u0013\n, (6)\nwhere the temperature is controlled by the parameter τ . From\nthe computed probabilities, the top-k experts with maximal\ninfluence are selected for the active set S(v). The final\noutput ˆhv is computed as a weighted linear combination of\noutputs from these chosen experts, re-normalized among the\nk candidates:\nˆhv = X\ni∈S(v)\nexp (si(hv )/τ )\nP\nj∈S(v) exp (sj (hv )/τ ) · ˆh(i)\nv . (7)\nThis mechanism allows for expanded model capacity while\nkeeping the per-node resource consumption manageable. As\na result, GAD-MoRE is well-suited for large-scale applica-\ntions, offering a scalable solution that still captures intricate\ngeometric patterns effectively.\nBy deploying experts in distinct curvature spaces and adap-\ntively selecting among them, GAD-MoRE represents nodes\nin their optimal geometric configuration, avoiding distortions\ninherent to fixed-geometry approaches and enabling accurate\nand generalizable detection of structural anomalies across\ndiverse graph domains.\nC. Memory-based Dynamic Router\nWith specialized Riemannian Expert Networks, each tai-\nlored to distinct structural patterns under its optimal curvature,\nthe central routing challenge is to assign each node to the\nmost suitable Riemannian expert for accurate anomaly scoring.\nConventional routing mechanisms in MoE models typically\nrely on learned gating networks that predict expert assignments\nbased on input features alone. For anomaly detection, however,\nthe routing policy must be tightly coupled to the reconstruction\nAlgorithm 2 Inference Procedure of GAD-MoRE\nRequire: Test graph Gtest(Xtest\n0 , Atest), trained model Θ, expert\nmemories {Bj }K\nj=1.\nEnsure: Anomaly scores S ∈ RNtest .\n1: /* Preprocessing */\n2: Align features: Xtest ← MCFA(Xtest\n0 , Atest) by Eq. (4).\n3: Propagate structure: {H(l)}L\nl=0 ← Prop(Xtest, Atest, L).\n4: /* Encoding & Routing */\n5: Encode structural context: Hres ← GNN({H(l)}L\nl=0).\n6: for each node v ∈ Vtest do\n7: Compute logits sv : sv,j ← − minm∈Bj dMj (. . . ) by Eq. (8).\n8: Calculate gating weights gv and select top-k set S(v) by\nEq. (6).\n9: end for\n10: /* Reconstruction */\n11: Reconstruct embeddings: ˆH ← P\nv\nP\nj∈S(v) wv,j · Ej (hv,res)\nby Eq. (7).\n12: /* Anomaly Scoring */\n13: for each node v ∈ Vtest do\n14: Calculate score: S(v) ← ∥hv − ˆhv ∥2 by Eq. (20).\n15: end for\n16: return S.\nobjective: nodes should be directed to experts who can recon-\nstruct their patterns with high fidelity, as reconstruction error\ndirectly determines the anomaly score. Without this alignment,\nthe router may assign nodes to geometrically inappropriate\nexperts, leading to unreliable anomaly scores and degraded\ndetection performance. Moreover, a node’s optimal Rieman-\nnian space depends on its historical reconstruction quality\nacross different experts, which is not captured by feature-based\nrouting alone. This motivates a routing mechanism capable\nof adaptively selecting experts based on their demonstrated\nability to reconstruct similar patterns, thereby ensuring that\nthe routing policy directly aligns with the anomaly detection\nobjective.\nTo enable reconstruction quality-based routing, we propose\na memory-based dynamic router that makes routing decisions\nbased on historical performance patterns. Each expert Ei\nis equipped with an expert memory bank Bi, which stores\na collection of node embeddings {mi,1, mi,2, . . . } that the\nexpert has previously reconstructed with high fidelity. These\nmemory banks serve as geometric prototypes, representing the\npatterns that each expert specializes in handling. For a given\nnode embedding hv , the router computes its similarity to each\nmemory bank. The raw routing logit si(hv ) for expert i is\ndefined as the negative squared minimum manifold distance\nfrom hv to any embedding in the memory bank Bi:\nsi(hv ) = − min\nm∈Bi\ndMi\n\u0000expoi (hv ) , expoi (m)\u0001 , (8)\nwhere dMi (·, ·) is the distance metric on the manifold of\nexpert i. This score measures how close node v is to the\npatterns that expert i is specialized in handling based on its\nhistorical reconstruction performance.\nExpert Memory Banks are not static but are populated\nand refined dynamically throughout the training process to\nstore a representative set of node embeddings that each expert\nreconstructs with high fidelity. The update mechanism is gov-\nerned by a multi-stage strategy involving a cold-start period, a\n\n-- 7 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 8\ndynamic quality gate, and a strategic replacement policy. The\nupdate process is triggered after each training batch. To allow\nthe expert networks to stabilize before populating memory\nbanks, we implement a cold-start period during which memory\nbanks remain inactive. This prevents the storage of low-quality\nreconstructions from poorly initialized experts. After the cold-\nstart period, for each expert Ei, we calculate a quality score\nq(v, i) for each candidate node embedding hv assigned to it.\nLet Lrecon(v, i) = ∥hv − ˆh(i)\nv ∥2\n2 be the reconstruction error,\nwhere ˆh(i)\nv is the reconstruction by expert Ei. We define the\nminimum and maximum errors within the current batch Bbatch\nas:\nL(i)\nmin = min\nv′∈Bbatch\nLrecon(v′, i), (9)\nL(i)\nmax = max\nv′′∈Bbatch\nLrecon(v′′, i). (10)\nThe normalized quality score is:\nq(v, i) = 1 − Lrecon(v, i) − L(i)\nmin\nL(i)\nmax − L(i)\nmin + ϵ . (11)\nA dynamic quality gate is then applied to filter these candidates\nand select a high-quality subset C∗\ni exceeding a progressively\nstricter threshold τq (e) defined as a function of the current\ntraining epoch e:\nC∗\ni = {hv | q(v, i) ≥ τq (e)}. (12)\nThe threshold τq (e) increases linearly as training progresses,\nensuring that the memory banks are populated with examples\nof progressively higher quality:\nτq (e) = τmin + (τmax − τmin) · min\n\u0012\n1, e − Ecold\nEtotal − Ecold\n\u0013\n,\n(13)\nwhere τmin and τmax are the start and end thresholds, and\nEcold and Etotal are the number of cold-start and total training\nepochs, respectively. To handle batches with universally low\nquality, the gate adaptively falls back to a percentile-based\nthreshold. Once high-quality candidates in C∗\ni are selected,\nthey are added to the memory bank Bi. If a bank is full, a\nhysteretic replacement policy is enacted: a new candidate will\nonly replace the existing embedding with the lowest quality\nscore if its own quality surpasses it by a significant margin.\nThis prevents noisy fluctuations and ensures memory stability.\nTo avoid domination by any single batch, the number of\nembeddings added per update is also capped.\nBy adaptively assigning nodes based on historical recon-\nstruction quality rather than feature similarity alone, the rout-\ning policy aligns expert selection with the anomaly detection\nobjective, directing each node to the Riemannian space where\nit is best modeled.\nFrom a modeling perspective, the proposed memory-based\ndynamic router provides a principled way to select experts\nbased on reconstruction behavior, rather than relying on\nfeature-based gating alone. Each Riemannian expert can be\nviewed as capturing a specific notion of normality under a\ngiven curvature prior, while its memory bank summarizes\nthe regions of the embedding space where this expert has\nconsistently achieved low reconstruction error. By routing\nnodes according to historical reconstruction fidelity, the router\neffectively favors experts who are better suited to model\nsimilar structural patterns. This design naturally aligns the\nrouting strategy with the anomaly detection objective, in which\nreconstruction error serves as the primary signal for identifying\nabnormal nodes.\nD. Model Training and Optimization\nGAD-MoRE is trained end-to-end in an unsupervised man-\nner, as detailed in Algorithm 1. The total loss function Ltotal\nis a weighted sum of multiple components:\n• Embedding Reconstruction Loss (Lembed): The primary\nreconstruction objective, defined as the Mean Squared\nError:\nLembed = 1\n|V|\nX\nv∈V\n∥hv − ˆhv ∥2\n2. (14)\n• Feature Reconstruction Loss (Lfeat): This loss enforces\nthe reconstructed embedding to preserve attribute infor-\nmation. A linear decoder maps the reconstructed embed-\nding ˆhv back to the original feature space, and the Mean\nSquared Error is computed against the original features\nXv :\nLfeat = 1\n|V|\nX\nv∈V\n∥Xv − Decoderfeat\n\u0010ˆhv\n\u0011\n∥2\n2. (15)\n• Structure Reconstruction Loss (Lstruct): This loss pre-\nserves topological information. The adjacency matrix is\nreconstructed via an inner product of the reconstructed\nembeddings. Let ˆH be the matrix formed by stacking all\nreconstructed node embeddings ˆhv . The Binary Cross-\nEntropy (BCE) loss is then computed against the original\nadjacency matrix A:\nLstruct = BCE\n\u0010\nσ\n\u0010 ˆH ˆH⊤\u0011\n, A\n\u0011\n. (16)\n• Structure-Contrastive Loss (Lcon): This structure-aware\nInfoNCE loss encourages connected nodes to have similar\nrepresentations. For a node v, the loss is:\nLcon(v) = − log\nP\nu∈Pv exp (sim (hv , hu) /τc)\nP\nj∈V exp (sim (hv , hj ) /τc) , (17)\nwhere Pv = {u | Avu = 1} is the set of posi-\ntive neighbors of v, and τc is a temperature parameter.\nFor large graphs, the denominator is computed over a\nrandomly sampled subset of nodes, consistent with our\nimplementation.\n• Gate Entropy Regularization (Lgate): This entropy-based\nloss encourages balanced router assignments and prevents\nexpert collapse. To maximize entropy, we minimize its\nnegative, which we define as the gate loss term:\nLgate = − 1\n|V|\nX\nv∈V\nH (g (hv ))\n= 1\n|V|\nX\nv∈V\nK\tX\ni=1\ngi (g (hv )) log gi (g (hv )) . (18)\n\n-- 8 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 9\nTABLE II: Statistics of the benchmark datasets.\nDataset #Nodes #Edges #Feat. #Anom. (%)\nTraining Datasets\nPubMed 19,717 44,338 500 600 (3.04)\nFlickr 7,575 239,738 12,047 450 (5.94)\nReddit 10,984 168,016 64 366 (3.33)\nYelpChi 23,831 49,315 32 1,217 (5.10)\nTest Datasets\nACM 16,484 71,980 8,337 597 (3.62)\nAmazon 10,244 175,608 25 693 (6.76)\nBlogCatalog 5,196 171,743 8,189 300 (5.77)\nCiteseer 3,327 4,732 3,703 150 (4.50)\nCora 2,708 5,429 1,433 150 (5.53)\nFacebook 1,081 55,104 576 25 (2.31)\nWeibo 8,405 407,963 400 868 (10.30)\nBy integrating these modules with specific hyperparameters,\nthe total training loss is established as follows:\nLtotal = λ1Lembed + λ2Lfeat + λ3Lstruct\n+ λ4Lcon + λ5Lgate, (19)\nwhere λ1, λ2, λ3, λ4, λ5 are the hyperparameters that control\nthe relative contributions of each loss term.\nFor the structure-contrastive objective, we use a memory-\nefficient implementation with mini-batch sampling and chun-\nked computations to approximate InfoNCE on large graphs\nwithout exceeding GPU memory. Specifically, the similarity\nfunction sim(hv , hu) operates on the node embedding vectors.\nE. Anomaly Inference\nDuring the inference procedure, as detailed in Algorithm 2,\nGAD-MoRE is deployed on unseen graphs in a zero-shot\nmanner. For each node v, we compute the anomaly score S(v)\nas the L2 norm of the residual between the input representation\nhv and its MoE-reconstructed counterpart ˆhv :\nS(v) = ∥hv − ˆhv ∥2. (20)\nHigher scores indicate greater deviation from curvature-aware\nnormal patterns learned by the Riemannian experts, reflecting\nreduced reconstruction fidelity and thus stronger evidence of\nanomalous structure.\nV. EXPERIMENTS\nIn this section, we conduct comprehensive experiments to\nsystematically evaluate our proposed GAD-MoRE framework.\nThe evaluation is designed to answer the following key re-\nsearch questions:\n• RQ1: Overall Performance. How does GAD-MoRE per-\nform against a wide range of supervised, unsupervised,\nand state-of-the-art generalist baselines in the challenging\nzero-shot cross-domain setting?\n• RQ2: Key Component Analysis. What are the precise con-\ntributions of the core innovations in GAD-MoRE, namely\nthe anomaly-aware multi-curvature feature alignment, the\nmixture of Riemannian experts scorer, and the memory-\nbased dynamic router, to overall model performance?\n• RQ3: Hyperparameter Sensitivity. How sensitive is GAD-\nMoRE to its key hyperparameters, such as the embedding\ndimension and the number of experts, assessing its robust-\nness and practical applicability?\n• RQ4: Comparison with Few-shot Learners. How does\nour strictly zero-shot GAD-MoRE model compare against\nstrong generalist competitors that are fine-tuned with a\nsmall number of labeled samples from the target graph?\nA. Experimental Setup\n1) Datasets: To evaluate the generalization capability of\nour model, we conduct experiments on 11 widely used\nbenchmark datasets spanning citation, social, and co-review\nnetworks. Following a rigorous protocol, all models are trained\non four source graphs (PubMed [15], Flickr [28], [58], Red-\ndit [14], YelpChi [7], [59]) and evaluated on seven unseen\ntarget graphs (ACM [60], Amazon [7], [59], BlogCatalog [28],\n[58], Citeseer [15], Cora [15], Facebook [61], Weibo [14]).\nDataset statistics are summarized in Table II.\n2) Baselines: To ensure a rigorous and fair experimental\nvalidation, we benchmark the proposed GAD-MoRE against\nan extensive collection of competitive methods:\n• Supervised Baselines: These methods are trained on\nthe source graphs with full label access. We include\nGCN [62], a foundational model that aggregates neigh-\nborhood features; GAT [63], which uses attention mecha-\nnisms for weighted neighbor aggregation; BWGNN [64],\nwhich applies band-pass filters to amplify high-frequency\nsignals associated with anomalies; and GHRN [24], which\nis designed to handle heterophily in graphs.\n• Unsupervised Baselines: These methods are trained on\nthe source graphs without any labels. We include Anoma-\nlyDAE [29], a classic reconstruction-based method us-\ning a dual autoencoder for structure and attributes;\nCoLA [21], a contrastive learning framework that learns\nrepresentations by distinguishing nodes from their cor-\nrupted counterparts; and TAM [37], which optimizes node\nembeddings based on a local affinity assumption.\n• Zero-shot Generalist Methods: These are the current\nstate-of-the-art models designed for zero-shot cross-\ndomain anomaly detection. We include UNPrompt [17],\nwhich utilizes a unified neighborhood prompting mech-\nanism; AnomalyGFM [18], a graph foundation model\nthat learns graph-agnostic prototypes; and the newest IA-\nGGAD [19] framework, which learns invariant represen-\ntations and structure-insensitive affinities.\n3) Evaluation Metrics: To evaluate anomaly detection per-\nformance comprehensively, we adopt two standard metrics:\nAUROC and AUPRC, which respectively assess overall dis-\ncriminative ability and performance on the minority class. To\nensure the stability of our findings, we conduct 5 independent\nruns for every experiment using various random seeds, pro-\nviding both average results and their corresponding standard\ndeviations.\n4) Implementation Details: For the detailed hyperparameter\nsettings, the unified feature dimension D after alignment is set\nto 32. The GNN backbone for structure encoding consists of 4\n\n-- 9 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 10\nTABLE III: AUROC results on seven target Graph Anomaly Detection (GAD) datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting. The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod \tACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\nSupervised\nGCN 47.69±1.48 53.83±4.01 51.99±3.20 43.83±2.39 46.09±18.88 37.64±13.84 41.10±4.24 46.02\nGAT 46.54±4.71 44.58±8.25 44.65±6.20 49.32±1.70 53.96±26.14 35.50±6.91 55.35±5.69 47.13\nBWGNN 67.43±2.48 42.58±2.86 39.75±3.16 69.91±4.66 64.84±4.17 50.08±0.03 50.01±0.04 54.94\nGHRN 52.72±1.01 54.11±0.88 47.65±2.03 62.28±2.42 54.04±3.81 17.79±5.00 63.52±1.92 50.30\nUnsupervised\nAnomalyDAE 77.60±1.03 82.00±2.78 84.01±1.19 57.53±0.30 10.87±0.70 19.77±1.14 58.38±0.25 55.74\nCoLA 49.30±1.00 52.56±1.36 49.35±1.52 49.50±1.27 50.70±5.49 45.25±2.39 47.57±3.02 49.17\nTAM 50.39±0.08 46.44±0.15 48.78±0.17 33.03±0.28 54.56±0.36 21.50±0.30 52.37±0.12 43.87\nGeneralist\nUNPrompt 73.20±0.36 59.53±0.53 63.18±1.29 70.85±0.50 60.64±1.94 66.29±1.38 72.14±2.94 66.55\nAnomalyGFM 38.91±1.21 40.37±1.37 40.93±1.09 40.93±1.22 74.45±2.36 44.43±4.89 61.24±5.21 48.75\nIA-GGAD 78.44±0.46 91.54±0.32 85.69±0.77 73.03±1.20 69.59±1.39 87.35±0.40 53.38±1.76 77.00\nGAD-MoRE 81.17±0.05 90.28±0.13 86.39±0.20 73.09±0.06 75.75±0.95 91.03±0.11 76.90±1.80 82.09\nTABLE IV: AUPRC results on seven target Graph Anomaly Detection (GAD) datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting. The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod \tACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\nSupervised\nGCN 3.68±0.16 5.21±0.89 5.85±0.55 5.71±0.38 4.55±3.06 25.97±15.84 5.54±0.51 8.07\nGAT 3.38±0.45 4.35±0.82 4.93±0.75 6.64±0.71 6.18±5.83 15.86±5.83 8.10±1.24 7.06\nBWGNN 19.48±2.20 4.02±0.43 5.30±0.87 28.37±4.31 5.71±1.60 10.47±0.05 6.79±0.03 11.45\nGHRN 9.21±2.94 5.37±0.14 5.23±0.19 24.57±3.60 3.61±0.68 8.35±2.44 11.18±1.10 9.65\nUnsupervised\nAnomalyDAE 11.67±0.38 31.37±1.09 32.65±1.46 7.17±0.04 1.32±0.01 6.10±0.08 9.26±1.51 14.22\nCoLA 3.55±0.12 4.76±0.21 5.86±0.34 6.11±0.36 3.41±1.38 9.67±0.50 6.55±0.44 5.70\nTAM 3.74±0.01 4.15±0.02 5.58±0.08 5.66±0.17 5.37±0.51 6.20±0.02 7.90±0.05 5.51\nGeneralist\nUNPrompt 24.02±1.38 9.47±0.91 10.26±0.52 35.29±0.90 3.44±0.31 28.41±2.25 12.28±1.63 17.59\nAnomalyGFM 3.10±0.17 3.69±0.20 4.36±0.09 4.85±0.40 6.00±0.52 9.05±1.03 9.18±1.69 5.75\nIA-GGAD 36.33±0.16 46.96±1.16 45.03±2.06 36.64±0.66 8.65±1.74 60.16±0.93 6.90±0.29 34.38\nGAD-MoRE 37.17±0.07 40.15±1.31 45.25±0.88 35.31±0.42 9.00±1.12 60.26±0.30 31.55±4.84 36.96\nlayers and aggregates information from a 2-hop neighborhood.\nThe final node embeddings are constructed using residual con-\nnections to capture deviations from the initial node features.\nFor the MoE scorer, the number of experts K is set to 5, and\nwe use a top-k routing strategy with k = 2. The Riemannian\nexperts are initialized with a diverse set of curvatures to cover\ndifferent Riemannian spaces; specifically, the initial curvatures\nare set to [0.0, -0.5, -1.0, 0.5, 1.0], allowing experts to\nspecialize in Euclidean, Hyperbolic, and Spherical geometries.\nThe gating mechanism’s softmax temperature is set to 0.7.\nThen we use the Adam optimizer with a learning rate of 5e-\n5 and a weight decay of 5e-5, training for 40 epochs on the\ncombined source graphs. The weights for the components in\nour final loss function (Eq. (19)) are set as λ1 = 1.0 (Lembed),\nλ2 = 0.5 (Lfeat), λ3 = 0.1 (Lstruct), λ4 = 0.1 (Lcon), and\nλ5 = 0.01 (Lgate). For all baselines, we adopt the optimal\nhyperparameter settings reported in their original papers or\ntune them on the source graphs. All experiments are conducted\non a single NVIDIA Tesla A100 with 40GB of memory.\nB. Overall Performance (RQ1)\nThe results, as detailed in Table III and Table IV, demon-\nstrate the superiority of our proposed GAD-MoRE frame-\nwork. Across seven test datasets, GAD-MoRE consistently\nachieves state-of-the-art performance with an average AUROC\nof 82.09% and AUPRC of 36.96%, surpassing all baseline\ncategories. Compared to the strongest generalist competitor,\nIA-GGAD, our model achieves an absolute improvement of\n5.09% in average AUROC, validating the effectiveness of our\ndesign. Specifically, it establishes a remarkable lead on the\nstructurally complex Weibo dataset, demonstrating the neces-\nsity of our specialized Riemannian experts. Notably, GAD-\nMoRE outperforms even the fully supervised baselines, which\nhave access to anomaly labels on the source graphs. This high-\nlights the limitation of traditional supervised learning in gen-\neralizing to new domains and underscores the effectiveness of\n\n-- 10 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 11\nACM\n60\n65\n70\n75\n80\n85\nAUROC (%)\n79.49\n81.16\n64.38\n81.17\nCiteseer\n84\n86\n88\n90\n92\n86.60\n90.20\n86.24\n90.28\nCora\n80\n82\n84\n86\n88\n84.66\n86.34\n82.14\n86.39\nFacebook\n60\n65\n70\n75\n80\n65.58\n75.52\n68.53\n75.75\nw/o MCFA \tw/o MDR \tw/o MoE \tGAD-MoRE\nFig. 3: AUROC performance of GAD-MoRE and its ablation variants on target GAD datasets. All models are trained exclusively\non four source graphs (PubMed, Flickr, Reddit, YelpChi) and evaluated in a zero-shot cross-domain setting.\n8 \t16 \t32 \t48\nAlignment Dimension\n72\n78\n84\n90\n96\nAUROC (%)\n8 \t16 \t32 \t48\nAlignment Dimension\n20\n32\n44\n56\n68\nAUPRC (%)\n2 \t3 \t4 \t5 \t6\nNumber of Experts\n76\n81\n86\n91\n96\nAUROC (%)\n2 \t3 \t4 \t5 \t6\nNumber of Experts\n32\n40\n48\n56\n64\nAUPRC (%)\nACM \tCiteseer \tCora \tWeibo\nFig. 4: Hyperparameter sensitivity analysis of GAD-MoRE. The left two subplots show the impact of the unified embedding\ndimension D on AUROC and AUPRC, while the right two subplots illustrate the sensitivity to the number of experts K.\nGAD-MoRE’s unsupervised, geometry-aware approach. When\ncompared to other generalist methods like UNPrompt and\nAnomalyGFM, GAD-MoRE shows a substantial improvement\nin both average metrics. This validates our core hypothesis\nthat explicitly modeling the geometric heterogeneity of graphs\nis crucial for effective domain generalization. The strong\nAUPRC score is particularly significant, as it confirms that\nour proposed GAD-MoRE is highly effective at identifying\nthe rare anomalous nodes in an imbalanced setting.\nFurthermore, the effectiveness of GAD-MoRE in distin-\nguishing normal from anomalous patterns is visualized in\nFigure 5, which shows the anomaly score distributions. In\nboth datasets, normal nodes (blue) receive lower scores, while\nanomalous nodes (red) are assigned higher scores, highlighting\nGAD-MoRE’s ability to accurately identify anomalies.\nC. Key Component Analysis (RQ2)\nTo answer our second research question and quantify the\nprecise contributions of the central innovations within GAD-\nMoRE, we conduct a thorough ablation study. We design\nseveral variants of our model, each disabling or replacing a key\ncomponent, and evaluate their AUROC performance against\nthe full model on representative datasets. The components\nunder investigation are: We define the following variants for\ncomparison, with their acronyms matching Figure 3:\n• w/o MCFA: In this variant, we bypass the MCFA module\nand use a standard PCA for dimensionality reduction,\nremoving the multi-geometry signals.\n0.0 \t2.5 \t5.0 \t7.5\nAnomaly Score\n0.0\n0.2\n0.4\n0.6\n0.8\nDensity\nNormal\nAnomaly\n(a) Citeseer\n0.0 \t2.0 \t4.0 \t6.0\nAnomaly Score\n0.0\n0.2\n0.4\n0.6\n0.8\nDensity\nNormal\nAnomaly\n (b) Cora\nFig. 5: The anomaly score distributions for Citeseer and Cora\nshow a clear distinction between normal and anomalous nodes.\nThis visual evidence confirms that our approach can effectively\ndetect anomalies in these graph datasets.\n• w/o MoE: We replace the MoE scorer with an attention-\nbased reconstruction scorer over reference embeddings.\n• w/o MDR: In this version, we replace our Memory-based\nDynamic Router with a simpler linear router.\nFigure 3 presents the results of our ablation study. These\nfindings clearly confirm the critical importance of each model\ncomponent. The most significant performance degradation is\nobserved in the w/o MoE variant, with the average AUROC\ndropping to 75.32%. This provides the strongest empirical\nevidence for our central hypothesis: a single geometric lens\nis insufficient for generalizable GAD, and a collection of\nspecialized Riemannian experts is essential for robust per-\nformance. By contrast, removing the Multi-curvature Fea-\n\n-- 11 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 12\nTABLE V: AUROC performance comparison (in %) of a zero-shot model against few-shot competitors on seven target Graph\nAnomaly Detection (GAD) datasets. The few-shot methods are fine-tuned with 10 labeled samples (10-shot). The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod ACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\n10-shot ARC 78.33±1.13 82.31±2.89 82.22±2.34 72.59±1.10 64.94±3.72 88.65±0.82 57.95±6.13 75.28\nAnomalyGFM 41.88±0.73 46.60±0.61 43.56±1.04 38.19±0.34 81.96±3.08 49.68±3.43 66.03±1.91 52.56\n0-shot GAD-MoRE 81.17±0.05 90.28±0.13 86.39±0.20 73.09±0.06 75.75±0.95 91.03±0.11 76.90±1.80 82.09\nTABLE VI: AUPRC performance comparison (in %) of a zero-shot model against few-shot competitors on seven target Graph\nAnomaly Detection (GAD) datasets. The few-shot methods are fine-tuned with 10 labeled samples (10-shot). The performance\nresults highlight the optimal outcomes in bold and the subsequent best in underline for every dataset. Furthermore, the “Average”\ncolumn indicates the calculated mean efficacy across the entire suite of benchmarks.\nDataset \tCitation \tSocial \tCo-review\nAverage\tMethod ACM Citeseer Cora BlogCatalog Facebook Weibo Amazon\n10-shot ARC 36.53±0.24 30.93±4.24 39.23±4.40 37.77±0.35 4.92±1.85 59.47±2.38 7.98±1.18 30.98\nAnomalyGFM 2.89±0.08 4.13±0.09 4.30±0.10 4.17±0.06 16.53±5.41 9.79±0.99 10.88±1.50 7.53\n0-shot GAD-MoRE 37.17±0.07 40.15±1.31 45.25±0.88 35.31±0.42 9.00±1.12 60.26±0.30 31.55±4.84 36.96\nture Alignment (w/o MCFA) also leads to a substantial per-\nformance drop, particularly on the Facebook dataset. This\ndemonstrates that enriching initial node representations with\nsignals from diverse Riemannian spaces provides a more ro-\nbust foundation, enabling the model to adapt more effectively\nto unseen graph structures. Lastly, replacing the Memory-\nbased Dynamic Router (w/o MDR) with a simpler linear\nrouter results in a slight but consistent performance decrease\nacross most datasets. This highlights the effectiveness of the\ndesign of our proposed dynamic routing strategy, as history-\naware assignments from the MDR lead to more precise final\nreconstruction.\nD. Hyperparameter Sensitivity (RQ3)\nIn this section, we investigate the sensitivity of GAD-\nMoRE to its two most critical hyperparameters: the unified\nembedding dimension D and the number of experts K. This\nanalysis helps to understand the model’s robustness and guides\npractical application. Figure 4 illustrates the performance of\nGAD-MoRE with respect to these two parameters on four\nrepresentative test datasets, including ACM, Citeseer, Cora,\nand Weibo.\nFor the embedding dimension D (left column of Figure 4),\nwe observe that performance for both AUROC and AUPRC\ngenerally improves as the dimension increases from 16 to\n32. This indicates that a larger dimension allows for more\nexpressive representations to capture complex patterns. How-\never, the performance then stabilizes or slightly decreases for\ndimension 48, suggesting that overly large dimensions may\nlead to overfitting on the source datasets without improving\ngeneralization. Our chosen value of D = 32 offers the best\ntrade-off between performance and model efficiency.\nFor the number of experts K (right column of Figure 4),\nperformance steadily increases as we add more experts from\nK = 2 up to K = 5. This suggests that a richer set of\ngeometric lenses is beneficial for handling the diverse graph\nstructures encountered in the test sets. Beyond K = 5, the\nperformance plateaus, indicating that five experts are suffi-\ncient to cover the geometric diversity in our datasets without\nbecoming redundant or introducing unnecessary complexity.\nThis confirms our choice of K = 5 as optimal for the MoE\nscorer. Overall, the results show that GAD-MoRE is robust to\nvariations in these hyperparameters within a reasonable range.\nE. Comparison with Few-shot Learners (RQ4)\nTo further demonstrate the strong performance of our pro-\nposed GAD-MoRE on the GAD task, we conduct a compari-\nson against the competitive methods that are fine-tuned using\nlabeled data from the target domain. In particular, we still\nrigorously evaluate the strictly zero-shot capability of GAD-\nMoRE in comparing it with few-shot learning approaches,\nwhich are allowed access to a limited amount of target-domain\nlabeled data. Specifically, we compare GAD-MoRE with\nARC [16] and AnomalyGFM [18], two representative state-of-\nthe-art generalist GAD frameworks designed for cross-domain\ntransfer. These methods are selected as strong baselines due\nto their demonstrated effectiveness under few-shot adaptation\nsettings. The baselines are detailed as follows:\n• ARC [16] utilizes an in-context learning mechanism to\nadapt to target graphs using limited target labels.\n• AnomalyGFM [18] is a graph foundation model that\naligns node representations with class-agnostic prototypes\nto achieve generalization.\nThese two methods are chosen because most traditional GAD\nmodels are graph-specific and lack the architectural support for\ncross-domain fine-tuning. To simulate a competitive few-shot\nscenario, we fine-tune these baselines on 10 labeled nodes\n\n-- 12 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 13\nfrom each test graph (10-shot) and report performance with\nour model, which receives no such target-specific advantage.\nThe quantitative results for AUROC and AUPRC are de-\ntailed in Table V and Table VI. Despite operating in a zero-\nshot setting, GAD-MoRE demonstrates remarkable superiority,\nachieving an average AUROC of 82.09% and AUPRC of\n36.96%. These results substantially surpass the 10-shot fine-\ntuned ARC (75.28% / 30.98%) and AnomalyGFM (52.56%\n/ 7.53%), proving that GAD-MoRE outperforms competitors\non most datasets without access to target domain labels.\nThis comparison reveals a crucial insight: GAD-MoRE’s\narchitecture is highly effective at learning generalizable,\ngeometry-aware patterns from source domains, enabling it\nto surpass models that benefit from direct, albeit limited,\nsupervision. This showcases the power of our approach and\ndemonstrates that GAD-MoRE is a more practical and scalable\nsolution for real-world GAD applications where labels for new\ndomains are scarce or entirely unavailable.\nVI. CONCLUSION\nIn this paper, we introduce GAD-MoRE, a novel framework\nfor generalizable graph anomaly detection that addresses the\nchallenge of geometric heterogeneity. Motivated by our em-\npirical finding that no single curvature is universally optimal,\nwe propose a novel MoE architecture, featuring a multi-\ncurvature feature alignment module, a mixture of Rieman-\nnian experts scorer, and a memory-based dynamic router.\nSpecifically, the anomaly-aware multi-curvature feature align-\nment module bridges the gap between geometry-agnostic raw\nfeatures and manifold representations by projecting inputs\ninto parallel Riemannian spaces. Subsequently, the mixture of\nRiemannian experts scorer employs specialized Riemannian\nexperts operating in distinct curvature spaces, ensuring that\ncomplex anomaly patterns are modeled in suitable geometric\nenvironments without distortion. Furthermore, the memory-\nbased dynamic router facilitates adaptive inference using\nhistorical reconstruction feedback to align expert selection\nwith the anomaly detection objective. Extensive experiments\ndemonstrate that GAD-MoRE establishes a new state-of-the-\nart in zero-shot settings and consistently outperforms strong\ngeneralist competitors, even those fine-tuned with target do-\nmain labels. Promising research directions include extending\nGAD-MoRE to dynamic graphs, exploring hierarchical MoE\narchitectures, and integrating with graph foundation models.\nACKNOWLEDGMENT\nThe corresponding author is Qingyun Sun. The authors are\nsupported in part by the National Natural Science Foundation\nof China through grants No.62225202 and No.62427808, and\nthe Fundamental Research Funds for the Central Universities.\nREFERENCES\n[1] Z. Yuan, Q. Sun, H. Zhou, M. Shao, and X. Fu, “A comprehensive\nsurvey on gnn-based anomaly detection: taxonomy, methods, and the\nrole of large language models,” Int. J. Mach. Learn. Cybern., pp. 1–26,\n2025.\n[2] X. Ma, J. Wu, S. Xue, J. Yang, C. Zhou, Q. Z. Sheng, H. Xiong, and\nL. Akoglu, “A comprehensive survey on graph anomaly detection with\ndeep learning,” IEEE TKDE, vol. 35, no. 12, pp. 12 012–12 038, 2021.\n[3] C. C. Aggarwal, “An introduction to outlier analysis,” in Outlier anal-\nysis. Springer, 2016, pp. 1–34.\n[4] W. Hilal, S. A. Gadsden, and J. Yawney, “Financial fraud: a review of\nanomaly detection techniques and recent advances,” ESWA, vol. 193, p.\n116429, 2022.\n[5] D. Wang, J. Lin, P. Cui, Q. Jia, Z. Wang, Y. Fang, Q. Yu, J. Zhou,\nS. Yang, and Y. Qi, “A semi-supervised graph attentive network for\nfinancial fraud detection,” in ICDM. IEEE, 2019, pp. 598–607.\n[6] Y. Yang, Y. Xu, Y. Sun, Y. Dong, F. Wu, and Y. Zhuang, “Mining fraud-\nsters and fraudulent strategies in large-scale mobile social networks,”\nIEEE TKDE, vol. 33, no. 1, pp. 169–179, 2019.\n[7] S. Rayana and L. Akoglu, “Collective opinion spam detection: Bridging\nreview networks and metadata,” in KDD, 2015, pp. 985–994.\n[8] S. Kumar, B. Hooi, D. Makhija, M. Kumar, C. Faloutsos, and V. Sub-\nrahmanian, “Rev2: Fraudulent user prediction in rating platforms,” in\nWSDM, 2018, pp. 333–341.\n[9] A. B. Nassif, M. A. Talib, Q. Nasir, and F. M. Dakalbab, “Machine\nlearning for anomaly detection: A systematic review,” IEEE Access,\nvol. 9, pp. 78 658–78 700, 2021.\n[10] H. Qiao, H. Tong, B. An, I. King, C. Aggarwal, and G. Pang, “Deep\ngraph anomaly detection: A survey and new perspectives,” IEEE TKDE,\n2025.\n[11] J. A. Hartigan and M. A. Wong, “Algorithm as 136: A k-means\nclustering algorithm,” J. R. Stat. Soc. Ser. C (Appl. Stat.), vol. 28, no. 1,\npp. 100–108, 1979.\n[12] T. Cover, “Estimation by the nearest neighbor rule,” IEEE TIT, vol. 14,\nno. 1, pp. 50–55, 1968.\n[13] F. T. Liu, K. M. Ting, and Z.-H. Zhou, “Isolation forest,” in ICDM.\nIEEE, 2008, pp. 413–422.\n[14] S. Kumar, X. Zhang, and J. Leskovec, “Predicting dynamic embedding\ntrajectory in temporal interaction networks,” in KDD, 2019, pp. 1269–\n1278.\n[15] P. Sen, G. Namata, M. Bilgic, L. Getoor, B. Galligher, and T. Eliassi-\nRad, “Collective classification in network data,” AI Magazine, vol. 29,\nno. 3, pp. 93–93, 2008.\n[16] Y. Liu, S. Li, Y. Zheng, Q. Chen, C. Zhang, and S. Pan, “Arc: A\ngeneralist graph anomaly detector with in-context learning,” NeurIPS,\nvol. 37, pp. 50 772–50 804, 2024.\n[17] C. Niu, H. Qiao, C. Chen, L. Chen, and G. Pang, “Zero-shot generalist\ngraph anomaly detection with unified neighborhood prompts,” ArXiv,\n2024.\n[18] H. Qiao, C. Niu, L. Chen, and G. Pang, “Anomalygfm: Graph foundation\nmodel for zero/few-shot anomaly detection,” in KDD, 2025, pp. 2326–\n2337.\n[19] X. Zhang, Z. He, C. Fu, and C. Xie, “Ia-ggad: Zero-shot generalist graph\nanomaly detection via invariant and affinity learning,” in NeurIPS, 2025.\n[20] K. Grover, G. J. Gordon, and C. Faloutsos, “Curvgad: Leveraging\ncurvature for enhanced graph anomaly detection,” in ICML, 2025.\n[21] Y. Liu, Z. Li, S. Pan, C. Gong, C. Zhou, and G. Karypis, “Anomaly de-\ntection on attributed networks via contrastive self-supervised learning,”\nIEEE TNNLS, vol. 33, no. 6, pp. 2378–2392, 2021.\n[22] T. N. Kipf and M. Welling, “Variational graph auto-encoders,” ArXiv,\n2016.\n[23] Y. Dou, Z. Liu, L. Sun, Y. Deng, H. Peng, and P. S. Yu, “Enhancing\ngraph neural network-based fraud detectors against camouflaged fraud-\nsters,” in CIKM, 2020, pp. 315–324.\n[24] Y. Gao, X. Wang, X. He, Z. Liu, H. Feng, and Y. Zhang, “Addressing\nheterophily in graph anomaly detection: A perspective of graph spec-\ntrum,” in WWW, 2023, pp. 1528–1538.\n[25] T. Zhao, X. Zhang, and S. Wang, “Graphsmote: Imbalanced node\nclassification on graphs with graph neural networks,” in WSDM, 2021,\npp. 833–841.\n[26] L. Wu, J. Xia, Z. Gao, H. Lin, C. Tan, and S. Z. Li, “Graphmixup:\nImproving class-imbalanced node classification by reinforcement mixup\nand self-supervised context prediction,” in ECML-PKDD, 2022, pp. 519–\n535.\n[27] K. Liu, H. Zhang, Z. Hu, F. Wang, and P. S. Yu, “Data augmentation for\nsupervised graph outlier detection with latent diffusion models,” ArXiv,\n2023.\n[28] K. Ding, J. Li, R. Bhanushali, and H. Liu, “Deep anomaly detection on\nattributed networks,” in SDM. SIAM, 2019, pp. 594–602.\n[29] H. Fan, F. Zhang, and Z. Li, “Anomalydae: Dual autoencoder for\nanomaly detection on attributed networks,” in ICASSP. IEEE, 2020,\npp. 5685–5689.\n[30] X. Yuan, N. Zhou, S. Yu, H. Huang, Z. Chen, and F. Xia, “Higher-\norder structure based anomaly detection on attributed networks,” in IEEE\nBigData. IEEE, 2021, pp. 2691–2700.\n\n-- 13 of 14 --\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2015 14\n[31] P. Veliˇckovi´c, W. Fedus, W. L. Hamilton, P. Li`o, Y. Bengio, and R. D.\nHjelm, “Deep graph infomax,” ArXiv, 2018.\n[32] F.-Y. Sun, J. Hoffmann, V. Verma, and J. Tang, “Infograph: Unsupervised\nand semi-supervised graph-level representation learning via mutual\ninformation maximization,” ArXiv, 2019.\n[33] F. Lin, X. Luo, J. Wu, J. Yang, S. Xue, Z. Wang, and H. Gong,\n“Discriminative graph-level anomaly detection via dual-students-teacher\nmodel,” in ADMA. Springer, 2023, pp. 261–276.\n[34] Z. Chen, B. Liu, M. Wang, P. Dai, J. Lv, and L. Bo, “Generative\nadversarial attributed network anomaly detection,” in CIKM, 2020, pp.\n1989–1992.\n[35] K. Ding, J. Li, N. Agarwal, and H. Liu, “Inductive anomaly detection\non attributed networks,” in IJCAI, 2021, pp. 1288–1294.\n[36] K. Ding, Q. Zhou, H. Tong, and H. Liu, “Few-shot network anomaly\ndetection via cross-network meta-learning,” in WWW, 2021, pp. 2448–\n2456.\n[37] S. Tian, J. Dong, J. Li, W. Zhao, X. Xu, B. Wang, B. Song, C. Meng,\nT. Zhang, and L. Chen, “Sad: semi-supervised anomaly detection on\ndynamic graphs,” in IJCAI, 2023, pp. 2306–2314.\n[38] R. A. Jacobs, M. I. Jordan, S. J. Nowlan, and G. E. Hinton, “Adaptive\nmixtures of local experts,” Neural Comput., vol. 3, no. 1, pp. 79–87,\n1991.\n[39] N. Shazeer, A. Mirhoseini, K. Maziarz, A. Davis, Q. Le, G. Hinton,\nand J. Dean, “Outrageously large neural networks: The sparsely-gated\nmixture-of-experts layer,” in ICLR, 2017.\n[40] Z. Mi, P. Yin, X. Xiao, and D. Xu, “Learning heterogeneous mixture\nof scene experts for large-scale neural radiance fields,” IEEE TPAMI,\n2025.\n[41] W. Fedus, B. Zoph, and N. Shazeer, “Switch transformers: Scaling to\ntrillion parameter models with simple and efficient sparsity,” JMLR,\nvol. 23, no. 120, pp. 1–39, 2022.\n[42] C. Riquelme, J. Puigcerver, B. Mustafa, M. Neumann, R. Jenatton,\nA. Susano Pinto, D. Keysers, and N. Houlsby, “Scaling vision with\nsparse mixture of experts,” NeurIPS, vol. 34, pp. 8583–8595, 2021.\n[43] L. Liu, P. Wang, G. Wu, J. Jiang, and H. Yang, “Towards optimal mixture\nof experts system for 3d object detection: A game of accuracy, efficiency\nand adaptivity,” IEEE TPAMI, 2025.\n[44] Z. Guo, Q. Sun, H. Yuan, X. Fu, M. Zhou, Y. Gao, and J. Li, “Graph-\nmore: Mitigating topological heterogeneity via mixture of riemannian\nexperts,” in AAAI, vol. 39, no. 11, 2025, pp. 11 754–11 762.\n[45] H. Zeng, H. Lyu, D. Hu, Y. Xia, and J. Luo, “Mixture of weak & strong\nexperts on graphs,” ArXiv, 2023.\n[46] H. Wang, Z. Jiang, Y. You, Y. Han, G. Liu, J. Srinivasa, R. Kompella,\nZ. Wang et al., “Graph mixture of experts: Learning on large-scale\ngraphs with explicit diversity modeling,” NeurIPS, vol. 36, pp. 50 825–\n50 837, 2023.\n[47] F. Hu, L. Wang, S. Wu, L. Wang, and T. Tan, “Graph classification by\nmixture of diverse experts,” ArXiv, 2021.\n[48] J. Cai, Y. Zhang, P. Wang, and S.-K. Ng, “Moegad: A mixture-of-experts\nframework with pseudo-anomaly generation for graph-level anomaly\ndetection.” IEEE TPAMI, 2025.\n[49] I. Chami, Z. Ying, C. R´e, and J. Leskovec, “Hyperbolic graph convolu-\ntional neural networks,” NeurIPS, vol. 32, 2019.\n[50] X. Fu, J. Li, J. Wu, Q. Sun, C. Ji, S. Wang, J. Tan, H. Peng, and P. S.\nYu, “Ace-hgnn: Adaptive curvature exploration hyperbolic graph neural\nnetwork,” in ICDM. IEEE, 2021, pp. 111–120.\n[51] J. Li, X. Fu, Q. Sun, C. Ji, J. Tan, J. Wu, and H. Peng, “Curvature graph\ngenerative adversarial networks,” in WWW, 2022, pp. 1528–1537.\n[52] R. C. Wilson, E. R. Hancock, E. Pekalska, and R. P. Duin, “Spherical\nand hyperbolic embeddings of data,” IEEE TPAMI, vol. 36, no. 11, pp.\n2255–2269, 2014.\n[53] M. Nickel and D. Kiela, “Poincar´e embeddings for learning hierarchical\nrepresentations,” NeurIPS, vol. 30, 2017.\n[54] Q. Liu, M. Nickel, and D. Kiela, “Hyperbolic graph neural networks,”\nNeurIPS, vol. 32, 2019.\n[55] Y. Zhang, X. Wang, C. Shi, X. Jiang, and Y. Ye, “Hyperbolic graph\nattention network,” IEEE TBD, vol. 8, no. 6, pp. 1690–1701, 2021.\n[56] K. Pearson, “Liii. on lines and planes of closest fit to systems of points\nin space,” The London, Edinburgh, and Dublin philosophical magazine\nand journal of science, vol. 2, no. 11, pp. 559–572, 1901.\n[57] H. Hotelling, “Analysis of a complex of statistical variables into principal\ncomponents.” J. Educ. Psychol., vol. 24, no. 6, p. 417, 1933.\n[58] L. Tang and H. Liu, “Relational learning via latent social dimensions,”\nin KDD, 2009, pp. 817–826.\n[59] J. J. McAuley and J. Leskovec, “From amateurs to connoisseurs:\nmodeling the evolution of user expertise through online reviews,” in\nWWW, 2013, pp. 897–908.\n[60] J. Tang, J. Zhang, L. Yao, J. Li, L. Zhang, and Z. Su, “Arnetminer:\nextraction and mining of academic social networks,” in KDD, 2008, pp.\n990–998.\n[61] Z. Xu, X. Huang, Y. Zhao, Y. Dong, and J. Li, “Contrastive at-\ntributed network anomaly detection with data augmentation,” in PAKDD.\nSpringer, 2022, pp. 444–457.\n[62] T. Kipf, “Semi-supervised classification with graph convolutional net-\nworks,” Arxiv, 2016.\n[63] P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Lio, and\nY. Bengio, “Graph attention networks,” ArXiv, 2017.\n[64] J. Tang, J. Li, Z. Gao, and J. Li, “Rethinking graph neural networks for\nanomaly detection,” in ICML, 2022, pp. 21 076–21 089.\nXinyu Zhao is currently a master’s candidate at the School of Computer\nScience and Engineering, Beihang University. His research interests include\ngraph anomaly detection and graph foundation models.\nQingyun Sun is currently an Associate Professor at the School of Computer\nScience and Engineering, Beihang University. Her research interests include\nmachine learning and graph mining. She has published several papers on IEEE\nTPAMI, IEEE TKDE, Web Conference, AAAI, ICDM, CIKM, etc..\nJiayi Luo is currently a Ph.D. candidate at the School of Computer Science\nand Engineering, Beihang University. His research interests include robust\ngraph learning and graph foundation models.\nXingcheng Fu is currently an associate professor at the Key Lab of Education\nBlockchain and Intelligent Technology at Guangxi Normal University. His\nresearch interests include graph representation learning, complex networks,\nand social network analysis. He has published several papers on IEEE TKDE,\nWeb Conference, AAAI, ICDM, CIKM, etc..\nJianxin Li is currently a Professor with the School of Computer Science and\nEngineering, Beihang University. His current research interests include social\nnetworks, machine learning, big data, and trustworthy computing. Dr. Li has\npublished research papers in top-tier journals and conferences, including the\nIEEE TKDE, TDSC, JAIR, ACM TOIS, TKDD, KDD, AAAI, and WWW.\n\n-- 14 of 14 --\n\n"
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "code": "import React, { useState, useEffect, useMemo, useRef } from 'react';\nimport { \n  LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer, \n  AreaChart, Area \n} from 'recharts';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { \n  Zap, Brain, Share2, AlertTriangle, CheckCircle, \n  Maximize2, Box, Radio, RefreshCw, Layers\n} from 'lucide-react';\n\n// --- Simulation Constants ---\nconst GEOMETRIES = {\n  HYPERBOLIC: { id: 'hyp', label: 'Hyperbolic', kappa: -1.0, color: 'rgb(168, 85, 247)', description: 'Best for Hierarchies/Trees' },\n  EUCLIDEAN: { id: 'euc', label: 'Euclidean', kappa: 0.0, color: 'rgb(59, 130, 246)', description: 'Best for Flat Grids' },\n  SPHERICAL: { id: 'sph', label: 'Spherical', kappa: 1.0, color: 'rgb(245, 158, 11)', description: 'Best for Cyclical/Dense' }\n};\n\n// Simplified manifold distance simulation\nfunction simulateReconstruction(nodeType, expertType, isAnomaly) {\n  const baseError = isAnomaly ? 0.6 : 0.1;\n  const geometryMismatch = nodeType !== expertType;\n  \n  if (geometryMismatch) {\n    // If we route a hierarchical node to a spherical room, reconstruction \"breaks\"\n    return Math.min(0.95, baseError + 0.7 + Math.random() * 0.1);\n  }\n  return Math.min(0.4, baseError + Math.random() * 0.1);\n}\n\nexport default function App() {\n  const [isPlaying, setIsPlaying] = useState(true);\n  const [nodeType, setNodeType] = useState('HYPERBOLIC');\n  const [isAnomaly, setIsAnomaly] = useState(false);\n  const [routerLogic, setRouterLogic] = useState('auto'); // 'auto', 'manual-hyp', 'manual-euc', 'manual-sph'\n  const [history, setHistory] = useState([]);\n  const [activeNode, setActiveNode] = useState(null);\n  const [memoryBankStatus, setMemoryBankStatus] = useState({ hyp: 85, euc: 92, sph: 78 });\n\n  // Processing Logic\n  useEffect(() => {\n    if (!isPlaying) return;\n\n    const interval = setInterval(() => {\n      const currentExpert = routerLogic === 'auto' ? nodeType : routerLogic.replace('manual-', '').toUpperCase();\n      const error = simulateReconstruction(nodeType, currentExpert, isAnomaly);\n      \n      const newNode = {\n        id: Date.now(),\n        nodeType,\n        expertType: currentExpert,\n        isAnomaly,\n        error,\n        timestamp: new Date().toLocaleTimeString().slice(-5)\n      };\n\n      setActiveNode(newNode);\n      setHistory(prev => [...prev.slice(-19), { ...newNode, score: error * 100 }]);\n      \n      // Dynamic memory bank \"learning\" simulation\n      setMemoryBankStatus(prev => ({\n        ...prev,\n        [currentExpert.toLowerCase()]: Math.min(100, prev[currentExpert.toLowerCase()] + (error < 0.3 ? 1 : -0.5))\n      }));\n\n    }, 2000);\n\n    return () => clearInterval(interval);\n  }, [isPlaying, nodeType, isAnomaly, routerLogic]);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white font-sans p-4 lg:p-8\">\n      {/* Header */}\n      <div className=\"max-w-7xl mx-auto mb-8 flex flex-col md:flex-row md:items-center justify-between gap-4\">\n        <div>\n          <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-500\">\n            GAD-MoRE: Expert Routing Flow\n          </h1>\n          <p className=\"text-gray-400 mt-1 flex items-center gap-2\">\n            <Brain size={16} className=\"text-purple-400\" />\n            Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts\n          </p>\n        </div>\n        <div className=\"flex gap-2\">\n          <button \n            onClick={() => setIsPlaying(!isPlaying)}\n            className={`px-6 py-2 rounded-full flex items-center gap-2 font-medium transition-all ${\n              isPlaying ? 'bg-red-500/20 text-red-400 border border-red-500/50' : 'bg-emerald-500/20 text-emerald-400 border border-emerald-500/50'\n            }`}\n          >\n            {isPlaying ? <Radio className=\"animate-pulse\" /> : <RefreshCw />}\n            {isPlaying ? 'Live Stream' : 'Paused'}\n          </button>\n        </div>\n      </div>\n\n      <div className=\"max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6\">\n        \n        {/* Sidebar Controls */}\n        <div className=\"lg:col-span-3 space-y-6\">\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5 shadow-xl\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4 flex items-center gap-2\">\n              <Zap size={14} className=\"text-yellow-400\" /> Input Generator\n            </h3>\n            \n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Node Intrinsic Geometry</label>\n                <div className=\"grid grid-cols-1 gap-2\">\n                  {Object.entries(GEOMETRIES).map(([key, geo]) => (\n                    <button\n                      key={key}\n                      onClick={() => setNodeType(key)}\n                      className={`text-left p-3 rounded-xl border transition-all ${\n                        nodeType === key \n                          ? `bg-${geo.color.replace('rgb', '')}/10 border-${geo.color} text-white` \n                          : 'bg-gray-800/30 border-white/5 text-gray-400 hover:bg-gray-800/50'\n                      }`}\n                      style={{ \n                        borderColor: nodeType === key ? geo.color : '',\n                        backgroundColor: nodeType === key ? `${geo.color.replace('rgb', 'rgba').replace(')', ', 0.15)')}` : ''\n                      }}\n                    >\n                      <div className=\"font-bold flex items-center gap-2\">\n                        <div className=\"w-2 h-2 rounded-full\" style={{ backgroundColor: geo.color }}></div>\n                        {geo.label}\n                      </div>\n                      <div className=\"text-[10px] opacity-60\">{geo.description}</div>\n                    </button>\n                  ))}\n                </div>\n              </div>\n\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Anomaly Status</label>\n                <button\n                  onClick={() => setIsAnomaly(!isAnomaly)}\n                  className={`w-full py-2 px-4 rounded-xl border transition-all flex items-center justify-between ${\n                    isAnomaly \n                      ? 'bg-red-500/20 border-red-500 text-red-200' \n                      : 'bg-emerald-500/20 border-emerald-500 text-emerald-200'\n                  }`}\n                >\n                  <span className=\"font-medium\">{isAnomaly ? 'Anomalous Node' : 'Normal Node'}</span>\n                  {isAnomaly ? <AlertTriangle size={16} /> : <CheckCircle size={16} />}\n                </button>\n              </div>\n\n              <div className=\"pt-4 border-t border-white/5\">\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold text-center\">Memory-Based Router Mode</label>\n                <select \n                  className=\"w-full bg-gray-800 border border-white/10 rounded-lg p-2 text-sm focus:outline-none focus:ring-2 focus:ring-purple-500\"\n                  value={routerLogic}\n                  onChange={(e) => setRouterLogic(e.target.value)}\n                >\n                  <option value=\"auto\">Automatic (Dynamic Memory)</option>\n                  <option value=\"manual-hyp\">Forced: Hyperbolic Expert</option>\n                  <option value=\"manual-euc\">Forced: Euclidean Expert</option>\n                  <option value=\"manual-sph\">Forced: Spherical Expert</option>\n                </select>\n              </div>\n            </div>\n          </section>\n\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4\">Router Stats</h3>\n            <div className=\"space-y-4\">\n              {['hyp', 'euc', 'sph'].map((id) => (\n                <div key={id} className=\"space-y-1\">\n                  <div className=\"flex justify-between text-[10px] font-mono\">\n                    <span className=\"uppercase\">{id} Memory Fidelity</span>\n                    <span>{memoryBankStatus[id]}%</span>\n                  </div>\n                  <div className=\"h-1.5 w-full bg-gray-800 rounded-full overflow-hidden\">\n                    <motion.div \n                      className=\"h-full rounded-full\"\n                      style={{ backgroundColor: GEOMETRIES[id.toUpperCase()].color }}\n                      initial={{ width: 0 }}\n                      animate={{ width: `${memoryBankStatus[id]}%` }}\n                    />\n                  </div>\n                </div>\n              ))}\n            </div>\n          </section>\n        </div>\n\n        {/* Main Animation Flow */}\n        <div className=\"lg:col-span-9 space-y-6\">\n          \n          <div className=\"grid grid-cols-1 md:grid-cols-4 gap-4 min-h-[400px]\">\n            {/* Input Stream */}\n            <div className=\"relative flex flex-col items-center justify-center p-4 border-l-2 border-dashed border-white/10\">\n              <span className=\"absolute top-2 text-[10px] text-gray-500 font-mono tracking-widest uppercase\">Input Stream</span>\n              <AnimatePresence>\n                {activeNode && (\n                  <motion.div\n                    key={activeNode.id}\n                    initial={{ x: -100, opacity: 0 }}\n                    animate={{ x: 0, opacity: 1 }}\n                    exit={{ x: 100, opacity: 0 }}\n                    transition={{ duration: 0.5 }}\n                    className=\"relative\"\n                  >\n                    <div className=\"w-16 h-16 rounded-2xl bg-gray-800 border border-white/20 flex items-center justify-center shadow-2xl overflow-hidden\">\n                      <motion.div \n                        className=\"w-full h-full opacity-30 absolute inset-0\"\n                        animate={{ rotate: 360 }}\n                        transition={{ duration: 10, repeat: Infinity, ease: \"linear\" }}\n                        style={{ background: `radial-gradient(circle, ${GEOMETRIES[activeNode.nodeType].color}, transparent)` }}\n                      />\n                      <Maximize2 className={activeNode.isAnomaly ? \"text-red-500 animate-pulse\" : \"text-gray-400\"} />\n                    </div>\n                  </motion.div>\n                )}\n              </AnimatePresence>\n              <div className=\"mt-4 text-center\">\n                <div className=\"text-xs font-mono text-gray-500\">v_{activeNode?.id.toString().slice(-4)}</div>\n              </div>\n            </div>\n\n            {/* Dynamic Router */}\n            <div className=\"relative flex flex-col items-center justify-center p-4\">\n              <div className=\"z-10 bg-gray-800 p-6 rounded-3xl border border-white/10 shadow-2xl text-center relative overflow-hidden group\">\n                <div className=\"absolute inset-0 bg-gradient-to-br from-purple-500/10 to-transparent opacity-50\"></div>\n                <Share2 className=\"mx-auto mb-2 text-purple-400\" />\n                <h4 className=\"text-sm font-bold uppercase tracking-widest text-white/80\">Router</h4>\n                <p className=\"text-[10px] text-gray-500 mt-2 font-mono\">Memory Check...</p>\n                <div className=\"mt-4 space-y-1\">\n                   <div className=\"w-12 h-1 bg-white/5 rounded-full mx-auto overflow-hidden\">\n                      <motion.div \n                        className=\"h-full bg-purple-500\"\n                        animate={{ width: [\"0%\", \"100%\", \"0%\"] }}\n                        transition={{ duration: 2, repeat: Infinity }}\n                      />\n                   </div>\n                </div>\n              </div>\n              \n              {/* Path Lines */}\n              <svg className=\"absolute inset-0 w-full h-full -z-10 opacity-20\" pointerEvents=\"none\">\n                <line x1=\"100%\" y1=\"50%\" x2=\"110%\" y2=\"50%\" stroke=\"white\" strokeDasharray=\"4\" />\n              </svg>\n            </div>\n\n            {/* Expert Rooms */}\n            <div className=\"md:col-span-2 grid grid-rows-3 gap-4\">\n              {Object.entries(GEOMETRIES).map(([key, geo]) => {\n                const isActive = activeNode?.expertType === key;\n                const isMismatch = isActive && activeNode.nodeType !== key;\n                \n                return (\n                  <div \n                    key={key}\n                    className={`relative flex items-center gap-4 p-4 rounded-2xl border transition-all duration-500 ${\n                      isActive \n                        ? 'bg-gray-800 border-opacity-100 scale-105 shadow-2xl ring-1 ring-white/20' \n                        : 'bg-gray-900/30 border-white/5 opacity-40'\n                    }`}\n                    style={{ borderColor: isActive ? geo.color : '' }}\n                  >\n                    <div className=\"p-3 rounded-xl bg-gray-950/50\" style={{ color: geo.color }}>\n                      {key === 'HYPERBOLIC' && <Layers size={24} />}\n                      {key === 'EUCLIDEAN' && <Box size={24} />}\n                      {key === 'SPHERICAL' && <RefreshCw size={24} />}\n                    </div>\n                    \n                    <div className=\"flex-1\">\n                      <div className=\"flex items-center justify-between\">\n                        <span className=\"text-xs font-bold uppercase tracking-tighter\" style={{ color: geo.color }}>\n                          {geo.label} Expert\n                        </span>\n                        {isActive && (\n                          <motion.span \n                            initial={{ opacity: 0 }} \n                            animate={{ opacity: 1 }} \n                            className=\"text-[10px] font-mono text-emerald-400 flex items-center gap-1\"\n                          >\n                            <Zap size={10} /> PROCESSING\n                          </motion.span>\n                        )}\n                      </div>\n                      <div className=\"mt-1 flex items-center gap-2\">\n                        <div className=\"text-[10px] text-gray-500 italic\">κ = {geo.kappa.toFixed(1)}</div>\n                        {isMismatch && (\n                          <div className=\"text-[10px] text-red-400 font-bold animate-pulse\">\n                             GEOMETRIC DISTORTION DETECTED!\n                          </div>\n                        )}\n                      </div>\n                    </div>\n\n                    {/* Reconstruction Visualization */}\n                    {isActive && (\n                      <motion.div \n                        initial={{ scale: 0 }}\n                        animate={{ scale: 1 }}\n                        className=\"w-12 h-12 rounded-full border-4 border-dashed relative flex items-center justify-center\"\n                        style={{ borderColor: activeNode.error > 0.6 ? 'rgba(239, 68, 68, 0.5)' : 'rgba(16, 185, 129, 0.5)' }}\n                      >\n                         <AnimatePresence>\n                           {activeNode.error > 0.6 && (\n                             <motion.div \n                               initial={{ opacity: 0 }}\n                               animate={{ opacity: [0, 1, 0] }}\n                               transition={{ repeat: Infinity }}\n                               className=\"absolute inset-0 bg-red-500/20 rounded-full\"\n                             />\n                           )}\n                         </AnimatePresence>\n                         <div className={`text-[10px] font-bold ${activeNode.error > 0.6 ? 'text-red-400' : 'text-emerald-400'}`}>\n                           {Math.round(activeNode.error * 100)}%\n                         </div>\n                      </motion.div>\n                    )}\n                  </div>\n                );\n              })}\n            </div>\n          </div>\n\n          {/* Metrics Section */}\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6 flex items-center justify-between\">\n                <span>Anomaly Scoring (Reconstruction Error)</span>\n                <span className=\"text-xs text-blue-400 bg-blue-500/10 px-2 py-1 rounded\">Real-time</span>\n              </h3>\n              <div className=\"h-64\">\n                <ResponsiveContainer width=\"100%\" height=\"100%\">\n                  <AreaChart data={history}>\n                    <defs>\n                      <linearGradient id=\"colorError\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">\n                        <stop offset=\"5%\" stopColor=\"#8b5cf6\" stopOpacity={0.3}/>\n                        <stop offset=\"95%\" stopColor=\"#8b5cf6\" stopOpacity={0}/>\n                      </linearGradient>\n                    </defs>\n                    <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#333\" vertical={false} />\n                    <XAxis dataKey=\"timestamp\" stroke=\"#666\" fontSize={10} tickLine={false} />\n                    <YAxis stroke=\"#666\" fontSize={10} tickLine={false} axisLine={false} domain={[0, 100]} />\n                    <Tooltip \n                      contentStyle={{ backgroundColor: '#111', border: '1px solid #333', fontSize: '12px' }}\n                      itemStyle={{ color: '#8b5cf6' }}\n                    />\n                    <Area \n                      type=\"monotone\" \n                      dataKey=\"score\" \n                      stroke=\"#8b5cf6\" \n                      fillOpacity={1} \n                      fill=\"url(#colorError)\" \n                      strokeWidth={2}\n                      animationDuration={1000}\n                    />\n                  </AreaChart>\n                </ResponsiveContainer>\n              </div>\n            </div>\n\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6\">Algorithm Concept</h3>\n              <div className=\"space-y-4\">\n                <div className=\"p-4 bg-black/40 rounded-xl border border-white/5 space-y-3\">\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-purple-500/20 text-purple-400 rounded-lg\">\n                      <Layers size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Riemannian Projection</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        MCFA (Multi-Curvature Feature Alignment) projects raw features into tangent spaces of varying κ before routing.\n                      </p>\n                    </div>\n                  </div>\n                  \n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-blue-500/20 text-blue-400 rounded-lg\">\n                      <Share2 size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Memory-Based Routing</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                         $s_i(h_v) = -\\min_{m \\in B_i} d_{M_i}(\\exp_{o_i}(h_v), \\exp_{o_i}(m))$\n                         <br/>Nodes are routed to experts whose memory bank contains similar high-fidelity reconstructions.\n                      </p>\n                    </div>\n                  </div>\n\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-red-500/20 text-red-400 rounded-lg\">\n                      <AlertTriangle size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Anomaly Signal</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        Anomaly Score $S(v) = \\|h_v - \\hat{h}_v\\|^2$. Mismatched geometry causes catastrophic reconstruction error, revealing anomalies.\n                      </p>\n                    </div>\n                  </div>\n                </div>\n\n                <div className=\"grid grid-cols-2 gap-4\">\n                   <div className=\"p-3 bg-emerald-500/5 border border-emerald-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-emerald-400 uppercase font-bold\">Model State</div>\n                      <div className=\"text-lg font-bold text-emerald-200\">Ready</div>\n                   </div>\n                   <div className=\"p-3 bg-blue-500/5 border border-blue-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-blue-400 uppercase font-bold\">Zero-Shot Latency</div>\n                      <div className=\"text-lg font-bold text-blue-200\">42ms</div>\n                   </div>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n      \n      {/* Footer Info */}\n      <div className=\"max-w-7xl mx-auto mt-8 text-center text-gray-600 text-[10px] uppercase tracking-widest\">\n        Reference Paper: Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts (2025)\n      </div>\n    </div>\n  );\n}",
                  "title": "GAD-MoRE Expert Routing Prototype"
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "functionResponse": {
                "name": "render_prototype",
                "response": {
                  "success": true,
                  "rendered": true
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "text": "The prototype has an error: Uncaught TypeError: Cannot read properties of undefined (reading 'color') (Line 10)\n\nPlease fix it."
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "code": "import React, { useState, useEffect, useMemo, useRef } from 'react';\nimport { \n  LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer, \n  AreaChart, Area \n} from 'recharts';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { \n  Zap, Brain, Share2, AlertTriangle, CheckCircle, \n  Maximize2, Box, Radio, RefreshCw, Layers\n} from 'lucide-react';\n\n// --- Simulation Constants ---\nconst GEOMETRIES = {\n  HYPERBOLIC: { id: 'hyp', label: 'Hyperbolic', kappa: -1.0, color: 'rgb(168, 85, 247)', description: 'Best for Hierarchies/Trees' },\n  EUCLIDEAN: { id: 'euc', label: 'Euclidean', kappa: 0.0, color: 'rgb(59, 130, 246)', description: 'Best for Flat Grids' },\n  SPHERICAL: { id: 'sph', label: 'Spherical', kappa: 1.0, color: 'rgb(245, 158, 11)', description: 'Best for Cyclical/Dense' }\n};\n\n// Simplified manifold distance simulation\nfunction simulateReconstruction(nodeType, expertType, isAnomaly) {\n  const baseError = isAnomaly ? 0.6 : 0.1;\n  const geometryMismatch = nodeType !== expertType;\n  \n  if (geometryMismatch) {\n    // If we route a hierarchical node to a spherical room, reconstruction \"breaks\"\n    return Math.min(0.95, baseError + 0.7 + Math.random() * 0.1);\n  }\n  return Math.min(0.4, baseError + Math.random() * 0.1);\n}\n\nexport default function App() {\n  const [isPlaying, setIsPlaying] = useState(true);\n  const [nodeType, setNodeType] = useState('HYPERBOLIC');\n  const [isAnomaly, setIsAnomaly] = useState(false);\n  const [routerLogic, setRouterLogic] = useState('auto'); // 'auto', 'manual-hyp', 'manual-euc', 'manual-sph'\n  const [history, setHistory] = useState([]);\n  const [activeNode, setActiveNode] = useState(null);\n  const [memoryBankStatus, setMemoryBankStatus] = useState({ hyp: 85, euc: 92, sph: 78 });\n\n  // Processing Logic\n  useEffect(() => {\n    if (!isPlaying) return;\n\n    const interval = setInterval(() => {\n      const currentExpert = routerLogic === 'auto' ? nodeType : routerLogic.replace('manual-', '').toUpperCase();\n      // Handle the forced mapping for manual modes if the strings don't match keys perfectly\n      const normalizedExpert = currentExpert === 'HYP' ? 'HYPERBOLIC' : \n                               currentExpert === 'EUC' ? 'EUCLIDEAN' : \n                               currentExpert === 'SPH' ? 'SPHERICAL' : currentExpert;\n\n      const error = simulateReconstruction(nodeType, normalizedExpert, isAnomaly);\n      \n      const newNode = {\n        id: Date.now(),\n        nodeType,\n        expertType: normalizedExpert,\n        isAnomaly,\n        error,\n        timestamp: new Date().toLocaleTimeString().slice(-5)\n      };\n\n      setActiveNode(newNode);\n      setHistory(prev => [...prev.slice(-19), { ...newNode, score: error * 100 }]);\n      \n      // Dynamic memory bank \"learning\" simulation\n      const shortId = GEOMETRIES[normalizedExpert].id;\n      setMemoryBankStatus(prev => ({\n        ...prev,\n        [shortId]: Math.min(100, prev[shortId] + (error < 0.3 ? 1 : -0.5))\n      }));\n\n    }, 2000);\n\n    return () => clearInterval(interval);\n  }, [isPlaying, nodeType, isAnomaly, routerLogic]);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white font-sans p-4 lg:p-8\">\n      {/* Header */}\n      <div className=\"max-w-7xl mx-auto mb-8 flex flex-col md:flex-row md:items-center justify-between gap-4\">\n        <div>\n          <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-500\">\n            GAD-MoRE: Expert Routing Flow\n          </h1>\n          <p className=\"text-gray-400 mt-1 flex items-center gap-2\">\n            <Brain size={16} className=\"text-purple-400\" />\n            Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts\n          </p>\n        </div>\n        <div className=\"flex gap-2\">\n          <button \n            onClick={() => setIsPlaying(!isPlaying)}\n            className={`px-6 py-2 rounded-full flex items-center gap-2 font-medium transition-all ${\n              isPlaying ? 'bg-red-500/20 text-red-400 border border-red-500/50' : 'bg-emerald-500/20 text-emerald-400 border border-emerald-500/50'\n            }`}\n          >\n            {isPlaying ? <Radio className=\"animate-pulse\" /> : <RefreshCw />}\n            {isPlaying ? 'Live Stream' : 'Paused'}\n          </button>\n        </div>\n      </div>\n\n      <div className=\"max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6\">\n        \n        {/* Sidebar Controls */}\n        <div className=\"lg:col-span-3 space-y-6\">\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5 shadow-xl\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4 flex items-center gap-2\">\n              <Zap size={14} className=\"text-yellow-400\" /> Input Generator\n            </h3>\n            \n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Node Intrinsic Geometry</label>\n                <div className=\"grid grid-cols-1 gap-2\">\n                  {Object.entries(GEOMETRIES).map(([key, geo]) => (\n                    <button\n                      key={key}\n                      onClick={() => setNodeType(key)}\n                      className={`text-left p-3 rounded-xl border transition-all ${\n                        nodeType === key \n                          ? `bg-${geo.color.replace('rgb', '')}/10 border-${geo.color} text-white` \n                          : 'bg-gray-800/30 border-white/5 text-gray-400 hover:bg-gray-800/50'\n                      }`}\n                      style={{ \n                        borderColor: nodeType === key ? geo.color : '',\n                        backgroundColor: nodeType === key ? `${geo.color.replace('rgb', 'rgba').replace(')', ', 0.15)')}` : ''\n                      }}\n                    >\n                      <div className=\"font-bold flex items-center gap-2\">\n                        <div className=\"w-2 h-2 rounded-full\" style={{ backgroundColor: geo.color }}></div>\n                        {geo.label}\n                      </div>\n                      <div className=\"text-[10px] opacity-60\">{geo.description}</div>\n                    </button>\n                  ))}\n                </div>\n              </div>\n\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Anomaly Status</label>\n                <button\n                  onClick={() => setIsAnomaly(!isAnomaly)}\n                  className={`w-full py-2 px-4 rounded-xl border transition-all flex items-center justify-between ${\n                    isAnomaly \n                      ? 'bg-red-500/20 border-red-500 text-red-200' \n                      : 'bg-emerald-500/20 border-emerald-500 text-emerald-200'\n                  }`}\n                >\n                  <span className=\"font-medium\">{isAnomaly ? 'Anomalous Node' : 'Normal Node'}</span>\n                  {isAnomaly ? <AlertTriangle size={16} /> : <CheckCircle size={16} />}\n                </button>\n              </div>\n\n              <div className=\"pt-4 border-t border-white/5\">\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold text-center\">Memory-Based Router Mode</label>\n                <select \n                  className=\"w-full bg-gray-800 border border-white/10 rounded-lg p-2 text-sm focus:outline-none focus:ring-2 focus:ring-purple-500\"\n                  value={routerLogic}\n                  onChange={(e) => setRouterLogic(e.target.value)}\n                >\n                  <option value=\"auto\">Automatic (Dynamic Memory)</option>\n                  <option value=\"manual-hyp\">Forced: Hyperbolic Expert</option>\n                  <option value=\"manual-euc\">Forced: Euclidean Expert</option>\n                  <option value=\"manual-sph\">Forced: Spherical Expert</option>\n                </select>\n              </div>\n            </div>\n          </section>\n\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4\">Router Stats</h3>\n            <div className=\"space-y-4\">\n              {Object.entries(GEOMETRIES).map(([key, geo]) => (\n                <div key={key} className=\"space-y-1\">\n                  <div className=\"flex justify-between text-[10px] font-mono\">\n                    <span className=\"uppercase\">{geo.id} Memory Fidelity</span>\n                    <span>{memoryBankStatus[geo.id]}%</span>\n                  </div>\n                  <div className=\"h-1.5 w-full bg-gray-800 rounded-full overflow-hidden\">\n                    <motion.div \n                      className=\"h-full rounded-full\"\n                      style={{ backgroundColor: geo.color }}\n                      initial={{ width: 0 }}\n                      animate={{ width: `${memoryBankStatus[geo.id]}%` }}\n                    />\n                  </div>\n                </div>\n              ))}\n            </div>\n          </section>\n        </div>\n\n        {/* Main Animation Flow */}\n        <div className=\"lg:col-span-9 space-y-6\">\n          \n          <div className=\"grid grid-cols-1 md:grid-cols-4 gap-4 min-h-[400px]\">\n            {/* Input Stream */}\n            <div className=\"relative flex flex-col items-center justify-center p-4 border-l-2 border-dashed border-white/10\">\n              <span className=\"absolute top-2 text-[10px] text-gray-500 font-mono tracking-widest uppercase\">Input Stream</span>\n              <AnimatePresence>\n                {activeNode && (\n                  <motion.div\n                    key={activeNode.id}\n                    initial={{ x: -100, opacity: 0 }}\n                    animate={{ x: 0, opacity: 1 }}\n                    exit={{ x: 100, opacity: 0 }}\n                    transition={{ duration: 0.5 }}\n                    className=\"relative\"\n                  >\n                    <div className=\"w-16 h-16 rounded-2xl bg-gray-800 border border-white/20 flex items-center justify-center shadow-2xl overflow-hidden\">\n                      <motion.div \n                        className=\"w-full h-full opacity-30 absolute inset-0\"\n                        animate={{ rotate: 360 }}\n                        transition={{ duration: 10, repeat: Infinity, ease: \"linear\" }}\n                        style={{ background: `radial-gradient(circle, ${GEOMETRIES[activeNode.nodeType].color}, transparent)` }}\n                      />\n                      <Maximize2 className={activeNode.isAnomaly ? \"text-red-500 animate-pulse\" : \"text-gray-400\"} />\n                    </div>\n                  </motion.div>\n                )}\n              </AnimatePresence>\n              <div className=\"mt-4 text-center\">\n                <div className=\"text-xs font-mono text-gray-500\">v_{activeNode?.id.toString().slice(-4)}</div>\n              </div>\n            </div>\n\n            {/* Dynamic Router */}\n            <div className=\"relative flex flex-col items-center justify-center p-4\">\n              <div className=\"z-10 bg-gray-800 p-6 rounded-3xl border border-white/10 shadow-2xl text-center relative overflow-hidden group\">\n                <div className=\"absolute inset-0 bg-gradient-to-br from-purple-500/10 to-transparent opacity-50\"></div>\n                <Share2 className=\"mx-auto mb-2 text-purple-400\" />\n                <h4 className=\"text-sm font-bold uppercase tracking-widest text-white/80\">Router</h4>\n                <p className=\"text-[10px] text-gray-500 mt-2 font-mono\">Memory Check...</p>\n                <div className=\"mt-4 space-y-1\">\n                   <div className=\"w-12 h-1 bg-white/5 rounded-full mx-auto overflow-hidden\">\n                      <motion.div \n                        className=\"h-full bg-purple-500\"\n                        animate={{ width: [\"0%\", \"100%\", \"0%\"] }}\n                        transition={{ duration: 2, repeat: Infinity }}\n                      />\n                   </div>\n                </div>\n              </div>\n              \n              {/* Path Lines */}\n              <svg className=\"absolute inset-0 w-full h-full -z-10 opacity-20\" pointerEvents=\"none\">\n                <line x1=\"100%\" y1=\"50%\" x2=\"110%\" y2=\"50%\" stroke=\"white\" strokeDasharray=\"4\" />\n              </svg>\n            </div>\n\n            {/* Expert Rooms */}\n            <div className=\"md:col-span-2 grid grid-rows-3 gap-4\">\n              {Object.entries(GEOMETRIES).map(([key, geo]) => {\n                const isActive = activeNode?.expertType === key;\n                const isMismatch = isActive && activeNode.nodeType !== key;\n                \n                return (\n                  <div \n                    key={key}\n                    className={`relative flex items-center gap-4 p-4 rounded-2xl border transition-all duration-500 ${\n                      isActive \n                        ? 'bg-gray-800 border-opacity-100 scale-105 shadow-2xl ring-1 ring-white/20' \n                        : 'bg-gray-900/30 border-white/5 opacity-40'\n                    }`}\n                    style={{ borderColor: isActive ? geo.color : '' }}\n                  >\n                    <div className=\"p-3 rounded-xl bg-gray-950/50\" style={{ color: geo.color }}>\n                      {key === 'HYPERBOLIC' && <Layers size={24} />}\n                      {key === 'EUCLIDEAN' && <Box size={24} />}\n                      {key === 'SPHERICAL' && <RefreshCw size={24} />}\n                    </div>\n                    \n                    <div className=\"flex-1\">\n                      <div className=\"flex items-center justify-between\">\n                        <span className=\"text-xs font-bold uppercase tracking-tighter\" style={{ color: geo.color }}>\n                          {geo.label} Expert\n                        </span>\n                        {isActive && (\n                          <motion.span \n                            initial={{ opacity: 0 }} \n                            animate={{ opacity: 1 }} \n                            className=\"text-[10px] font-mono text-emerald-400 flex items-center gap-1\"\n                          >\n                            <Zap size={10} /> PROCESSING\n                          </motion.span>\n                        )}\n                      </div>\n                      <div className=\"mt-1 flex items-center gap-2\">\n                        <div className=\"text-[10px] text-gray-500 italic\">κ = {geo.kappa.toFixed(1)}</div>\n                        {isMismatch && (\n                          <div className=\"text-[10px] text-red-400 font-bold animate-pulse\">\n                             GEOMETRIC DISTORTION DETECTED!\n                          </div>\n                        )}\n                      </div>\n                    </div>\n\n                    {/* Reconstruction Visualization */}\n                    {isActive && (\n                      <motion.div \n                        initial={{ scale: 0 }}\n                        animate={{ scale: 1 }}\n                        className=\"w-12 h-12 rounded-full border-4 border-dashed relative flex items-center justify-center\"\n                        style={{ borderColor: activeNode.error > 0.6 ? 'rgba(239, 68, 68, 0.5)' : 'rgba(16, 185, 129, 0.5)' }}\n                      >\n                         <AnimatePresence>\n                           {activeNode.error > 0.6 && (\n                             <motion.div \n                               initial={{ opacity: 0 }}\n                               animate={{ opacity: [0, 1, 0] }}\n                               transition={{ repeat: Infinity }}\n                               className=\"absolute inset-0 bg-red-500/20 rounded-full\"\n                             />\n                           )}\n                         </AnimatePresence>\n                         <div className={`text-[10px] font-bold ${activeNode.error > 0.6 ? 'text-red-400' : 'text-emerald-400'}`}>\n                           {Math.round(activeNode.error * 100)}%\n                         </div>\n                      </motion.div>\n                    )}\n                  </div>\n                );\n              })}\n            </div>\n          </div>\n\n          {/* Metrics Section */}\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6 flex items-center justify-between\">\n                <span>Anomaly Scoring (Reconstruction Error)</span>\n                <span className=\"text-xs text-blue-400 bg-blue-500/10 px-2 py-1 rounded\">Real-time</span>\n              </h3>\n              <div className=\"h-64\">\n                <ResponsiveContainer width=\"100%\" height=\"100%\">\n                  <AreaChart data={history}>\n                    <defs>\n                      <linearGradient id=\"colorError\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">\n                        <stop offset=\"5%\" stopColor=\"#8b5cf6\" stopOpacity={0.3}/>\n                        <stop offset=\"95%\" stopColor=\"#8b5cf6\" stopOpacity={0}/>\n                      </linearGradient>\n                    </defs>\n                    <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#333\" vertical={false} />\n                    <XAxis dataKey=\"timestamp\" stroke=\"#666\" fontSize={10} tickLine={false} />\n                    <YAxis stroke=\"#666\" fontSize={10} tickLine={false} axisLine={false} domain={[0, 100]} />\n                    <Tooltip \n                      contentStyle={{ backgroundColor: '#111', border: '1px solid #333', fontSize: '12px' }}\n                      itemStyle={{ color: '#8b5cf6' }}\n                    />\n                    <Area \n                      type=\"monotone\" \n                      dataKey=\"score\" \n                      stroke=\"#8b5cf6\" \n                      fillOpacity={1} \n                      fill=\"url(#colorError)\" \n                      strokeWidth={2}\n                      animationDuration={1000}\n                    />\n                  </AreaChart>\n                </ResponsiveContainer>\n              </div>\n            </div>\n\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6\">Algorithm Concept</h3>\n              <div className=\"space-y-4\">\n                <div className=\"p-4 bg-black/40 rounded-xl border border-white/5 space-y-3\">\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-purple-500/20 text-purple-400 rounded-lg\">\n                      <Layers size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Riemannian Projection</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        MCFA (Multi-Curvature Feature Alignment) projects raw features into tangent spaces of varying κ before routing.\n                      </p>\n                    </div>\n                  </div>\n                  \n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-blue-500/20 text-blue-400 rounded-lg\">\n                      <Share2 size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Memory-Based Routing</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                         $s_i(h_v) = -\\min_{m \\in B_i} d_{M_i}(\\exp_{o_i}(h_v), \\exp_{o_i}(m))$\n                         <br/>Nodes are routed to experts whose memory bank contains similar high-fidelity reconstructions.\n                      </p>\n                    </div>\n                  </div>\n\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-red-500/20 text-red-400 rounded-lg\">\n                      <AlertTriangle size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Anomaly Signal</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        Anomaly Score $S(v) = \\|h_v - \\hat{h}_v\\|^2$. Mismatched geometry causes catastrophic reconstruction error, revealing anomalies.\n                      </p>\n                    </div>\n                  </div>\n                </div>\n\n                <div className=\"grid grid-cols-2 gap-4\">\n                   <div className=\"p-3 bg-emerald-500/5 border border-emerald-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-emerald-400 uppercase font-bold\">Model State</div>\n                      <div className=\"text-lg font-bold text-emerald-200\">Ready</div>\n                   </div>\n                   <div className=\"p-3 bg-blue-500/5 border border-blue-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-blue-400 uppercase font-bold\">Zero-Shot Latency</div>\n                      <div className=\"text-lg font-bold text-blue-200\">42ms</div>\n                   </div>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n      \n      {/* Footer Info */}\n      <div className=\"max-w-7xl mx-auto mt-8 text-center text-gray-600 text-[10px] uppercase tracking-widest\">\n        Reference Paper: Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts (2025)\n      </div>\n    </div>\n  );\n}",
                  "title": "GAD-MoRE Expert Routing Prototype (Fixed)"
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "functionResponse": {
                "name": "render_prototype",
                "response": {
                  "success": true,
                  "rendered": true
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "text": "The prototype has an error: Uncaught ReferenceError: m is not defined (Line 10)\n\nPlease fix it."
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "title": "GAD-MoRE Expert Routing Prototype (Final Fix)",
                  "code": "import React, { useState, useEffect, useMemo, useRef } from 'react';\nimport { \n  LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer, \n  AreaChart, Area \n} from 'recharts';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { \n  Zap, Brain, Share2, AlertTriangle, CheckCircle, \n  Maximize2, Box, Radio, RefreshCw, Layers\n} from 'lucide-react';\n\n// --- Simulation Constants ---\nconst GEOMETRIES = {\n  HYPERBOLIC: { id: 'hyp', label: 'Hyperbolic', kappa: -1.0, color: 'rgb(168, 85, 247)', description: 'Best for Hierarchies/Trees' },\n  EUCLIDEAN: { id: 'euc', label: 'Euclidean', kappa: 0.0, color: 'rgb(59, 130, 246)', description: 'Best for Flat Grids' },\n  SPHERICAL: { id: 'sph', label: 'Spherical', kappa: 1.0, color: 'rgb(245, 158, 11)', description: 'Best for Cyclical/Dense' }\n};\n\n// Simplified manifold distance simulation\nfunction simulateReconstruction(nodeType, expertType, isAnomaly) {\n  const baseError = isAnomaly ? 0.6 : 0.1;\n  const geometryMismatch = nodeType !== expertType;\n  \n  if (geometryMismatch) {\n    // If we route a hierarchical node to a spherical room, reconstruction \"breaks\"\n    return Math.min(0.95, baseError + 0.7 + Math.random() * 0.1);\n  }\n  return Math.min(0.4, baseError + Math.random() * 0.1);\n}\n\nexport default function App() {\n  const [isPlaying, setIsPlaying] = useState(true);\n  const [nodeType, setNodeType] = useState('HYPERBOLIC');\n  const [isAnomaly, setIsAnomaly] = useState(false);\n  const [routerLogic, setRouterLogic] = useState('auto'); // 'auto', 'manual-hyp', 'manual-euc', 'manual-sph'\n  const [history, setHistory] = useState([]);\n  const [activeNode, setActiveNode] = useState(null);\n  const [memoryBankStatus, setMemoryBankStatus] = useState({ hyp: 85, euc: 92, sph: 78 });\n\n  // Processing Logic\n  useEffect(() => {\n    if (!isPlaying) return;\n\n    const interval = setInterval(() => {\n      // Logic for selecting the expert\n      let expertKey = nodeType;\n      if (routerLogic !== 'auto') {\n        const manualMap = {\n          'manual-hyp': 'HYPERBOLIC',\n          'manual-euc': 'EUCLIDEAN',\n          'manual-sph': 'SPHERICAL'\n        };\n        expertKey = manualMap[routerLogic];\n      }\n\n      const error = simulateReconstruction(nodeType, expertKey, isAnomaly);\n      \n      const newNode = {\n        id: Date.now(),\n        nodeType,\n        expertType: expertKey,\n        isAnomaly,\n        error,\n        timestamp: new Date().toLocaleTimeString().slice(-5)\n      };\n\n      setActiveNode(newNode);\n      setHistory(prev => [...prev.slice(-19), { ...newNode, score: error * 100 }]);\n      \n      // Dynamic memory bank \"learning\" simulation\n      const shortId = GEOMETRIES[expertKey].id;\n      setMemoryBankStatus(prev => ({\n        ...prev,\n        [shortId]: Math.min(100, prev[shortId] + (error < 0.3 ? 1 : -0.5))\n      }));\n\n    }, 2000);\n\n    return () => clearInterval(interval);\n  }, [isPlaying, nodeType, isAnomaly, routerLogic]);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white font-sans p-4 lg:p-8\">\n      {/* Header */}\n      <div className=\"max-w-7xl mx-auto mb-8 flex flex-col md:flex-row md:items-center justify-between gap-4\">\n        <div>\n          <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-blue-400 to-purple-500\">\n            GAD-MoRE: Expert Routing Flow\n          </h1>\n          <p className=\"text-gray-400 mt-1 flex items-center gap-2\">\n            <Brain size={16} className=\"text-purple-400\" />\n            Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts\n          </p>\n        </div>\n        <div className=\"flex gap-2\">\n          <button \n            onClick={() => setIsPlaying(!isPlaying)}\n            className={`px-6 py-2 rounded-full flex items-center gap-2 font-medium transition-all ${\n              isPlaying ? 'bg-red-500/20 text-red-400 border border-red-500/50' : 'bg-emerald-500/20 text-emerald-400 border border-emerald-500/50'\n            }`}\n          >\n            {isPlaying ? <Radio className=\"animate-pulse\" /> : <RefreshCw />}\n            {isPlaying ? 'Live Stream' : 'Paused'}\n          </button>\n        </div>\n      </div>\n\n      <div className=\"max-w-7xl mx-auto grid grid-cols-1 lg:grid-cols-12 gap-6\">\n        \n        {/* Sidebar Controls */}\n        <div className=\"lg:col-span-3 space-y-6\">\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5 shadow-xl\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4 flex items-center gap-2\">\n              <Zap size={14} className=\"text-yellow-400\" /> Input Generator\n            </h3>\n            \n            <div className=\"space-y-4\">\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Node Intrinsic Geometry</label>\n                <div className=\"grid grid-cols-1 gap-2\">\n                  {Object.entries(GEOMETRIES).map(([key, geo]) => (\n                    <button\n                      key={key}\n                      onClick={() => setNodeType(key)}\n                      className={`text-left p-3 rounded-xl border transition-all ${\n                        nodeType === key \n                          ? `bg-${geo.id}/10 border-opacity-100` \n                          : 'bg-gray-800/30 border-white/5 text-gray-400 hover:bg-gray-800/50'\n                      }`}\n                      style={{ \n                        borderColor: nodeType === key ? geo.color : '',\n                        backgroundColor: nodeType === key ? geo.color.replace('rgb', 'rgba').replace(')', ', 0.1)') : ''\n                      }}\n                    >\n                      <div className=\"font-bold flex items-center gap-2\">\n                        <div className=\"w-2 h-2 rounded-full\" style={{ backgroundColor: geo.color }}></div>\n                        {geo.label}\n                      </div>\n                      <div className=\"text-[10px] opacity-60\">{geo.description}</div>\n                    </button>\n                  ))}\n                </div>\n              </div>\n\n              <div>\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold\">Anomaly Status</label>\n                <button\n                  onClick={() => setIsAnomaly(!isAnomaly)}\n                  className={`w-full py-2 px-4 rounded-xl border transition-all flex items-center justify-between ${\n                    isAnomaly \n                      ? 'bg-red-500/20 border-red-500 text-red-200' \n                      : 'bg-emerald-500/20 border-emerald-500 text-emerald-200'\n                  }`}\n                >\n                  <span className=\"font-medium\">{isAnomaly ? 'Anomalous Node' : 'Normal Node'}</span>\n                  {isAnomaly ? <AlertTriangle size={16} /> : <CheckCircle size={16} />}\n                </button>\n              </div>\n\n              <div className=\"pt-4 border-t border-white/5\">\n                <label className=\"text-xs text-gray-500 block mb-2 uppercase font-bold text-center\">Memory-Based Router Mode</label>\n                <select \n                  className=\"w-full bg-gray-800 border border-white/10 rounded-lg p-2 text-sm focus:outline-none focus:ring-2 focus:ring-purple-500\"\n                  value={routerLogic}\n                  onChange={(e) => setRouterLogic(e.target.value)}\n                >\n                  <option value=\"auto\">Automatic (Dynamic Memory)</option>\n                  <option value=\"manual-hyp\">Forced: Hyperbolic Expert</option>\n                  <option value=\"manual-euc\">Forced: Euclidean Expert</option>\n                  <option value=\"manual-sph\">Forced: Spherical Expert</option>\n                </select>\n              </div>\n            </div>\n          </section>\n\n          <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-5\">\n            <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-4\">Router Stats</h3>\n            <div className=\"space-y-4\">\n              {Object.entries(GEOMETRIES).map(([key, geo]) => (\n                <div key={key} className=\"space-y-1\">\n                  <div className=\"flex justify-between text-[10px] font-mono\">\n                    <span className=\"uppercase\">{geo.id} Memory Fidelity</span>\n                    <span>{memoryBankStatus[geo.id]}%</span>\n                  </div>\n                  <div className=\"h-1.5 w-full bg-gray-800 rounded-full overflow-hidden\">\n                    <motion.div \n                      className=\"h-full rounded-full\"\n                      style={{ backgroundColor: geo.color }}\n                      initial={{ width: 0 }}\n                      animate={{ width: `${memoryBankStatus[geo.id]}%` }}\n                    />\n                  </div>\n                </div>\n              ))}\n            </div>\n          </section>\n        </div>\n\n        {/* Main Animation Flow */}\n        <div className=\"lg:col-span-9 space-y-6\">\n          \n          <div className=\"grid grid-cols-1 md:grid-cols-4 gap-4 min-h-[400px]\">\n            {/* Input Stream */}\n            <div className=\"relative flex flex-col items-center justify-center p-4 border-l-2 border-dashed border-white/10\">\n              <span className=\"absolute top-2 text-[10px] text-gray-500 font-mono tracking-widest uppercase\">Input Stream</span>\n              <AnimatePresence>\n                {activeNode && (\n                  <motion.div\n                    key={activeNode.id}\n                    initial={{ x: -100, opacity: 0 }}\n                    animate={{ x: 0, opacity: 1 }}\n                    exit={{ x: 100, opacity: 0 }}\n                    transition={{ duration: 0.5 }}\n                    className=\"relative\"\n                  >\n                    <div className=\"w-16 h-16 rounded-2xl bg-gray-800 border border-white/20 flex items-center justify-center shadow-2xl overflow-hidden\">\n                      <motion.div \n                        className=\"w-full h-full opacity-30 absolute inset-0\"\n                        animate={{ rotate: 360 }}\n                        transition={{ duration: 10, repeat: Infinity, ease: \"linear\" }}\n                        style={{ background: `radial-gradient(circle, ${GEOMETRIES[activeNode.nodeType].color}, transparent)` }}\n                      />\n                      <Maximize2 className={activeNode.isAnomaly ? \"text-red-500 animate-pulse\" : \"text-gray-400\"} />\n                    </div>\n                  </motion.div>\n                )}\n              </AnimatePresence>\n              <div className=\"mt-4 text-center\">\n                <div className=\"text-xs font-mono text-gray-500\">v_{activeNode ? activeNode.id.toString().slice(-4) : '....'}</div>\n              </div>\n            </div>\n\n            {/* Dynamic Router */}\n            <div className=\"relative flex flex-col items-center justify-center p-4\">\n              <div className=\"z-10 bg-gray-800 p-6 rounded-3xl border border-white/10 shadow-2xl text-center relative overflow-hidden group\">\n                <div className=\"absolute inset-0 bg-gradient-to-br from-purple-500/10 to-transparent opacity-50\"></div>\n                <Share2 className=\"mx-auto mb-2 text-purple-400\" />\n                <h4 className=\"text-sm font-bold uppercase tracking-widest text-white/80\">Router</h4>\n                <p className=\"text-[10px] text-gray-500 mt-2 font-mono\">Memory Check...</p>\n                <div className=\"mt-4 space-y-1\">\n                   <div className=\"w-12 h-1 bg-white/5 rounded-full mx-auto overflow-hidden\">\n                      <motion.div \n                        className=\"h-full bg-purple-500\"\n                        animate={{ width: [\"0%\", \"100%\", \"0%\"] }}\n                        transition={{ duration: 2, repeat: Infinity }}\n                      />\n                   </div>\n                </div>\n              </div>\n            </div>\n\n            {/* Expert Rooms */}\n            <div className=\"md:col-span-2 grid grid-rows-3 gap-4\">\n              {Object.entries(GEOMETRIES).map(([key, geo]) => {\n                const isActive = activeNode?.expertType === key;\n                const isMismatch = isActive && activeNode.nodeType !== key;\n                \n                return (\n                  <div \n                    key={key}\n                    className={`relative flex items-center gap-4 p-4 rounded-2xl border transition-all duration-500 ${\n                      isActive \n                        ? 'bg-gray-800 border-opacity-100 scale-105 shadow-2xl ring-1 ring-white/20' \n                        : 'bg-gray-900/30 border-white/5 opacity-40'\n                    }`}\n                    style={{ borderColor: isActive ? geo.color : '' }}\n                  >\n                    <div className=\"p-3 rounded-xl bg-gray-950/50\" style={{ color: geo.color }}>\n                      {key === 'HYPERBOLIC' && <Layers size={24} />}\n                      {key === 'EUCLIDEAN' && <Box size={24} />}\n                      {key === 'SPHERICAL' && <RefreshCw size={24} />}\n                    </div>\n                    \n                    <div className=\"flex-1\">\n                      <div className=\"flex items-center justify-between\">\n                        <span className=\"text-xs font-bold uppercase tracking-tighter\" style={{ color: geo.color }}>\n                          {geo.label} Expert\n                        </span>\n                        {isActive && (\n                          <motion.span \n                            initial={{ opacity: 0 }} \n                            animate={{ opacity: 1 }} \n                            className=\"text-[10px] font-mono text-emerald-400 flex items-center gap-1\"\n                          >\n                            <Zap size={10} /> PROCESSING\n                          </motion.span>\n                        )}\n                      </div>\n                      <div className=\"mt-1 flex items-center gap-2\">\n                        <div className=\"text-[10px] text-gray-500 italic\">κ = {geo.kappa.toFixed(1)}</div>\n                        {isMismatch && (\n                          <div className=\"text-[10px] text-red-400 font-bold animate-pulse\">\n                             GEOMETRIC DISTORTION DETECTED!\n                          </div>\n                        )}\n                      </div>\n                    </div>\n\n                    {/* Reconstruction Visualization */}\n                    {isActive && (\n                      <motion.div \n                        initial={{ scale: 0 }}\n                        animate={{ scale: 1 }}\n                        className=\"w-12 h-12 rounded-full border-4 border-dashed relative flex items-center justify-center\"\n                        style={{ borderColor: activeNode.error > 0.6 ? 'rgba(239, 68, 68, 0.5)' : 'rgba(16, 185, 129, 0.5)' }}\n                      >\n                         <AnimatePresence>\n                           {activeNode.error > 0.6 && (\n                             <motion.div \n                               initial={{ opacity: 0 }}\n                               animate={{ opacity: [0, 1, 0] }}\n                               transition={{ repeat: Infinity }}\n                               className=\"absolute inset-0 bg-red-500/20 rounded-full\"\n                             />\n                           )}\n                         </AnimatePresence>\n                         <div className={`text-[10px] font-bold ${activeNode.error > 0.6 ? 'text-red-400' : 'text-emerald-400'}`}>\n                           {Math.round(activeNode.error * 100)}%\n                         </div>\n                      </motion.div>\n                    )}\n                  </div>\n                );\n              })}\n            </div>\n          </div>\n\n          {/* Metrics Section */}\n          <div className=\"grid grid-cols-1 md:grid-cols-2 gap-6\">\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6 flex items-center justify-between\">\n                <span>Anomaly Scoring (Reconstruction Error)</span>\n                <span className=\"text-xs text-blue-400 bg-blue-500/10 px-2 py-1 rounded\">Real-time</span>\n              </h3>\n              <div className=\"h-64\">\n                <ResponsiveContainer width=\"100%\" height=\"100%\">\n                  <AreaChart data={history}>\n                    <defs>\n                      <linearGradient id=\"colorError\" x1=\"0\" y1=\"0\" x2=\"0\" y2=\"1\">\n                        <stop offset=\"5%\" stopColor=\"#8b5cf6\" stopOpacity={0.3}/>\n                        <stop offset=\"95%\" stopColor=\"#8b5cf6\" stopOpacity={0}/>\n                      </linearGradient>\n                    </defs>\n                    <CartesianGrid strokeDasharray=\"3 3\" stroke=\"#333\" vertical={false} />\n                    <XAxis dataKey=\"timestamp\" stroke=\"#666\" fontSize={10} tickLine={false} />\n                    <YAxis stroke=\"#666\" fontSize={10} tickLine={false} axisLine={false} domain={[0, 100]} />\n                    <Tooltip \n                      contentStyle={{ backgroundColor: '#111', border: '1px solid #333', fontSize: '12px' }}\n                      itemStyle={{ color: '#8b5cf6' }}\n                    />\n                    <Area \n                      type=\"monotone\" \n                      dataKey=\"score\" \n                      stroke=\"#8b5cf6\" \n                      fillOpacity={1} \n                      fill=\"url(#colorError)\" \n                      strokeWidth={2}\n                      animationDuration={1000}\n                    />\n                  </AreaChart>\n                </ResponsiveContainer>\n              </div>\n            </div>\n\n            <div className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <h3 className=\"text-sm font-semibold text-gray-400 uppercase tracking-wider mb-6\">Algorithm Concept</h3>\n              <div className=\"space-y-4\">\n                <div className=\"p-4 bg-black/40 rounded-xl border border-white/5 space-y-3\">\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-purple-500/20 text-purple-400 rounded-lg\">\n                      <Layers size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Riemannian Projection</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        MCFA (Multi-Curvature Feature Alignment) projects raw features into tangent spaces of varying curvature before routing.\n                      </p>\n                    </div>\n                  </div>\n                  \n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-blue-500/20 text-blue-400 rounded-lg\">\n                      <Share2 size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Memory-Based Routing</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                         Nodes are routed based on distance to memory bank centroids in manifold space.\n                         Experts specialize in patterns where they achieve high historical fidelity.\n                      </p>\n                    </div>\n                  </div>\n\n                  <div className=\"flex items-start gap-3\">\n                    <div className=\"p-2 bg-red-500/20 text-red-400 rounded-lg\">\n                      <AlertTriangle size={16} />\n                    </div>\n                    <div>\n                      <h4 className=\"text-xs font-bold text-gray-200\">Anomaly Signal</h4>\n                      <p className=\"text-[11px] text-gray-400 mt-1\">\n                        Reconstruction error represents the deviation from normal manifold structure.\n                        Mismatched geometry causes catastrophic error, flagging anomalies.\n                      </p>\n                    </div>\n                  </div>\n                </div>\n\n                <div className=\"grid grid-cols-2 gap-4\">\n                   <div className=\"p-3 bg-emerald-500/5 border border-emerald-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-emerald-400 uppercase font-bold\">Model State</div>\n                      <div className=\"text-lg font-bold text-emerald-200\">Ready</div>\n                   </div>\n                   <div className=\"p-3 bg-blue-500/5 border border-blue-500/20 rounded-xl\">\n                      <div className=\"text-[10px] text-blue-400 uppercase font-bold\">Zero-Shot Latency</div>\n                      <div className=\"text-lg font-bold text-blue-200\">42ms</div>\n                   </div>\n                </div>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n      \n      {/* Footer Info */}\n      <div className=\"max-w-7xl mx-auto mt-8 text-center text-gray-600 text-[10px] uppercase tracking-widest\">\n        Reference Paper: Zero-shot Generalizable Graph Anomaly Detection with Mixture of Riemannian Experts (2025)\n      </div>\n    </div>\n  );\n}"
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "functionResponse": {
                "name": "render_prototype",
                "response": {
                  "success": true,
                  "rendered": true
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "functionResponse": {
                "name": "render_prototype",
                "response": {
                  "success": true,
                  "rendered": true
                }
              }
            }
          ]
        }
      ],
      "created_at": 1770621701469,
      "updated_at": 1770623315675
    },
    "interactive-cooling-branching-tree-1770623846645": {
      "id": "interactive-cooling-branching-tree-1770623846645",
      "paper_hash": "arxiv-2602.04878",
      "title": "Interactive Cooling & Branching Tree",
      "description": "A visualization of the operator splitting process. Users start with a single 'Identity' node. As they increase inverse temperature (beta) via a slider, they see the operator multiply and branch into new Pauli strings based on the Hamiltonian terms.",
      "code": "import React, { useState, useMemo, useEffect } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { Sliders, Thermometer, Share2, Activity, Info, Zap } from 'lucide-react';\n\n/**\n * Pauli String Utilities\n */\nconst PAULI_MAP = { I: 0, X: 1, Y: 2, Z: 3 };\nconst PAULI_CHARS = ['I', 'X', 'Y', 'Z'];\n\n// Commutation check for two Pauli strings\n// [P, Q] = 0 if they commute, != 0 if they anti-commute\nfunction commutes(p1, p2) {\n  let antiCount = 0;\n  for (let i = 0; i < p1.length; i++) {\n    const c1 = p1[i];\n    const c2 = p2[i];\n    if (c1 !== 'I' && c2 !== 'I' && c1 !== c2) {\n      antiCount++;\n    }\n  }\n  return antiCount % 2 === 0;\n}\n\n// Pauli Multiplication (ignoring global phase as coefficients stay real in this paper)\nfunction multiply(p1, p2) {\n  let res = \"\";\n  for (let i = 0; i < p1.length; i++) {\n    const v1 = PAULI_MAP[p1[i]];\n    const v2 = PAULI_MAP[p2[i]];\n    if (v1 === 0) res += p2[i];\n    else if (v2 === 0) res += p1[i];\n    else if (v1 === v2) res += 'I';\n    else {\n      // X*Y=Z, Y*Z=X, Z*X=Y (ignoring i)\n      const others = [1, 2, 3].filter(v => v !== v1 && v !== v2);\n      res += PAULI_CHARS[others[0]];\n    }\n  }\n  return res;\n}\n\n// Simple 1D Heisenberg Hamiltonian for 4 qubits: H = sum Z_i Z_{i+1} + X_i\nconst HAMILTONIAN = [\n  { term: \"ZZII\", weight: 1.0 },\n  { term: \"IZZI\", weight: 1.0 },\n  { term: \"IIZZ\", weight: 1.0 },\n  { term: \"XIII\", weight: 0.5 },\n  { term: \"IXII\", weight: 0.5 },\n  { term: \"IIXI\", weight: 0.5 },\n  { term: \"IIIX\", weight: 0.5 },\n];\n\nexport default function App() {\n  const [beta, setBeta] = useState(0.0);\n  const [truncation, setTruncation] = useState(0.001);\n  const [numSteps, setNumSteps] = useState(5);\n\n  const simulation = useMemo(() => {\n    let state = { \"IIII\": 1.0 };\n    const tau = beta / (2 * numSteps); // beta/2 is the evolution parameter for I\n    \n    // We iterate imaginary time evolution\n    for (let s = 0; s < numSteps; s++) {\n      let nextState = {};\n      \n      // Apply each Hamiltonian term in Trotter order\n      HAMILTONIAN.forEach(({ term, weight }) => {\n        const currentKeys = Object.keys(state);\n        const t = tau * weight;\n        const c = Math.cosh(t);\n        const s_ = Math.sinh(t);\n\n        currentKeys.forEach(q => {\n          const coef = state[q];\n          if (commutes(term, q)) {\n            // Eq 4: cosh(t)Q - sinh(t)PQ\n            const prod = multiply(term, q);\n            nextState[q] = (nextState[q] || 0) + coef * c;\n            nextState[prod] = (nextState[prod] || 0) - coef * s_;\n          } else {\n            // Eq 4: Q\n            nextState[q] = (nextState[q] || 0) + coef;\n          }\n        });\n        state = nextState;\n        nextState = {};\n      });\n\n      // Truncation\n      Object.keys(state).forEach(k => {\n        if (Math.abs(state[k]) < truncation) {\n          delete state[k];\n        }\n      });\n\n      // Normalization per paper: alpha_I should be normalized to keep values stable\n      const alphaI = state[\"IIII\"] || 1.0;\n      Object.keys(state).forEach(k => {\n        state[k] = state[k] / alphaI;\n      });\n    }\n\n    return state;\n  }, [beta, truncation, numSteps]);\n\n  const sortedNodes = useMemo(() => {\n    return Object.entries(simulation)\n      .sort((a, b) => Math.abs(b[1]) - Math.abs(a[1]))\n      .slice(0, 40); // Limit for visualization\n  }, [simulation]);\n\n  // Derived metrics\n  const totalTerms = Object.keys(simulation).length;\n  const avgWeight = Object.values(simulation).reduce((a, b) => a + (b === \"IIII\" ? 0 : b), 0) / (totalTerms || 1);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white p-4 md:p-8 font-sans selection:bg-blue-500/30\">\n      <div className=\"max-w-6xl mx-auto\">\n        {/* Header */}\n        <header className=\"mb-8\">\n          <div className=\"flex items-center gap-3 mb-2\">\n            <div className=\"p-2 bg-blue-600 rounded-lg shadow-lg shadow-blue-900/20\">\n              <Thermometer className=\"w-6 h-6\" />\n            </div>\n            <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-white to-gray-500\">\n              Cooling & Branching Tree\n            </h1>\n          </div>\n          <p className=\"text-gray-400 max-w-2xl\">\n            Visualizing <strong>Schrödinger-picture imaginary-time evolution</strong>. As inverse temperature \n            (β) increases, the state branches from a sparse Identity operator into a dense cluster of Pauli strings.\n          </p>\n        </header>\n\n        <div className=\"grid grid-cols-1 lg:grid-cols-12 gap-6\">\n          \n          {/* Controls Panel */}\n          <div className=\"lg:col-span-4 space-y-6\">\n            <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6 backdrop-blur-sm\">\n              <div className=\"flex items-center gap-2 mb-6 text-blue-400\">\n                <Sliders className=\"w-5 h-5\" />\n                <h2 className=\"font-semibold uppercase tracking-wider text-sm\">System Parameters</h2>\n              </div>\n\n              <div className=\"space-y-8\">\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Inverse Temperature (β)</label>\n                    <span className=\"text-blue-400 font-mono font-bold\">{beta.toFixed(2)}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"0\" max=\"2\" step=\"0.05\" \n                    value={beta} \n                    onChange={e => setBeta(parseFloat(e.target.value))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-blue-500\"\n                  />\n                  <div className=\"flex justify-between text-[10px] text-gray-500 mt-1 uppercase tracking-tighter\">\n                    <span>Infinite Temp (β=0)</span>\n                    <span>Cooling...</span>\n                  </div>\n                </div>\n\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Truncation Cutoff (ε)</label>\n                    <span className=\"text-emerald-400 font-mono font-bold\">{truncation.toExponential(1)}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"-5\" max=\"-1\" step=\"0.1\" \n                    value={Math.log10(truncation)} \n                    onChange={e => setTruncation(Math.pow(10, parseFloat(e.target.value)))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-emerald-500\"\n                  />\n                </div>\n\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Trotter Steps (L)</label>\n                    <span className=\"text-purple-400 font-mono font-bold\">{numSteps}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"1\" max=\"10\" step=\"1\" \n                    value={numSteps} \n                    onChange={e => setNumSteps(parseInt(e.target.value))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-purple-500\"\n                  />\n                </div>\n              </div>\n            </section>\n\n            <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <div className=\"flex items-center gap-2 mb-4 text-emerald-400\">\n                <Activity className=\"w-5 h-5\" />\n                <h2 className=\"font-semibold uppercase tracking-wider text-sm\">State Metrics</h2>\n              </div>\n              <div className=\"grid grid-cols-2 gap-4\">\n                <div className=\"p-3 bg-black/40 rounded-xl border border-white/5\">\n                  <div className=\"text-xs text-gray-500 mb-1\">Pauli Strings</div>\n                  <div className=\"text-2xl font-mono font-bold text-white\">{totalTerms}</div>\n                </div>\n                <div className=\"p-3 bg-black/40 rounded-xl border border-white/5\">\n                  <div className=\"text-xs text-gray-500 mb-1\">Max Weight</div>\n                  <div className=\"text-2xl font-mono font-bold text-white\">\n                    {Math.max(...Object.keys(simulation).map(s => s.replace(/I/g, '').length))}\n                  </div>\n                </div>\n              </div>\n              \n              <div className=\"mt-4 flex items-start gap-2 text-xs text-gray-500 bg-blue-500/5 p-3 rounded-lg border border-blue-500/10\">\n                <Info className=\"w-4 h-4 text-blue-400 shrink-0\" />\n                <p>\n                  Identity coefficient αI is normalized to 1.0. All other coefficients shown are relative to the maximally mixed component.\n                </p>\n              </div>\n            </section>\n          </div>\n\n          {/* Visualization Area */}\n          <div className=\"lg:col-span-8 bg-gray-900/30 border border-white/10 rounded-2xl p-4 relative min-h-[500px] overflow-hidden\">\n            <div className=\"absolute top-4 left-4 flex items-center gap-2 text-xs font-mono text-gray-500\">\n              <Share2 className=\"w-3 h-3\" />\n              OPERATOR BRANCHING MAP\n            </div>\n\n            <div className=\"flex flex-wrap justify-center items-center h-full gap-3 p-8\">\n              <AnimatePresence>\n                {sortedNodes.map(([string, val], idx) => {\n                  const weight = string.replace(/I/g, '').length;\n                  const absVal = Math.abs(val);\n                  const isIdentity = string === \"IIII\";\n                  \n                  return (\n                    <motion.div\n                      key={string}\n                      layout\n                      initial={{ scale: 0, opacity: 0 }}\n                      animate={{ \n                        scale: isIdentity ? 1.2 : 0.5 + absVal * 0.5, \n                        opacity: 1 \n                      }}\n                      exit={{ scale: 0, opacity: 0 }}\n                      className={`\n                        relative flex flex-col items-center justify-center\n                        p-3 rounded-xl border transition-colors cursor-default\n                        ${isIdentity \n                          ? 'bg-blue-600/20 border-blue-500/50 shadow-lg shadow-blue-500/10 z-10' \n                          : 'bg-gray-800/40 border-white/5 hover:border-white/20'\n                        }\n                      `}\n                      style={{\n                        width: isIdentity ? '100px' : '70px',\n                        height: isIdentity ? '80px' : '60px',\n                      }}\n                    >\n                      <span className={`font-mono font-bold tracking-widest ${isIdentity ? 'text-blue-300' : 'text-gray-300'} text-xs md:text-sm`}>\n                        {string}\n                      </span>\n                      <span className={`text-[10px] font-mono mt-1 ${val > 0 ? 'text-emerald-400' : 'text-rose-400'}`}>\n                        {val.toFixed(3)}\n                      </span>\n                      \n                      {/* Weight Indicator */}\n                      <div className=\"absolute -top-1 -right-1 flex gap-0.5\">\n                        {Array.from({ length: weight }).map((_, i) => (\n                          <div key={i} className=\"w-1 h-1 rounded-full bg-blue-400\" />\n                        ))}\n                      </div>\n                    </motion.div>\n                  );\n                })}\n              </AnimatePresence>\n\n              {totalTerms === 0 && (\n                <div className=\"text-gray-600 italic\">State collapsed (adjust truncation)</div>\n              )}\n            </div>\n\n            {/* Legend */}\n            <div className=\"absolute bottom-4 right-4 flex gap-4 text-[10px] uppercase tracking-widest text-gray-500\">\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-blue-500\" /> Identity\n               </div>\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-emerald-500\" /> Positive\n               </div>\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-rose-500\" /> Negative\n               </div>\n            </div>\n          </div>\n        </div>\n\n        {/* Algorithm Insight Card */}\n        <div className=\"mt-8 grid grid-cols-1 md:grid-cols-3 gap-6\">\n          <div className=\"bg-blue-500/5 border border-blue-500/10 rounded-xl p-4\">\n            <h3 className=\"text-blue-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Zap className=\"w-4 h-4\" />\n              Branching Rule\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              For imaginary time, if gate <em>P</em> commutes with operator <em>Q</em>, it branches: \n              <code className=\"block mt-2 bg-black/40 p-2 rounded text-blue-300\">\n                Q → cosh(τ)Q - sinh(τ)PQ\n              </code>\n            </p>\n          </div>\n          <div className=\"bg-emerald-500/5 border border-emerald-500/10 rounded-xl p-4\">\n            <h3 className=\"text-emerald-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Thermometer className=\"w-4 h-4\" />\n              High Temp Sparsity\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              At β=0, the state is 100% Identity. As we cool (β↑), higher-order Pauli strings emerge. \n              The prototype simulates this growth in the operator basis.\n            </p>\n          </div>\n          <div className=\"bg-purple-500/5 border border-purple-500/10 rounded-xl p-4\">\n            <h3 className=\"text-purple-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Activity className=\"w-4 h-4\" />\n              Truncation Effect\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              By discarding terms with coefficients below <em>ε</em>, we maintain a sparse representation \n              that stays efficient at high temperatures.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
      "algorithm_info": "",
      "history": [
        {
          "role": "user",
          "parts": [
            {
              "text": "Create an interactive prototype for \"Interactive Cooling & Branching Tree\". Description: A visualization of the operator splitting process. Users start with a single 'Identity' node. As they increase inverse temperature (beta) via a slider, they see the operator multiply and branch into new Pauli strings based on the Hamiltonian terms.\n\nPAPER CONTENT:\nThermal State Simulation with Pauli and Majorana Propagation\nManuel S. Rudolph,1, 2, ∗, § Armando Angrisani,1, 2, †, § Andrew\nWright,1, 2 Iwo Sanderski,1, 2 Ricard Puig,1, 2, ‡ and Zo¨e Holmes1, 2, 3\n1Institute of Physics, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Lausanne, Switzerland\n2Centre for Quantum Science and Engineering, Ecole Polytechnique F´ed´erale de Lausanne (EPFL), Lausanne, Switzerland\n3Algorithmiq Ltd, Kanavakatu 3 C, FI-00160 Helsinki, Finland\n(Dated: February 5, 2026)\nWe introduce a propagation-based approach to thermal state simulation by adapting Pauli and\nMajorana propagation to imaginary-time evolution in the Schr¨odinger picture. Our key observa-\ntion is that high-temperature states can be sparse in the Pauli or Majorana bases, approaching the\nidentity at infinite temperature. By formulating imaginary-time evolution directly in these operator\nbases and evolving from the maximally mixed state, we access a continuum of temperatures where\nthe state remains efficiently representable. We provide analytic guarantees for small-coefficient trun-\ncation and Pauli-weight (Majorana-length) truncation strategies by quantifying the error growth and\nthe impact of backflow. Large-scale numerics on the 1D J1–J2 model (energies) and the triangular-\nlattice Hubbard model (static correlations) validate efficiency at high temperatures.\nI. INTRODUCTION\nUnderstanding quantum matter at finite temperatures\nis central to material science, condensed matter and\nquantum chemistry. From a fundamental perspective,\nthermal fluctuations compete with quantum coherence\nand can change phases of matter, drive phase transi-\ntions, and determine observables such as susceptibilities\nand transport coefficients. From an applications perspec-\ntive, many target problems, including reaction rates and\nfree energies are inherently finite-temperature. Classi-\ncally probing these properties requires efficient methods\nfor approximating thermal states.\nPropagation methods, most commonly Pauli [1–15]\nand Majorana [16–20] propagation, are relative newcom-\ners to the classical toolbox for simulating quantum sys-\ntems. At their core, propagation methods approximate\nthe evolution of a quantum operator via a truncated path\nintegral. Due to Pauli propagation’s initial conceptual-\nization for simulating real-time dynamics [6, 21], the fam-\nily of propagation algorithms as a whole are currently\nprimarily understood as tools for precisely that. Both\nin the continuous-time [22] or discrete quantum circuit\nformulations [2–15]. Furthermore, they are almost exclu-\nsively presented as methods for estimating expectation\nvalues in the Heisenberg picture, i.e., for the backward\nevolution of observables that are typically sparser in the\nPauli or Majorana basis than states.\nIn this work, we challenge this perspective and pro-\npose a propagation algorithm for the simulation of finite-\ntemperature quantum states in the Schr¨odinger picture.\nWhile zero-temperature pure states are always dense in\nthe Pauli or Majorana basis, consisting of at least 2n op-\nerators for an n-site system, high-temperature states can\n∗ manuel.rudolph@epfl.ch\n† armando.angrisani@epfl.ch\n‡ ricard.puigivalls@epfl.ch\n§ These authors contributed equally to this work.\nbe exceptionally sparse. In the limit of infinite temper-\nature, the maximally-mixed state is representable by a\nsingle operator: the identity operator. By defining the\naction of imaginary-time evolution in the Pauli and Ma-\njorana basis, and starting to evolve the maximally mixed\nstate, we gain access to a range of temperatures at which\nwe can efficiently store the quantum state in memory.\nWe analyze two complementary truncation strate-\ngies, small-coefficient truncation and Pauli-weight (and\nMajorana-length) truncation. We derive upper bounds\nshowing how the resulting approximation error decreases\nas the truncation threshold is increased, guaranteeing\nthat propagation methods can run efficiently at high tem-\nperatures. We complement these results with large-scale\nnumerical experiments: for the 1D J1–J2 model we study\nenergy estimates across system sizes and temperatures,\nand for the Fermi-Hubbard model on a triangular lattice\nwe demonstrate direct computation of finite-temperature\nstatic correlation functions from the propagated thermal\nstate. Both our analytic and numerical results indicate\nthat simulating high temperatures is efficient but low\ntemperatures remain challenging.\nOur algorithm has several natural applications.\nFirstly, it provides a route to estimating free energies,\nsince once a thermal state (or its partition function) is\naccessible, thermodynamic quantities follow with mini-\nmal additional work. Secondly, as we can easily com-\nbine thermal preparation with subsequent time evolution,\nwe can, for example, probe finite-temperature correc-\ntions to infinite-temperature dynamical correlation func-\ntions. Thirdly, the ability to represent thermal states\ncompactly suggests applications to Gibbs sampling and\ngenerative modeling, where one aims to efficiently draw\nsamples from thermal distributions or learn compact gen-\nerative surrogates for finite-temperature data [23]. More\nbroadly, imaginary time propagation methods retain two\npractical advantages: they make no assumptions about\nlattice topology and they interface naturally with quan-\ntum hardware.\narXiv:2602.04878v1 [quant-ph] 4 Feb 2026\n\n-- 1 of 34 --\n\n2\n0110101110\n1010011010\n0000111111 ...\nFigure 1. Schematic depiction of thermal state preparation via propagation methods. The process begins at infinite\ntemperature (β = 0) with the maximally mixed state, represented by the identity operator I. We then apply a sequence of\nimaginary-time gates (propagators e−τ H ) to evolve the operator. As the system cools (corresponding to larger β), the state\nbecomes less sparse and the number of operators (either Paulis or Majoranas) that need to be propagated grow. This approach\nallows us to efficiently store and manipulate high-temperature states.\nII. FRAMEWORK\nIn this paper, we develop methods to simulate the ther-\nmal (Gibbs) state at inverse temperature β,\nρβ = e−βH\nTr(e−βH ) = e− β\n2 H I e− β\n2 H\nTr(e−βH ) , (1)\nwhere H is the Hamiltonian of interest. As shown\nin Eq. (1), the numerator can be viewed as evolving\nthe identity operator by the non-unitary imaginary-time\npropagator e− β\n2 H , i.e., as a “rotation” by an imaginary\nangle τ = −i β\n2 . Pauli [1–15] and Majorana [16–20] prop-\nagation methods can be used to compute the action of\nthis imaginary-time evolution on I. We will focus initially\non describing the method for Pauli propagation but the\nMajorana generalization is entirely analogous.\nPauli Propagation. The first step to simulating imag-\ninary time evolution via Pauli propagation is to express\nthe Hamiltonian as a sum of (local) Pauli terms,\nH =\nM\tX\nm=1\nhm, hm = λmPm, Pm ∈ Pn, (2)\nand apply a Trotter approximation of the imaginary evo-\nlution operator, for example, a first-order Trotter approx-\nimation,\ne−βH ≈\nM\tY\nm=1\ne−τ λmPm\n!L\n, L := β/τ (3)\nwhere the Trotter error associated with this approxima-\ntion scales as O(Cβτ ) with C := P\nm<m′ [hm, hm′ ] .\nThis approximation decomposes the evolution for imag-\ninary time β into a product of L × M local short τ\n“imaginary-time gates” each of which can be applied it-\neratively to a Pauli expansion, starting from I.\nThe action of an imaginary time gate generated by\nsome Pauli operator P on another Pauli operator Q is\ne− τ\n2 P Q e− τ\n2 P =\n(Q, [P, Q]̸ = 0,\ncosh(τ ) Q − sinh(τ ) P Q, [P, Q] = 0,\n(4)\nwhere for Pauli strings P, Q, the product P Q is also a\nPauli string, up to a phase. Note that contrary to the\nreal-time case, branching occurs when P and Q commute.\nAlso, all coefficients remain real due to the product of\ncommuting Pauli strings producing an even number of\nimaginary factors.\nAfter imaginary-time Pauli propagation, where the\ngates are iteratively applied to the initial identity op-\nerator, we obtained a collection of Pauli operators P ’s\nweighted by coefficients αP ’s, such that\ne− β\n2 H I e− β\n2 H ≈ X\nP ∈Pn\nαP P, (5)\nand the thermal state can be written as\nρβ ≈\nP\nP ∈Pn αP P\nTr\u0000P\nP ∈Pn αP P \u0001 =\nP\nP ∈Pn αP P\n2n αI\n, (6)\nsince Tr(P ) = 0 for all non-identity Paulis and Tr(I) =\n2n. In particular, the partition function Tr\u0000e−βH \u0001 is pro-\nportional to the identity coefficient αI.\nIn general, the number of Pauli terms generated by\nrepeated application of these gates grows exponentially\nwith the number of gates. Pauli propagation methods\nusually remain practical (or even formally polynomially\nscaling) when combined with truncation strategies that\nlimit the growth of the Pauli expansion to the most\n\n-- 2 of 34 --\n\n3\nrelevant contributions. Two natural choices are small-\ncoefficient truncation, where one discards terms whose\namplitudes |αP | are smaller than some cutoff value and\nPauli-weight truncation, where one removes Pauli strings\nwhose weight, i.e., the number of non-identity single-\nqubit factors in P , exceeds a prescribed cutoff. The latter\nexploits the fact that local observables are sensitive pri-\nmarily to low-weight contributions and high-weight Pauli\nstrings, have a tendency to increase in weight rather than\nbackflow to low weights under subsequent propagation.\nRandomized product formulas. For the purposes of\nour analysis (or if reducing Trotter error is a primary\ninterest), we will also consider an alternative to determin-\nistic Trotterization based on the quantum stochastic drift\nprotocol (qDRIFT) [24]. In this setting one defines the\n1-norm of the Hamiltonian coefficients Λ := PM\nm=1 |λm|\nand samples indices m i.i.d. from the distribution pm =\n|λm|/Λ. A qDRIFT approximation to the imaginary-\ntime propagator is then obtained by applying a sequence\nof randomly chosen local gates,\ne−βH ≈\nLqD\t\nY\nℓ=1\nexp(−τ smℓ Pmℓ ) , LqD := Λβ/τ (7)\nwhere each mℓ ∼ p is drawn independently and smℓ :=\nsign(λmℓ ). Intuitively, qDRIFT replaces L repetitions\nof the fixed ordering over all M terms by a stochastic\nwalk over LqD Hamiltonian terms. The qDRIFT sim-\nulation error is expected to scale as O(Λβτ ) which can\nbe less than the 1st order Trotter error when Λ < C =\tP\nm<m′ [hm, hm′ ] .\nWithin Pauli propagation, taking a qDRIFT approach\nto imaginary time simulation simply means that at each\nstep one updates the current operator expansion by\nthe adjoint action of the sampled gate. Averaging over\nmany sampled sequences yields an unbiased estimator\nof observables under the approximated imaginary-time\nevolution, while the per-step cost remains identical to the\nTrotter case. In the context of this paper the qDRIFT\napproach to imaginary time simulation is largely an\nanalytic tool that helps us to intuitively understand the\nprobability of backflow from high to low weight Paulis\nin our algorithm and thereby derive guarantees based\non weight-truncation. However, we also foresee that it\ncould become the go-to method for the Monte-Carlo\nimplementations of our algorithm that will ultimately\nbe necessary to overcome memory limitations and utilize\nGPU capabilities [14].\nMajorana propagation. In the context of fermionic\nsystems, it is more natural to work in the Majorana op-\nerator basis. For a system of n fermionic modes {aj }N\nj=1,\nthe Majorana operator basis is defined by\nm2j−1 := aj +a†\nj , m2j := −i(aj −a†\nj ), j ∈ {1, . . . , N },\n(8)\nwhich satisfy {mp, mq } = 2δpq and m†\np = mp. A Ma-\njorana monomial is indexed by a binary vector b =\n(b1, . . . , b2N ) ∈ {0, 1}2N and defined as\nMb := irb mb1\n1 mb2\n2 · · · mb2N\n2N , (9)\nwith the phase choice rb ∈ {0, 1} ensuring Mb is Hermi-\ntian (equivalently, rb = 0 when ∥b∥1 ≡ 0, 1 (mod 4) and\nrb = 1 otherwise). The length of a monomial is\n|Mb| := ∥b∥1 =\n2N\tX\nj=1\nbj , (10)\nand the set Γ := {Mb : b ∈ {0, 1}2N } forms an operator\nbasis. Hence any operator admits a unique expansion\nO = X\nb∈{0,1}2N\nαb Mb, (11)\nwith real coefficients αb ∈ R whenever O is Hermitian.\nTo simulate imaginary-time evolution in this represen-\ntation, we expand the Hamiltonian in the same basis,\nH =\nM\tX\nm=1\nhm, hm = λmMbm , Mbm ∈ Γ, (12)\nand approximate e−βH by a product formula as in the\nPauli case, yielding local imaginary-time gates Gm :=\ne−∆β λmMbm . Because any two monomials either com-\nmute or anticommute and satisfy M 2\nb = I, the update rule\non a basis element Ma takes the same form as Eq. (4),\nnamely e− τ\n2 Mb Ma e− τ\n2 Mb\n=\n(Ma, [Mb, Ma]̸ = 0,\ncosh(τ ) Ma − sinh(τ ) MbMa, [Mb, Ma] = 0. (13)\nIn particular, branching occurs when Mb and Ma com-\nmute. Moreover, the product MbMa is again Hermitian\n(up to an overall sign), so the propagated coefficients\nremain real. Finally, truncation can be implemented by\ndiscarding monomials with small coefficient prefactors\nas well as those whose length exceeds a threshold\nℓmax (Majorana-length truncation), in analogy with\nPauli-weight truncation.\nRelation to other methods. At a high level, our ap-\nproach is a series treatment of imaginary-time evolu-\ntion in operator space. Conventional finite-temperature\nMonte Carlo methods [25–30] also exploit a path-integral\nviewpoint to estimate observables without explicitly con-\nstructing ρβ . In contrast, propagation tracks how ba-\nsis operators (Pauli strings or Majorana monomials) are\ntransformed under successive imaginary-time gates. The\nresulting tradeoff replaces the sign-problem barrier [31]\nwith an operator-growth/branching barrier.\nOur truncation rules are closely connected to high-\ntemperature [32–34] and cluster-expansion ideas [35–37].\nSmall-coefficient truncation in the case of small rotation\nangles mirrors a high-temperature series expansion in\n\n-- 3 of 34 --\n\n4\nwhich higher-order contributions are suppressed and can\nbe discarded. Pauli-weight (or Majorana-length) trunca-\ntion plays the role of a cluster-size cutoff in the sense that\nlocal observables are primarily sensitive to low-support\noperators, and contributions from large-support terms\nare generally suppressed. In this sense, our methods\nare analogous to a cluster-expansion-like approximation,\nbut organized by operator algebra rather than by explicit\nenumeration of connected graph components.\nOur methods also complement the rich literature on\nquantum algorithms for preparing or sampling from\nGibbs states [38–46], and provide a practical classical\nbaseline for delineating the temperatures and system\nsizes at which quantum thermal-state preparation may\nyield a quantum advantage.\nFinally, there is a structural analogy to tensor-network\nthermal states [47–50]. Methods based on purification\nor MPO/PEPO imaginary-time evolution can also apply\nlocal imaginary-time gates followed by truncation to con-\ntrol complexity. The main difference is– as usually– the\nrepresentation and truncation metric: spatial factoriza-\ntion and finite bond dimension versus sparse representa-\ntion and finite support. This complementary perspective\nhighlights when propagation may be advantageous: it is\ntopology-agnostic, allows directly reading off the Pauli\nor Majorana decomposition of the state, and can inter-\nface directly with quantum hardware for hybrid work-\nflows [10, 13].\nIII. ANALYTIC GUARANTEES\nIn this section, we provide guarantees for the efficiency\nof simulation in low-β (i.e., high-temperature) regimes.\nWhile our results here are framed in the context of\nPauli propagation, everything carries directly over to\nMajorana propagation, as explained in Appendix I.\nCoefficient truncation. We start by analyzing coeffi-\ncient truncation schemes whereby after each update we\ndiscard Pauli terms whose amplitudes are below some\ncutoff. For the analysis, however, it is convenient to work\nwith a closely related proxy rule that is simpler to treat\nanalytically. Namely, we consider a small-angle trunca-\ntion scheme which exploits the fact that for τ ≪ 1 the\nbranching amplitudes produced by imaginary-time prop-\nagation are suppressed in powers of sinh(τ ) ≈ τ ≪ 1.\nTherefore we can discard any Pauli path that accumu-\nlates more than k non-identity updates (equivalently,\nmore than k factors of sinh(τ )) as sinh(τ )k ≈ τ k ≪ 1.\nThis results in the following theorem.\nTheorem 1 (Small-angle truncation error). Consider\nthe simulation of the thermal state starting from the\nidentity I. The algorithm performs L steps of the map\nEt(·) = e−τ Pt/2(·)e−τ Pt/2, with step angle τ = βΛ\nL , where\nΛ = P\nj |hj | is the sum of Hamiltonian coefficients. Let ˜ρ\nbe the approximate state obtained by truncating any Pauli\npath that accumulates more than k non-identity updates\n(i.e., discarding paths with more than k factors of sinh τ ).\nThen the approximate thermal state ˜ρ satisfies\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (14)\nAs a consequence, for any observable O one has\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥O∥∞ eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (15)\nThis is proven in Appendix E. Thus, for temperatures\nsuch that β scales inversely with the 1-norm of the Hamil-\ntonian (i.e., βΛ ∈ O(1)), the truncation error is sup-\npressed super-exponentially in k:\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥O∥∞\n\u0010 c\nk\n\u0011k\u0013\n∈ exp\u0000−Ω(k log k)\u0001\n(16)\nfor k ≫ c for some constant c. Equivalently, to achieve a\ntarget accuracy ϵ, it suffices to choose\nk = Θ\n\n log\n\u0010 ∥O∥∞\nϵ\n\u0011\nlog log\n\u0010 ∥O∥∞\nϵ\n\u0011\n\n , (17)\nwhich grows only slightly faster than log(1/ϵ).\nSince the number of retained terms (and hence the\nruntime of propagation) scales polynomially with the\ntruncation level k for fixed system size and locality\nstructure [8, 10], this implies that for β ∈ O(1/Λ)\nthe small-angle imaginary-time simulation error decays\nsuper-exponentially in k,\nϵ = ∥O∥∞ exp\u0000−Ω(k log k)\u0001. (18)\nin time polynomial in k (and therefore is polylogarith-\nmic in 1/ϵ, up to the log log correction). Furthermore,\nas proven in Lemma 14 in Appendix E, for slightly\nlower temperatures such that βΛ ∈ Θ(log n) we can ob-\ntain an error that is polynomially suppressed in n for\nk ∈ O(log(n)) which corresponds to super-polynomial\nresources. We stress that as Theorem 1 also bounds the\nerror of the 1-norm of the state and so the simulated state\ncan be used for sampling-based applications [23].\nWeight truncation. We now provide efficiency guar-\nantees for imaginary-time Pauli propagation under\nweight truncation, where we discard any Pauli string\nwhose weight exceeds a threshold k. The same logic can\nalso be applied to Majorana length truncation.\nThe intuition underlying this truncation scheme begins\nwith the observation that only Pauli strings that overlap\nthe support of the observable O can contribute to Tr(Oρ).\nThus, if O is low weight, high-weight strings matter only\ninsofar as they subsequently backflow to low weight. Any\npath that realizes such a large net decrease in weight must\nbranch many times, and therefore accumulates multiple\n\n-- 4 of 34 --\n\n5\nfactors of sinh(τ ). Since sinh(τ ) ≈ τ ≪ 1 for small τ ,\nthese contributions acquire very small coefficients and\ninduce only a small error. This effect is further strength-\nened by a typical drift toward higher weight: for a Pauli\nstring of weight w ≲ n/2, applying a local imaginary-\ntime gate is more likely to increase weight than to de-\ncrease it. Consequently, the overall contribution of trun-\ncated high-weight terms is additionally suppressed by the\nsmall probability of backflow from weight k down to the\n(low) weight scale relevant to O.\nCombining these effects yields a bound analogous to\ncoefficient truncation, but with an additional suppres-\nsion factor governed by the backflow probability. Let\nqbf (w) denote the probability (over the random choice of\ngate e.g. under qDRIFT) that applying one imaginary-\ntime gate to a Pauli string of weight w produces a branch\nwhose resulting Pauli string has strictly smaller weight.\nAs shown in Appendix F, this quantity for a range of\nmodels typically depends on the current weight w of the\npropagated string but does not vary significantly between\ndifferent strings of the same weight. We further show\nthat qbf (w) typically increases with w since higher-weight\nstrings have more opportunities for cancellations that re-\nduce support. When deriving a worst-case bound for\nweight truncation, we upper bound all backflow events\noriginating from the truncated sector w > k (as any path\nthat starts backflowing from higher will also have to back-\nflow from k down to the low weight region). Therefore,\nthe maximum backflow probability is\nqmax := sup\nw⩽k\nqbf (w) := qbf (k) . (19)\nThis results in the following bound.\nTheorem 2 (Weight truncation Backflow Error, In-\nformal). Consider the qDRIFT simulation of a thermal\nstate starting from the identity I and let O be a constant\nweight observable. The algorithm applies L steps of size\nτ = βΛ\nL , where Λ = P |hi|. Let ˜ρ be the state obtained by\ntruncating any Pauli string with weight exceeding k. For\nsufficiently large k ∈ O(1), the error in the expectation\nvalue is bounded by:\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2k\n\u0013k!\n, (20)\nwhere ∥o∥1 is the 1-norm of its Pauli coefficients of O.\nFor approximately uniform all-to-all Hamiltonians the\nbackflow probability is quadratically suppressed,\nqbf (k) ∈ O(k2/n2) , (21)\nwhere as for 1D Hamiltonians it is linearly suppressed,\nqbf (k) ∈ O(k/n) . (22)\nThis theorem is proven in Appendix F for a general\nqbf (k), and in Appendix G we compute qbf (k) for different\nHamiltonians.\nSince Theorem 2 has the same functional form as The-\norem 1, we again obtain super-exponential suppression\nof the truncation error in the high-temperature regime\nβΛ = O(1). Moreover, the additional factor qbf (k) in\nthe exponent further suppresses contributions from trun-\ncated high-weight strings and therefore permits meaning-\nful guarantees at moderately larger β. Concretely, when\nβΛ = O(log n), the error becomes exponentially small in\nthe truncation order. In particular, for sufficiently large\n(but still O(1)) truncation threshold k, we obtain the\nscaling\nϵ ∈\n\u0012 log n\nn\n\u0013Θ(k)\n. (23)\nFor details, see the proof of Lemma 17 in Appendix F.\nIn Appendix G, we argue that most physically rele-\nvant Hamiltonians can be viewed as close-to-uniform and\ntherefore exhibit between linearly to quadratically sup-\npressed backflow depending on their topology.\nWe emphasize that the bound above is stated for\nqDRIFT because it provides a natural probabilistic lan-\nguage for defining and analyzing backflow. Nevertheless,\nthe same intuition carries over to deterministic product\nformulas: in a standard Trotter scheme, a significant pro-\nportion of high-weight contributions continue to grow in\nweight rather than backflow to low weight, so the net\ninfluence of truncated high-weight terms on local observ-\nables is suppressed. We can capture this via a direct\ncombinatorial (frequentist) analysis of Trotter paths, the\nbroad intuition is the same as in qDRIFT but the anal-\nysis is technically more awkward. In Appendix H, we\nobtain the following bound.\nTheorem 3 (Weight-truncation error for 1st-order Trot-\nter imaginary-time evolution (informal)). Let H =\nPM\na=1 λaQa be a Pauli Hamiltonian on n qubits with\n|λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Assume H has\nbounded degree ℓ, i.e. each qubit participates in at most ℓ\nterms. Fix an inverse temperature β > 0 and a step size\nδ > 0, and let L := β/δ ∈ N. Let ρ denote the (normal-\nized) state obtained by applying L steps of the 1st-order\nTrotter imaginary-time evolution, and let ˜ρ be the classi-\ncal approximation obtained by truncating all propagated\nPauli operators to weight < k after any imaginary time\noperation.\nThen there exist absolute constants c1, c2 > 0 such\nthat, for every observable O,\nTr\u0002O(ρ − ˜ρ)\u0003 ≤ ∥o∥1 exp\u0000c1 βM \u0001 \u0010\nc2 β ℓ w\n\u0011k/w\n. (24)\nwhere ∥o∥1 is again the 1-norm of the Pauli coefficients\nof O.\nWe note that the error obtained here aligns with the\nscalings obtained in Theorem 2. Consider the high-\ntemperature regime βM = Θ(1) and w = O(1). Then\n\n-- 5 of 34 --\n\n6\nFigure 2. Comparison between 1st-order Trotter and qDRIFT. We evolve using truncated trotterization (full) and\nqDRIFT (dashed) for different models and compare to the untruncated evolutions using the mean relative error of the energy\nas a metric. This error is plotted as a function of β (top) and as a function of the number of Paulis it utilizes (bottom) for a\n10 qubit system. The overlap of the curves between the trotter evolution and the qDRIFT suggests that weight truncation is\nequally justified for both types of evolution. The bottom plot gives a comparison of the effectiveness of each truncation scheme\nwhere in general the coefficient truncation leads to a better error at a given number of Paulis.\n(24) implies\nTr[O(ρ − ˜ρ)] ≤ ∥o∥1\n\u0000β ℓ\u0001Ω(k) (25)\n=∥o∥1\n\u0010 ℓ\nM\n\u0011Ω(k)\n. (26)\nUnder the natural assumption that the degree is sublin-\near in the number of terms, e.g. ℓ ≤ M c for some constant\nc < 1, we obtain a polynomially small error in M with\nexponent linear in k:\nTr[O(ρ − ˜ρ)] ≤ ∥o∥1 M −Ω(k).\nSimilarly to our bound in Theorem 2, Theorem 3 yields\nmeaningful guarantees also for the case where βM ∈\nΘ(log(M )). In this regime, assuming also w ∈ O(1) and\nthat the degree is sublinear in the number of terms, e.g.\nℓ ≤ M c for some constant c < 1, one has\nTr\u0002O(ρ − ˜ρ)\u0003 ∈ ∥o∥1 M O(1)\n\u0012 log(M )\nM 1−c\n\u0013Ω(k)\n(27)\n∈ ∥o∥1 M O(1)−Ω(k). (28)\nExactly which of the bounds in Theorem 3 and\nTheorem 2 is tighter depends on the relative magnitude\nof the degree l of the Hamiltonian and the truncation\nk considered which will vary on a case-by-case basis.\nHowever, we suspect these differences are not fundamen-\ntal but rather are an artifact of our proof techniques.\nIndeed this is further supported by our numerics below.\nNumerically probing theoretical predictions. In Fig. 2,\nwe numerically illustrate the effects of coefficient and\nweight truncation for imaginary time evolution via\nqDRIFT or a 1st-order Trotter decomposition. This\nis to test whether Theorem 2 and Theorem 3 point\nto more general effects that transcend our proof tech-\nniques. We consider three types of Hamiltonians, two\nrandom and one physical one, all composed of 30 weight-\n2 Paulis: Random all-to-all interactions with coefficients\n∈ {−1, 1}, random nearest-neighbor interactions with co-\nefficients ∈ {−1, 1}, and a 1D Heisenberg Hamiltonian\nwith +1 coefficients. The simulations were done on 10-\nqubit systems for exact verification. In the Trotter case,\nwe use L = 50 steps with τ = 0.02, and for qDRIFT\nLqD = Λβ/τ = ΛL = 1500 with Λ = 30 to match the\ntheoretical time discretization error. For each model, we\nconsider 200 samples and compute the mean relative er-\nror of the energy between the truncated and exact simu-\nlations.\nThere appears to be hardly any difference between how\nTrotter or qDRIFT respond to truncations, indicating\nthat both our theoretical guarantees for weight trunca-\ntion have similar predictive power. When comparing co-\n\n-- 6 of 34 --\n\n7\nFigure 3. Imaginary time evolution under the J1-J2 Hamiltonian. Numerical results for the 1D J1 − J2 Heisenberg\nmodel across system sizes ranging from 10 to 40 qubits. The top row shows the estimated energy density ⟨H⟩/n converging\ntoward the ground state (dashed line) as the inverse temperature β increases. The bottom row tracks the number of Pauli\nstrings generated, showing the exponential growth in complexity as the temperature drops. Different shades of blue represent\ndifferent coefficient truncation thresholds (from 2−9 to 2−18); the point where these lines diverge indicates the limit where our\napproximation is no longer accurate.\nefficient and weight truncation, we observe that, for a\ngiven temperature, coefficient truncation obtains lower\nerror per propagated Pauli operator, which is a proxy for\nruntime and memory consumption. This is in large part\nbecause coefficient truncation integrates one partial effect\nof weight truncation. Namely, high-weight terms have ac-\ncumulated more sinh (or sin) coefficients to become high\nweight and thus tend to have smaller coefficients and thus\nas naturally truncated anyway via coefficient truncation.\nBelow we outline further practical considerations and nu-\nmerical results.\nIV. NUMERICAL IMPLEMENTATION\nPractitioners notes. In this section, we discuss prac-\ntical considerations for performant numerical implemen-\ntations, both ones that are specific to imaginary time\nevolution, as well as ones that apply more broadly to\npropagation methods.\nFor numerical stability and to facilitate coefficient\ntruncation, we (i) continually normalize our representa-\ntion of the state by 1/αI after every gate, and (ii) never\ndivide by the factor 2n in Eq. (6). This is a variant on\nthe necessary normalization by Tr[ρ] that keeps our co-\nefficients at unit scale and less dependent on the number\nof qubits (at least at high temperatures). Our coefficient\ntruncation threshold can then be seen as a relative trun-\ncation threshold to one of the largest terms, the identity\noperator. Neglecting the 2n factor has a flavor of working\nin the normalized Pauli basis, and the factor is automat-\nically, implicitly regained by calculating expectation val-\nues by proceeding as if Tr[I] = 1. Both practices together\nprovide a natural and convenient rescaling.\nThen we would like to draw attention to the choice\nof truncation method. Truncated numerical simulations\noften perform substantially better than their theoretical\nguarantees. At the same time, some truncation strategies\nare more amenable to theoretical analysis than others.\nPutting both observations together, we realize that the\nbest truncation may not be the one that has the most\n(or any) attractive bound. For imaginary time evolution,\nsimilarly to previous experiences with real time evolution,\nwe have found that coefficient truncation is most effective\nin general. We stress that coefficient truncation will be\nstrictly better than the ‘small angle’ truncation scheme\nanalyzed above because we truncate on the exact values\nof the coefficients which will depend on the Hamiltonian\nparameters and can be larger due to merging different\npaths that produce the same Pauli.\nPauli weight and Majorana length truncation do have\ntheir distinct effects for estimating local expectation val-\nues [8, 16] that go beyond what coefficient truncation\nalone can enable. However, we find that in combination\nwith coefficient truncation they often add little and so it\nis preferable to focus on just coefficient truncation. This\nis particularly relevant when aiming to converge a simu-\nlation, i.e., to gain confidence in the result, which is less\ncumbersome with just one truncation parameter. Hence\nin our large scale numerics below we use only coefficient\ntruncation.\nFinally, we would like to highlight our numerical\nimplementation. Until recently, PauliPropagation.jl\nnatively supported only single-threaded dictionary-\nbased propagation. While multi-threaded CPU and\n\n-- 7 of 34 --\n\n8\nFigure 4. Spin correlation in the Fermi-Hubbard model on a triangular lattice. Snapshots of spin-spin correlations\n(CZZ ) emerging in a Fermi-Hubbard model on a 37 site triangular lattice (corresponding to 74 Majorana modes). As we lower\nthe temperature from β = 0 to β = 0.1, we can observe magnetic order and correlations beginning to form around the central\nsite (red). While reaching the deep frustration patterns of lower temperatures (β ∼ 2 to β ∼ 3) remains challenging for current\npropagation techniques, this demonstrates the ability to compute static correlations for complex geometries directly from the\npropagated state.\neven GPU implementations were possible, one would\nlikely run out of memory trying to simulate real-time\ndynamics rather than run out of time, even with a\nsingle CPU thread. Imaginary time evolution, on the\nother hand, appears to be noticeably slower, owing to\nits accelerated branching upon commutation akin to\nthe Heisenberg evolution of global observables in the\nreal-time case. Truncations can keep operator numbers\nin check, but the time per gate remains elevated. We\nare pleased to report that our large-scale results were\ngenerated with array-based propagation that was at\nleast an order of magnitude faster by use of up to 72\nCPU threads with off-the-shelf code publicly available\nvia PauliPropagation.jl. GPU acceleration is already\npossible, but faces continued limitations due to the\nlower memory of everything but the highest-end GPU\nhardware compared to conventional HPC CPU nodes.\nOur work showcases that innovations in the applications\ncan motivate innovation in the algorithms, which we\nbelieve will continue in the future.\nThe J1-J2 Heisenberg Model. As a first practi-\ncal demonstration of our algorithm, we study the\none-dimensional Heisenberg model with both nearest-\nneighbor (J1) and next-nearest-neighbor (J2) interac-\ntions. The Hamiltonian is defined as\nH = J1\nX\ni\n(XiXi+1 + YiYi+1 + ZiZi+1)\n+ J2\nX\ni\n(XiXi+2 + YiYi+2 + ZiZi+2) , (29)\nwhere Xi, Yi, Zi are Pauli operators at site i. The terms\nwith the J1 coefficient represent the standard nearest-\nneighbor Heisenberg exchange. Assuming an antiferro-\nmagnetic coupling (J1 > 0), this term favors an antipar-\nallel alignment of adjacent spins. The J2 terms introduce\na next-nearest-neighbor interaction. When J2 > 0, this\nterm acts as a source of geometrical frustration, as it com-\npetes with the ordering tendency of the J1 term. Here,\nwe use J1 = 1.0 and J2 = 0.5, with a Trotter step of\nτ = 0.02\nFig. 3 depicts our results for preparing states at\nincreasing inverse temperature β for 10, 20, 30, and 40\nqubits using τ = 0.02 in a first-order Trotter approxima-\ntion, and for decreasing coefficient truncation thresholds\n(relative to the identity operator) ranging from 2−9 to\n2−18. We report the energy density, i.e., ⟨H⟩/n, as well\nas the number of Pauli strings that are being generated.\nThe black dashed line at energy density −1.5 denotes the\nenergy density of the ground state in this model, which\ncan be computed to numerical precision using tensor\nnetwork techniques [51]. It is evident that our approach\nis increasingly inefficient in reaching low-temperature\nstates, yet high-temperature states remain trackable\nat scale. The largest β for which the simulations can\nbe trusted can be estimated by the convergence of\noverlapping lines at lower and lower truncations.\nFermi-Hubbard model on a triangular lattice. We fur-\nther consider the Fermi-Hubbard model of interacting\nFermions on a triangular lattice with radial hexagonal\ngeometry. The system is described by the Hamiltonian\nH = − t X\n⟨i,j⟩,σ\n(c†\niσ cjσ + c†\njσ ciσ )\n+ U X\ni\nni↑ni↓ − μ X\ni\nni, (30)\nwhere c†\niσ (ciσ ) creates (annihilates) a Fermion with spin\nσ ∈ {↑, ↓} at site i, niσ = c†\niσ ciσ is the number op-\nerator, μ the chemical potential and ni = ni↑ + ni↓.\nWe explore the strong coupling regime with interaction\nstrengths t = 1, U = 8, similar to other realizations in,\nfor example, Refs. [52, 53]. We tune the chemical po-\n\n-- 8 of 34 --\n\n9\ntential to μ = U/2, which stabilizes the average particle\nnumber to approximately equal the number of sites, i.e.,\nto half-filling. Being mindful of Trotter error and the\nreduced simulation horizon of this more challenging sys-\ntem, we employ a smaller Trotter step of τ = 0.01 and\na randomized order in the evolution under the hopping\nterms.\nAs the temperature sinks, magnetic order and correla-\ntions start to form. We characterize it by the spin-spin\ncorrelation function CZZi between the center site r and\nsite i. It reads\nCZZi = ⟨Zr Zi⟩ − ⟨Zr ⟩⟨Zi⟩, (31)\nwhere Zi = ni↑ − ni↓.\nOur results can be seen in Fig. 4, where in a system\nwith 37 sites (corresponding to 74 Majorana modes) we\nobserve correlations build up as we lower the temperature\nto β = 0.1. Ref. [52, 53] shows by use of a neutral atom\nanalog simulator that thermal states at lower tempera-\nture (β ∼ 2 to β ∼ 3) exhibit frustration and staggered\ncorrelation patterns, temperatures which we can unfor-\ntunately not access with current propagation techniques.\nYet, it is noteworthy that we can start tackling such sys-\ntems with off-the-shelf code, and explore both physical\nphenomena and the potential use of propagation meth-\nods.\nV. DISCUSSION\nIn this work, we introduce a framework for simulating\nthermal states via Pauli and Majorana propagation. It\nutilizes imaginary time evolution applied to maximally\nmixed states in the Schr¨odinger picture to continually\nlower the temperature. At the end of the simulation,\none receives the quantum states “in plain text”, and\ncan readily read off properties of interest. Our high-\nperformance numerical implementation effectively lever-\nages multi-CPU computing resources and can quickly\ngenerate billions of Pauli or Majorana strings.\nWe further provide analytical guarantees for both co-\nefficient and weight truncation strategies which hint to-\nward propagation algorithms being highly capable of sim-\nulating high-temperature states in arbitrary system ge-\nometries. At the same time, both our analysis and nu-\nmerical results indicate that lower temperatures where\nβ ∼ 1 can be very challenging to accurately simulate for\nphysically motivated problems.\nGoing forward, we would like to highlight three re-\nsearch directions. One is the question of when propaga-\ntion methods are the algorithm of choice for simulating\nquantum states. Promising cases include repeated evalu-\nations of high-temperature states with complicated con-\nnectivities. This lends itself, for example, to quantum\nBoltzmann machine training [54]. Another direction is\nthat of ground state exploration. While sheer numbers\nindicate that zero-temperature states are not efficiently\nrepresentable in Pauli or Majorana basis due to being\nexponentially dense, truncated propagation may be use-\nful for estimating or extrapolating ground state energies\n(see, e.g., Ref. [55]). Finally, we would like to highlight\npropagation algorithms natural capabilities in hybridiz-\ning with quantum hardware. We can envision that uni-\ntary circuits for approximate thermal state preparation\ncould be learned or compressed classically [56] for fur-\nther processing on quantum devices once they are mature\nenough.\nCode Availability. The Pauli propagation results\nin this work have been obtained with the open-source\nlibrary PauliPropagation.jl, which now supports imagi-\nnary Pauli rotations. The Majorana propagation results\nin this work have been obtained with the open-source\nlibrary MajoranaPropagation.jl, which is not yet reg-\nistered and will soon support imaginary Majorana\nrotations.\nAcknowledgements. The authors would like to thank\nMatteo D’Anna for his work on MajoranaPropagation.jl.\nThe authors would like to thank Yanting Teng for\ninsightful discussions. MSR acknowledges funding from\nthe 2024 Google PhD Fellowship and the Swiss National\nScience Foundation [grant number 200021-219329] AA\nand ZH acknowledge support from the Sandoz Family\nFoundation-Monique de Meuron program for Academic\nPromotion. RP acknowledges the support of the SNF\nQuantum Flagship Replacement Scheme (Grant No.\n215933).\nAdded note. In the final stages of preparing this\nmanuscript, the authors became aware of independent\nwork demonstrating imaginary time evolution for Pauli\npropagation [57].\n[1] P. Rall, D. Liang, J. Cook, and W. Kretschmer, Simu-\nlation of qubit quantum circuits via pauli propagation,\nPhysical Review A 99, 062337 (2019).\n[2] D. Aharonov, X. Gao, Z. Landau, Y. Liu, and U. Vazi-\nrani, A polynomial-time classical algorithm for noisy ran-\ndom circuit sampling, Proceedings of the 55th Annual\nACM Symposium on Theory of Computing , 945 (2023).\n[3] T. Beguˇsi´c, K. Hejazi, and G. K. Chan, Simulating\nquantum circuit expectation values by Clifford pertur-\nbation theory, The Journal of Chemical Physics 162,\n10.1063/5.0269149 (2025).\n[4] E. Fontana, M. S. Rudolph, R. Duncan, I. Rungger,\nand C. Cˆırstoiu, Classical simulations of noisy varia-\ntional quantum circuits, npj Quantum Information 11,\n1 (2025).\n\n-- 9 of 34 --\n\n10\n[5] Y. Shao, F. Wei, S. Cheng, and Z. Liu, Simulating noisy\nvariational quantum algorithms: A polynomial approach,\nPhysical Review Letters 133, 120603 (2024).\n[6] M. S. Rudolph, E. Fontana, Z. Holmes, and L. Cin-\ncio, Classical surrogate simulation of quantum sys-\ntems with LOWESA, arXiv preprint arXiv:2308.09109\n10.48550/arXiv.2308.09109 (2023).\n[7] T. Schuster, C. Yin, X. Gao, and N. Y. Yao, A\npolynomial-time classical algorithm for noisy quantum\ncircuits, Physical Review X 15, 041018 (2025).\n[8] A. Angrisani, A. Schmidhuber, M. S. Rudolph,\nM. Cerezo, Z. Holmes, and H.-Y. Huang, Classically es-\ntimating observables of noiseless quantum circuits, Phys.\nRev. Lett. 135, 170602 (2025).\n[9] G. Gonz´alez-Garc´ıa, J. I. Cirac, and R. Trivedi, Pauli\npath simulations of noisy quantum circuits beyond aver-\nage case, arXiv preprint arXiv:2407.16068 (2024).\n[10] S. Lerch, R. Puig, M. Rudolph, A. Angrisani, T. Jones,\nM. Cerezo, S. Thanasilp, and Z. Holmes, Efficient\nquantum-enhanced classical simulation for patches of\nquantum landscapes, arXiv preprint arXiv:2411.19896\n10.48550/arXiv.2411.19896 (2024).\n[11] C. Cirstoiu, A fourier analysis framework for approx-\nimate classical simulations of quantum circuits, arXiv\npreprint arXiv:2410.13856 10.48550/arXiv.2410.13856\n(2024).\n[12] A. Angrisani, A. A. Mele, M. S. Rudolph, M. Cerezo,\nand Z. Holmes, Simulating quantum circuits with arbi-\ntrary local noise using pauli propagation, arXiv preprint\narXiv:2501.13101 10.48550/arXiv.2501.13101 (2025).\n[13] B. Fuller, M. C. Tran, D. Lykov, C. Johnson, M. Ross-\nmannek, K. X. Wei, A. He, Y. Kim, D. Vu, K. Sharma,\net al., Improved quantum computation using opera-\ntor backpropagation, arXiv preprint arXiv:2502.01897\nhttps://doi.org/10.48550/arXiv.2502.01897 (2025).\n[14] M. S. Rudolph, T. Jones, Y. Teng, A. Angrisani, and\nZ. Holmes, Pauli propagation: A computational frame-\nwork for simulating quantum systems, arXiv preprint\narXiv:2505.21606 10.48550/arXiv.2505.21606 (2025).\n[15] Y. Teng, S. Y. Chang, M. S. Rudolph, and\nZ. Holmes, Leveraging symmetry merging in\npauli propagation, arXiv preprint arXiv:2512.12094\n10.48550/arXiv.2512.12094 (2025).\n[16] A. Miller, Z. Holmes, ¨O. Salehi, R. Chakraborty,\nA. Nyk¨anen, Z. Zimbor´as, A. Glos, and G. Garc´ıa-\nP´erez, Simulation of fermionic circuits using ma-\njorana propagation, arXiv preprint arXiv:2503.18939\n10.48550/arXiv.2503.18939 (2025).\n[17] F. Alam, J. L. Bosse, I. ˇCepait˙e, A. Chapman, L. Clin-\nton, M. Crichigno, E. Crosson, T. Cubitt, C. Derby,\nO. Dowinton, et al., Fermionic dynamics on a trapped-\nion quantum computer beyond exact classical simulation,\narXiv:2510.26300 (2025).\n[18] F. Alam, J. L. Bosse, I. ˇCepait˙e, A. Chapman, L. Clinton,\nM. Crichigno, E. Crosson, T. Cubitt, C. Derby, O. Dow-\ninton, et al., Programmable digital quantum simulation\nof 2d fermi-hubbard dynamics using 72 superconducting\nqubits, arXiv:2510.26845 (2025).\n[19] M. D’Anna, J. Nys, and J. Carrasquilla, Majorana\nstring simulation of nonequilibrium dynamics in two-\ndimensional lattice fermion systems, arXiv:2511.02809\n(2025).\n[20] G. Facelli, H. Fawzi, and O. Fawzi, Fast con-\nvergence of majorana propagation for weakly in-\nteracting fermions, arXiv preprint arXiv:2601.05226\nhttps://doi.org/10.48550/arXiv.2601.05226 (2026).\n[21] T. Beguˇsi´c, J. Gray, and G. K.-L. Chan, Fast and con-\nverged classical simulations of evidence for the utility of\nquantum computing before fault tolerance, Science Ad-\nvances 10, 10.1126/sciadv.adk4321 (2024).\n[22] N. Loizeau, J. C. Peacock, and D. Sels, Quantum many-\nbody simulations with paulistrings. jl, SciPost Phys.\nCodebases 54, 10.21468/SciPostPhysCodeb.54 (2025).\n[23] M. Minervini, J. Goldman, M. M. Wilde, Z. Holmes,\nand M. S. Rudolph, From strong to weak simulation:\nSampling from quantum states via pauli propagation,\nPreprint (2026), forthcoming.\n[24] E. Campbell, Random compiler for fast Hamiltonian sim-\nulation, Phys. Rev. Lett. 123, 070503 (2019).\n[25] Y. Alhassid, Quantum monte carlo methods for nuclei\nat finite temperature, International Journal of Modern\nPhysics B 15, 1447 (2001).\n[26] S.-Y. Chang, V. Pandharipande, J. Carlson, and K. E.\nSchmidt, Quantum monte carlo studies of superfluid\nfermi gases, Physical Review A—Atomic, Molecular, and\nOptical Physics 70, 043602 (2004).\n[27] K. Van Houcke, S. Rombouts, and L. Pollet, Quantum\nmonte carlo simulation in the canonical ensemble at finite\ntemperature, Physical Review E—Statistical, Nonlinear,\nand Soft Matter Physics 73, 056703 (2006).\n[28] A. Bulgac, J. E. Drut, and P. Magierski, Quantum monte\ncarlo simulations of the bcs-bec crossover at finite tem-\nperature, Physical Review A—Atomic, Molecular, and\nOptical Physics 78, 023625 (2008).\n[29] B. Militzer and K. P. Driver, Development of path in-\ntegral monte carlo simulations with localized nodal sur-\nfaces for second-row elements, Physical Review Letters\n115, 176403 (2015).\n[30] J. Gubernatis, N. Kawashima, and P. Werner, Quan-\ntum Monte Carlo Methods (Cambridge University Press,\n2016).\n[31] M. Troyer and U.-J. Wiese, Computational complexity\nand fundamental limitations to fermionic quantum monte\ncarlo simulations, Physical review letters 94, 170201\n(2005).\n[32] G. A. Baker Jr, H. Gilbert, J. Eve, and G. Rushbrooke,\nHigh-temperature expansions for the spin-1/2 heisenberg\nmodel, Physical Review 164, 800 (1967).\n[33] D. S. Gaunt and G. A. Baker Jr, Low-temperature crit-\nical exponents from high-temperature series: The ising\nmodel, Physical Review B 1, 1184 (1970).\n[34] A. Georges and J. S. Yedidia, How to expand around\nmean-field theory using high-temperature expansions,\nJournal of Physics A: Mathematical and General 24,\n2173 (1991).\n[35] J. M. Sanchez, F. Ducastelle, and D. Gratias, Generalized\ncluster description of multicomponent systems, Physica\nA: Statistical Mechanics and its Applications 128, 334\n(1984).\n[36] V. Blum and A. Zunger, Mixed-basis cluster expan-\nsion for thermodynamics of bcc alloys, Physical Review\nB—Condensed Matter and Materials Physics 70, 155108\n(2004).\n[37] Q. Wu, B. He, T. Song, J. Gao, and S. Shi, Cluster expan-\nsion method and its application in computational mate-\nrials science, Computational Materials Science 125, 243\n\n-- 10 of 34 --\n\n11\n(2016).\n[38] K. Temme, T. J. Osborne, K. G. Vollbrecht, D. Poulin,\nand F. Verstraete, Quantum metropolis sampling, Nature\n471, 87 (2011).\n[39] D. Poulin and P. Wocjan, Sampling from the thermal\nquantum gibbs state and evaluating partition functions\nwith a quantum computer, Physical review letters 103,\n220502 (2009).\n[40] A. N. Chowdhury and R. D. Somma, Quantum algo-\nrithms for gibbs sampling and hitting-time estimation,\nQuantum Information & Computation 17, 41 (2017).\n[41] M. Motta, C. Sun, A. T. Tan, M. J. O’Rourke, E. Ye,\nA. J. Minnich, F. G. Brandao, and G. K.-L. Chan, De-\ntermining eigenstates and thermal states on a quantum\ncomputer using quantum imaginary time evolution, Na-\nture Physics 16, 205 (2020).\n[42] C. Rouz´e, D. S. Fran¸ca, and ´A. M. Alhambra, Optimal\nquantum algorithm for gibbs state preparation, arXiv\npreprint arXiv:2411.04885 10.48550/arXiv.2411.04885\n(2024).\n[43] M. Consiglio, J. Settino, A. Giordano, C. Mastroianni,\nF. Plastina, S. Lorenzo, S. Maniscalco, J. Goold, and\nT. J. G. Apollaro, Variational gibbs state preparation on\nnoisy intermediate-scale quantum devices, Phys. Rev. A\n110, 012445 (2024).\n[44] L. Lin, Dissipative preparation of many-body quantum\nstates: Toward practical quantum advantage, APL Com-\nputational Physics 1, 010901 (2025).\n[45] T. S. Cubitt, Dissipative ground state preparation and\nthe dissipative quantum eigensolver, arXiv preprint\narXiv:2303.11962 10.48550/arXiv.2303.11962 (2023).\n[46] R. Puig, M. Drudis, S. Thanasilp, and Z. Holmes, Varia-\ntional quantum simulation: A case study for understand-\ning warm starts, PRX Quantum 6, 010317 (2025).\n[47] F. Verstraete, J. J. Garcia-Ripoll, and J. I. Cirac, Ma-\ntrix product density operators: Simulation of finite-\ntemperature and dissipative systems, Physical review let-\nters 93, 207204 (2004).\n[48] M. Zwolak and G. Vidal, Mixed-state dynamics in one-\ndimensional quantum lattice systems: A time-dependent\nsuperoperator renormalization algorithm, Physical re-\nview letters 93, 207205 (2004).\n[49] M. M. Wolf, F. Verstraete, M. B. Hastings, and J. I.\nCirac, Area laws in quantum systems: mutual informa-\ntion and correlations, Physical review letters 100, 070502\n(2008).\n[50] E. Stoudenmire and S. R. White, Minimally entangled\ntypical thermal state algorithms, New Journal of Physics\n12, 055026 (2010).\n[51] S. R. White, Density matrix formulation for quantum\nrenormalization groups, Physical Review Letters 69,\n2863 (1992).\n[52] M. Xu, L. H. Kendrick, A. Kale, Y. Gang, G. Ji, R. T.\nScalettar, M. Lebrat, and M. Greiner, Frustration-and\ndoping-induced magnetism in a fermi–hubbard simulator,\nNature 620, 971 (2023).\n[53] A. Sinha, M. M. Rams, P. Czarnik, and J. Dziarmaga,\nFinite-temperature tensor network study of the hubbard\nmodel on an infinite square lattice, Physical Review B\n106, 195105 (2022).\n[54] M. H. Amin, E. Andriyash, J. Rolfe, B. Kulchytskyy, and\nR. Melko, Quantum boltzmann machine, Phys. Rev. X\n8, 021050 (2018).\n[55] C. Shrikhande, A. Bachhar, A. R. Jimenez, and\nN. J. Mayhall, Rapid ground state energy estima-\ntion with a sparse pauli dynamics-enabled variational\ndouble bracket flow, arXiv preprint arXiv:2511.21651\n10.48550/arXiv.2511.21651 (2025).\n[56] M. D’Anna, Y. Zhang, R. Wiersema, M. S. Rudolph,\nand J. Carrasquilla, Circuit compression for 2d\nquantum dynamics, arXiv preprint arXiv:2507.01883\nhttps://doi.org/10.48550/arXiv.2507.01883 (2025).\n[57] R. G´omez-Lurbe and A. P´erez, Pauli\npropagation for imaginary time evolu-\ntion, arXiv preprint arXiv:2601.14400\nhttps://doi.org/10.48550/arXiv.2601.14400 (2026).\n[58] C. Amoruso, E. Marinari, O. C. Martin, and A. Pagnani,\nScalings of domain wall energies in two dimensional ising\nspin glasses, Physical review letters 91, 087201 (2003).\n\n-- 11 of 34 --\n\n12\nAppendix A: Notation\nWe denote the n-qubit Pauli basis by Pn := {I, X, Y, Z}⊗n. Any operator O admits a Pauli expansion\nO = X\nP ∈Pn\ncP P.\nWe define the Pauli-1 norm of O as\n∥O∥Pauli,1 := X\nP ∈Pn\n|cP |.\nWhen no confusion can arise, we use the shorthand ∥o∥1 := ∥O∥Pauli,1.\nAppendix B: Preliminaries\nIn this section, we present basic lemmas that are required for the subsequent proofs.\nLemma 4. Let r(γ) be the number of times the sinh(τ ) branch is taken along a path γ. Then for all τ ∈ (0, 1],\ncosh(τ )L−r(γ) sinh(τ )r(γ) ≤ eLτ 2/2 τ r(γ). (B1)\nProof. For τ ≥ 0 we have sinh(τ ) ≤ τ cosh(τ ). Hence\ncosh(τ )L−r(γ) sinh(τ )r(γ) ≤ cosh(τ )L−r(γ) (τ cosh(τ ))r(γ) = τ r(γ) cosh(τ )L.\nUsing cosh(τ ) ≤ eτ 2/2, we get\nτ r(γ) cosh(τ )L ≤ τ r(γ)eLτ 2/2.\nLemma 5. Consider a matrix A = QJ\nj=1 e−τ Pj I Q1\nj=J e−τ Pj . Then Tr[A] ≥ 2n.\nProof. First, observe that det\u0000e−τ Pj\n\u0001 = e−τ Tr[Pj ] = e0 = 1 for any Pauli operator Pj . Consequently, using the\nmultiplicativity of the determinant, we have det(A) = 1. Then since A is of the form A†A (with A = Q1\nj=J e−τ Pj ),\nit is positive semidefinite (A ⪰ 0). Let d = 2n be the dimension of the Hilbert space. Applying the Arithmetic\nMean-Geometric Mean inequality to the eigenvalues of A, we obtain:\nTr[A]\nd ⩾ det(A)1/d = 1. (B2)\nMultiplying by d yields Tr[A] ≥ 2n.\nDefinition 6 (Max Divergence). Let p and u be two probability distributions on a set E of size M . The (forward)\nmax-divergence of p from u is defined as:\nD∞(p∥u) := log\n\u0012\nmax\ne∈E\np(e)\nu(e)\n\u0013\n= log\n\u0012\nM · max\ne∈E p(e)\n\u0013\n. (B3)\nLemma 7. Let u denote the uniform distribution on a finite set E, i.e., u(e) = 1/M . Let p be any distribution on\nE. If D∞(p∥u) ≤ α, then for every event A ⊆ E,\np(A) ≤ eα u(A). (B4)\nProof. The assumption D∞(p∥u) ≤ α implies pointwise domination:\np(e) ≤ eαu(e) ∀e ∈ E. (B5)\nSumming this inequality over all elements e ∈ A yields the result:\np(A) = X\ne∈A\np(e) ≤ eα X\ne∈A\nu(e) = eαu(A). (B6)\n\n-- 12 of 34 --\n\n13\nProposition 8. Let E be a set of size M . Let weights (We)e∈E be drawn i.i.d. from Unif(0, 1), and define p(e) =\nWe/ P\nf Wf . Let u be the uniform distribution over E. Then, with probability at least 1 − e−M/8, D∞(p∥u) ≤ log 4.\nProof. Let S := P\nf ∈E Wf . Since E[Wf ] = 1/2, E[S] = M/2. By Hoeffding’s inequality:\nPr\n\u0014\nS ≤ M\n4\n\u0015\n≤ exp\n\u0012\n− 2(M/4)2\nM\n\u0013\n= e−M/8. (B7)\nConditioned on S ≥ M/4, for any e ∈ E:\np(e)\nu(e) = We/S\n1/M = M We\nS ≤ M · 1\nM/4 = 4. (B8)\nTaking the logarithm gives D∞(p∥u) ≤ log 4.\nAppendix C: General truncation error\nHere we present a general error bound for a Pauli Propagation scheme where the simulation is restricted to a specific\nsubset of Pauli strings. This will be the starting point to derive both our small angle and weight truncation guarantees\nfor the case of observables.\nLemma 9. Let O be a h-local observable, O = P\nwt(Q)≤h oQQ, and let AL be the unnormalized state obtained after\napplying L steps of an imaginary time evolution e−τ Pt (·)e−τ Pt , where Pt is sampled randomly at each step t. Let\nA ⊆ Pn be an arbitrary set of “allowed” Pauli strings (containing the identity). Let e\tAL be the matrix produced by\ntruncating any Pauli string Q /∈ A at any step. Then, the expected error in the observable expectation value is bounded\nby\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1 E\n\" X\nγ /∈ΓA\nwt(QL(γ))≤h\ncosh(τ )L−r(γ) sinh(τ )r(γ)\n#\n, (C1)\nwhere ΓA is the set of paths that remain strictly within the set A at all steps, and r(γ) is the number of non-identity\nupdates in path γ.\nProof. A Pauli path γ = (Q0, Q1, . . . , QL) ∈ PL+1\nn with Q0 = I is a sequence where each Qt is obtained from Qt−1\nby applying the local update rule in Eq. (4) for the sampled term Pt. For such a path γ, we denote the Pauli string\nat step t by Qt(γ), and the product of the accumulated cosh(τ ) and sinh(τ ) factors by w(γ). We define the set of\nadmissible paths for the truncated recursion as those that never leave the allowed set A:\nΓA := {γ | ∀t ≤ L, Qt(γ) ∈ A}. (C2)\nThe truncated evolution e\tAL has the same path expansion as the full evolution but is restricted to ΓA:\ne\tAL = X\nγ∈ΓA\nw(γ) QL(γ). (C3)\nConsequently, the difference ∆AL := AL − e\tAL is the sum over the excluded (or “killed”) paths:\n∆AL = X\nγ /∈ΓA\nw(γ) QL(γ). (C4)\nThe error in the expectation value of the observable O is therefore:\nTr(O ∆AL) = X\nγ /∈ΓA\nw(γ) Tr\u0000O QL(γ)\u0001 . (C5)\nSince O is h-local, O = P\nwt(Q)≤h oQQ, the term Tr(O QL(γ)) is non-zero only if wt(QL(γ)) ≤ h. Thus, we may\nrestrict the sum to excluded paths that end with a weight ≤ h:\nTr\u0000O(AL − e\tAL)\u0001 = X\nγ /∈ΓA\nwt(QL(γ))≤h\nw(γ) Tr\u0000OQL(γ)\u0001 . (C6)\n\n-- 13 of 34 --\n\n14\nUsing the bound | Tr(OQ)| ≤ 2n|oQ| for any Pauli string Q and applying the triangle inequality, we obtain:\nTr\u0000O(AL − e\tAL)\u0001 ≤ 2n∥o∥1\nX\nγ /∈ΓA\nwt(QL(γ))≤h\n|w(γ)|. (C7)\nFinally, taking the expectation over the random choice of Hamiltonian terms yields\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1 E\n\" X\nγ /∈ΓA\nwt(QL(γ))≤h\n|w(γ)|\n#\n. (C8)\nNoting that |w(γ)| ≤ cosh(τ )L−r(γ) sinh(τ )r(γ) completes the proof.\nAppendix D: Technical lemmas for controlling the normalization via the partition function\nIn this section we derive a bound that can translate an error guarantee for the approximate un-normalized state\n˜\tAL into a bound for the approximate normalized state ˜\tρL = ˜\tAL\nTr[ ˜\tAL] .\nTheorem 10 (Expectation value stability under additive error). Let A ⪰ 0 be a positive semidefinite operator on\na d-dimensional Hilbert space with Z := Tr(A) > 0. Let ˜\tA be an approximation of A, and define ˜\tZ := Tr\n\u0010 ˜\tA\n\u0011\n. We\ndenote the normalized states and the error operator as:\nρ := A\nZ , ˜ρ := ˜\tA\n˜\tZ , ∆ := A − ˜\tA. (D1)\nAssume that for all Pauli operators P with weight |P | ⩽ h, the error satisfies |Tr[∆P ]| ≤ d ε for some ε < Z/d. Then,\nfor all such P ,\n|Tr[P (ρ − ˜ρ)]| ≤ 2dε\nZ − dε . (D2)\nMoreover, if A satisfies Z ≥ d, then for ε < 1:\n|Tr[P (ρ − ˜ρ)]| ≤ 2ε\n1 − ε . (D3)\nProof. We start from the identity:\nρ − ˜ρ = A\nZ − ˜\tA\n˜\tZ = A − ˜\tA\nZ + ˜\tA\n\u0012 1\nZ − 1\n˜\tZ\n\u0013\n= ∆\nZ + ˜\tA ˜\tZ − Z\nZ ˜\tZ\n!\n. (D4)\nMultiplying by P and taking the trace, we apply the triangle inequality:\n|Tr[P (ρ − ˜ρ)]| ≤ |Tr[P ∆]|\nZ + Tr\nh\nP ˜\tA\ni |Z − ˜\tZ|\nZ ˜\tZ . (D5)\nWe now bound each term. By assumption, |Tr[P ∆]| ⩽ dε. Since the identity I is a Pauli operator of weight 0, we\nalso have |Z − ˜\tZ| = | Tr(∆)| ≤ dε. Consequently, ˜\tZ ≥ Z − dε > 0.\nNext, we bound Tr\nh\nP ˜\tA\ni\n. Using ˜\tA = A − ∆, we have:\nTr\nh\nP ˜\tA\ni\n≤ |Tr[P A]| + |Tr[P ∆]|. (D6)\nSince A ⪰ 0 and ∥P ∥∞ = 1, we have |Tr[P A]| ≤ Tr(A) = Z. Thus,\nTr\nh\nP ˜\tA\ni\n≤ Z + dε. (D7)\n\n-- 14 of 34 --\n\n15\nSubstituting these estimates into (D5) gives:\n|Tr[P (ρ − ˜ρ)]| ≤ dε\nZ + (Z + dε) dε\nZ(Z − dε)\n= dε\nZ\n\u0012\n1 + Z + dε\nZ − dε\n\u0013\n= dε\nZ\n\u0012 Z − dε + Z + dε\nZ − dε\n\u0013\n= 2dε\nZ − dε .\nFinally, if Z ≥ d, then d/Z ≤ 1, and substitution yields the simplified bound 2ε\n1−ε .\nTheorem 11. Let A ⪰ 0 be a positive semidefinite operator on a d-dimensional Hilbert space with Z := Tr(A) > 0.\nLet ˜\tA be an approximation of A, and define ˜\tZ := Tr\n\u0010 ˜\tA\n\u0011\n. We denote the normalized states and the error operator as:\nρ := A\nZ , ˜ρ := ˜\tA\n˜\tZ , ∆ := A − ˜\tA. (D8)\nAssume that the error satisfies ∥∆∥1 ≤ d ε for some ε < Z/d. Then,\n∥ρ − ˜ρ∥1 ≤ 2dε\nZ − dε . (D9)\nMoreover, if A satisfies Z ≥ d, then for ε < 1:\n∥ρ − ˜ρ∥1 ≤ 2ε\n1 − ε . (D10)\nProof. The proof is the same as for Theorem 10 substituting the condition | Tr[P ∆]| ⩽ dε by ∥∆∥1 ⩽ dε.\nAppendix E: Small angle truncation\nIn this section we prove error bounds for small angle truncation, presented in Theorem 1. This proof follows a\nsimilar argument to the proof of Theorem 3 in [10]. We start by proving a bound for the error when truncating\nunnormalized matrices in Theorem 12, after applying L steps of imaginary time evolution. To prove this we count the\nmaximum number of paths that we are truncating, and we bound them using counting arguments. In Theorem 13,\nwe combine Theorems 12, and 10 to bound the truncation error for normalized states.\n1. Small angle truncation for unnormalized matrices\nTheorem 12. Let AL be the unnormalized state obtained after applying L steps of an imaginary time evolution\ne−τ Pt (·)e−τ Pt , where Pt is sampled randomly at each step t. Let A ⊆ Pn be all the paths that accumulate less than k\nnon-identity updates ΓA = {γ : r(γ) ≤ k}. Let e\tAL be the state produced by truncating any path γ that contains more\nthan k non-identity updates (i.e., discarding γ if r(γ) > k). If k > eLτ , then\n∥AL − e\tAL∥1 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n. (E1)\nProof. We can slightly modify Lemma 9. Starting from Eq. (C4), where ∆AL = AL − e\tAL\n∆AL = X\nγ /∈ΓA\nw(γ) QL(γ). (E2)\n\n-- 15 of 34 --\n\n16\nwhere ΓA = {γ : r(γ) ≤ k}. Thus we can write\n∥∆AL∥1 =∥ X\nγ:r(γ)>k\nw(γ) QL(γ)∥1 (E3)\n⩽2n X\nγ:r(γ)>k cosh(τ )L−r(γ) sinh(τ )r(γ) . (E4)\nWhere we used triangular inequality to upper-bound all the paths as the sinh, cosh weight times the one norm of any\nPauli string. There are at most \u0000L\nj\n\u0001 paths with exactly j non-identity updates (corresponding to choosing j steps to\napply the sinh branch). Thus, we can bound the sum by:\nSk,L := X\nγ:r(γ)>k\ncosh(τ )L−r(γ) sinh(τ )r(γ)\n⩽\nL\tX\nj=k+1\n\u0012L\nj\n\u0013\ncoshL−j (τ ) sinhj (τ ) . (E5)\nWe factor out the total weight eτ L = (cosh τ + sinh τ )L. Defining p := sinh(τ )/eτ = (1 − e−2τ )/2, we can rewrite the\nterms as:\ncoshL−j (τ ) sinhj (τ ) = eτ L(1 − p)L−j pj . (E6)\nSubstituting this back into the sum, we recognize the tail of a Binomial distribution:\nSk,L ≤ eτ L\nL\tX\nj=k+1\n\u0012L\nj\n\u0013\n(1 − p)L−j pj = eτ L Pr[X > k], where X ∼ Bin(L, p). (E7)\nUsing the standard Chernoff bound for the tail of a binomial distribution, Pr[X > k] ≤\n\u0010 eLp\nk\n\u0011k\nfor k > Lp.\nSince 1 − e−x ≤ x for x ≥ 0, we have p ≤ τ . Thus, for k > eLτ ≥ eLp, the bound simplifies to:\nSk,L ≤ eτ L\n\u0012 eLτ\nk\n\u0013k\n. (E8)\nCombining this with the prefactor 2n∥o∥1 yields the claim\n∥(AL − e\tAL)∥1 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n(E9)\nNow we proceed to use this Theorem to prove that a similar bound holds for normalized quantum states.\n2. Small angle truncation for normalized states\nTheorem 13 (qDRIFT small angle truncation error). Consider the simulation of the thermal state starting from\nthe identity I. The algorithm performs L steps of the map Et(·) = e−τ Pt (·)e−τ Pt , with step angle τ = βΛ\n2L , where\nΛ = P\nj |hj | is the sum of Hamiltonian coefficients. Let ˜ρ be the approximate state obtained by truncating any Pauli\npath that accumulates more than k non-identity updates (i.e., discarding paths with more than k factors of sinh τ ).\nThen\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (E10)\nProof. We first bound the error for the unnormalized state AL. Invoking Theorem 12 with the qDRIFT step size\nτ = βΛ\n2L , the expected additive error is:\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2neτ L\n\u0012 eLτ\nk\n\u0013k\n= 2neβΛ/2\n\u0012 eβΛ\n2k\n\u0013k\n. (E11)\n\n-- 16 of 34 --\n\n17\nTo recover the error for the physical, normalized state ρ = AL/Z, we apply the stability bound from Theorem 10.\nWe observe that for imaginary time evolution starting from I, the partition function satisfies Z = Tr(AL) ≥ Tr(I) = 2n\n(see Lemma 5).\nLet εunnorm denote the RHS of Eq. (E11). The normalized error parameter ε in Theorem 11 is given by ε =\nεunnorm/d, where d = 2n. The dimension factor 2n strictly cancels out:\nε = eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k\n. (E12)\nProvided that k is sufficiently large such that ε < 1, Theorem 10 dictates that the normalized trace distance is\nbounded by 2ε\n1−ε . In the asymptotic limit, this is linear in ε:\n∥ρ − ˜ρ∥1 ∈ O(ε) = O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (E13)\nLemma 14. Assume the model in Theorem 13. Let βΛ = Θ(log n), and choose k = cβΛ. Then the error in\nTheorem 13 scales as\n∥ρ − ˜ρ∥1 ∈ c−Θ(log n) = 1\npoly(n) (E14)\nProof. We start with by substituting k = cβΛ in the bound of Theorem 13\n∥ρ − ˜ρ∥1 ∈ O\n\u0012\neβΛ/2 \u0010 e\n2c\n\u0011cβΛ\u0013\n(E15)\nWe can simplify this by taking the coefficients inside of the order and massaging them to obtain\neβΛ/2 \u0010 e\n2c\n\u0011cβΛ\n=\n\u0012 ec+1/2\n(2c)c\n\u0013βΛ\n⩽ 1∀c ⩾ 3 . (E16)\nTherefore, if we recover Eq. (E15), we find\n∥ρ − ˜ρ∥1 ∈ c−Θ(βΛ) (E17)\nwhere we used that 1/√cc ⩾ ec+1/2\n(2c)c and if we choose βΛ ∈ Θ(log n) we find that the error is polynomially suppressed\nin c, n.\nAppendix F: Weight truncation\nIn this section we prove error bounds for weight truncation, presented in Theorem 2. This proof follows a similar\nargument to the proof of Theorem 3 in [10], and the small angle truncation presented in the previous section. We\nstart by proving Theorem 15, a bound for the error when truncating unnormalized matrices, after applying L steps of\nimaginary time evolution. Differently to the case in the previous appendix, here we consider what is the probability\nthat an truncated path would go back to a Pauli string that could overlap with our observable. We consider this\nby analyzing the probability of going back to a Pauli with weight smaller or equal to the maximum weight of the\nobservable. In Theorem 16, we combine Theorems 15, and 10 to bound the truncation error for normalized states.\nThe resulting bound is less general that the small angle truncation bound in virtue of applying only to the expectation\nvalues of low weight observables, but strictly due to the additional error suppression from the suppressed probability\nof backflow.\nTheorem 15 (Backflow Truncation Bound for Unnormalized Matrices). Consider an imaginary time evolution of L\nsteps with angle τ starting from the identity I. Let e\tAL be the unnormalized operator produced by truncating any Pauli\nstring Q with weight wt(Q) > k.\nLet h be the weight of the observable O. Define m as the minimum number of weight-reducing updates required to\ntransform a Pauli string of weight > k to one of weight ≤ h. Let qbf be the maximum probability that a random update\nreduces the weight of a Pauli string (the “backflow probability”).\n\n-- 17 of 34 --\n\n18\nThe expected error in the observable is bounded by:\nE\u0002| Tr\n\u0010\nO(AL − e\tAL)\n\u0011\n|\u0003 ⩽ 2n∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eLτ qbf\nm\n\u0013m\n. (F1)\nProof. We start from the general bound derived in Lemma 9 (Eq. C8). Using the bound |w(γ)| ≤ eLτ 2/2τ r(γ) (where\nr(γ) is the number of non-identity updates), we have:\nE\u0002| Tr\u0000O(AL − e\tAL))|\u0003 ⩽ 2n∥o∥1e 1\n2 Lτ 2\nE\n\" X\nγ∈K\nτ r(γ)\n#\n, (F2)\nwhere K is the set of “killed” paths: those that exceed weight k at some point but end with weight ≤ h.\nAny such path must realize at least m weight-decreasing updates to bridge the gap from weight > k down to h.\nLet D(γ) denote the number of weight decreases in path γ. The condition γ ∈ K implies D(γ) ≥ m.\nWe now bound the expected sum S := E\nh P\nγ∈K τ r(γ)\ni\n. We first sum over the total number of non-identity updates\nr (from m to L). For a fixed r, the number of decreases D follows a distribution bounded by a Binomial distribution\nB(r, qbf ). Thus, we sum over the number of backflow steps j (from m to r):\nS ≤\nL\tX\nr=m\n\u0012L\nr\n\u0013\nτ r\nr\tX\nj=m\n\u0012r\nj\n\u0013\nqbf j . (F3)\nWe use the identity \u0000L\nr\n\u0001\u0000r\nj\n\u0001 = \u0000L\nj\n\u0001\u0000L−j\nr−j\n\u0001 to rearrange the binomial coefficients. This allows us to swap the summation\norder to sum over j first:\nS ≤\nL\tX\nj=m\n\u0012L\nj\n\u0013\nqbf j\nL\tX\nr=j\n\u0012L − j\nr − j\n\u0013\nτ r . (F4)\nWe re-index the inner sum by setting ℓ = r − j. As r goes from j to L, ℓ goes from 0 to L − j:\nL\tX\nr=j\n\u0012L − j\nr − j\n\u0013\nτ r = τ j\nL−j\tX\nℓ=0\n\u0012L − j\nℓ\n\u0013\nτ ℓ\n= τ j (1 + τ )L−j , (F5)\nwhere the last equality follows from the binomial theorem. Substituting this back into the expression for S:\nS ≤\nL\tX\nj=m\n\u0012L\nj\n\u0013\nqbf j τ j (1 + τ )L−j\n=\nL\tX\nj=m\n\u0012L\nj\n\u0013\n(τ qbf )j (1 + τ )L−j . (F6)\nWe now apply the tail bound for the binomial sum: PL\nj=m\n\u0000L\nj\n\u0001aj bL−j ≤ bL\n\u0010 eL(a/b)\nm\n\u0011m\n. Identifying a = τ qbf and\nb = 1 + τ , we get:\nS ≤ (1 + τ )L\n\u0012 eLτ qbf\nm(1 + τ )\n\u0013m\n. (F7)\nSince 1 + τ > 1, we can simplify the denominator to obtain the strict upper bound:\nS ≤ (1 + τ )L\n\u0012 eLτ qbf\nm\n\u0013m\n. (F8)\nFinally, we combine this with the prefactor from Eq. (F2). The total error prefactor is exp\u0000Lτ 2/2\u0001(1 + τ )L. Taking\nthe logarithm and using the Taylor inequality log(1 + τ ) ≤ τ − τ 2\n2 + τ 3\n3 (valid for τ > 0):\n1\n2 Lτ 2 + L log(1 + τ ) ≤ 1\n2 Lτ 2 + L\n\u0012\nτ − τ 2\n2 + τ 3\n3\n\u0013\n= Lτ + 1\n3 Lτ 3. (F9)\n\n-- 18 of 34 --\n\n19\nExponentiating this result gives the final bound:\nE\u0002 Tr\n\u0010\nO(AL − e\tAL)\n\u0011\u0003 ⩽ 2n∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eL τ qbf\nm\n\u0013m\n. (F10)\nNow we proceed to use this Theorem to prove that a similar bound holds for normalized quantum states.\n1. Weight truncation for normalized states\nTheorem 16 (qDRIFT Backflow Error). Consider the qDRIFT simulation of a thermal state starting from the\nidentity I. The algorithm applies L steps of size τ = βΛ\n2L , where Λ = P |hi|. Let ˜ρ be the state obtained by truncating\nany Pauli string with weight exceeding k. Let qbf (k) be the backflow probability at weight k, and let m be the minimum\nnumber of steps required to reduce a Pauli string of weight > k to one overlapping with the h-local observable O.\nProvided that m > eβΛqbf (k)\n2 , the error in the expectation value is bounded by:\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2m\n\u0013m\u0013\n. (F11)\nProof. We begin with the general backflow bound from Theorem 15. For an unnormalized evolution of L steps with\nangle τ , the expected error is:\nE\u0002 Tr\n\u0010\nO(AL − e\tAL)\n\u0011\u0003 ⩽ d∥o∥1 exp\n\u0010\nLτ + 1\n3 Lτ 3\u0011 \u0012 eL τ qbf (k)\nm\n\u0013m\n. (F12)\nWe substitute the qDRIFT parameters. The total rotation angle is fixed to βΛ/2, so we set τ = βΛ\n2L .\nFirst, we simplify the pre-factor. As L → ∞, the cubic term vanishes:\nLτ + 1\n3 Lτ 3 = βΛ\n2 + 1\n3 L\n\u0012 βΛ\n2L\n\u00133\n= βΛ\n2 + O(L−2) . (F13)\nNext, we substitute τ into the geometric base:\neLτ qbf (k)\nm = eL( βΛ\n2L )qbf (k)\nm = eβΛqbf (k)\n2m . (F14)\nCombining these, the unnormalized error bound is:\nE\u0002|Tr(O∆AL)|\u0003 ∈ O\n\u0012\nd∥o∥1eβΛ/2\n\u0012 eβΛqbf (k)\n2m\n\u0013m\u0013\n. (F15)\nWe can use Markov’s inequality to see that\nPr\u0000|Tr(O∆AL)| < aE\u0002|Tr(O∆AL)|\u0003\u0001 = 1 − Pr\u0000|Tr(O∆AL)| > aE\u0002|Tr(O∆AL)|\u0003\u0001 ⩾ 1 − 1\na (F16)\nTo obtain the error for the physical state ρ = AL/Z, we invoke Theorem 10. We identify the normalized error\nparameter ε by dividing Eq. (F15) by the dimension d:\nε = a∥o∥1eβΛ/2\n\u0012 eβΛqbf (k)\n2m\n\u0013m\n. (F17)\nwith probability at worst 1 − 1/a, where we used Eq. (F16). Assuming the truncation threshold k is large enough\nsuch that ε < 1, the stability theorem guarantees that the normalized error scales as O(ε). Thus obtaining\n|Tr[O(ρ − ˜ρ)]| ∈ O\n\u0012\n∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (k)\n2m\n\u0013m\u0013\n. (F18)\nFinally, we note that m is determined by the locality of the Hamiltonian terms. If the maximum weight reduction\nper step is δ (e.g., δ = 2 for commutators of weight-2 Paulis), then m = ⌈(k − h)/δ⌉. This completes the proof.\n\n-- 19 of 34 --\n\n20\nLemma 17. Assume the model in Theorem 20. Let βΛ ∈ O(log(n)), m ∈ Θ(k), and ∥o∥1 ∈ poly(n) then the error\nscales as\n|Tr[O(ρ − ˜ρ)]| ∈\n\u0012 log(n)\nn\n\u0013Θ(k)\n. (F19)\nfor any of the models of qbf (w) considered in Appendix G.\nProof. We start with the bound in Theorem 20. First we see that for any of the models of qbf (w) considered in\nAppendix G are suppressed either quadratically or linearly with the number of qubits n, i.e. qbf (w) ∈ O\u0000 w\nn\n\u0001. Thus,\nqbf (k)βΛ ∈ O\n\u0010 k log n\nn\n\u0011\n. If we substitute this along side with βΛ ∈ O(log(n)), m ∈ Θ(k), and ∥o∥1 ∈ poly(n) we obtain\n|Tr[O(ρ − ˜ρ)]| ∈ O poly(n)\n\u0012 log n\nn\n\u0013k!\n. (F20)\nwhich for sufficiently large k (but k ∈ O(1)) we can further simplify the expression to\n|Tr[O(ρ − ˜ρ)]| ∈\n\u0012 log n\nn\n\u0013Θ(k)\n. (F21)\nAppendix G: Probabilities of Backflow\nIn this section, we derive upper bounds for the backflow probability qbf (w)—the probability that a random update\nreduces the weight of a Pauli string—under different interaction geometries and Hamiltonian distributions. In par-\nticular, we analyze the bounds on the backflow probability qbf (w) under four distinct weight 2 Hamiltonian models,\ndefined by the geometry of the qubit interactions and the probability distribution of the applied gates. A summary\nof the backflow probabilities is provided in Table G.\nAll-to-All Uniform: A fully connected geometry where any two-qubit gate is applied to a pair (i, j) sampled uni-\nformly from all \u0000n\n2\n\u0001 possible edges. This model assumes perfect uniformity in interaction strength across the\nentire system.\nNearest-Neighbor Uniform: A 1D chain geometry where interactions are restricted to adjacent qubits (i, i + 1).\nThe specific edge is sampled uniformly from the n available nearest-neighbor pairs, representing an ideal linear\ntopology.\nGeneral Close-to-Uniform: A model relaxing the uniformity assumption. The probability p(e) of interacting on\nan edge e is arbitrary, provided it does not deviate excessively from the uniform distribution u(e). The deviation\nis constrained by the max-divergence (see Definition 6) D∞(p∥u) ≤ α, which implies the dominance condition\np(e) ≤ eαu(e).\nRandom Hamiltonian: A specific stochastic instance of the general model. Here, the interaction weights for edges\nare drawn i.i.d. from a continuous uniform distribution Unif(−1, 1). We establish that these systems behave as\nclose-to-uniform models with high probability, specifically satisfying the bound with eα ≈ 4. These Hamiltonians\ninclude, for example, Spin Glasses [58].\n1. All-to-all two-body interactions\nLemma 18 (Backflow Probability for All-to-All interactions). Consider a Pauli string Q of weight wt(Q) = w. If we\napply a random two-qubit Pauli gate sampled uniformly from all \u0000n\n2\n\u0001 pairs and all 9 non-identity Pauli combinations,\nthe probability of backflow is bounded by:\nqbf (w) ∈ Θ\n\u0012 w2\nn2\n\u0013\n(G1)\n\n-- 20 of 34 --\n\n21\nTable I. Summary of Backflow Probability Bounds qbf (w).\nModel Geometry Distribution p Backflow Bound qbf (w)\nAll-to-All Interactions\nUniform Complete Uniform (u) ∈ Θ\n\u0012 w2\nn2\n\u0013\nGeneral Complete D∞(p∥u) ≤ α ∈ O\n\u0012 eαw2\nn2\n\u0013\nRandom Complete we ∼ Unif(−1, 1) ∈ O\n\u0012 w2\nn2\n\u0013\nwith probability 1 − e−Θ(n2)\nNearest-Neighbor (NN) Interactions\nUniform 1D Chain Uniform (uNN) ∈ O\n\u0010 w\nn\n\u0011\nGeneral 1D Chain D∞(p∥uNN) ≤ α ∈ O\n\u0012 eαw\nn\n\u0013\nRandom 1D Chain we ∼ Unif(−1, 1) ∈ O\n\u0010 w\nn\n\u0011\nwith probability 1 − e−Θ(n)\nProof. Let S = supp(Q) be the support of the Pauli string, with |S| = w. Suppose an edge e = (i, j) is sampled\nuniformly at random from the \u0000n\n2\n\u0001 possible pairs, and a two-body Pauli operator Pij is sampled uniformly from the 9\npossibilities on that edge.\nTo calculate the conditional probability qbf (w) = Pr(Decay | Commute), we first classify the interaction by the size\nof the overlap r := |{i, j} ∩ S| and analyze the conditions for weight reduction and commutation in each case:\n1. Case r = 0 (Disjoint): The gate acts on two sites where Q is identity.\n• Commutation: The operators always commute ([P, Q] = 0).\n• Weight Change: The weight strictly increases (∆w = +2).\n2. Case r = 1 (Partial Overlap): The gate acts on one site in S and one outside.\n• Commutation: The operators commute if and only if the Pauli matrices match on the single overlapping\nsite (probability 1/3). Otherwise, they anticommute (probability 2/3).\n• Weight Change: If they commute (match), the site in S becomes identity, but the site outside S gains\na Pauli. The net weight change is ∆w = −1 + 1 = 0.\n3. Case r = 2 (Full Overlap): The gate acts on two sites within S.\n• Commutation: The operators commute if they anticommute on an even number of sites (0 or 2). This\nhappens with probability 5/9. They anticommute with probability 4/9.\n• Weight Change: A weight decrease (∆w = −2) occurs only if the gate Pij is the exact inverse of Q on\nboth sites (e.g., Pij = Qi ⊗ Qj ). This specific configuration implies commutation.\nWe now compute the joint probability of decay and commutation, and the total probability of commutation.\nNumerator: Pr(Decay ∩ Commute) Weight decay occurs exclusively in the r = 2 case and requires the specific\nPauli choice that cancels Q.\nPr(Decay ∩ Commute) = Pr(r = 2) × Pr(Cancel | r = 2) (G2)\n=\n\u0000w\n2\n\u0001\n\u0000n\n2\n\u0001 · 1\n9 . (G3)\nIndeed, there are 9 possible Pauli combinations. Only 1 cancels the string Q perfectly. This 1 combination inherently\ncommutes.\n\n-- 21 of 34 --\n\n22\nDenominator: Pr(Commute) It is more convenient to calculate the probability of anticommutation and subtract\nit from 1. Anticommutation occurs in cases r = 1 and r = 2:\nPr(Anticommute) = Pr(r = 1) Pr(Anti | r = 1) + Pr(r = 2) Pr(Anti | r = 2) (G4)\n= w(n − w)\n\u0000n\n2\n\u0001 · 2\n3 +\n\u0000w\n2\n\u0001\n\u0000n\n2\n\u0001 · 4\n9 (G5)\n= 1\n9\u0000n\n2\n\u0001\nh\n6w(n − w) + 4 w(w − 1)\n2\ni\n(G6)\n= 4w(3n − 2w − 1)\n9\u0000n\n2\n\u0001 . (G7)\nTherefore, the probability of commuting is:\nPr(Commute) = 1 − Pr(Anticommute) = 9\u0000n\n2\n\u0001 − 4w(3n − 2w − 1)\n9\u0000n\n2\n\u0001 . (G8)\nThe Ratio Finally, we divide the numerator by the denominator:\nqbf (w) = Pr(Decay ∩ Commute)\nPr(Commute) (G9)\n=\n(w\n2 )\n9(n\n2)\n9(n\n2)−4w(3n−2w−1)\n9(n\n2)\n(G10)\n=\n\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − 4w(3n − 2w − 1) (G11)\n∈ Θ\n\u0012 w2\nn2\n\u0013\n. (G12)\n2. Nearest-neighbor two-body interactions\nLemma 19 (Backflow Bound for Nearest-Neighbor Gates). The probability of backflow qbf (w) for a Pauli string Q of\nweight w, under the application of random nearest-neighbor two-qubit gates on a chain of n qubits, is upper-bounded\nby:\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n(G13)\nProof. Let S = supp(Q) be the support of the Pauli string. We analyze the probability of backflow qbf (w) =\nPr(Decay|Commute) = Pr(Decay∩Commute)\nPr(Commute) by bounding the numerator and denominator separately over all possible\ngeometric configurations of S.\nMaximizing the Numerator (Decay ∩ Commute) Weight decay can only occur if the sampled edge e = (i, i + 1)\nhas non-identity terms in both i and i + 1.\n• Geometric Constraint: The number of bulk edges, denoted kbulk, is maximized when the qubits in S form a\nsingle contiguous block. In this configuration, kbulk = w − 1.\n• Operator Constraint: On a chosen bulk edge, there are 9 equiprobable two-body Pauli operators. Decay\noccurs only if the operator cancels Q on both sites (e.g., P = Qi ⊗ Qi+1). There is exactly 1 such operator out\nof 9. This operator automatically commutes with Q.\nThus, the probability of decay and commutation is bounded by:\nPr(Decay ∩ Commute) = kbulk\nM · 1\n9 ≤ w − 1\n9M . (G14)\nwhere M is the total number of edges possible (M = n − 1 for open boundaries and M = n for closed boundaries).\n\n-- 22 of 34 --\n\n23\nMinimizing the Denominator (Commute) To obtain a robust upper bound on the ratio, we must consider the\nworst-case scenario for the denominator. Minimizing the commutation probability is equivalent to maximizing the\nanticommutation probability.\n• Geometric Constraint: Anticommutation occurs primarily on “boundary” edges (connecting S to non-S)\nwhere the probability is 2/3, versus in edges where there are two Pauli matrices, where it is 4/9. Since 2/3 > 4/9,\nanticommutation is maximized when the number of boundary edges is maximal. This occurs when the errors\nin S are maximally spread out (isolated), creating up to 2w boundary edges.\n• Probability Calculation:\nPr(Anticommute) ≤ 2w\nM · 2\n3 = 4w\n3M . (G15)\nConsequently, the probability of commuting is lower-bounded by:\nPr(Commute) = 1 − Pr(Anticommute) ≥ 1 − 4w\n3M = 3M − 4w\n3M . (G16)\nBounding the Ratio Combining the maximized numerator and the minimized denominator:\nqbf (w) = Pr(Decay ∩ Commute)\nPr(Commute) ≤\nw−1\n9M\n3M −4w\n3M\n(G17)\n= w − 1\n9M · 3M\n3M − 4w (G18)\n= w − 1\n3(3M − 4w) (G19)\n= w − 1\n9M − 12w . (G20)\nIf we have open boundary conditions M = n − 1 and without we have M = n, thus we can write\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n(G21)\n3. General close-to-uniform Hamiltonians\nIn this section, we relax the assumption of perfect uniformity in the sampling of Hamiltonian terms. We characterize\nthe deviation from the uniform distribution using the max-divergence D∞(p∥uNN) (see Definition 6) and derive a\nrobust upper bound on the backflow probability.\nTheorem 20 (Backflow for General Distributions). Let u be the uniform sampling distribution over unordered pairs\nof n qubits. Let p be an arbitrary sampling distribution over these pairs such that its max-divergence from uniform is\nbounded by D∞(p∥u) ≤ α. Then, the probability of backflow qbf (w) under 2-local Pauli gates distributed according to\np is bounded by:\nqbf (w) ∈ O\n\u0012 eαw2\nn2\n\u0013\n(G22)\nProof. Let u be the uniform distribution of sampling one two-body all-to-all Pauli matrix. Let p be a probability\ndistribution such that the max-divergence D∞(p∥u) ≤ α (see Definition 6) implies that for any event E, p(E) ≤\neαu(E). Then in the worst case we find\nqbf (w) = Pr\np (Decay|Commute) = eα Pru(Decay ∩ Commute)\n1 − eα Pru(Commute) (G23)\n\n-- 23 of 34 --\n\n24\nwhere Prp(·) denotes the probability of an event according to distribution p and, similarly, Pru(·) corresponds to the\nuniform. Therefore, recovering the probabilities from Eqs. (G3,G7)\nqbf (w) ⩽ eα\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − eα4w(3n − 2w − 1) (G24)\n∈O\n\u0012 eαw2\nn2\n\u0013\n(G25)\nCorollary 21 (Backflow for Random Hamiltonians). Let the weights of the Hamiltonian terms be chosen i.i.d. from\nUnif(−1, 1), defining a sampling distribution p. With probability at least 1−e−Θ(n2), the backflow probability is bounded\nby:\nqbf (w) ∈ O\n\u0012 w2\nn2\n\u0013\n(G26)\nProof. The coefficient of the Hamiltonian being sampled i.i.d from Unif(−1, 1), is equivalent to sampling them from a\nprobability distribution Unif(0, 1) since qDRIFT does not care about the sign. Then, immediately Proposition 8, we\nknow that with probability ≥ 1 − e−M/8, the distribution p satisfies D∞(p∥u) ≤ log 4 (see Definition 6). Substituting\nα = log 4 (so eα = 4) into Theorem 20 yields the following result immediately\nqbf (w) ⩽ 4\u0000w\n2\n\u0001\n9\u0000n\n2\n\u0001 − 16w(3n − 2w − 1) ∈ O\n\u0012 w2\nn2\n\u0013\n(G27)\n4. Non-uniform Nearest-Neighbor Interactions\nWe now extend the robustness analysis to nearest-neighbor geometries where the sampling of edges may not be\nperfectly uniform, such as in systems with disordered coupling strengths. To prove this we use the Max Divergence\nD∞(p∥uNN), introduced in Definition 6\nTheorem 22 (Backflow for General Nearest-Neighbor Distributions). Let uNN be the uniform distribution over the\nn possible nearest-neighbor edges on a chain. Let p be an arbitrary sampling distribution over these edges such that\nD∞(p∥uNN) ≤ α.\nThen, the probability of backflow qbf (w) for a Pauli string of weight w is bounded by:\nqbf (w) ∈ O\n\u0012 eαw\nn\n\u0013\n(G28)\nProof. Let u be the uniform distribution of sampling one two-body all-to-all Pauli matrix. Let p be a palisaded\ndistribution such that the max-divergence D∞(p∥u) ≤ α (see Definition 6) implies that for any event E, p(E) ≤\neαu(E). Then in the worst case we find\nqbf (w) = Pr\np (Decay|Commute) = eα Pru(Decay ∩ Commute)\n1 − eα Pru(Commute) (G29)\nwhere Prp(·) denotes the provability of an event according to distribution p and, similarly, Pru(·) corresponds to the\nuniform. Therefore, recovering the probabilities from Eqs. (G14,G15)\nqbf (w) ⩽ eα(w − 1)\n9M − eα12w . (G30)\nIf we have open boundary conditions M = n − 1 and without we have M = n, thus we can write\nqbf (w) ∈ O\n\u0012 eαw\nn\n\u0013\n(G31)\n\n-- 24 of 34 --\n\n25\nCorollary 23 (Backflow for Random Nearest-Neighbor Hamiltonians). Let the weights of the nearest-neighbor Hamil-\ntonian terms be chosen i.i.d. from Unif(−1, 1). With probability at least 1 − eΘ(n), the backflow probability is bounded\nby:\nqbf (w) ∈ O\n\u0010 w\nn\n\u0011\n. (G32)\nProof. The coefficient of the Hamiltonian being sampled i.i.d from Unif(−1, 1), is equivalent to sampling them from a\nprobability distribution Unif(0, 1) since qDRIFT does not care about the sign. Then, by Proposition 8, substituting\nthe number of edges M = Θ(n), the distribution p satisfies D∞(p∥uNN) ≤ log 4 with probability ≥ 1 − e−Θ(n). Setting\neα = 4 in the preceding theorem leads to\nqbf (w) ⩽ 4(w − 1)\n9M − 48w ∈ O\n\u0010 w\nn\n\u0011\n. (G33)\nAppendix H: Extended weight-truncation analysis\n1. Proof outline\nThis section formalizes a simple intuition: for a high-temperature Gibbs operator e−βH , the overlap with a high-\nweight Pauli string Q is typically very small, so discarding high-weight Pauli components can be a controlled ap-\nproximation. While Section F develops this idea for a specific simulation primitive (e.g. qDRIFT ), here we give an\nalternative analysis that applies more broadly to algorithms that build thermal operators by composing general maps,\nand we provide a bound specialized on 1st order Trotter formula. Concretely, we consider a procedure that produces\nan (unnormalized) thermal operator by applying a sequence of maps to the identity:\nAj := M⌊j,1⌋(I) = Mj ◦ Mj−1 ◦ · · · ◦ M1(I), A0 := I.\nTo keep the simulation classically tractable, we introduce a weight-truncated surrogate in which we project onto\nPauli strings of weight < k after each step. Let Π<k denote the projector onto the span of Pauli strings of weight\n< k (equivalently, Π<k discards all Pauli components of weight ≥ k). We define the truncated forward evolution\nrecursively by\ne\tA0 := I, e\tAj := Π<k ◦ Mj\n\u0010 e\tAj−1\n\u0011\n, (j = 1, . . . , L),\nso that e\tAL is obtained from the same forward maps as AL, but with truncation applied between layers.\nGiven an observable O, our estimator is Tr\nh\nO e\tAL\ni\n, intended to approximate Tr[OAL]. It is convenient to evaluate\nthe approximation error in the Heisenberg picture. Since Π<k is self-adjoint with respect to the Hilbert–Schmidt\ninner product, i.e. Π†\n<k = Π<k, one has\nTr\nh\nO e\tAL\ni\n= Tr\nh e\tO0\ni\n,\nwhere the backward-truncated observables are defined by\ne\tOL := O, e\tOj−1 := M†\nj ◦ Π<k\n\u0010 e\tOj\n\u0011\n, (j = L, L − 1, . . . , 1).\nImportantly, the algorithm itself is the forward construction of the truncated surrogate e\tAL, and the backward recursion\nis used only as an analytical tool, which allows to track the truncation error layer-by-layer via a telescoping identity\nthat compares Tr[OAL] and Tr\nh\nO e\tAL\ni\n.\nThe resulting error has two conceptually distinct sources that we bound separately.\n(i) Thermal suppression of high-weight Paulis. The first ingredient is a bound on Pauli expectation values taken on\nthe partially evolved operator M⌊j,1⌋(I),\nmax\nQ:|Q|≥k 2−n Tr\u0000QM⌊j,1⌋(I)\u0001 ≤ Ck.\n\n-- 25 of 34 --\n\n26\nThis formalizes idea that high-weight Paulis have small expectation in the (approximate) Gibbs operator when β is\nsmall enough.\n(ii) Controlling error accumulation under multiple truncations. The second ingredient is to bound the total mass of\nPaulis that can “leak” into the discarded sector during the backward propagation Oj 7 → M†\nj (Oj ). We quantify this\nusing a layerwise Pauli-ℓ1 growth bound and a standard Pauli-path expansion, which together control the total mass\nthat ever reaches weight ≥ k. Combining this with a telescoping identity yields an error bound of the form\n2−n| Tr(O0) − Tr(OAL)| ≲ Ck eδL ∥O∥Pauli,1,\nmaking explicit how accuracy depends on thermal suppression of high-weight Paulis (Ck), and the cumulative growth\nof Pauli-ℓ1 mass under the adjoint layers (eδL).\n2. Moment bound for Pauli expectation values: 1st order Trotter\nLemma 24 (Overlap bound for imaginary-time product-formula evolution). Let H = P\na∈T λaQa be a Pauli Hamil-\ntonian on n qubits with |λa| ≤ 1 and |supp(Qa)| ≤ k for all a ∈ T . Fix an ordering π = (a0, . . . , aM −1) of T (so\nM := |T |) and a step size δ > 0.\nFor integers p ≥ 0 and j ∈ {1, . . . , M − 1}, define the partial product-formula operators\nU (p,j)\nright :=\n\u0010 M\tY\nm=1\neδλam Qam\n\u0011p \u0010 j\tY\nm=1\neδλam Qam\n\u0011\n, U (p,j)\nleft :=\n\u0010 1\tY\nm=j\neδλam Qam\n\u0011 \u0010 1\tY\nm=M\neδλam Qam\n\u0011p\n, (H1)\nConsider the corresponding double-sided evolution from the identity\nXp,j := U (p,j)\nleft I U (p,j)\nright = U (p,j)\nleft U (p,j)\nright .\nFix a Pauli P with R := supp(P ), w := |R|, and set r := ⌈w/k⌉. Let\nTR := {a ∈ T : supp(Qa) ∩ R̸ = ∅}, B := |TR|.\nSet β = (p + 1)δ. Then for all p ≥ 0 and 0 ≤ j < M ,\n2−n Tr(P Xp,j ) ≤\n\u0012 2eβBeδ\nr\n\u0013r\ne2βM . (H2)\nProof. Each gate satisfies the expansion\neδλQ = cosh(δλ)I + sinh(δλ)Q. (H3)\nFix an ordering π = (a0, . . . , aM −1) of the Hamiltonian terms, and let L = pM + j for integers p ≥ 0 and 0 ≤ j < M .\nWe define the squared partial product operator Xp,j := (U (p,j)\nδ )2 by indexing the sequence of 2L gates appropriately.\nBy substituting (H3) into the product and expanding, we obtain a sum over bitstrings y ∈ {0, 1}2L:\nXp,j = X\nz∈{0,1}2L\n2L−1\tY\nt=0\ncosh(δλit )1−zt sinh(δλit )zt\n! 2L−1\tY\nt=0\nQzt\nit\n!\n, (H4)\nwhere Q0 := I and Q1 := Q, and the operators in the final product are ordered by increasing t.\nBy Pauli orthogonality, the Pauli coefficient of P in this expansion equals 2−n Tr(P Xp,j ), hence\n2−n| Tr(P Xp,j )| ≤ X\nz: Q(z)=ωP\n2L\tY\nℓ=1\ncosh(δλℓ) 1−zℓ sinh(δλℓ) zℓ ,\nwhere Q(z) := Q2L−1\nt=0 Qzt\nit denotes the resulting Pauli product.\nLet JR be the set of factor positions ℓ ∈ {1, . . . , 2L} whose Pauli term Qℓ acts nontrivially on R = supp(P ). As Xp,j\nis obtained by performing p full Trotter evolution plus an additional partial Trotter evolution containing j distinct\nimaginary time rotations, and each imaginary time rotation contribute with 2 factor positions, we have\n|JR| ≤ 2(p + 1)B.\n\n-- 26 of 34 --\n\n27\nIf Q(z) = ωP , then the union support of the selected Paulis must contain R. Since each selected Pauli has weight\nat most k, at least r = ⌈w/k⌉ of the selected positions must come from JR. Thus every contributing z satisfies\n|{ℓ ∈ JR : zℓ = 1}| ≥ r.\nApply a union bound over subsets S ⊆ JR with |S| = r. For each fixed S, dropping the constraint Q(z) = ωP only\nincreases the sum, giving\n2−n| Tr(P Xp,j )| ≤ X\nS⊆JR\n|S|=r\nX\nz=(z1,...,z2L)\nzℓ=1 if ℓ∈S\nzℓ∈{0,1} if ℓ̸∈S\nY\nℓ∈S\nsinh(λℓδ)\n\"2L−r\tY\nℓ=0\ncosh1−zℓ (λℓδ) sinhzℓ (λℓδ)\n#\n(H5)\n= X\nS⊆JR\n|S|=r\nsinhr (δ) X\ny∈{0,1}2L−r\n\"2L−r\tY\nt=0\ncosh1−yℓ (δ) sinhyℓ (δ)\n#\n(H6)\nwhere we used that |λℓ| ≤ 1 and therefore | sinh(δλℓ)| ≤ sinh(δ) and | cosh(δλℓ)| ≤ cosh(δ). Then, using the fact that\tP\nx∈{0,1}m\nQm\ni=1 αxi β1−xi = (α + β)m, the sum in y can we rearranged in the following form\n2−n| Tr(P Xp,j )| ≤ X\nS⊆JR, |S|=r\nsinh(δ)r \u0002cosh(δ) + sinh(δ)\u00032L−r . (H7)\nWe can use that cosh(δ) + sinh(δ) = eδ to obtain\n2−n| Tr(P Xp,j )| ≤\n\u0012|JR|\nr\n\u0013\n(sinh δ)r eδ(2L−r) ≤\n\u00122(p + 1)B\nr\n\u0013\n(sinh δ)r e2δ(p+1)M ,\nNote that here we are also considering the terms that have more than r sinh paths, as in Eq. (H7) we consider all the\npaths that have at least r sinh terms.\nUsing \u0000N\nr\n\u0001 ≤ (eN/r)r and sinh δ ≤ δeδ , and setting β = (p + 1)δ, one finds that\n2−n| Tr(P Xp,j )| ≤\n\u00122(p + 1)B\nr\n\u0013\n(sinh δ)r e2δ(p+1)M ≤\n\u0012 2eβBeδ\nr\n\u0013r\ne2βM . (H8)\n3. Weight-truncated Quantum Imaginary-Time Evolution\nLet d := 2n and let Pn = {I, X, Y, Z}⊗n denote the n-qubit Pauli basis. For a linear map M = ML ◦ML−1 ◦· · ·◦M1\nand indices i ≥ j, write\nM⌊i,j⌋ := Mi ◦ Mi−1 ◦ · · · ◦ Mj .\nFor any operator X and Pauli Q ∈ Pn, define its (normalized) Pauli coefficient by\n⟨Q, X⟩ := 1\nd Tr(QX).\nThen Tr(QQ′) = d δQ,Q′ and\nX = X\nQ∈Pn\n⟨Q, X⟩ Q.\nDefine the Pauli-ℓ1 norm by\n∥X∥Pauli,1 := X\nQ∈Pn\n⟨Q, X⟩ = 1\nd\nX\nQ∈Pn\nTr(QX) .\nFor an integer cutoff k ≥ 1, let Π<k and Π≥k denote the projectors onto the span of Pauli strings of weight < k and\n≥ k, respectively:\nΠ<k(X) := X\n|Q|<k\n⟨Q, X⟩ Q, Π≥k(X) := X\n|Q|≥k\n⟨Q, X⟩ Q.\nAssumptions. Let H be a Hamiltonian and fix β ≥ 0. We assume:\n\n-- 27 of 34 --\n\n28\n1. (Layerwise ℓ1-growth bound in the Pauli basis.) For every Pauli P ∈ Pn and every j ∈ [L],\nX\nQ∈Pn\n1\nd Tr\u0000Q M†\nj (P )\u0001 ≤ eδ .\nEquivalently, for every operator X,\n∥M†\nj (X)∥Pauli,1 ≤ eδ ∥X∥Pauli,1. (H9)\n2. (Thermal Pauli expectation bound at weight ≥ k.) Let the partially evolved operator at step j be\nAj := M⌊j,1⌋(I) (A0 := I).\nThere exists a quantity Ck such that\nmax\nQ∈Pn: |Q|≥k\n1\nd |Tr(QAj )| ≤ Ck. (H10)\nWeight-truncated propagation. Given an observable O, define recursively\nOL := O, e\tOj−1 := M†\nj (Oj ), Oj−1 := Π<k( e\tOj−1) (j = L, L − 1, . . . , 1).\nDefine the discarded (high-weight) part at layer j:\n∆j := Π≥k( e\tOj−1) = e\tOj−1 − Oj−1 (j = 1, . . . , L).\nBy construction,\n∥∆j ∥Pauli,1 = X\n|Q|≥k\n⟨Q, ∆j ⟩ = 1\nd\nX\n|Q|≥k\nTr(Q ∆j ) .\nTelescoping identity and truncation error. We compare Tr(O AL) = Tr(OLAL) with the truncated estimate\nTr(O0A0) = Tr(O0).\nLemma 25 (One-step telescoping). For every j ∈ {1, . . . , L},\nTr(Oj Aj ) − Tr(Oj−1Aj−1) = Tr(∆j Aj−1).\nProof. Using Aj = Mj (Aj−1) and duality,\nTr(Oj Aj ) = Tr\u0000Oj Mj (Aj−1)\u0001 = Tr\u0000M†\nj (Oj ) Aj−1\n\u0001 = Tr\n\u0010 e\tOj−1Aj−1\n\u0011\n.\nSince e\tOj−1 = Oj−1 + ∆j , the claim follows.\nSumming Lemma 25 over j yields\nTr(O0) − Tr(OAL) ≤\nL\tX\nj=1\nTr(∆j Aj−1) .\nUsing the Pauli expansion ∆j = P\n|Q|≥k⟨Q, ∆j ⟩Q, we have\nTr(∆j Aj−1) = X\n|Q|≥k\n⟨Q, ∆j ⟩ Tr(QAj−1),\nso by triangle inequality,\n| Tr(∆j Aj−1)| ≤\n\u0010 X\n|Q|≥k\n|⟨Q, ∆j ⟩|\n\u0011\nmax\n|Q|≥k | Tr(QAj−1)| = ∥∆j ∥Pauli,1 max\n|Q|≥k | Tr(QAj−1)|.\nApplying (H10) gives max|Q|≥k | Tr(QAj−1)| ≤ d Ck, hence\nTr(O0) − Tr(OAL) ≤ d Ck\nL\tX\nj=1\n∥∆j ∥Pauli,1. (H11)\n\n-- 28 of 34 --\n\n29\n4. Bounding PL\nj=1 ∥∆j ∥Pauli,1\nFor each layer j and Pauli P , expand M†\nj (P ) in the Pauli basis using trace coefficients:\nM†\nj (P ) = X\nQ∈Pn\nm(j)(Q, P ) Q, m(j)(Q, P ) := ⟨Q, M†\nj (P )⟩ = 1\nd Tr\u0000Q M†\nj (P )\u0001.\nAlso expand\nO = X\nPL∈Pn\n⟨PL, O⟩ PL where ⟨PL, O⟩ = 1\nd Tr(PLO).\nFor a Pauli path γ = (PL, PL−1, . . . , P0) ∈ PL+1\nn define its amplitude\nΦγ := ⟨PL, O⟩\nL\tY\nj=1\nm(j)(Pj−1, Pj ),\nso that\nM†(O) = X\nγ\nΦγ P0.\nDefine the path-ℓ1 mass\n∥M†(O)∥paths,1 := X\nγ\n|Φγ |.\nLemma 26 (Total path mass). Under Assumption 1,\n∥M†(O)∥paths,1 ≤ eδL ∥O∥Pauli,1.\nProof. Assumption 1 is exactly the statement that for every fixed P and j,\nX\nQ∈Pn\n|m(j)(Q, P )| ≤ eδ .\nTherefore,\nX\nγ\n|Φγ | = X\nPL\n|⟨PL, O⟩| X\nPL−1\n|m(L)(PL−1, PL)| · · · X\nP0\n|m(1)(P0, P1)|\n≤ X\nPL\n|⟨PL, O⟩| (eδ )L = eδL ∥O∥Pauli,1.\nLemma 27 (Sum of truncation tails). The truncation tails satisfy\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ ∥M†(O)∥paths,1.\nProof. Partition the set of all paths γ = (PL, . . . , P0) according to the first layer at which the path leaves the low-weight\nsector:\nΓ0 := {γ : |Pi| < k ∀i = 0, 1, . . . , L},\nand for j ∈ {1, . . . , L},\nΓj := {γ : |Pj | < k, |Pj−1| ≥ k, and |Pi| < k for all i = j, j + 1, . . . , L}.\n\n-- 29 of 34 --\n\n30\nThese sets are disjoint and cover all paths.\nFix j ∈ {1, . . . , L} and Q with |Q| ≥ k. By construction of the recursion, ∆j = Π≥k(M†\nj (Oj )) collects exactly those\ncontributions whose first high-weight Pauli occurs at stage j − 1, hence\n⟨Q, ∆j ⟩ = X\nγ∈Γj : Pj−1=Q\nΦγ .\nTherefore, by triangle inequality,\n∥∆j ∥Pauli,1 = X\n|Q|≥k\n|⟨Q, ∆j ⟩| ≤ X\n|Q|≥k\nX\nγ∈Γj : Pj−1=Q\n|Φγ | = X\nγ∈Γj\n|Φγ |.\nSumming over j and using disjointness of the Γj yields\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤\nL\tX\nj=1\nX\nγ∈Γj\n|Φγ | ≤ X\nγ\n|Φγ | = ∥M†(O)∥paths,1.\nCombining (H11) with Lemmas 26 and 27, we obtain\nTr(O0) − Tr(OAL) ≤ d Ck ∥M†(O)∥paths,1 ≤ d Ck eδL ∥O∥Pauli,1.\nIn particular, if ∥O∥Pauli,1 ≤ 1 (e.g. O is a Pauli observable), then\nTr(O0) − Tr(OAL) ≤ d eδL Ck.\n5. Error bound: 1st order Trotter\nTheorem 28 (Truncation error for 1st-order Trotter). Let H = P\na∈T λaQa be a Pauli Hamiltonian on n qubits with\n|λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Fix an ordering π = (a1, . . . , aM ) of T and a step size δ > 0. Let p ≥ 0 and\nset β := (p + 1)δ and L := (p + 1)M . Define the imaginary-time Trotter layers\nMj (X) := eδλaj Qaj X eδλaj Qaj , j = 1, . . . , L,\nwith the periodic convention aj+qM := aj for q = 0, . . . , p. Let Aj := M⌊j,1⌋(I) and let O0 be the weight-< k truncated\nbackward propagation output.\nAssume H has bounded degree ℓ, i.e. each qubit appears in at most ℓ terms Qa. Define\ng := 2e β ℓ w eδ .\nIf g ≤ 1, then for every observable O,\nTr(O0) − Tr(OAL) ≤ d e2δL e2βM g⌈k/w⌉ ∥O∥Pauli,1 = d e4βM g⌈k/w⌉ ∥O∥Pauli,1. (H12)\nIn particular, if ∥O∥Pauli,1 ≤ 1 (e.g. O is a Pauli), then\nTr(O0) − Tr(OAL) ≤ d e4βM g⌈k/w⌉.\nProof. We will apply the strategy described in the previous sections with Aj = M⌊j,1⌋(I).\nLayerwise Pauli-ℓ1 growth. Fix a layer map Mj (X) = GXG with G = eδλQ. For any Pauli P , using G = cosh(δλ)I +\nsinh(δλ)Q,\nGP G = cosh(δλ)2P + cosh(δλ) sinh(δλ)(QP + P Q) + sinh(δλ)2QP Q.\nThis is a linear combination of at most four Paulis, hence\n∥M†\nj (P )∥Pauli,1 = ∥Mj (P )∥Pauli,1 ≤ \u0000| cosh(δλ)| + | sinh(δλ)|\u00012 = e2|δλ| ≤ e2δ .\n\n-- 30 of 34 --\n\n31\nBy linearity, ∥M†\nj (X)∥Pauli,1 ≤ e2δ ∥X∥Pauli,1 for all X. Therefore Lemma 26 gives\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ e2δL ∥O∥Pauli,1. (H13)\nBounding Ck. Fix j ∈ {0, 1, . . . , L} and a Pauli P with |P | ≥ k. Write R := supp(P ), wP := |R|, and set\nr :=\nl wP\nw\nm\n≥\n\u0018 k\nw\n\u0019\n.\nThere exist integers p′ ∈ {0, . . . , p} and j′ ∈ {0, . . . , M − 1} such that Aj = Xp′,j′ in the notation of Lemma 24, with\nβ′ := (p′ + 1)δ ≤ β. Lemma 24 yields\n1\nd | Tr(P Aj )| = 2−n| Tr(P Xp′,j′ )| ≤\n\u0012 2e β′ B eδ\nr\n\u0013r\ne2β′M ≤\n\u0012 2e β B eδ\nr\n\u0013r\ne2βM , (H14)\nwhere B := |{a ∈ T : supp(Qa) ∩ R̸ = ∅}|.\nUsing the bounded-degree assumption, each qubit in R participates in at most ℓ terms, so\nB ≤ ℓ |R| = ℓ wP ≤ ℓ w r.\nSubstituting into (H14) gives\n1\nd | Tr(P Aj )| ≤\n\u0010\n2e β ℓ w eδ \u0011r\ne2βM = g r e2βM .\nSince g ≤ 1 and r ≥ ⌈k/w⌉, we have gr ≤ g⌈k/w⌉, hence for all j and all |P | ≥ k,\n1\nd | Tr(P Aj )| ≤ e2βM g⌈k/w⌉.\nTherefore Assumption (H10) holds with\nCk := e2βM g⌈k/w⌉. (H15)\nConclusion. Plugging (H13) and (H15) into (H11) yields\n| Tr(O0) − Tr(OAL)| ≤ d Ck\nL\tX\nj=1\n∥∆j ∥Pauli,1 ≤ d (e2βM g⌈k/w⌉) (e2δL∥O∥Pauli,1) = d e4βM g⌈k/w⌉ ∥O∥Pauli,1,\nsince δL = δ(p+1)M = βM .\nCorollary 29 (Truncation error for 1st-order Trotter). Let H = P\na∈T λaQa be a Pauli Hamiltonian on n qubits\nwith |λa| ≤ 1 and |supp(Qa)| ≤ w for all a. Fix an ordering π = (a1, . . . , aM ) of T and a step size δ > 0. Let p ≥ 0\nand set β := (p + 1)δ and L := (p + 1)M . Define the imaginary-time Trotter layers\nMj (X) := eδλaj Qaj X eδλaj Qaj , j = 1, . . . , L,\nwith the periodic convention aj+qM := aj for q = 0, . . . , p. Let ρ := M(I)\nTr[M(I)] and let ˜ρ be the approximate version\nobtained by truncating Pauli operators with weight exceeding k.\nAssume H has bounded degree ℓ, i.e. each qubit appears in at most ℓ terms Qa. Define\ng := 2e β ℓ w eδ .\nIf g ≤ 1, then for every observable O,\nTr(O(ρ − ˜ρ)) ≤ 4 e4βM g⌈k/w⌉ ∥O∥Pauli,1. (H16)\n\n-- 31 of 34 --\n\n32\nProof. Let d = 2n and set\nO′ := O\n∥O∥Pauli,1\n, ε := e4βM g⌈k/w⌉.\nBy Theorem 28 (applied with observable O′), we have\n1\nd Tr\n\u0010\nAL − ˜\tAL\n\u0011\n≤ ε and 1\nd Tr\u0000O′(AL − ˜\tAL)\u0001 ≤ ε. (H17)\nRecall that ρ = AL/ Tr(AL) and ˜ρ = ˜\tAL/ Tr\n\u0010 ˜\tAL\n\u0011\n. We invoke Theorem 10 with A = AL, ˜\tA = ˜\tAL, and O′. Using\n(H17), it yields\nTr \u0000O′(ρ − ˜ρ)\u0001 ≤ 2ε\n1 − ε .\nTherefore,\nTr \u0000O(ρ − ˜ρ)\u0001 = ∥O∥Pauli,1 Tr \u0000O′(ρ − ˜ρ)\u0001 ≤ 2ε\n1 − ε ∥O∥Pauli,1.\nFinally, assume in addition that ε ≤ 1\n2 (which can be ensured by choosing k large enough since g < 1 implies ε → 0\nas k → ∞). Then\n2ε\n1 − ε ≤ 2ε\n1 − 1\n2\n= 4ε,\nand hence\nTr \u0000O(ρ − ˜ρ)\u0001 ≤ 4 ε ∥O∥Pauli,1 = 4 e4βM g⌈k/w⌉ ∥O∥Pauli,1.\nThis proves the claim.\nAppendix I: From Pauli to Majorana propagation\nIn this section, we argue that the main theorems stated for Pauli propagation in the manuscript can be extended\nto the setting of Majorana propagation. We begin by recalling that, for imaginary-time evolution, conjugating a basis\noperator by an elementary gate has the same algebraic form in the Pauli and Majorana cases:\ne− τ\n2 P Q e− τ\n2 P =\n(Q, [P, Q]̸ = 0,\ncosh(τ ) Q − sinh(τ ) P Q, [P, Q] = 0, (I1)\ne− τ\n2 Mb Ma e− τ\n2 Mb =\n(Ma, [Mb, Ma]̸ = 0,\ncosh(τ ) Ma − sinh(τ ) MbMa, [Mb, Ma] = 0. (I2)\nIn particular, in both settings the operator branches only when it commutes with the generator of the imaginary-\ntime step; in that case, the two resulting branches are weighted by hyperbolic coefficients.\nAs a consequence, the small-coefficient truncation analysis (Theorem 1) extends essentially verbatim: it relies\non combinatorial properties of propagation paths and on controlling the accumulation of sinh factors, and these\nfeatures carry over directly to Majorana monomials via (I2). In particular, consider the simulation of the imaginary\ntime evolution for a Hamiltonian H = P\nb hbMb. Start from the identity I, and apply L steps of the map Et(·) =\ne−τ Mb/2(·)e−τ Mb/2, with step angle τ = βΛ\nL , where Λ = P\nb |hb| is the sum of Hamiltonian coefficients. Then, if ˜ρ is\nthe approximate state obtained by truncating any Majorana path that accumulates more than k non-identity updates\n(i.e., discarding paths with more than k factors of sinh τ ), the 1-norm error will scale as\n∥ρ − ˜ρ∥1 ∈ O eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (I3)\n\n-- 32 of 34 --\n\n33\nTherefore, for any observable O one has\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥O∥∞ eβΛ/2\n\u0012 eβΛ\n2k\n\u0013k!\n. (I4)\nThe weight-truncation analysis (Theorems 2 and 3) can be adapted in the same spirit. There, we use that non-\nidentity Pauli operators are traceless and square to the identity, implying that the Hilbert–Schmidt inner product\nbetween two Pauli strings is nonzero only if they have identical support (equivalently, they are the same string up to\nphase). We then bound contributions by counting the number of propagation paths that lead to a prescribed support.\nThe same reasoning applies to Majorana monomials: they are likewise traceless (for non-identity monomials) and\nsquare to the identity (up to a sign convention), and their Hilbert–Schmidt overlap is nonzero only when they act on\nthe same set of Majorana modes (i.e., have the same mode support). One can therefore again count the propagation\npaths that produce the relevant mode support and obtain analogous bounds. Before doing so, however, we need\nto establish that the Majorana length (denoted by ℓ) plays the same role as the weight in this proof. Indeed, it is\nsufficient to bound the probability of backflow. Thus, we consider a qDRIFT simulation of a thermal state starting\nfrom the identity I, and let O be a constant length ℓ observable. When applying L steps of size τ = βΛ\nL , where\nΛ = P |hb|, the error in expected value for a state ˜ρ obtained by truncating any Majorana monomial with length\nexceeding ℓmax is\n|Tr[O(ρ − ˜ρ)]| ∈ O ∥o∥1 eβΛ/2\n\u0012 eβΛ qbf (ℓmax)\n2ℓmax\n\u0013ℓmax\n!\n, (I5)\nfor a sufficiently large but constant ℓ. Note that qbf (ℓmax) is also the probability of backflow, but will be different for\nthe Majoranas than it is for the Paulis.\nAs for first-order Trotterization, consider a fermionic Hamiltonian H of bounded degree b that can be written as a\nsum of M Majorana monomials, each of length at most w. Proceeding as in the proof of Theorem 3, one can show\nthat, if ˜ρ is obtained by truncating all Majorana monomials of length larger than ℓmax, then the resulting error in the\nexpectation value of any observable O satisfies\nTr\u0002O(ρ − ˜ρ)\u0003 ≤ ∥o∥1 exp\u0000c1 βM \u0001 \u0010\nc2 β b w\n\u0011ℓmax/w\n, (I6)\nwhere c1, c2 > 0 are absolute constants.\nAppendix J: Additional numerical results\nIn Fig. 5 we supplement the results in Fig. 4 with the estimated energy per imaginary time and the number of\nMajorana operators for various coefficient truncation thresholds. The 37-site data corresponds to the system studied\nin the main text, with an imaginary time step of τ = 0.02. It explains how an inverse temperature of β = 0.1 is this\nchallenging: We quickly generate billions of Majorana operators, which have a memory footprint of 74 qubits, i.e., 4\nbits per site. With this and slightly over-allocated auxiliary data structures to compute more quickly, we reach the\nlimit of ∼ 500GB memory computing nodes. Further optimizations are possible, but it does not appear particularly\nlikely that even a factor of 2 would allow significantly further evolution. The 19-site system, equivalent to the 37 sites\nwithout the outermost hexagon layer, can be simulated further, though still notably less than the J1 − J2 data in\nFig. 3.\n\n-- 33 of 34 --\n\n34\nFigure 5. Imaginary time evolution under the Fermi-Hubbard Hamiltonian. A look “under the hood” of the triangular\nlattice simulations from Figure 3. Here we track the energy (top) and the count of Majorana operators (bottom) as imaginary\ntime progresses for 19-site and 37-site systems. The sharp rise in the bottom plots illustrates the “operator-growth barrier”:\neven at a high temperature of β ≈ 0.1, the 37-site simulation generates billions of terms, saturating 500GB of memory. As\nbefore, the diverging lines show where stricter truncation thresholds cause the simulation to lose accuracy.\n\n-- 34 of 34 --\n\n"
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "functionCall": {
                "name": "render_prototype",
                "args": {
                  "code": "import React, { useState, useMemo, useEffect } from 'react';\nimport { motion, AnimatePresence } from 'framer-motion';\nimport { Sliders, Thermometer, Share2, Activity, Info, Zap } from 'lucide-react';\n\n/**\n * Pauli String Utilities\n */\nconst PAULI_MAP = { I: 0, X: 1, Y: 2, Z: 3 };\nconst PAULI_CHARS = ['I', 'X', 'Y', 'Z'];\n\n// Commutation check for two Pauli strings\n// [P, Q] = 0 if they commute, != 0 if they anti-commute\nfunction commutes(p1, p2) {\n  let antiCount = 0;\n  for (let i = 0; i < p1.length; i++) {\n    const c1 = p1[i];\n    const c2 = p2[i];\n    if (c1 !== 'I' && c2 !== 'I' && c1 !== c2) {\n      antiCount++;\n    }\n  }\n  return antiCount % 2 === 0;\n}\n\n// Pauli Multiplication (ignoring global phase as coefficients stay real in this paper)\nfunction multiply(p1, p2) {\n  let res = \"\";\n  for (let i = 0; i < p1.length; i++) {\n    const v1 = PAULI_MAP[p1[i]];\n    const v2 = PAULI_MAP[p2[i]];\n    if (v1 === 0) res += p2[i];\n    else if (v2 === 0) res += p1[i];\n    else if (v1 === v2) res += 'I';\n    else {\n      // X*Y=Z, Y*Z=X, Z*X=Y (ignoring i)\n      const others = [1, 2, 3].filter(v => v !== v1 && v !== v2);\n      res += PAULI_CHARS[others[0]];\n    }\n  }\n  return res;\n}\n\n// Simple 1D Heisenberg Hamiltonian for 4 qubits: H = sum Z_i Z_{i+1} + X_i\nconst HAMILTONIAN = [\n  { term: \"ZZII\", weight: 1.0 },\n  { term: \"IZZI\", weight: 1.0 },\n  { term: \"IIZZ\", weight: 1.0 },\n  { term: \"XIII\", weight: 0.5 },\n  { term: \"IXII\", weight: 0.5 },\n  { term: \"IIXI\", weight: 0.5 },\n  { term: \"IIIX\", weight: 0.5 },\n];\n\nexport default function App() {\n  const [beta, setBeta] = useState(0.0);\n  const [truncation, setTruncation] = useState(0.001);\n  const [numSteps, setNumSteps] = useState(5);\n\n  const simulation = useMemo(() => {\n    let state = { \"IIII\": 1.0 };\n    const tau = beta / (2 * numSteps); // beta/2 is the evolution parameter for I\n    \n    // We iterate imaginary time evolution\n    for (let s = 0; s < numSteps; s++) {\n      let nextState = {};\n      \n      // Apply each Hamiltonian term in Trotter order\n      HAMILTONIAN.forEach(({ term, weight }) => {\n        const currentKeys = Object.keys(state);\n        const t = tau * weight;\n        const c = Math.cosh(t);\n        const s_ = Math.sinh(t);\n\n        currentKeys.forEach(q => {\n          const coef = state[q];\n          if (commutes(term, q)) {\n            // Eq 4: cosh(t)Q - sinh(t)PQ\n            const prod = multiply(term, q);\n            nextState[q] = (nextState[q] || 0) + coef * c;\n            nextState[prod] = (nextState[prod] || 0) - coef * s_;\n          } else {\n            // Eq 4: Q\n            nextState[q] = (nextState[q] || 0) + coef;\n          }\n        });\n        state = nextState;\n        nextState = {};\n      });\n\n      // Truncation\n      Object.keys(state).forEach(k => {\n        if (Math.abs(state[k]) < truncation) {\n          delete state[k];\n        }\n      });\n\n      // Normalization per paper: alpha_I should be normalized to keep values stable\n      const alphaI = state[\"IIII\"] || 1.0;\n      Object.keys(state).forEach(k => {\n        state[k] = state[k] / alphaI;\n      });\n    }\n\n    return state;\n  }, [beta, truncation, numSteps]);\n\n  const sortedNodes = useMemo(() => {\n    return Object.entries(simulation)\n      .sort((a, b) => Math.abs(b[1]) - Math.abs(a[1]))\n      .slice(0, 40); // Limit for visualization\n  }, [simulation]);\n\n  // Derived metrics\n  const totalTerms = Object.keys(simulation).length;\n  const avgWeight = Object.values(simulation).reduce((a, b) => a + (b === \"IIII\" ? 0 : b), 0) / (totalTerms || 1);\n\n  return (\n    <div className=\"min-h-screen bg-gray-950 text-white p-4 md:p-8 font-sans selection:bg-blue-500/30\">\n      <div className=\"max-w-6xl mx-auto\">\n        {/* Header */}\n        <header className=\"mb-8\">\n          <div className=\"flex items-center gap-3 mb-2\">\n            <div className=\"p-2 bg-blue-600 rounded-lg shadow-lg shadow-blue-900/20\">\n              <Thermometer className=\"w-6 h-6\" />\n            </div>\n            <h1 className=\"text-3xl font-bold bg-clip-text text-transparent bg-gradient-to-r from-white to-gray-500\">\n              Cooling & Branching Tree\n            </h1>\n          </div>\n          <p className=\"text-gray-400 max-w-2xl\">\n            Visualizing <strong>Schrödinger-picture imaginary-time evolution</strong>. As inverse temperature \n            (β) increases, the state branches from a sparse Identity operator into a dense cluster of Pauli strings.\n          </p>\n        </header>\n\n        <div className=\"grid grid-cols-1 lg:grid-cols-12 gap-6\">\n          \n          {/* Controls Panel */}\n          <div className=\"lg:col-span-4 space-y-6\">\n            <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6 backdrop-blur-sm\">\n              <div className=\"flex items-center gap-2 mb-6 text-blue-400\">\n                <Sliders className=\"w-5 h-5\" />\n                <h2 className=\"font-semibold uppercase tracking-wider text-sm\">System Parameters</h2>\n              </div>\n\n              <div className=\"space-y-8\">\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Inverse Temperature (β)</label>\n                    <span className=\"text-blue-400 font-mono font-bold\">{beta.toFixed(2)}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"0\" max=\"2\" step=\"0.05\" \n                    value={beta} \n                    onChange={e => setBeta(parseFloat(e.target.value))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-blue-500\"\n                  />\n                  <div className=\"flex justify-between text-[10px] text-gray-500 mt-1 uppercase tracking-tighter\">\n                    <span>Infinite Temp (β=0)</span>\n                    <span>Cooling...</span>\n                  </div>\n                </div>\n\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Truncation Cutoff (ε)</label>\n                    <span className=\"text-emerald-400 font-mono font-bold\">{truncation.toExponential(1)}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"-5\" max=\"-1\" step=\"0.1\" \n                    value={Math.log10(truncation)} \n                    onChange={e => setTruncation(Math.pow(10, parseFloat(e.target.value)))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-emerald-500\"\n                  />\n                </div>\n\n                <div>\n                  <div className=\"flex justify-between mb-2\">\n                    <label className=\"text-sm text-gray-400\">Trotter Steps (L)</label>\n                    <span className=\"text-purple-400 font-mono font-bold\">{numSteps}</span>\n                  </div>\n                  <input \n                    type=\"range\" min=\"1\" max=\"10\" step=\"1\" \n                    value={numSteps} \n                    onChange={e => setNumSteps(parseInt(e.target.value))}\n                    className=\"w-full h-2 bg-gray-800 rounded-lg appearance-none cursor-pointer accent-purple-500\"\n                  />\n                </div>\n              </div>\n            </section>\n\n            <section className=\"bg-gray-900/50 border border-white/10 rounded-2xl p-6\">\n              <div className=\"flex items-center gap-2 mb-4 text-emerald-400\">\n                <Activity className=\"w-5 h-5\" />\n                <h2 className=\"font-semibold uppercase tracking-wider text-sm\">State Metrics</h2>\n              </div>\n              <div className=\"grid grid-cols-2 gap-4\">\n                <div className=\"p-3 bg-black/40 rounded-xl border border-white/5\">\n                  <div className=\"text-xs text-gray-500 mb-1\">Pauli Strings</div>\n                  <div className=\"text-2xl font-mono font-bold text-white\">{totalTerms}</div>\n                </div>\n                <div className=\"p-3 bg-black/40 rounded-xl border border-white/5\">\n                  <div className=\"text-xs text-gray-500 mb-1\">Max Weight</div>\n                  <div className=\"text-2xl font-mono font-bold text-white\">\n                    {Math.max(...Object.keys(simulation).map(s => s.replace(/I/g, '').length))}\n                  </div>\n                </div>\n              </div>\n              \n              <div className=\"mt-4 flex items-start gap-2 text-xs text-gray-500 bg-blue-500/5 p-3 rounded-lg border border-blue-500/10\">\n                <Info className=\"w-4 h-4 text-blue-400 shrink-0\" />\n                <p>\n                  Identity coefficient αI is normalized to 1.0. All other coefficients shown are relative to the maximally mixed component.\n                </p>\n              </div>\n            </section>\n          </div>\n\n          {/* Visualization Area */}\n          <div className=\"lg:col-span-8 bg-gray-900/30 border border-white/10 rounded-2xl p-4 relative min-h-[500px] overflow-hidden\">\n            <div className=\"absolute top-4 left-4 flex items-center gap-2 text-xs font-mono text-gray-500\">\n              <Share2 className=\"w-3 h-3\" />\n              OPERATOR BRANCHING MAP\n            </div>\n\n            <div className=\"flex flex-wrap justify-center items-center h-full gap-3 p-8\">\n              <AnimatePresence>\n                {sortedNodes.map(([string, val], idx) => {\n                  const weight = string.replace(/I/g, '').length;\n                  const absVal = Math.abs(val);\n                  const isIdentity = string === \"IIII\";\n                  \n                  return (\n                    <motion.div\n                      key={string}\n                      layout\n                      initial={{ scale: 0, opacity: 0 }}\n                      animate={{ \n                        scale: isIdentity ? 1.2 : 0.5 + absVal * 0.5, \n                        opacity: 1 \n                      }}\n                      exit={{ scale: 0, opacity: 0 }}\n                      className={`\n                        relative flex flex-col items-center justify-center\n                        p-3 rounded-xl border transition-colors cursor-default\n                        ${isIdentity \n                          ? 'bg-blue-600/20 border-blue-500/50 shadow-lg shadow-blue-500/10 z-10' \n                          : 'bg-gray-800/40 border-white/5 hover:border-white/20'\n                        }\n                      `}\n                      style={{\n                        width: isIdentity ? '100px' : '70px',\n                        height: isIdentity ? '80px' : '60px',\n                      }}\n                    >\n                      <span className={`font-mono font-bold tracking-widest ${isIdentity ? 'text-blue-300' : 'text-gray-300'} text-xs md:text-sm`}>\n                        {string}\n                      </span>\n                      <span className={`text-[10px] font-mono mt-1 ${val > 0 ? 'text-emerald-400' : 'text-rose-400'}`}>\n                        {val.toFixed(3)}\n                      </span>\n                      \n                      {/* Weight Indicator */}\n                      <div className=\"absolute -top-1 -right-1 flex gap-0.5\">\n                        {Array.from({ length: weight }).map((_, i) => (\n                          <div key={i} className=\"w-1 h-1 rounded-full bg-blue-400\" />\n                        ))}\n                      </div>\n                    </motion.div>\n                  );\n                })}\n              </AnimatePresence>\n\n              {totalTerms === 0 && (\n                <div className=\"text-gray-600 italic\">State collapsed (adjust truncation)</div>\n              )}\n            </div>\n\n            {/* Legend */}\n            <div className=\"absolute bottom-4 right-4 flex gap-4 text-[10px] uppercase tracking-widest text-gray-500\">\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-blue-500\" /> Identity\n               </div>\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-emerald-500\" /> Positive\n               </div>\n               <div className=\"flex items-center gap-1.5\">\n                  <div className=\"w-2 h-2 rounded-full bg-rose-500\" /> Negative\n               </div>\n            </div>\n          </div>\n        </div>\n\n        {/* Algorithm Insight Card */}\n        <div className=\"mt-8 grid grid-cols-1 md:grid-cols-3 gap-6\">\n          <div className=\"bg-blue-500/5 border border-blue-500/10 rounded-xl p-4\">\n            <h3 className=\"text-blue-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Zap className=\"w-4 h-4\" />\n              Branching Rule\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              For imaginary time, if gate <em>P</em> commutes with operator <em>Q</em>, it branches: \n              <code className=\"block mt-2 bg-black/40 p-2 rounded text-blue-300\">\n                Q → cosh(τ)Q - sinh(τ)PQ\n              </code>\n            </p>\n          </div>\n          <div className=\"bg-emerald-500/5 border border-emerald-500/10 rounded-xl p-4\">\n            <h3 className=\"text-emerald-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Thermometer className=\"w-4 h-4\" />\n              High Temp Sparsity\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              At β=0, the state is 100% Identity. As we cool (β↑), higher-order Pauli strings emerge. \n              The prototype simulates this growth in the operator basis.\n            </p>\n          </div>\n          <div className=\"bg-purple-500/5 border border-purple-500/10 rounded-xl p-4\">\n            <h3 className=\"text-purple-400 text-sm font-bold mb-2 flex items-center gap-2\">\n              <Activity className=\"w-4 h-4\" />\n              Truncation Effect\n            </h3>\n            <p className=\"text-xs text-gray-400 leading-relaxed\">\n              By discarding terms with coefficients below <em>ε</em>, we maintain a sparse representation \n              that stays efficient at high temperatures.\n            </p>\n          </div>\n        </div>\n      </div>\n    </div>\n  );\n}\n",
                  "title": "Interactive Cooling & Branching Tree Prototype"
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "functionResponse": {
                "name": "render_prototype",
                "response": {
                  "success": true,
                  "rendered": true
                }
              }
            }
          ]
        },
        {
          "role": "user",
          "parts": [
            {
              "text": "who is schrodinger and what is he known for"
            }
          ]
        },
        {
          "role": "model",
          "parts": [
            {
              "text": "Erwin Schrödinger (1887–1933) was a Nobel Prize-winning Austrian-Irish physicist and one of the founding fathers of quantum mechanics. \n\nHe is primarily known for:\n\n1.  **The Schrödinger Equation:** This is the fundamental equation of motion in quantum mechanics. It describes how the quantum state (the wave function) of a physical system changes over time. In the paper you provided, they use the **\"Schrödinger picture,\"** which refers to the formulation where the state (or operator representing the state) evolves in time while the observables stay fixed.\n2.  **Wave Mechanics:** He developed the framework of wave mechanics, showing that particles like electrons could be described as waves. This was a massive shift from the previous \"matrix mechanics\" developed by Werner Heisenberg.\n3.  **Schrödinger's Cat:** This is his most famous thought experiment. He proposed a scenario where a cat in a box is simultaneously alive and dead (quantum superposition) until someone looks inside, to highlight what he saw as the absurdity of applying quantum logic to everyday objects.\n4.  **\"What is Life?\":** Later in his career, he wrote an influential book titled *What is Life?*, which explored the physical basis of genetics. It famously inspired James Watson and Francis Crick to search for the structure of DNA.\n\nIn the context of the prototype I built, the **Schrödinger picture** is relevant because instead of evolving an \"observable\" backward in time to see its value (Heisenberg picture), we are evolving the **state itself** (starting from the Identity at infinite temperature) to prepare the thermal state."
            }
          ]
        }
      ],
      "created_at": 1770623882878,
      "updated_at": 1770624002341
    }
  }
}